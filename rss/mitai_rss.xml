<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2023 年 10 月 30 日星期一 04:00:00 +0000</lastbuilddate><item><title>使用人工智能优化快速神经成像</title><link/>https://news.mit.edu/2023/using-ai-optimize-rapid-neural-imaging-1106<description>麻省理工学院 CSAIL 研究人员将人工智能和电子显微镜结合起来，加快详细的大脑网络绘图，旨在加强连接组学研究和临床病理学。</description><pubDate> Mon, 06 Nov 2023 13:00:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/using-ai-optimize-rapid-neural-imaging-1106</guid><dc:creator>雷切尔戈登|麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;连接组学是一个雄心勃勃的研究领域，旨在绘制动物大脑复杂的网络图谱，目前正在经历突飞猛进的发展。在十年的时间里，它已经从萌芽阶段发展成为一门学科，有望（希望）解开认知之谜和阿尔茨海默病等神经病理学的物理基础。&lt;/p>; &lt;p>;最前沿的是强大的电子显微镜的使用，来自麻省理工学院计算机科学和人工智能实验室 (CSAIL) 以及哈佛大学塞缪尔和利希特曼实验室的研究人员赋予了电子显微镜机器学习的分析能力。与传统电子显微镜不同，集成人工智能充当“大脑”，在获取图像的同时学习样本，并以纳米级分辨率智能地聚焦于相关像素，类似于动物检查其世界的方式。&lt;/p>; &lt;p>; “&lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2023.10.05.561103v1.abstract&quot; target=&quot;_blank&quot;>;SmartEM&lt;/a>;”协助连接组学快速检查和重建大脑的复杂网络具有纳米精度的突触和神经元。与传统电子显微镜不同，其集成的人工智能为理解大脑复杂的架构打开了新的大门。&lt;/p>; &lt;p>;在此过程中硬件和软件的集成至关重要。该团队将 GPU 嵌入到与显微镜相连的支持计算机中。这使得能够在图像上运行机器学习模型，帮助显微镜光束被引导到人工智能认为感兴趣的区域。麻省理工学院教授兼 CSAIL 首席研究员尼尔·沙维特 (Nir Shavit) 表示：“这可以让显微镜在难以理解的区域停留更长时间，直到捕捉到所需的信息。” “这一步骤有助于反映人眼控制，从而能够快速理解图像。”&lt;/p>; &lt;p>;“当我们看着人脸时，我们的眼睛会迅速导航到焦点，这些焦点提供了有效的重要线索。 SmartEM 的首席架构师 Yaron Meirovitch 说道，他是麻省理工学院 CSAIL 的访问科学家，也是哈佛大学的前博士后和现任研究员神经科学家。 “当我们沉浸在一本书中时，我们不会扫视所有的空白空间；而是会扫视所有的空白区域。相反，我们将目光投向相对于我们的句子期望而言含糊不清的单词和字符。人类视觉系统中的这种现象为新颖的显微镜概念的诞生铺平了道路。”&amp;nbsp;&lt;/p>; &lt;p>;对于重建包含约 100,000 个神经元的人脑部分的任务，使用传统显微镜实现了这一目标需要十年的连续成像和令人望而却步的预算。然而，有了 SmartEM，通过投资四台这样的创新显微镜，每台不到 100 万美元，这项任务可以在短短三个月内完成。&lt;/p>; &lt;p>;&lt;strong>;诺贝尔奖和小虫子&amp;nbsp;&amp;nbsp;&lt; /strong>;&lt;/p>; &lt;p>;一个多世纪前，西班牙神经科学家圣地亚哥·拉蒙·卡哈尔被誉为第一个描述神经系统结构特征的人。利用他那个时代的基本光学显微镜，他开始了对神经科学的领先探索，奠定了对神经元的基础理解，并勾勒出这个广阔而未知领域的初步轮廓——这一壮举为他赢得了诺贝尔奖。他在谈到灵感和发现的话题时指出，“只要我们的大脑还是一个谜，宇宙、大脑结构的反映也将是一个谜。”&lt;/p>; &lt;p>;从这些进展在早期阶段，该领域取得了巨大的进步，20 世纪 80 年代的努力证明了这一点，绘制了相对简单的连接组&lt;a href=&quot;https://www.nature.com/articles/s41586-021-03778-8&quot;>;&lt;u >;C.从线虫&lt;/u>;&lt;/a>;，小蠕虫，到今天探索斑马鱼和小鼠等更复杂的生物大脑的努力。这种演变不仅反映了巨大的进步，而且还反映了不断升级的复杂性和需求：仅绘制小鼠大脑图谱就意味着管理惊人的数千 PB &lt;a href=&quot;https://www.cell.com/cell/pdf/S0092-8674( 20)31001-1.pdf&quot;>;&lt;u>;数据&lt;/u>;&lt;/a>;，该团队表示，这项任务大大超越了任何大学的存储能力。&lt;/p>; &lt;p>;&lt;strong>;试水&lt;/strong>;&lt;/p>; &lt;p>;在自己的工作中，Meirovitch 和研究团队的其他人研究了 30 纳米厚的章鱼组织切片，这些切片被安装在胶带上，放在晶圆上，最后插入到电子显微镜。章鱼大脑的每个部分包含数十亿像素，都被成像，让科学家们能够将切片重建为纳米分辨率的三维立方体。这提供了突触的超详细视图。主要目标？为了给这些图像着色，识别每个神经元，并了解它们的相互关系，从而创建大脑电路的详细地图或“连接组”。&lt;/p>; &lt;p>;“SmartEM 会将此类项目的成像时间从两周缩短至 1.5 周Meirovitch 说。“目前无法进行昂贵且长时间的 EM 成像的神经科学实验室现在将能够做到这一点。”该方法还应该允许对精神疾病和精神疾病患者的样本进行突触级回路分析。神经系统疾病。&lt;/p>; &lt;p>;最终，该团队设想了一个连接组学既便宜又容易获得的未来。他们希望借助 SmartEM 这样的工具，更广泛的研究机构可以在不依赖大型合作伙伴的情况下为神经科学做出贡献，并且该方法将很快成为可用于活体患者活检的情况下的标准流程。此外，他们渴望应用该技术来理解病理学，将实用性扩展到连接组学之外。 Shavit 说：“我们现在正努力将其引入医院，利用电子显微镜进行大型活检，旨在提高病理学研究的效率。”&lt;/p>; &lt;p>;该论文的另外两位作者与 MIT CSAIL 有联系：主要作者 Lu Mi MCS &#39;19，PhD &#39;22，现在是艾伦脑科学研究所的博士后，Shashata Sawmya 是该实验室的麻省理工学院研究生。其他主要作者是 Core Francisco Park 和 Pavel Potocek，而哈佛大学教授 Jeff Lichtman 和 Aravi Samuel 是其他高级作者。他们的研究得到了 NIH BRAIN Initiative 的支持，并在 2023 年国际机器学习会议 (ICML) 计算生物学研讨会上进行了展示。这项工作是与 Thermo Fisher Scientific 的科学家合作完成的。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202310/SmartEM7.png?itok=eZSfEcQ_" width="390"><media:description type="plain">麻省理工学院的研究人员发明了一种技术和软件，通过将实时机器学习无缝集成到成像过程中，将电子显微镜提升到一个新的水平——“智能显微镜”。</media:description><media:credit>左图：Yaron Meirovitch 使用 Stable Diffusion XL AI 图像生成器，Alex Shipps 使用 Midjourney AI 图像生成器。右图：Daniel Berger 和 Meirovitch，由 Alex Shipps/MIT CSAIL 编辑</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/neuroscience">神经科学</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/microscopy">显微镜检查</category><category domain="https://news.mit.edu/topic/imaging">影像学</category><category domain="https://news.mit.edu/topic/brain-cognitive">脑与认知科学</category><category domain="https://news.mit.edu/topic/neurons">神经元</category><category domain="https://news.mit.edu/topic/nanotech">纳米科学和纳米技术</category><category domain="https://news.mit.edu/topic/synapses">突触</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item><item><title>使用语言让机器人更好地掌握开放世界</title><link/>https://news.mit.edu/2023/using-language-give-robots-better-grasp-open-ending-world-1102<description>通过将 2D 图像与基础模型混合来构建 3D 特征场，麻省理工学院的一种新方法可以帮助机器人通过开放式语言提示理解和操作附近的物体。</description><pubDate> Thu, 02 Nov 2023 16:25:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/using-language-give-robots-better-grasp-open-ending-world-1102</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;想象一下，您正在国外拜访一位朋友，您查看了他们的冰箱，看看有什么可以做一顿丰盛的早餐。许多物品一开始对您来说都是陌生的，每一件物品都装在不熟悉的包装和容器中。尽管有这些视觉上的区别，你还是开始了解每一个的用途，并根据需要挑选它们。&lt;/p>; &lt;p>;受到人类处理陌生物体的能力的启发，来自麻省理工学院计算机科学和人工智能实验室的一个小组（ CSAIL）设计了用于机器人操作的特征字段（&lt;a href=&quot;https://arxiv.org/abs/2308.07931&quot; target=&quot;_blank&quot;>;F3RM&lt;/a>;），这是一个将 2D 图像与基础模型特征混合到3D 场景可帮助机器人识别和抓取附近的物品。 F3RM 可以解释人类的开放式语言提示，这使得该方法在包含数千个对象的现实环境中很有用，例如仓库和家庭。&lt;/p>; &lt;p>;F3RM 为机器人提供了解释开放式文本提示的能力使用自然语言，帮助机器操纵物体。因此，机器可以理解人类不太具体的请求，并仍然完成所需的任务。例如，如果用户要求机器人“拿起一个高杯子”，机器人可以找到并抓取最适合该描述的物品。&lt;/p>; &lt;p>;“打造能够在现实世界中实际推广的机器人非常难，”美国国家科学基金会 AI 研究所人工智能与基础交互和麻省理工学院 CSAIL 的博士后 Ge Yang 说道。 “我们真的很想弄清楚如何做到这一点，因此通过这个项目，我们试图推动泛化的积极水平，从三四个物体到我们在麻省理工学院 Stata 中心找到的任何东西。我们想学习如何让机器人像我们一样灵活，因为我们可以抓住并放置物体，即使我们以前从未见过它们。”&lt;/p>; &lt;p>;&lt;strong>;学习“通过观察知道什么在哪里”&lt;/p>; &lt;p>;&lt;strong>;强>;&lt;br />; &lt;br />;该方法可以帮助机器人在大型配送中心拣选物品，不可避免地会造成混乱和不可预测。在这些仓库中，机器人通常会收到需要识别的库存描述。无论包装如何变化，机器人都必须匹配提供给对象的文本，以便正确运送客户的订单。&lt;br />; &lt;br />;例如，主要在线零售商的履行中心可以包含数百万件商品，其中许多是机器人以前从未遇到过的。为了在如此大规模的情况下运行，机器人需要理解不同物品的几何形状和语义，其中一些物品位于狭小的空间内。凭借 F3RM 先进的空间和语义感知能力，机器人可以更有效地定位物体、将其放入垃圾箱，然后将其发送进行包装。最终，这将帮助工厂工人更有效地运送客户的订单。&lt;/p>; &lt;p>;“F3RM 经常让人们感到惊讶的是，同一系统也适用于房间和建筑规模，并且可用于构建机器人学习和大地图的模拟环境，”杨说。 “但在我们进一步扩大这项工作之前，我们希望首先让这个系统运行得非常快。这样，我们就可以使用这种类型的表示来执行更动态的机器人控制任务，希望是实时的，以便处理更多动态任务的机器人可以将其用于感知。”&lt;/p>; &lt;p>;麻省理工学院团队指出F3RM 理解不同场景的能力可以使其在城市和家庭环境中发挥作用。例如，该方法可以帮助个性化机器人识别并拾取特定物品。该系统帮助机器人从物理上和感知上掌握周围环境。&lt;/p>; &lt;p>;“视觉感知被 David Marr 定义为通过观察了解‘什么在哪里’的问题，”麻省理工学院的资深作者 Phillip Isola 说道。电气工程和计算机科学副教授，CSAIL 首席研究员。 “最近的基础模型已经非常擅长了解他们所关注的内容；它们可以识别数千种物体类别并提供图像的详细文本描述。与此同时，辐射场已经非常擅长代表场景中物体的位置。这两种方法的组合可以创建 3D 位置的表示，我们的工作表明，这种组合对于需要在 3D 中操作对象的机器人任务特别有用。”&lt;br />; &lt;br />; &lt; strong>;创建“数字孪生”&lt;/strong>;&lt;/p>; &lt;p>;F3RM 开始通过用自拍杆拍照来了解周围环境。安装的摄像头以不同姿势拍摄 50 张图像，使其能够构建&lt;a href=&quot;https://www.matthewtancik.com/nerf&quot;>;神经辐射场&lt;/a>; (NeRF)，这是一种深度学习方法， 2D 图像构建 3D 场景。这幅 RGB 照片拼贴画以 360 度呈现附近事物的形式创建了周围环境的“数字双胞胎”。&lt;/p>; &lt;p>;除了高度详细的神经辐射场之外，F3RM 还构建了一个特征场用语义信息增强几何形状。该系统使用&lt;a href=&quot;https://openai.com/research/clip&quot;>;CLIP&lt;/a>;，这是一种经过数亿图像训练的视觉基础模型，可以有效地学习视觉概念。通过重建自拍杆拍摄图像的 2D CLIP 特征，F3RM 有效地将 2D 特征提升为 3D 表示。&lt;br />; &lt;br />; &lt;strong>;保持开放性&lt;/strong>;&lt;/p>; &lt;p>;经过几次演示后，机器人应用其所了解的几何和语义来抓取以前从未遇到过的物体。一旦用户提交文本查询，机器人就会搜索可能的抓取空间，以识别那些最有可能成功拾取用户请求的物体的人。每个潜在选项的评分基于其与提示的相关性、与机器人所接受训练的演示的相似性以及是否会导致任何碰撞。然后选择并执行得分最高的抓握动作。&lt;br />; &lt;br />;为了展示系统解释人类开放式请求的能力，研究人员提示机器人拾取迪士尼《大英雄》中的角色大白 (Baymax)。 6.”虽然 F3RM 从未接受过捡起卡通超级英雄玩具的直接训练，但该机器人利用基础模型中的空间意识和视觉语言特征来决定抓握哪个物体以及如何捡起它。&lt;br />; &lt; br />; F3RM 还允许用户指定他们希望机器人在不同语言细节级别上处理的对象。例如，如果有一个金属杯和一个玻璃杯，用户可以向机器人询问“玻璃杯”。如果机器人看到两个玻璃杯，其中一个装满咖啡，另一个装满果汁，则用户可以要求“装有咖啡的玻璃杯”。嵌入特征字段中的基础模型特征实现了这种程度的开放式理解。&lt;/p>; &lt;p>;“如果我向一个人展示如何通过嘴唇拿起杯子，他们可以轻松地将这些知识转移到拿起杯子上。”具有相似几何形状的物体，例如碗、量杯，甚至卷带。对于机器人来说，达到这种水平的适应性是相当具有挑战性的，”麻省理工学院博士生、CSAIL 附属机构、联合主要作者 William Shen 说。 “F3RM 将几何理解与基于互联网规模数据训练的基础模型的语义相结合，只需少量演示就能实现这种程度的激进泛化。”&lt;br />; &lt;br />; Shen 和 Yang 在Isola 与麻省理工学院教授兼 CSAIL 首席研究员 Leslie Pack Kaelbling 以及本科生 Alan Yu 和 Jansen Wong 为共同作者。该团队得到了 Amazon.com Services、国家科学基金会、空军科学研究办公室、海军研究办公室多学科大学计划、陆军研究办公室、MIT-IBM Watson AI 实验室和麻省理工学院的智力探索。他们的工作将在 2023 年机器人学习会议上展示。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202310/MIT-F3RM.png?itok=26tJjDee" width="390"><media:description type="plain">机器人操纵功能字段 (F3RM) 使机器人能够使用自然语言解释开放式文本提示，帮助机器操纵不熟悉的物体。该系统的 3D 要素字段在包含数千个对象的环境（例如仓库）中可能会很有帮助。</media:description><media:credit>图片由研究人员提供。</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/natural-language-processing">自然语言处理</category><category domain="https://news.mit.edu/topic/robotics">机器人技术</category><category domain="https://news.mit.edu/topic/industry">行业</category><category domain="https://news.mit.edu/topic/manufacturing">制造业</category><category domain="https://news.mit.edu/topic/human-computer-interaction">人机交互</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category></item></channel></rss>