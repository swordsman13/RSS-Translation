<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 8 月 16 日星期五 00:00:00 -0400</lastbuilddate><item><title> AI助手监控团队协作，促进有效协作</title><link/>https://news.mit.edu/2024/ai-assistant-monitors-teamwork-promote- effective-collaboration-0819<description>人工智能团队协调员负责协调特工对如何完成任务的信念，并在必要时进行干预，以帮助完成搜索和救援、医院和视频游戏等任务。</description><pubDate> Mon, 19 Aug 2024 15:50:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/ai-assistant-monitors-teamwork-promote- effective-collaboration-0819</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;在 2018 年夏威夷周围的一次研究航行中，张月宁 SM &#39;19、PhD &#39;24 发现保持一艘紧密的船是多么困难。绘制水下地形所需的仔细协调有时可能会给团队成员带来压力，他们可能对必须在自发变化的条件下完成哪些任务有不同的理解。在这些旅行中，张思考了机器人伴侣如何帮助她和她的船员更有效地实现目标。&lt;br>;&lt;br>;六年后，作为麻省理工学院计算机科学与人工智能实验室 (CSAIL) 的研究助理，张开发了一个可以被认为是缺失的部分：一个人工智能助手，可以与团队成员沟通以调整角色并实现共同目标。在国际机器人与自动化会议 (ICRA) 上发表的一篇论文中，&lt;a href=&quot;https://ieeexplore.ieee.org/document/10609865&quot; target=&quot;_blank&quot;>;8 月 8 日在 IEEE Xplore 上发布&lt; /a>;，她和她的同事提出了一个系统，可以监督人类和人工智能代理团队，在需要时进行干预，以潜在地提高搜索和救援任务、医疗程序和策略视频游戏等领域的团队合作效率。&lt; br>;&lt;br>;CSAIL 领导的小组开发了一种人工智能代理的心理理论模型，该模型代表了人类在合作执行任务时如何思考和理解彼此可能的行动计划。通过观察其他特工的行为，这位新的团队协调员可以从之前的信念中推断出他们的计划以及对彼此的理解。当他们的计划不一致时，人工智能助手会通过调整他们对彼此的信念、指导他们的行动以及在需要时提出问题来进行干预。&lt;br>;&lt;br>;例如，当救援人员团队在现场时为了对受害者进行分类，他们必须根据对彼此角色和进展的看法做出决定。 CSAIL 的软件可以改进这种类型的认知规划，该软件可以发送有关每个代理打算做什么或已经做什么的消息，以确保任务完成并避免重复工作。在这种情况下，人工智能助手可能会进行干预，告知特工已经前往某个房间，或者没有特工覆盖潜在受害者的特定区域。&lt;br>;&lt;br>;“我们的工作考虑到了“我相信你相信别人所相信的，”张说，他现在是 Mobi Systems 的研究科学家。 “想象一下，你正在一个团队中工作，你会问自己，‘那个人到底在做什么？我要做什么？他知道我要做什么吗？我们模拟不同的团队成员如何理解总体计划，并传达他们需要完成哪些任务以帮助完成团队的总体目标。”&lt;br>;&lt;br>;&lt;strong>;人工智能来救援&lt;/strong>;&lt;br>;&lt;br>;甚至有了复杂的计划，如果角色不明确，人类和机器人代理都会遇到混乱，甚至犯错误。这种困境在搜救任务中尤为突出，其目标可能是在有限的时间和广阔的扫描区域中找到处于危险中的人。值得庆幸的是，通过新的机器人助手增强的通信技术可能会通知搜索方每个小组正在做什么以及他们正在寻找的地方。反过来，特工可以更有效地导航他们的地形。&lt;/p>;&lt;p>;这种类型的任务组织可以帮助完成手术等其他高风险场景。在这些情况下，护士首先需要将病人带到手术室，然后麻醉师让病人入睡，然后外科医生开始手术。在整个手术过程中，团队必须持续监测患者的状况，同时动态响应每位同事的行动。为了确保程序中的每项活动都组织良好，如果对任何这些任务出现混淆，人工智能团队协调员可以进行监督和干预。&lt;/p>;&lt;p>;有效的团队合作也是“Valorant”等视频游戏不可或缺的一部分。玩家可以协作协调谁需要在线攻击和防御另一支球队。在这些场景中，人工智能助手可能会在屏幕上弹出，提醒个人用户他们在哪里误解了需要完成的任务。&lt;/p>;&lt;p>;在她领导该模型的开发之前，张设计了 EPike，可以充当团队成员的计算模型。在 3D 模拟程序中，该算法控制机器人代理，该代理需要将容器与人类选择的饮料相匹配。尽管它们可能是理性和复杂的，但这些人工智能模拟机器人由于对人类伙伴或任务的误解而受到限制。新的人工智能协调员可以在需要解决潜在问题时纠正代理人的信念，并且在这种情况下始终进行干预。该系统向机器人发送有关人类真实意图的消息，以确保其正确匹配容器。&lt;/p>;&lt;p>;“在我们的人机协作工作中，多年来，我们既感到谦卑又受到启发。麻省理工学院航空航天学教授、CSAIL 成员、该研究的资深作者 Brian C. Williams 说：“液体人类伴侣可以是这样。” “看看一对带着孩子的年轻夫妇，他们一起为孩子们准备早餐，然后一起去学校。如果其中一位家长看到自己的伴侣在准备早餐，但还穿着浴袍，家长就会知道赶紧洗澡，然后拖着孩子去学校，无需多说一句话。好的合作伙伴彼此的信念和目标非常一致，我们在认知规划方面的工作努力捕捉这种推理风格。”&lt;/p>;&lt;p>;研究人员的方法将概率推理与递归心理模型结合起来。代理，允许人工智能助手做出风险有限的决策。此外，他们还关注建模代理对计划和行动的理解，这可以补充之前对当前世界或环境的信念进行建模的工作。人工智能助手目前根据给定的可能信念先验推断智能体的信念，但麻省理工学院的团队设想应用机器学习技术来动态生成新的假设。为了将这一对应物应用到现实生活中的任务中，他们还致力于在工作中考虑更丰富的计划表示并进一步降低计算成本。&lt;/p>;&lt;p>;动态对象语言实验室主席 Paul Robertson、约翰霍普金斯大学助理教授 Tianmin Shu，以及前 CSAIL 附属机构 Sungkweon Hong 博士 &#39;23 与张和威廉姆斯一起发表论文。他们的工作部分得到了美国国防高级研究计划局 (DARPA) 成功团队人工智能社会智能 (ASIST) 计划的支持。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202404/MIT-csail-overseer.png?itok=5p9AU7sw" width="390"><media:description type="plain">麻省理工学院 CSAIL 研究人员开发的系统可以监督人类和人工智能代理团队，与团队成员进行沟通以调整角色并实现共同目标。</media:description><media:credit>图片来源：Alex Shipps/MIT CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/robotics">机器人技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/aeronautics">航空航天工程</category><category domain="https://news.mit.edu/topic/games">游戏</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/darpa">国防高级研究计划局 (DARPA)</category></item><item><title> 3问：如何在网上证明人性</title><link/>https://news.mit.edu/2024/3-questions-proving-humanity-online-0816<description>人工智能代理可能很快就会变得与在线人类没有区别。 “人格凭证”能否保护人们免受数字冒名顶替者的侵害？</description><pubDate> Fri, 16 Aug 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/3-questions-proving-humanity-online-0816</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;&lt;em>;随着人工智能代理变得更加先进，区分人工智能驱动的用户和互联网上的真人可能会变得越来越困难。在&lt;/em>;&lt;a href=&quot;https://arxiv.org/pdf/2408.07892&quot; target=&quot;_blank&quot;>;&lt;em>;新白皮书&lt;/em>;&lt;/a>;&lt;em>;中，麻省理工学院的研究人员、OpenAI、微软和其他科技公司和学术机构建议使用人格凭证，这是一种验证技术，使某人能够证明自己是在线的真人，同时保护他们的隐私。&lt;/em>;&lt;/p>;&lt;p>;麻省理工学院新闻采访了该论文的两位合著者，即电气工程和计算机科学研究生 Nouran Soliman 和媒体实验室研究生 Tobin South，讨论了此类证书的必要性以及与此相关的风险。以及如何以安全、公平的方式实施它们。&lt;/em>;&lt;/p>;&lt;p>;&lt;strong>;问：&lt;/strong>;为什么我们需要人格凭证？&lt;/p>;&lt;p >;&lt;strong>;Tobin South：&lt;/strong>;人工智能能力正在迅速提高。虽然很多公众讨论都是关于聊天机器人如何不断变得更好，但复杂的 AI 能够实现的功能远不止更好的 ChatGPT，例如 AI 自主在线交互的能力。人工智能可以创建帐户、发布内容、生成虚假内容、在网上假装人类或通过算法大规模放大内容。这释放了很多风险。你可以将其视为“数字冒名顶替者”问题，区分复杂的人工智能和人类变得越来越困难。人格凭证是该问题的一种潜在解决方案。&lt;/p>;&lt;p>;&lt;strong>;Nouran Soliman：&lt;/strong>;这种先进的人工智能功能可以帮助不良行为者发动大规模攻击或传播错误信息。互联网上可能充斥着人工智能，它们会重新分享真人的内容来开展虚假信息活动。浏览互联网，特别是社交媒体将变得更加困难。您可以想象使用人格凭据来过滤社交媒体源上的某些内容和审核内容，或确定您在线接收的信息的信任级别。&lt;/p>;&lt;p>;&lt;strong>;问：&amp;nbsp;&lt;/strong>;什么是人格凭证，如何确保此类凭证的安全？&lt;/p>;&lt;p>;&lt;strong>;South：&lt;/strong>;人格凭证可让您证明自己是人类，而无需透露有关您身份的任何其他信息。这些凭证可让您从政府等实体获取信息，这些实体可以保证您是人类，然后通过隐私技术，让您可以证明这一事实，而无需共享任何有关您身份的敏感信息。要获得人格证书，您必须亲自出面或与政府建立关系，例如税号。有一个离线组件。你将不得不做一些只有人类才能做的事情。例如，人工智能不能出现在DMV。即使是最复杂的人工智能也无法伪造或破解密码学。因此，我们结合了两个想法——通过密码学实现的安全性以及人类仍然拥有人工智能所不具备的一些能力这一事实——来真正可靠地保证你是人类。&lt;/p>;&lt;p>;&lt;strong>; Soliman：&amp;nbsp;&lt;/strong>;但是人格凭证可以是可选的。服务提供商可以让人们选择是否使用。目前，如果人们只想与真实的、经过验证的人在线互动，则没有合理的方法可以做到这一点。除了创建内容和与人们交谈之外，人工智能代理在某些时候还将代表人们采取行动。如果我要在网上购买东西或协商交易，那么也许在这种情况下我想确定我正在与具有人格凭证的实体进行交互，以确保他们是值得信赖的。&lt;/p>;&lt;p>;&lt;strong>;South ：&amp;nbsp;&lt;/strong>;个人凭证建立在基础设施和我们数十年来拥有的一组安全技术之上，例如使用电子邮件帐户等标识符来登录在线服务，它们可以补充现有的服务&lt;/p>;&lt;p>;&lt;strong>;问：&lt;/strong>;与人格凭证相关的一些风险是什么？如何降低这些风险？&lt;/p>;&lt;p>;&lt;strong>;Soliman ：&amp;nbsp;&lt;/strong>;其中一个风险来自人格凭证的实施方式。人们担心权力集中。假设一个特定实体是唯一的发行人，或者系统的设计方式是将所有权力赋予一个实体。这可能会引起一部分人的很多担忧——也许他们不信任该实体，并且觉得与他们接触不安全。我们需要以人们信任发行者的方式实施人格凭证，并确保人们的身份与其人格凭证完全隔离，以保护隐私。&lt;/p>;&lt;p>;&lt;strong>;South：&amp;nbsp;&lt;/strong>;如果获得人格证书的唯一方法是亲自去某个地方证明你是人类，那么如果你处于一个很难或危险的社会政治环境中去那个实际地点，这可能会很可怕。这可能会阻止一些人以不受限制的方式在网上分享他们的信息，可能会扼杀言论自由。这就是为什么拥有各种人格证书颁发者和开放协议以确保维护言论自由非常重要。&lt;/p>;&lt;p>;&lt;strong>;索利曼：&amp;nbsp;&lt;/strong>;我们的论文是试图鼓励政府、政策制定者、领导者和研究人员在人格证书上投入更多资源。我们建议研究人员研究不同的实施方向，并探索人格证书可能对社区产生的更广泛影响。我们需要确保就如何实施人格凭证制定正确的政策和规则。&lt;/p>;&lt;p>;&lt;strong>;South：&lt;/strong>;人工智能的发展速度非常快，肯定比人类发展的速度快得多。政府适应。政府和大公司现在应该开始考虑如何调整他们的数字系统，以便准备好证明某人是人类，但要以保护隐私和安全的方式，这样我们就可以在达到目标时做好准备。人工智能拥有这些先进功能的未来。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202408/MIT-3Q-personhood-01-press.jpg?itok=ZbOrOGY_" width="390"><media:description type="plain">托宾·索斯 (Tobin South) 表示：“人格证书可以让你证明自己是人类，而无需透露任何有关你身份的信息。”</media:description><media:credit>图片：麻省理工学院新闻；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/interview">面试</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/cyber-security">网络安全</category><category domain="https://news.mit.edu/topic/privacy">隐私</category><category domain="https://news.mit.edu/topic/social-media">社交媒体</category><category domain="https://news.mit.edu/topic/social-networks">社交网络</category><category domain="https://news.mit.edu/topic/policy">政策</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/media-lab-0">媒体实验室</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/school-architecture-and-planning">建筑与规划学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item></channel></rss>