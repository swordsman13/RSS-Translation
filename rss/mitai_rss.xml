<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 8 月 16 日星期五 00:00:00 -0400</lastbuilddate><item><title> 3问：如何在网上证明人性</title><link/>https://news.mit.edu/2024/3-questions-proving-humanity-online-0816<description>人工智能代理可能很快就会变得与在线人类难以区分。 “人格凭证”能否保护人们免受数字冒名顶替者的侵害？</description><pubDate> Fri, 16 Aug 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/3-questions-proving-humanity-online-0816</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;&lt;em>;随着人工智能代理变得更加先进，区分人工智能驱动的用户和互联网上的真人可能会变得越来越困难。在&lt;/em>;&lt;a href=&quot;https://arxiv.org/pdf/2408.07892&quot; target=&quot;_blank&quot;>;&lt;em>;新白皮书&lt;/em>;&lt;/a>;&lt;em>;中，麻省理工学院的研究人员、OpenAI、微软和其他科技公司和学术机构建议使用人格凭证，这是一种验证技术，使某人能够证明自己是在线的真人，同时保护他们的隐私。&lt;/em>;&lt;/p>;&lt;p>;麻省理工学院新闻采访了该论文的两位合著者，即电气工程和计算机科学研究生 Nouran Soliman 和媒体实验室研究生 Tobin South，讨论了此类证书的必要性以及与此相关的风险。以及如何以安全、公平的方式实施它们。&lt;/em>;&lt;/p>;&lt;p>;&lt;strong>;问：&lt;/strong>;为什么我们需要人格凭证？&lt;/p>;&lt;p >;&lt;strong>;Tobin South：&lt;/strong>;人工智能能力正在迅速提高。虽然很多公众讨论都是关于聊天机器人如何不断变得更好，但复杂的 AI 能够实现的功能远不止更好的 ChatGPT，例如 AI 自主在线交互的能力。人工智能可以创建帐户、发布内容、生成虚假内容、在网上假装人类或通过算法大规模放大内容。这释放了很多风险。你可以将其视为“数字冒名顶替者”问题，区分复杂的人工智能和人类变得越来越困难。人格凭证是该问题的一种潜在解决方案。&lt;/p>;&lt;p>;&lt;strong>;Nouran Soliman：&lt;/strong>;这种先进的人工智能功能可以帮助不良行为者发动大规模攻击或传播错误信息。互联网上可能充斥着人工智能，它们会重新分享真人的内容来开展虚假信息活动。浏览互联网，特别是社交媒体将变得更加困难。您可以想象使用人格凭据来过滤社交媒体源上的某些内容和审核内容，或确定您在线接收的信息的信任级别。&lt;/p>;&lt;p>;&lt;strong>;问：&amp;nbsp;&lt;/strong>;什么是人格凭证，如何确保此类凭证的安全？&lt;/p>;&lt;p>;&lt;strong>;South：&lt;/strong>;人格凭证可让您证明自己是人类，而无需透露有关您身份的任何其他信息。这些凭证可让您从政府等实体获取信息，这些实体可以保证您是人类，然后通过隐私技术，让您可以证明这一事实，而无需共享任何有关您身份的敏感信息。要获得人格证书，您必须亲自出面或与政府建立关系，例如税号。有一个离线组件。你将不得不做一些只有人类才能做的事情。例如，人工智能不能出现在DMV。即使是最复杂的人工智能也无法伪造或破解密码学。因此，我们结合了两个想法——通过密码学实现的安全性以及人类仍然拥有人工智能所不具备的一些能力这一事实——来真正可靠地保证你是人类。&lt;/p>;&lt;p>;&lt;strong>; Soliman：&amp;nbsp;&lt;/strong>;但是人格凭证可以是可选的。服务提供商可以让人们选择是否使用。目前，如果人们只想与真实的、经过验证的人在线互动，则没有合理的方法可以做到这一点。除了创建内容和与人们交谈之外，人工智能代理在某些时候还将代表人们采取行动。如果我要在网上购买东西或协商交易，那么也许在这种情况下我想确定我正在与具有人格凭证的实体进行交互，以确保他们是值得信赖的。&lt;/p>;&lt;p>;&lt;strong>;South ：&amp;nbsp;&lt;/strong>;个人凭证建立在基础设施和我们数十年来拥有的一组安全技术之上，例如使用电子邮件帐户等标识符来登录在线服务，它们可以补充现有的服务&lt;/p>;&lt;p>;&lt;strong>;问：&lt;/strong>;与人格凭证相关的一些风险是什么？如何降低这些风险？&lt;/p>;&lt;p>;&lt;strong>;Soliman ：&amp;nbsp;&lt;/strong>;其中一个风险来自人格凭证的实施方式。人们担心权力集中。假设一个特定实体是唯一的发行人，或者系统的设计方式是将所有权力赋予一个实体。这可能会引起一部分人的很多担忧——也许他们不信任该实体，并且觉得与他们接触不安全。我们需要以人们信任发行者的方式实施人格凭证，并确保人们的身份与其人格凭证完全隔离，以保护隐私。&lt;/p>;&lt;p>;&lt;strong>;South：&amp;nbsp;&lt;/strong>;如果获得人格证书的唯一方法是亲自去某个地方证明你是人类，那么如果你处于一个很难或危险的社会政治环境中去那个实际地点，这可能会很可怕。这可能会阻止一些人以不受限制的方式在网上分享他们的信息，可能会扼杀言论自由。这就是为什么拥有各种人格证书颁发者和开放协议以确保维护言论自由非常重要。&lt;/p>;&lt;p>;&lt;strong>;索利曼：&amp;nbsp;&lt;/strong>;我们的论文是试图鼓励政府、政策制定者、领导者和研究人员在人格证书上投入更多资源。我们建议研究人员研究不同的实施方向，并探索人格证书可能对社区产生的更广泛影响。我们需要确保就如何实施人格凭证制定正确的政策和规则。&lt;/p>;&lt;p>;&lt;strong>;South：&lt;/strong>;人工智能的发展速度非常快，肯定比人类发展的速度快得多。政府适应。政府和大公司现在应该开始考虑如何调整他们的数字系统，以便准备好证明某人是人类，但要以保护隐私和安全的方式，这样当我们达到目标时，我们就可以做好准备。人工智能拥有这些先进功能的未来。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202408/MIT-3Q-personhood-01-press.jpg?itok=ZbOrOGY_" width="390"><media:description type="plain">托宾·索斯 (Tobin South) 表示：“人格证书可以让你证明自己是人类，而无需透露任何有关你身份的信息。”</media:description><media:credit>图片：麻省理工学院新闻；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/interview">面试</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/cyber-security">网络安全</category><category domain="https://news.mit.edu/topic/privacy">隐私</category><category domain="https://news.mit.edu/topic/social-media">社交媒体</category><category domain="https://news.mit.edu/topic/social-networks">社交网络</category><category domain="https://news.mit.edu/topic/policy">政策</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/media-lab-0">媒体实验室</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/school-architecture-and-planning">建筑与规划学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item><item><title>随着语言能力的提高，法学硕士会发展自己对现实的理解</title><link/>https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-powered-improve-0814<description>在受控实验中，麻省理工学院 CSAIL 研究人员发现法学硕士内部对现实的模拟正在深入发展，这表明对语言的理解超越了简单的模仿。</description><pubDate> Wed, 14 Aug 2024 13:20:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-powered-improve-0814</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p dir=&quot;ltr&quot; id=&quot;docs-internal-guid-0578c06c-7fff-5502-9169-dd202ec75971&quot;>;让像 GPT-4 这样的大型语言模型 (LLM) 去闻一下被雨水浸透的露营地的味道，结果就是这样。会礼貌地拒绝。让同一个系统向你描述这种气味，它会充满诗意地描述“一种充满期待的空气”和“一种既新鲜又朴实的气味”，尽管你之前既没有下雨的经验，也没有鼻子来帮助它做出这样的观察。对这种现象的一种可能的解释是，法学硕士只是模仿其大量训练数据中存在的文本，而不是对雨或气味进行任何真正的理解。&lt;br>;&lt;br>;但是缺少眼睛是否意味着语言模型永远无法“理解”狮子比家猫“更大”？哲学家和科学家长期以来都认为赋予语言意义的能力是人类智能的标志，并思考哪些基本要素使我们能够做到这一点。&lt;br>;&lt;br>;麻省理工学院计算机科学和人工智能的研究人员深入研究这个谜团实验室（CSAIL）发现了有趣的结果，表明语言模型可以发展自己对现实的理解，以此作为提高其生成能力的一种方式。该团队首先开发了一套小型卡雷尔谜题，其中包括提出在模拟环境中控制机器人的指令。然后，他们对一名法学硕士进行了有关解决方案的培训，但没有演示这些解决方案的实际工作原理。最后，他们使用一种称为“探测”的机器学习技术，在模型生成新解决方案时深入了解模型的“思维过程”。&lt;br>;&lt;br>;在对超过 100 万个随机谜题进行训练后，他们发现该模型自发地尽管在训练期间从未接触过这一现实，但开发了自己的底层模拟概念。这些发现使我们对学习语言意义所需的信息类型的直觉产生了疑问，以及法学硕士是否有一天能够比现在更深入地理解语言。&lt;br>;&lt;br>;“在这些实验开始时，语言模型生成的随机指令不起作用。当我们完成训练时，我们的语言模型生成了 92.4% 的正确指令，”麻省理工学院电气工程和计算机科学 (EECS) 博士生、CSAIL 附属机构 Charles Jin 说道，他是&lt;a href= “https://arxiv.org/pdf/2305.11169” target=&quot;_blank&quot;>;关于这项工作的新论文&lt;/a>;。 “这对我们来说是一个非常激动人心的时刻，因为我们认为，如果你的语言模型能够以这种准确度完成任务，我们可能会期望它也能理解语言中的含义。这为我们提供了一个起点来探索法学硕士是否真的理解文本，现在我们看到他们的能力不仅仅是盲目地将单词拼接在一起。”&lt;br>;&lt;br>;&lt;strong>;在一个人的头脑中法学硕士&lt;/strong>;&lt;/p>;&lt;p dir=&quot;ltr&quot;>;此次调查帮助 Jin 亲眼目睹了这一进展。它的作用是解释法学硕士认为指令的含义，揭示法学硕士开发了自己的内部模拟来模拟机器人如何响应每条指令。随着模型解决难题的能力提高，这些概念也变得更加准确，表明法学硕士开始理解这些指令。不久之后，该模型就始终如一地将各个部分正确地组合在一起，形成工作指令。&lt;br>;&lt;br>;Jin 指出，法学硕士对语言的理解是分阶段发展的，就像孩子分多个步骤学习语音一样。一开始，它就像婴儿牙牙学语：重复且大多难以理解。然后，语言模型获取语法或语言规则。这使其能够生成看似真正的解决方案的说明，但它们仍然不起作用。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;不过，LLM 的说明逐渐改进。一旦模型获得了意义，它就会开始生成正确实现所请求的规范的指令，就像孩子形成连贯的句子一样。&lt;br>;&lt;br>;&lt;strong>;将方法与模型分开：“奇异世界”&lt;/strong >;&lt;/p>;&lt;p dir=&quot;ltr&quot;>;正如 Jin 所描述的那样，该探测器的目的只是“进入法学硕士的大脑内部”，但它也有可能对模型进行一些思考。研究人员希望确保他们的模型能够独立于探针理解指令，而不是探针根据法学硕士对语法的掌握来推断机器人的动作。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“想象一下，你有一堆对 LM 思维过程进行编码的数据，”Jin 表示。 “探测器就像一名取证分析师：你将这堆数据交给分析师并说，‘这就是机器人的移动方式，现在尝试在这堆数据中找到机器人的移动。’分析师后来告诉你，他们从一堆数据中知道机器人发生了什么。但是，如果这堆数据实际上只是对原始指令进行编码，并且分析人员已经找到了一些巧妙的方法来提取指令并相应地遵循它们，该怎么办？那么语言模型根本就没有真正了解指令的含义。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;为了理清它们的角色，研究人员翻转了指令的含义以进行新的探测。在 Jin 所说的这个“奇异世界”中，在让机器人穿过网格的指令中，“向上”等方向现在意味着“向下”。&lt;br>;&lt;br>;“如果探头将指令转换为机器人位置，它应该能够同样出色地根据奇怪的含义翻译指令，”Jin 说。 “但是，如果探测器实际上是在语言模型的思维过程中找到原始机器人动作的编码，那么它应该很难从原始思维过程中提取奇异的机器人动作。”&lt;br>;&lt;br>;事实证明，新的探测器遇到了翻译错误，无法解释具有不同指令含义的语言模型。这意味着原始语义嵌入到语言模型中，表明法学硕士独立于原始探测分类器理解需要哪些指令。&lt;br>;&lt;br>;“这项研究直接针对现代人工智能的一个核心问题：令人惊讶的大型语言模型的能力仅仅是由于大规模的统计相关性，或者大型语言模型是否对它们被要求处理的现实产生了有意义的理解？这项研究表明，法学硕士开发了模拟现实的内部模型，尽管它从未接受过开发该模型的培训。”麻省理工学院 EECS 教授、CSAIL 成员、该论文的高级作者 Martin Rinard 说道。&lt;/p >;&lt;p dir=&quot;ltr&quot;>;这个实验进一步支持了团队的分析，即语言模型可以加深对语言的理解。尽管如此，金承认他们的论文存在一些局限性：他们使用非常简单的编程语言和相对较小的模型来收集他们的见解。在&lt;a href=&quot;http://arxiv.org/abs/2407.13765&quot;>;即将开展的工作&lt;/a>;中，他们将寻求使用更通用的设置。虽然 Jin 的最新研究没有概述如何让语言模型更快地学习意义，但他相信未来的工作可以基于这些见解来改进语言模型的训练方式。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“一个有趣的研究悬而未决的问题是，法学硕士在解决机器人导航问题时是否真的使用其内部现实模型来推理现实，”里纳德说。 “虽然我们的结果与以这种方式使用模型的法学硕士一致，但我们的实验并不是为了回答下一个问题。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“现在有很多关于布朗大学计算机科学和语言学助理教授埃莉·帕夫利克 (Ellie Pavlick) 表示：“法学硕士是否真的能够‘理解’语言，或者更确切地说，他们的成功是否可以归因于通过吸收大量文本而产生的本质上的技巧和启发式方法。”没有参与该论文。 “这些问题是我们如何构建人工智能以及我们期望技术固有的可能性或局限性的核心。这是一篇很好的论文，以受控的方式看待这个问题——作者利用了这样一个事实：计算机代码像自然语言一样，既有语法又有语义，但与自然语言不同的是，语义可以直接观察和操作以用于实验目的。实验设计很优雅，他们的发现也很乐观，这表明法学硕士也许可以更深入地了解语言的“含义”。”&lt;/p>;&lt;p>;Jin 和 Rinard 的论文部分得到了美国的资助国防高级研究计划局 (DARPA)。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202407/MIT-EmRep-LLMs.png?itok=dCndKN2z" width="390"><media:description type="plain">语言模型可能会发展自己对现实的理解，作为提高其生成能力的一种方式，这表明这些模型有一天可能会比现在更深层次地理解语言。</media:description><media:credit>图片来源：Alex Shipps/MIT CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/programming">编程</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/language">语言</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/darpa">国防高级研究计划局 (DARPA)</category></item></channel></rss>