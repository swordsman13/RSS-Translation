<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language>恩</language><lastbuilddate>2023 年 6 月 5 日星期一 03:00:00 -0400</lastbuilddate><item><title>麻省理工学院的研究人员使语言模型可扩展的自学者</title><link/>https://news.mit.edu/2023/language-models-scalable-self-learners-0608<description>科学家们使用基于自然语言的逻辑推理数据集来创建更小的语言模型，其性能优于更大的对应模型。</description><pubDate> Thu, 08 Jun 2023 13:35:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/language-models-scalable-self-learners-0608</guid><dc:creator>雷切尔戈登 |麻省理工学院</dc:creator><content:encoded>&lt;p>;苏格拉底曾经说过：“真正重要的不是事物的大小，而是它的质量。因为真正的价值在于物质的本质，而不是它的体积。”&lt;/p>; &lt;p>;对于大型语言模型 (LLM) 来说，大小总是很重要吗？麻省理工学院计算机科学与人工智能实验室 (CSAIL) 的一组研究人员认为，在 LLM 成为焦点的技术领域，不应忽视较小的模型，尤其是对于行业中广泛部署的自然语言理解产品。&lt;/p>; &lt;p>;为此，研究人员制定了一种解决长期存在的与基于文本的大型 AI 模型相关的低效率和隐私问题的方法——一种逻辑感知模型，在某些语言理解任务上的表现优于 500 倍大的对应模型没有人工生成的注释，同时通过高性能保持隐私和稳健性。&lt;/p>; &lt;p>;LLM 在生成语言、艺术和代码方面显示出一些有前途的技能，但计算成本很高，而且它们的数据要求可能会冒隐私风险使用应用程序编程接口进行数据上传时发生泄漏。与较大的模型相比，较小的模型历来能力较弱，尤其是在多任务处理和弱监督任务方面。&lt;/p>; &lt;p>;那么，是什么帮助这些较小的模型表现得如此强大呢？一种叫做“文本蕴含”的方法，可以帮助这些模型理解各种语言任务，如果一个句子（前提）为真，那么另一个句子（假设）也可能为真。例如，如果前提是“所有的猫都有尾巴”，那么假设“一只虎斑猫有尾巴”将被该前提所蕴涵。这个概念被用来训练一个“蕴含模型”，该模型被证明比团队之前的研究中的其他语言模型具有更少的偏见。然后他们创建了“提示”，模型可以使用这些提示来根据不同的任务确定给定的句子或短语是否包含某些信息。这种方法提高了模型在无需任何额外训练的情况下适应不同任务的能力，称为零样本适应。&lt;/p>; &lt;p>;在“自然语言理解”领域，有各种依赖于确定关系的应用两段文字之间。例如，在情感分类中，可以从“我喜欢这个故事，表演很棒”的电影评论中推断或推导出“我认为这部电影很好”这样的陈述，这表明了一种积极的情感。另一个是新闻分类，新闻文章的主题可以从其内容中推断出来。例如，如果文章的主要内容是关于 NBA 比赛的报道，则可以包含“新闻文章是关于体育的”这样的陈述。关键的见解是，许多现有的自然语言理解任务可以重铸为蕴含（即自然语言中的逻辑推理）任务。&amp;nbsp;&lt;/p>; &lt;p>;“我们的研究是关于提高计算机程序的理解能力和处理自然语言——人类说话和写作的方式。我们自行训练的 3.5 亿参数蕴含模型，没有人工生成的标签，优于具有 137 到 1750 亿参数的监督语言模型，”&lt;a href=&quot;https:/ /arxiv.org/pdf/2305.17197.pdf&quot; target=&quot;_blank&quot;>;关于这项研究的新论文&lt;/a>;。 “这有可能重塑人工智能和机器学习的格局，为语言建模提供更具可扩展性、可信度和成本效益的解决方案，”罗说。 “通过证明较小的模型在语言理解方面可以与较大的模型达到相同的水平，这项工作为更可持续和保护隐私的 AI 技术铺平了道路。”&amp;nbsp;&lt;/p>; &lt;p>;团队发现他们可以通过使用一种称为“自我训练”的技术进一步提高模型的性能，其中模型使用自己的预测来自学，在没有人工监督和额外注释训练数据的情况下有效地学习。自我训练方法显着提高了一堆性能下游任务，包括情感分析、问答和新闻分类。它在零样本能力、GPT 模型和其他监督算法方面优于谷歌的 LaMDA 和 FLAN。&amp;nbsp;&lt;/p>; &lt;p>;然而，自我训练的一个挑战是模型有时会生成不正确或嘈杂的标签，害性能。为了克服这个问题，他们开发了一种称为“SimPLE”（简单伪标签编辑）的新算法，这是一种审查和修改在最初几轮学习中制作的伪标签的过程。通过纠正任何错误标记的实例，它提高了自生成标签的整体质量。这不仅使模型在理解语言方面更有效，而且在面对对抗性数据时也更加稳健。&amp;nbsp;&lt;/p>; &lt;p>;与大多数研究一样，也存在一些局限性。多类分类任务的自训练不如二元自然语言理解任务的表现好，表明将蕴含模型应用于多选择任务的挑战。&lt;br />; &lt;br />;“这项研究提出了一个通过将自然语言理解任务表述为上下文蕴涵问题并采用伪标记自训练机制在训练过程中合并大量未标记的文本数据，训练大型语言模型 (LLM) 的高效且有效的方法，”CSAIL 高级研究补充道科学家詹姆斯·格拉斯，他也是该论文的作者。 “虽然 LLM 领域正在经历快速而巨大的变化，但这项研究表明，与同等规模甚至更大的语言模型相比，可以产生相对紧凑的语言模型，这些模型在基准理解任务上表现非常好”&lt;/p>; &lt;p>;“隐含任务是评估 AI 模型对给定上下文的“理解”的流行代理，”MIT-IBM Watson AI 实验室的研究人员 Leonid Karlinsky 说。 “它被用于许多领域，分析具有单模态（如 LLM）和多模态（如 VLMs [视觉语言模型]&lt;em>; &lt;/em>;输入）的模型，简化了关于给定输入上下文的问答任务一个二元分类问题——这个上下文是否需要某个（例如，文本）结论？本文在这个领域做出了两个贡献。首先，它提出了一种方法，通过调整为原始 NLU 任务生成的合成（专用）蕴含任务，来提高零样本（无需额外调整）NLU 性能和对对抗性攻击的鲁棒性。其次，它提供了一种自我监督的 SimPLE 方法，包括伪标记和基于置信度的过滤，以进一步提高大型 LLM 的 NLU 性能。”&lt;/p>; &lt;p>;Luo 和 Glass 与 CSAIL 成员 Yoon Kim 和麻省理工学院电气工程与计算机科学系助理教授，北京大学葛家新。他们的工作将于今年 7 月在安大略省多伦多举行的计算语言学协会会议上发表。这项研究得到了香港创新人工智能计划的资助。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202305/MIT-%20Entailment-transformed-cov.png?itok=p2R4GKMQ" width="390"><media:description type="plain"> “我们的研究是关于提高计算机程序理解和处理自然语言的能力——人类说话和写作的方式，”麻省理工学院 CSAIL 博士后 Hongyin Luo 说。 “我们的自我训练的 3.5 亿参数蕴含模型没有人工生成的标签，其性能优于具有 137 到 1750 亿参数的监督语言模型。”</media:description><media:credit>图片：Alex Shipps/MIT CSAIL 来自 Midjourney</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/natural-language-processing">自然语言处理</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学 (eecs) </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室 (CSAIL)</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工苏世民计算学院</category></item><item><title>在没有标签的情况下扩展视听学习</title><link/>https://news.mit.edu/2023/scaling-audio-visual-learning-without-labels-0605<description>一种新的多模式技术融合了主要的自我监督学习方法，以更类似于人类的方式学习。</description><pubDate> Mon, 05 Jun 2023 16:55:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/scaling-audio-visual-learning-without-labels-0605</guid><dc:creator>劳伦·欣克尔 | MIT-IBM 沃森人工智能实验室</dc:creator><content:encoded>&lt;p>;麻省理工学院、麻省理工学院-IBM 沃森人工智能实验室、IBM 研究院和其他地方的研究人员开发了一种新技术，用于分析未标记的音频和视觉数据，可以提高语音识别和对象等应用中使用的机器学习模型的性能检测。这项工作首次结合了两种自监督学习架构、对比学习和屏蔽数据建模，以努力在不需要注释的情况下扩展单模态和多模态数据中的事件分类等机器学习任务，从而复制&lt;/p>; &lt;p>;“人类知识的很大一部分是通过自我监督的方式学习的，因为我们并不总能得到监督信号，我们希望使机器学习成为可能麻省理工学院计算机科学与人工智能实验室 (CSAIL) 的博士后 Yuan Gong 说。&lt;/p>; &lt;p>;初始模型的基础，因为它可以学习大量未标记的数据。然后，如果您愿意，您可以使用经典的监督学习或强化学习将模型微调到特定的东西，”麻省理工学院高级研究科学家兼麻省理工学院-IBM 沃森人工智能实验室成员 Jim Glass 说。&lt;/p>; &lt;p>;这项技术称为对比视听掩蔽自动编码器 (CAV-MAE)，是一种神经网络，可以通过对大型数据集进行训练，学习从声学和视觉数据中提取有意义的潜在表示并将其映射到高维空间音频和视频 10 秒剪辑的 YouTube 数据集。研究人员表示，该技术比以前的方法更有效，因为它以一种其他方法没有的方式明确地模拟音频和视觉数据之间的关系。&lt;/p>; &lt;p>;在 &lt;a href=&quot;https: //openreview.net/pdf?id=QPtMRyk5rb&quot; target=&quot;_blank&quot;>;这项研究&lt;/a>;是麻省理工学院的研究生 Andrew Rouditchenko 和 Alexander H. Liu，德克萨斯大学奥斯汀分校的 David Harwath PhD &#39;18， MIT-IBM Watson AI 实验室成员 Leonid Karlinsky 和 ​​Hilde Kuehne。 Kuehne 还隶属于法兰克福歌德大学。该方法最近在国际学习表示会议上提出。&lt;/p>; &lt;p>;&lt;strong>;联合协调方法&lt;/strong>;&lt;/p>; &lt;p>;CAV-MAE 通过“通过预测学习”工作龚说：“通过比较学习”。屏蔽数据建模或预测方法将视频及其协调的音频波形一起拍摄，将音频转换为频谱图，并屏蔽两者的 75%。未屏蔽的数据被标记化，然后在进入联合编码器/解码器之前被送入单独的音频和视觉编码器，在那里模型被要求恢复丢失的数据。然后使用生成的重建预测与原始视听组合之间的差异（重建损失）来训练模型以获得更好的性能。这方面的一个例子是覆盖钢琴视频的一部分和钢琴音乐谱图的一部分，然后要求模型尝试确定屏蔽的输入。不幸的是，这种方法可能无法捕获视频和音频对之间的关​​联，而对比学习利用了这一点，但可能会丢弃一些模态独特的信息，例如视频中的背景。&lt;/p>; &lt;p>;对比学习旨在映射彼此相似的表示。例如，该模型将尝试将不同鹦鹉的不同视频和音频数据放置得彼此靠近，并远离吉他演奏的视频和音频对。以与掩码自动编码类似的方式，视听对被传递到单独的模态编码器中；然而，在模型执行池化和对比损失之前，音频和视觉组件分别保存在联合编码器中。通过这种方式，对比学习试图识别每个音频或视频中彼此最相关的部分。例如，如果一段视频显示某人在说话，而相应的音频片段包含语音，自动编码器将学习将说话者的嘴部动作与所说的话联系起来。然后它将调整模型的参数，使这些输入彼此接近。最终，CAV-MAE 方法将这两种技术与多个前向数据流结合在一起，第一步是掩码、模态特定编码器和层归一化，因此表示强度相似。&lt;/p>; &lt;p>;“我们 [then]我想将所提出的 CAV-MAE 与仅使用掩码自动编码器训练的模型和仅使用对比学习训练的模型进行比较，因为我们想证明通过结合掩码自动编码器和对比学习，我们可以获得一些性能提升，”Gong 说，“结果支持我们的假设，即有明显的改进。”&lt;/p>; &lt;p>;研究人员测试了 CAV-MAE - 以及他们的方法，没有对比损失或掩蔽的自动编码器 - 与其他最先进的使用标准 AudioSet（20K 和 2M）和 VGGSound 数据集的视听检索和视听事件分类任务的方法——标记的、逼真的短片，其中可能包含多种声音。视听检索意味着模型看到查询对的音频或视觉组件并搜索丢失的组件；事件分类包括识别数据中的动作或声音，例如唱歌的人或驾驶的汽车。&lt;/p>; &lt;p>;总的来说，他们发现对比学习和屏蔽数据建模是互补的方法。 CAV-MAE 能够在事件分类性能与具有可比较计算的模型方面比以前的技术（具有完全自我监督的预训练）高出约 2%，更令人印象深刻的是，与具有行业级计算资源的模型保持同步或优于模型。该团队的模型与仅使用对比损失训练的模型排名相似。令人惊讶的是，该团队表示，将多模态数据纳入 CAV-MAE 预训练极大地提高了通过监督学习（使用一些标记数据）对单模态表示的微调以及纯音频事件分类任务的性能.这表明，与人类一样，多模式信息提供了额外的“软标签”提升，即使对于仅音频或视觉的任务也是如此；例如，它可以帮助模型了解它是在寻找电吉他还是原声吉他——一种更丰富的监督信号。&lt;/p>; &lt;p>;“我认为人们喜欢这种模型的优雅，因为它可以将不同音频和视频中的信息结合起来溪流。它具有对比损失和重建损失，并且与使用类似数据评估过的模型相比，它显然在一系列这些任务中表现非常出色，”Glass 说。&lt;/p>; &lt;p>;在此基础上，“一个特别的是，我们的模型可以同时进行分类和检索，这并不常见，”Gong 补充道。 “在这项工作之前，这些方法是分开使用的，但在这项工作之后，&amp;nbsp;我看到大多数视听学习框架都将收缩损失和掩码自动编码器一起使用，隐式或显式。”&lt;/p>; &lt;p>; &lt;strong>;将自我监督的视听学习带入我们的世界&lt;/strong>;&lt;/p>; &lt;p>;研究人员将他们对对比视听屏蔽自动编码器 (CAV-MAE) 的贡献视为一个重要的里程碑和一步面向越来越多地从单一模式转向多模式并且需要或利用视听融合的应用程序。他们假设有一天它可以用于体育、教育、娱乐、机动车辆和公共安全等领域的动作识别。有一天，它也可能扩展到其他方式。目前，“这仅适用于视听数据可能是一个限制，但我们的目标是多模态学习，这是机器学习的趋势，”龚说。 “作为人类，我们有多种方式——我们有嗅觉、触觉——还有更多只是视听的东西。因此，当我们尝试构建 AI 时，我们会尝试以某种方式模仿人类，不一定是从生物学角度，并且这种方法可以 [潜在] 推广到其他未探索的模式。”&lt;/p>; &lt;p>;作为机器学习模型继续在我们的生活中发挥越来越重要的作用，像这样的技术将变得越来越有价值。&lt;/p>; &lt;p>;这项研究得到了麻省理工学院-IBM 沃森人工智能实验室的支持。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202305/machine-learning-technique.jpg?itok=ga8BiHAh" width="390"><media:description type="plain">一种新的机器学习技术允许更有效的多模式学习。</media:description><media:credit>图片：Lauren Hinkel/麻省理工学院-IBM 沃森人工智能实验室，来自 Bing Create</media:credit></media:content><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学 (eecs) </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室 (CSAIL)</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab"> MIT-IBM 沃森人工智能实验室</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工苏世民计算学院</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category></item></channel></rss>