<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 6 月 14 日星期五 00:00:00 -0400</lastbuilddate><item><title>理解语言模型的视觉知识</title><link/>https://news.mit.edu/2024/understanding-visual-knowledge-language-models-0617<description>主要接受文本训练的法学硕士可以通过自我修正的代码生成复杂的视觉概念。研究人员使用这些插图来训练无图像计算机视觉系统来识别真实照片。</description><pubDate> Mon, 17 Jun 2024 15:30:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/understanding-visual-knowledge-language-models-0617</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p dir=&quot;ltr&quot; id=&quot;docs-internal-guid-5a3b11bb-7fff-ba34-2e4c-b796b4334e93&quot;>;您可能听说过一张图片胜过一千个单词，但大型语言模型 (LLM) 可以如果以前从未见过图像，那么它能得到图片吗？&lt;br>;&lt;br>;事实证明，纯粹基于文本训练的语言模型对视觉世界有着扎实的理解。他们可以编写图像渲染代码来生成具有有趣对象和构图的复杂场景 - 即使这些知识没有正确使用，法学硕士也可以改进他们的图像。麻省理工学院计算机科学与人工智能实验室 (CSAIL) 的研究人员在提示语言模型针对不同图像自我纠正代码时观察到了这一点，系统在每次查询时都改进了简单的剪贴画绘图。&lt;/p>;&lt;p dir=&quot; ltr&quot;>;这些语言模型的视觉知识是通过互联网上如何描述形状和颜色等概念（无论是用语言还是代码）获得的。当给出“在丛林中画一只鹦鹉”这样的指示时，用户会催促法学硕士考虑之前在描述中读到的内容。为了评估法学硕士拥有多少视觉知识，CSAIL 团队为法学硕士构建了“视力检查”：使用他们的“视觉能力数据集”，他们测试了模型绘制、识别和自我纠正这些概念的能力。研究人员收集了这些插图的每个最终草稿，训练了一个计算机视觉系统，该系统可以识别真实照片的内容。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“我们本质上是在不直接使用任何视觉数据的情况下训练视觉系统，” &lt;a href=&quot;https://arxiv.org/pdf/2401.01862.pdf&quot; target=&quot;_blank&quot;>;研究&lt;/a>;和麻省理工学院电气工程和计算机科学项目的联合主要作者 Tamar Rott Shaham 说道（ EECS）CSAIL 博士后。 “我们的团队查询语言模型来编写图像渲染代码来为我们生成数据，然后训练视觉系统来评估自然图像。我们受到视觉概念如何通过其他媒介（如文本）表示的问题的启发。为了表达他们的视觉知识，法学硕士可以使用代码作为文本和视觉之间的共同点。”&lt;br>;&lt;br>;为了构建此数据集，研究人员首先查询模型以生成不同形状、对象和场景的代码。然后，他们编译该代码来渲染简单的数字插图，例如一排自行车，表明法学硕士足够了解空间关系，可以将两轮车绘制成水平行。另一个例子，模型结合了两个随机概念，生成了一个汽车形状的蛋糕。该语言模型还产生了一个发光的灯泡，表明其创建视觉效果的能力。&lt;br>;&lt;br>;“我们的工作表明，当您查询 LLM（无需多模态预训练）来创建图像时，它知道比看起来要多得多。”联合主要作者、EECS 博士生、CSAIL 成员 Pratyusha Sharma 说道。 “假设你要求它画一把椅子。该模型知道有关这件家具的其他信息，但它可能没有立即渲染，因此用户可以查询模型以改进每次迭代产生的视觉效果。令人惊讶的是，该模型可以通过在很大程度上改进渲染代码来迭代地丰富绘图。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;研究人员收集了这些插图，然后将其用于训练计算机视觉系统，该系统可以识别真实照片中的物体（尽管以前从未见过）。凭借这种合成的文本生成数据作为唯一参考点，该系统优于其他使用真实照片训练的程序生成的图像数据集。&lt;br>;&lt;br>;CSAIL 团队认为，将法学硕士隐藏的视觉知识与艺术其他人工智能工具（如扩散模型）的功能也可能是有益的。像 Midjourney 这样的系统有时缺乏持续调整图像中更精细细节的专业知识，这使得它们很难处理诸如减少拍摄的汽车数量或将一个物体放在另一个物体后面等请求。如果法学硕士事先勾画出扩散模型所需的更改，则最终的编辑可能会更令人满意。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;讽刺的是，正如 Rott Shaham 和 Sharma 承认的那样，法学硕士有时无法认识到他们可以画出的相同概念。当模型错误地识别数据集中的图像的人类重新创建时，这一点变得很明显。视觉世界的如此多样化的表示可能引发了语言模型的误解。&lt;br>;&lt;br>;虽然模型很难理解这些抽象描述，但它们表现出了每次以不同方式绘制相同概念的创造力。当研究人员多次要求法学硕士绘制草莓和拱廊等概念时，他们从不同角度制作了不同形状和颜色的图片，暗示这些模型可能对视觉概念有实际的心理意象（而不是背诵他们之前看到的例子）。&lt; /p>;&lt;p dir=&quot;ltr&quot;>;CSAIL 团队认为此过程可以作为评估生成式 AI 模型训练计算机视觉系统效果的基准。此外，研究人员希望扩大他们挑战语言模型的任务。至于他们最近的研究，麻省理工学院的小组指出，他们无法访问他们所使用的法学硕士的训练集，这使得进一步调查他们的视觉知识的起源变得具有挑战性。未来，他们打算通过让法学硕士直接使用来探索训练更好的视觉模型。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;Sharma 和 Rott Shaham 加入 &lt;a href=&quot;https:/ /arxiv.org/pdf/2401.01862.pdf&quot; target=&quot;_blank&quot;>;论文&lt;/a>;，作者为前 CSAIL 附属机构 Stephanie Fu &#39;22、MNG &#39;23 和 EECS 博士生 Manel Baradad、Adrián Rodríguez-Muñoz &#39;22，以及Shivam Duggal，均为 CSAIL 附属机构；以及麻省理工学院副教授菲利普·伊索拉和安东尼奥·托拉尔巴教授。他们的工作部分得到了 MIT-IBM Watson AI 实验室、LaCaixa 奖学金、Zuckerman STEM 领导力计划和 Viterbi 奖学金的资助。他们本周在 IEEE/CVF 计算机视觉和模式识别会议上发表了论文。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202406/LLM-swivel-chair-drawings.png?itok=qrSPCDxC" width="390"><media:description type="plain">基于文本的大型语言模型可以被提示编码更好的插图，这意味着它们对周围的世界有扎实的视觉知识。</media:description><media:credit> Alex Shipps/MIT CSAIL，包含来自 Canva 和 Pixabay 的元素。</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category></item><item><title>技术提升大型语言模型的推理能力</title><link/>https://news.mit.edu/2024/technique-improves-reasoning-capability-large-language-models-0614<description>该方法将自然语言和编程相结合，使法学硕士能够透明地解决数值、分析和基于语言的任务。</description><pubDate> Fri, 14 Jun 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/technique-improves-reasoning-capability-large-language-models-0614</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;大型语言模型（例如为 ChatGPT 提供支持的模型）在起草法律摘要、分析客户评论的情绪或将文档翻译成不同语言等任务上表现出了令人印象深刻的性能。&lt;/p>;&lt;p>;这些机器学习模型通常使用仅使用自然语言来处理信息和回答查询，这可能使他们难以执行需要数字或符号推理的任务。&lt;/p>;&lt;p>;例如，大型语言模型可能能够记住和背诵列表近期美国总统及其生日，但如果问“1950 年后当选的美国总统中有哪些是在星期三出生的？”这个问题，同样的模型可能会失败。 （答案是吉米·卡特。）&lt;/p>;&lt;p>;来自麻省理工学院和其他地方的研究人员提出了一种新技术，使大型语言模型能够通过生成程序来解决自然语言、数学和数据分析以及符号推理任务。&lt;/p>;&lt;p>; p>;&lt;p>;他们的方法称为自然语言嵌入式程序 (NLEP)，涉及提示语言模型创建并执行 Python 程序来解决用户的查询，然后将解决方案输出为自然语言。&lt;/p>;&lt;p >;他们发现 NLEP 使大型语言模型能够在各种推理任务上实现更高的准确性。该方法也是可推广的，这意味着一个 NLEP 提示可以重复用于多个任务。&lt;/p>;&lt;p>;NLEP 还提高了透明度，因为用户可以检查程序以准确了解模型如何推理查询并修复问题如果模型给出了错误的答案，则执行程序。&lt;/p>;&lt;p>;“我们希望人工智能以透明且值得信赖的方式执行复杂的推理。还有很长的路要走，但我们已经证明，在大型语言模型中结合编程和自然语言的能力是迈向未来的一个非常好的潜在第一步，让人们可以完全理解和信任人工智能内部正在发生的事情模型，”麻省理工学院博士后、&lt;a href=&quot;https://arxiv.org/pdf/2309.10814&quot; target=&quot;_blank&quot;>;关于 NLEP 的论文&lt;/a>;的共同主要作者 Hongyin Luo 博士 &#39;22 说道。 .&lt;/p>;&lt;p>;罗与香港中文大学研究生张天华共同撰写了这篇论文。葛佳欣，北京大学本科生； Yoon Kim，麻省理工学院电气工程与计算机科学系助理教授，计算机科学与人工智能实验室（CSAIL）成员；资深作者 James Glass，CSAIL 高级研究科学家兼口语系统小组负责人；和别的。该研究将在计算语言学协会北美分会年会上公布。&lt;/p>;&lt;p>;&lt;strong>;用程序解决问题&lt;/strong>;&lt;/p>;&lt;p>;许多流行的大型语言模型的工作原理是在给定一些自然语言输入的情况下预测下一个单词或标记。虽然像 GPT-4 这样的模型可以用来编写程序，但它们将这些程序嵌入自然语言中，这可能会导致程序推理或结果出现错误。&lt;/p>;&lt;p>;对于 NLEP，麻省理工学院的研究人员采取了相反的方法。它们提示模型完全用 Python 代码生成分步程序，然后在程序中嵌入必要的自然语言。&lt;/p>;&lt;p>;NLEP 是一个包含四个步骤的问题解决模板。首先，模型调用必要的包或函数，它需要解决任务。第二步涉及导入任务所需知识的自然语言表示（例如美国总统的生日列表）。对于第三步，模型实现了一个计算答案的函数。最后一步，模型将结果输出为一行自然语言，并在需要时自动数据可视化。&lt;/p>;&lt;p>;“它就像一个数字计算器，只要因为程序是正确的。”Luo 说。&lt;/p>;&lt;p>;用户可以轻松地调查程序并直接修复代码中的任何错误，而无需重新运行整个模型来进行故障排除。&lt;/p>;&lt;p>;该方法还比其他一些方法提供更高的效率。如果用户有很多类似的问题，他们可以生成一个核心程序，然后替换某些变量，而不需要重复运行模型。&lt;/p>;&lt;p>;为了促使模型生成 NLEP，研究人员给了它一个整体指令编写一个 Python 程序，提供两个 NLEP 示例（一个包含数学，一个包含自然语言）和一个测试题。&lt;/p>;&lt;p>;“通常，当人们进行这种几次提示时，他们仍然会为每项任务设计提示。我们发现，我们可以为许多任务设置一个提示，因为它不是教法学硕士解决一个问题的提示，而是教法学硕士通过编写程序解决许多问题的提示。”罗说。&lt;/p>;&lt;p >;“让语言模型通过代码进行推理可以释放许多工具使用、输出验证、对模型功能和思维方式进行更结构化理解等方面的机会，”MIT-IBM Watson AI 实验室首席科学家 Leonid Karlinsky 说道。&lt;/ p>;&lt;p>;&lt;strong>;“这里没有魔法”&lt;/strong>;&lt;/p>;&lt;p>;在提示 GPT-4 解决一系列符号推理任务（例如跟踪打乱的对象或玩 24 人游戏，以及遵循指令和文本分类任务。研究人员发现，NLEP 的准确度甚至比特定任务提示方法高出 30%。该方法还显示出相对于开源 LLM 的改进。&lt;/p>;&lt;p>;除了提高大型语言模型的准确性之外，NLEP 还可以改善数据隐私。由于 NLEP 程序在本地运行，因此敏感的用户数据不需要发送到 OpenAI 或 Google 这样的公司来由模型处理。&lt;/p>;&lt;p>;此外，NLEP 可以使小型语言模型在无需需要针对特定​​任务重新训练模型，这可能是一个成本高昂的过程。&lt;/p>;&lt;p>;“这里没有魔法。我们没有更昂贵或更奇特的语言模型。我们所做的就是使用程序生成而不是自然语言生成，我们可以让它的性能显着提高。”罗说。&lt;/p>;&lt;p>;但是，NLEP 依赖于模型的程序生成能力，因此该技术对于在有限数据集上训练的较小模型来说效果不佳。未来，研究人员计划研究可以使更小的语言模型生成更有效的 NLEP 的方法。此外，他们希望研究即时变化对 NLEP 的影响，以增强模型推理过程的稳健性。&lt;/p>;&lt;p>;这项研究得到了香港感知与交互智能中心的部分支持.&amp;nbsp;&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202406/MIT_LANGUAGE-Prorams-01-PRESS.jpg?itok=4RzlMAUE" width="390"><media:description type="plain">一项新技术通过在代码中编写 Python 程序来生成用户查询的正确答案，使 GPT-4 等大型语言模型能够更准确地解决数字或符号推理任务。</media:description><media:credit>图片来源：Christine Daniloff，麻省理工学院；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/language">语言</category><category domain="https://news.mit.edu/topic/programming">编程</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item></channel></rss>