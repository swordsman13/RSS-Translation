<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 7 月 16 日，星期二 20:55:00 +0000</lastbuilddate><item><title>麻省理工学院的研究人员推进人工智能模型的自动解释性</title><link/>https://news.mit.edu/2024/mit-researchers-advance-automated-interpretability-ai-models-maia-0723<description> MAIA 是一种多模式代理，可以迭代设计实验以更好地理解 AI 系统的各个组成部分。</description><pubDate> Tue, 23 Jul 2024 16:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/mit-researchers-advance-automated-interpretability-ai-models-maia-0723</guid><dc:creator>雷切尔戈登|麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p>;随着人工智能模型变得越来越普遍，并融入医疗保健、金融、教育、交通和娱乐等不同领域，了解它们的幕后工作原理至关重要。解释人工智能模型背后的机制使我们能够审核它们的安全性和偏见，并有可能加深我们对智能本身背后的科学的理解。&lt;/p>;&lt;p>;想象一下，如果我们可以通过操纵每个模型来直接研究人脑它的单个神经元检查它们在感知特定物体时的作用。虽然这样的实验对人脑的侵入性太大，但在另一种类型的神经网络中更可行：人工神经网络。然而，与人脑有些相似，包含数百万个神经元的人工模型太大且复杂，无法手工研究，这使得大规模的可解释性成为一项非常具有挑战性的任务。&lt;/p>;&lt;p>;为了解决这个问题，麻省理工学院计算机科学学院人工智能实验室 (CSAIL) 的研究人员决定采用自动化方法来解释评估图像不同属性的人工视觉模型。他们开发了“MAIA”（多模态自动解释代理），这是一个使用视觉语言模型主干自动执行各种神经网络解释任务的系统，该主干配备了用于在其他人工智能系统上进行实验的工具。&lt;/p>;&lt;p>;“我们的目标就是创造一个能够自主进行可解释性实验的人工智能研究员。现有的自动解释方法仅在一次性过程中标记或可视化数据。另一方面，MAIA 可以生成假设，设计实验来测试它们，并通过迭代分析完善其理解。” &lt;a href=&quot;https://arxiv.org/pdf/2404.14394.pdf&quot; target=&quot;_blank&quot;>;有关研究的论文&lt;/a>;。 “通过将预先训练的视觉语言模型与可解释性工具库相结合，我们的多模态方法可以通过在特定模型上编写和运行有针对性的实验来响应用户查询，不断完善其方法，直到能够提供全面的答案。”&lt; /p>;&lt;p>;自动化代理被证明可以解决三个关键任务：它标记视觉模型内的各个组件并描述激活它们的视觉概念，它通过删除不相关的特征来清理图像分类器，使它们对新情况更加鲁棒，它会寻找人工智能系统中隐藏的偏见，以帮助发现其输出中潜在的公平问题。 “但是像 MAIA 这样的系统的一个关键优势是它的灵活性，”CSAIL 的研究科学家、该研究的联合负责人 Sarah Schwettmann 博士 &#39;21 说道。 “我们展示了 MAIA 在一些特定任务上的实用性，但鉴于该系统是根据具有广泛推理功能的基础模型构建的，它可以回答用户的许多不同类型的可解释性查询，并动态设计实验来研究它们。” &lt;/p>;&lt;p>;&lt;strong>;逐个神经元&lt;/strong>;&lt;/p>;&lt;p>;在一个示例任务中，人类用户要求 MAIA 描述视觉模型中特定神经元负责的概念用于检测。为了研究这个问题，MAIA 首先使用一种工具从 ImageNet 数据集中检索“数据集范例”，从而最大限度地激活神经元。对于这个示例神经元，这些图像显示了穿着正式服装的人，以及他们的下巴和脖子的特写镜头。 MAIA 对驱动神经元活动的因素做出了各种假设：面部表情、下巴或领带。然后，MAIA 使用其工具设计实验，通过生成和编辑合成图像来单独测试每个假设 - 在一个实验中，在人脸图像上添加领结会增加神经元的反应。 Rott Shaham 说：“这种方法使我们能够确定神经元活动的具体原因，就像真正的科学实验一样。”&lt;/p>;&lt;p>;MAIA 对神经元行为的解释通过两种关键方式进行评估。首先，具有已知真实行为的合成系统用于评估 MAIA 解释的准确性。其次，对于训练有素的人工智能系统中没有真实描述的“真实”神经元，作者设计了一种新的自动评估协议，用于衡量 MAIA 的描述在未见过的数据上预测神经元行为的效果。&lt;/p>;&lt;p>;CSAIL 领导的该方法优于描述各种视觉模型（例如 ResNet、CLIP 和视觉转换器 DINO）中的单个神经元的基线方法。 MAIA 在具有已知真实描述的合成神经元新数据集上也表现良好。对于真实系统和合成系统，描述通常与人类专家编写的描述相同。&lt;/p>;&lt;p>;人工智能系统组件（如单个神经元）的描述有何用处？ “理解和定位大型人工智能系统内部的行为是在部署这些系统之前对其安全性进行审核的关键部分 - 在我们的一些实验中，我们展示了如何使用 MAIA 来查找具有不良行为的神经元，并从系统中删除这些行为。模型，”施韦特曼说。 “我们正在构建一个更具弹性的人工智能生态系统，其中用于理解和监控人工智能系统的工具与系统扩展保持同步，使我们能够调查并希望了解新模型带来的不可预见的挑战。”&lt;br>;&lt;br>;&lt;strong>;偷看随着“黑匣子”机器学习模型的兴起，可解释性这一新兴领域正在成熟为一个独特的研究领域。研究人员如何破解这些模型并了解它们是如何工作的？&lt;br>;&lt;br>;当前窥视内部的方法往往在规模或所产生的解释的精度方面受到限制。此外，现有的方法往往适合特定的模型和特定的任务。这引起研究人员的疑问：我们如何构建一个通用系统来帮助用户回答有关人工智能模型的可解释性问题，同时将人体实验的灵活性与自动化技术的可扩展性结合起来？&lt;/p>;&lt;p>;他们想要这个的一个关键领域系统要解决的是偏见。为了确定图像分类器是否对图像的特定子类别表现出偏见，该团队查看了分类流的最后一层（在一个旨在对项目进行排序或标记的系统中，就像识别照片是否是狗、猫的机器一样）或鸟）和输入图像的概率分数（机器分配给其猜测的置信度）。为了了解图像分类中的潜在偏差，MAIA 被要求找到特定类别（例如“拉布拉多猎犬”）中可能被系统错误标记的图像子集。在此示例中，MAIA 发现黑色拉布拉多犬的图像可能被错误分类，这表明模型对黄毛猎犬存在偏见。&lt;/p>;&lt;p>;由于 MAIA 依赖外部工具来设计实验，因此其性能受到限制通过这些工具的质量。但是，随着图像合成模型等工具质量的提高，MAIA 也会提高。 MAIA 有时也会表现出确认偏差，有时会错误地证实其最初的假设。为了缓解这个问题，研究人员构建了一个图像到文本的工具，它使用语言模型的不同实例来总结实验结果。另一种失败模式是对特定实验的过度拟合，模型有时会根据最少的证据做出过早的结论。&lt;/p>;&lt;p>;“我认为我们实验室的下一步自然是超越人工系统，并将类似的实验应用于人类的感知，”罗特·沙汉姆说。 “传统上测试这一点需要手动设计和测试刺激，这是劳动密集型的。通过我们的代理，我们可以扩大这个过程，同时设计和测试大量的刺激。这也可能使我们能够将人类视觉感知与人工系统进行比较。”&lt;/p>;&lt;p>;“理解神经网络对人类来说很困难，因为他们有数十万个神经元，每个神经元都有复杂的行为模式。 MAIA 通过开发人工智能代理来帮助弥合这一问题，这些代理可以自动分析这些神经元，并以易于理解的方式将提取的结果报告给人类，”加州大学伯克利分校助理教授 Jacob Steinhardt 说，他没有参与这项研究。 “扩大这些方法的规模可能是理解和安全监督人工智能系统的最重要途径之一。”&lt;/p>;&lt;p>;Rott Shaham 和 Schwettmann 以及五名 CSAIL 附属机构也参与了这篇论文：本科生 Franklin Wang；麻省理工学院即将入学的学生 Achyuta Rajaram； EECS 博士生 Evan Hernandez SM &#39;22；以及 EECS 教授 Jacob Andreas 和 Antonio Torralba。他们的工作部分得到了 MIT-IBM Watson AI 实验室、开放慈善机构、现代汽车公司、陆军研究实验室、英特尔、国家科学基金会、Zuckerman STEM Leadership Program 和 Viterbi Fellowship 的支持。研究人员的研究结果将于本周在国际机器学习会议上公布。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202407/MIT-Multimodal-Automated-Interpretability-Agent-00.jpg?itok=u0hyhxpb" width="390"><media:description type="plain">麻省理工学院研究人员开发的自动化多模式方法解释了评估图像属性的人工视觉模型。</media:description><media:credit>图片：iStock</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/language">语言</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/nsf">美国国家科学基金会 (NSF)</category></item><item><title>以严格灵活的方式创建和验证稳定的人工智能控制系统</title><link/>https://news.mit.edu/2024/creating-verifying-stable-ai-control-systems-rigorous-flexible-way-0717<description>神经网络控制器为复杂的机器人提供了稳定性保证，为自动驾驶车辆和工业机器的更安全部署铺平了道路。</description><pubDate> Wed, 17 Jul 2024 21:20:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/creating-verifying-stable-ai-control-systems-rigorous-flexible-way-0717</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p>;神经网络对工程师设计机器人控制器的方式产生了巨大影响，催生了更具适应性和更高效的机器。尽管如此，这些类脑机器学习系统仍然是一把双刃剑：它们的复杂性使它们变得强大，但也使得很难保证由神经网络驱动的机器人能够安全地完成其任务。&lt;br>;&lt;br >;验证安全性和稳定性的传统方法是通过称为李亚普诺夫函数的技术。如果你能找到一个其值持续减小的李亚普诺夫函数，那么你就可以知道与较高值相关的不安全或不稳定情况永远不会发生。然而，对于由神经网络控制的机器人，之前验证李亚普诺夫条件的方法并不能很好地扩展到复杂的机器。&lt;/p>;&lt;p>;来自麻省理工学院计算机科学和人工智能实验室 (CSAIL) 和其他地方的研究人员现已开发出新技术在更复杂的系统中严格验证李雅普诺夫计算。他们的算法有效地搜索并验证了李亚普诺夫函数，为系统的稳定性提供了保证。这种方法有可能使机器人和自动驾驶车辆（包括飞机和航天器）的部署更加安全。&lt;/p>;&lt;p>;为了超越以前的算法，研究人员找到了一条训练和验证过程的节俭捷径。他们生成了更便宜的反例——例如，来自传感器的对抗性数据可能会脱离控制器——然后优化机器人系统来解释它们。了解这些边缘情况有助于机器学习如何处理具有挑战性的环境，从而使它们能够在比以前更广泛的条件下安全运行。然后，他们开发了一种新颖的验证公式，可以使用可扩展的神经网络验证器 α,β-CROWN，提供超越反例的严格的最坏情况保证。&lt;/p>;&lt;p>;“我们已经看到了一些麻省理工学院电气工程与计算机科学 (EECS) 博士生兼 CSAIL 附属机构 Lujie Yang 表示：他与丰田研究所研究员 Hongkai Dai SM &#39;12、PhD &#39;16 共同发表了一篇关于该项目的新论文。 “我们的工作弥补了神经网络控制器的性能水平与在现实世界中部署更复杂的神经网络控制器所需的安全保证之间的差距，”杨指出。&lt;/p>;&lt;p>;对于数字演示，该团队模拟了带有激光雷达传感器的四旋翼无人机如何在二维环境中保持稳定。他们的算法仅使用激光雷达传感器提供的有限环境信息，成功引导无人机到达稳定的悬停位置。在另外两个实验中，他们的方法使两个模拟机器人系统能够在更广泛的条件下稳定运行：倒立摆和路径跟踪车辆。这些实验虽然规模不大，但比神经网络验证社区以前可以做的实验相对更复杂，特别是因为它们包括传感器模型。&lt;br>;&lt;br>;“与常见的机器学习问题不同，严格使用神经网络作为李亚普诺夫“函数需要解决全局优化问题，因此可扩展性是关键瓶颈。”未参与这项工作的加州大学圣地亚哥分校计算机科学与工程副教授高思存说道。 “当前的工作通过开发算法方法做出了重要贡献，这些算法方法更适合神经网络在控制问题中的李亚普诺夫函数的特定用途。与现有方法相比，它在可扩展性和解决方案质量方面取得了令人印象深刻的改进。这项工作为神经李雅普诺夫方法的优化算法的进一步开发以及深度学习在控制和机器人技术中的严格应用开辟了令人兴奋的方向。”&lt;/p>;&lt;p>;Yang 和她的同事的稳定性方法具有广泛的潜力保证安全至关重要的应用。它可以帮助确保飞机和航天器等自动驾驶车辆更平稳地行驶。同样，运送物品或绘制不同地形的无人机也可以从这种安全保证中受益。&lt;/p>;&lt;p>;这里开发的技术非常通用，不仅适用于机器人技术；而且还适用于机器人技术。相同的技术将来可能会有助于其他应用，例如生物医学和工业加工。&lt;br>;&lt;br>;虽然该技术在可扩展性方面是对先前工作的升级，但研究人员正在探索如何才能更好地执行在更高维度的系统中。他们还希望考虑激光雷达读数之外的数据，例如图像和点云。&lt;/p>;&lt;p>;作为未来的研究方向，该团队希望为处于不确定环境和环境中的系统提供相同的稳定性保证。受到干扰。例如，如果一架无人机面临一阵强风，杨和她的同事希望确保它仍然能够稳定飞行并完成预期的任务。&lt;br>;&lt;br>;此外，他们打算将他们的方法应用于优化问题，目标是最大限度地减少机器人完成任务所需的时间和距离，同时保持稳定。他们计划将他们的技术扩展到类人机器人和其他现实世界的机器上，其中机器人在与周围环境接触时需要保持稳定。&lt;br>;&lt;br>;Russ Tedrake，丰田 EECS、航空航天和机械学教授麻省理工学院工程系、TRI 机器人研究副总裁、CSAIL 成员，是这项研究的高级作者。该论文还归功于加州大学洛杉矶分校博士生Zhouxing Shi和副教授Cho-Jui Hsieh，以及伊利诺伊大学厄巴纳-香槟分校助理教授Huan Zhang。他们的工作部分得到了亚马逊、美国国家科学基金会、海军研究办公室和施密特科学公司 AI2050 项目的支持。研究人员的论文将在 2024 年国际机器学习会议上发表。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202407/MIT-Lyapunov_0.png?itok=6ZQzm3yD" width="390"><media:description type="plain">麻省理工学院 CSAIL 研究人员帮助设计了一种新技术，可以保证神经网络控制的机器人的稳定性。这一发展最终可能会带来更安全的自动驾驶汽车和工业机器人。</media:description><media:credit>图片来源：Alex Shipps/MIT CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/mechanical-engineering">机械工业</category><category domain="https://news.mit.edu/topic/drones">无人机</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/safety">安全</category><category domain="https://news.mit.edu/topic/networks">网络</category><category domain="https://news.mit.edu/topic/robotics">机器人技术</category><category domain="https://news.mit.edu/topic/robots">机器人</category><category domain="https://news.mit.edu/topic/autonomous-vehicles">自动驾驶汽车</category><category domain="https://news.mit.edu/topic/aeronautics">航空航天工程</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category></item></channel></rss>