<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 12 月 11 日星期三 00:00:00 -0500</lastbuilddate><item><title>教会机器人其极限，安全地完成开放式任务</title><link/>https://news.mit.edu/2024/teaching-robot-its-limits-complete-open-ending-tasks-safely-1212<description> “PRoC3S”方法通过测试模拟中的每个步骤来帮助法学硕士创建可行的行动计划。这种策略最终可以帮助家用机器人完成更模糊的家务请求。</description><pubDate> Thu, 12 Dec 2024 17:00:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/teaching-robot-its-limits-complete-open-ending-tasks-safely-1212</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p dir=&quot;ltr&quot; id=&quot;docs-internal-guid-8a4c5d2f-7fff-0f2d-8a04-5aa86fc148ee&quot;>;如果有人建议您“了解自己的极限”，他们很可能会建议您做一些事情，例如适度锻炼。然而，对于机器人来说，这句座右铭代表了学习约束，或者机器环境中特定任务的限制，以安全、正确地做家务。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;例如，想象一下要求机器人做事当厨房不了解周围环境的物理原理时，请清洁它。机器如何生成实用的多步骤计划以确保房间一尘不染？大型语言模型 (LLM) 可以让它们接近，但如果模型仅接受文本训练，则可能会错过有关机器人物理约束的关键细节，例如它可以到达多远或附近是否有需要避开的障碍物。仅坚持攻读法学硕士，您最终可能会清除地板上的意大利面污渍。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;为了指导机器人执行这些开放式任务，麻省理工学院计算机科学和技术学院的研究人员人工智能实验室 (CSAIL) 使用视觉模型来查看机器附近的物体并对其限制进行建模。该团队的策略包括法学硕士草拟一个计划，并在模拟器中进行检查，以确保其安全和现实。如果该动作序列不可行，语言模型将生成一个新计划，直到达到机器人可以执行的计划。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;这种试错方法，研究人员称之为“通过连续约束满足代码规划机器人”（PRoC3S），测试长期计划以确保它们满足所有约束，并使机器人能够执行各种任务，例如写单个字母、画星星和排序并将方块放置在不同的位置。未来，PRoC3S 可以帮助机器人在房屋等动态环境中完成更复杂的家务，在那里它们可能会被提示做由许多步骤组成的一般家务（例如“给我做早餐”）。&lt;/p>;&lt;p dir=&quot; ltr&quot;>;“法学硕士和经典机器人系统（例如任务和运动规划器）无法单独执行此类任务，但它们的协同作用使开放式问题解决成为可能，”博士生 Nishanth Kumar SM 说道&#39;24，一篇关于 PRoC3S 的新论文的共同主要作者。 “我们正在对机器人周围的情况进行动态模拟，并尝试许多可能的行动计划。视觉模型帮助我们创建一个非常现实的数字世界，使机器人能够推理长期计划的每一步的可行行动。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;该团队的工作已于上个月展示。在德国慕尼黑机器人学习会议 (CoRL) 上发表的一篇论文中。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;研究人员的方法使用了对来自互联网的文本进行预训练的法学硕士。在要求 PRoC3S 执行任务之前，团队向其语言模型提供了与目标任务（绘制星星）相关的示例任务（例如绘制正方形）。示例任务包括活动描述、长期计划以及有关机器人环境的相关详细信息。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;但是这些计划在实践中表现如何？在模拟中，PRoC3S 成功绘制了星星和字母各 10 次中的 8 次。它还可以将数字块堆叠成金字塔和线条，并准确地放置物品，例如盘子上的水果。在每个数字演示中，CSAIL 方法比类似方法（如&lt;a href=&quot;https://arxiv.org/pdf/2403.11552&quot;>;“LLM3”&lt;/a>; 和&lt;a）更一致地完成了所请求的任务href=&quot;https://arxiv.org/pdf/2209.07753&quot;>;“代码即策略”&lt;/a>;。&lt;br>;&lt;br>;CSAIL 工程师接下来带来了他们对待现实世界的方法。他们的方法在机械臂上开发并执行了计划，教它将方块放置在直线上。 PRoC3S 还使机器能够将蓝色和红色块放入匹配的碗中，并将所有物体移动到桌子中心附近。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;Kumar 和联合主要作者 Aidan Curtis SM &#39;23（他是另一位在 CSAIL 工作的博士生表示，这些发现表明法学硕士如何能够制定出更安全的计划，让人类可以信赖并在实践中发挥作用。研究人员设想了一种家庭机器人，它可以收到更一般的请求（例如“给我一些芯片”），并可靠地找出执行它所需的具体步骤。 PRoC3S 可以帮助机器人在相同的数字环境中测试计划，找到可行的行动方案，更重要的是，为您带来美味的零食。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;对于未来的工作，研究人员的目标是使用更先进的物理模拟器改进结果，并通过更可扩展的数据搜索技术扩展到更复杂的长期任务。此外，他们计划将 PRoC3S 应用于移动机器人，例如四足机器人，以执行包括行走和扫描周围环境的任务。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“使用 ChatGPT 等基础模型来控制机器人动作可能会导致不安全或人工智能研究所研究员 Eric Rosen 说道，他没有参与这项研究。 “PRoC3S 通过利用基础模型进行高级任务指导来解决这个问题，同时采用人工智能技术来明确地推理世界，以确保可验证的安全和正确的行动。这种基于规划和数据驱动的方法的结合可能是开发能够理解并可靠地执行比目前更广泛的任务的机器人的关键。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;Kumar 和 Curtis 的合作-作者也是 CSAIL 附属机构：麻省理工学院本科生研究员 Jing Cao 以及麻省理工学院电气工程和计算机科学系教授 Leslie Pack Kaelbling 和 Tomás Lozano-Pérez。他们的工作部分得到了国家科学基金会、空军科学研究办公室、海军研究办公室、陆军研究办公室、麻省理工学院情报探索和人工智能研究所的支持。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/TestPRoC3S_0.jpg?itok=jmbmbHcq" width="390"><media:description type="plain">博士生艾丹·柯蒂斯（左）和尼山斯·库马尔。为了帮助机器人安全地执行开放式任务，研究人员使用视觉模型来查看机器附近的物体并对其限制进行建模。他们的“PRoC3S”策略由法学硕士起草了一份行动计划，该计划在模拟器中进行检查，以确保其在现实世界中发挥作用。</media:description><media:credit>迈克·格里米特/麻省理工学院 CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程和计算机科学（EECS） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/quest-intelligence">寻求情报</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/natural-language-processing">自然语言处理</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/robotics">机器人技术</category><category domain="https://news.mit.edu/topic/research">研究</category></item><item><title>研究人员表示，健康领域的人工智能应该受到监管，但不要忘记算法</title><link/>https://news.mit.edu/2024/ai-health-should-be-regulated-dont-forget-about-algorithms-1212<description>在最近的一篇评论中，来自麻省理工学院、Equality AI 和波士顿大学的团队强调了医疗保健领域人工智能模型和非人工智能算法的监管差距。</description><pubDate> Thu, 12 Dec 2024 16:25:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/ai-health-should-be-regulated-dont-forget-about-algorithms-1212</guid><dc:creator>欧阳历 |安利捷健康机器学习诊所</dc:creator><content:encoded>&lt;p dir=&quot;ltr&quot;>;有人可能会说，医生的主要职责之一是不断评估和重新评估可能性：医疗程序成功的机会有多大？患者是否有出现严重症状的风险？患者什么时候应该返回接受更多检查？在这些重要的审议中，人工智能的兴起有望降低临床环境中的风险，并帮助医生优先考虑高风险患者的护理。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;尽管有潜力，但来自麻省理工学院系的研究人员电气工程和计算机科学 (EECS) 学院、Equality AI 和波士顿大学呼吁监管机构对人工智能进行更多监督&lt;a href=&quot;https://ai.nejm.org/doi/full/10.1056/AIp2400583&quot;>;10 月《新英格兰医学杂志 AI》(NEJM AI) 发表的新评论&lt;/a>;&lt;/em>;美国卫生与公众服务部 (HHS) 民权办公室 (OCR) 根据《平价医疗法案》(ACA) 发布新规则后出现的问题。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;5 月，OCR 发布了&lt;a href=&quot;https://www.federalregister.gov/documents/2024/05/06/2024-08711/nondiscrimination-in-health-programs-and-活动&quot;>;《平价医疗法案》中的一项最终规则&lt;/a>;，禁止在“患者护理决策支持工具”中基于种族、肤色、国籍、年龄、残疾或性别的歧视，该工具是新建立的该术语涵盖医学中使用的人工智能和非自动化工具。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;为响应乔·拜登总统的&lt;a href=&quot;https://www.federalregister.gov/documents /2023/11/01/2023-24283/safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence&quot;>;关于安全、从 2023 年开始安全、值得信赖地开发和使用人工智能&lt;/a>;，最终规则建立在拜登-哈里斯政府致力于通过重点防止歧视来促进健康公平的承诺之上。&lt;/p>;&lt;p dir=&quot;ltr ” EECS 资深作者兼副教授 Marzyeh Ghassemi 表示，“该规则是向前迈出的重要一步。” Ghassemi 隶属于麻省理工学院安利捷健康机器学习诊所 (Jameel Clinic)、计算机科学和人工智能实验室 (CSAIL) 以及医学工程与科学研究所 (IMES)，他补充说，该规则“应要求对临床亚专业已使用的非人工智能算法和临床决策支持工具进行公平驱动的改进。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;美国食品和药品的数量自 1995 年批准第一台人工智能设备（PAPNET 测试系统，宫颈筛查工具）以来，经过政府批准的人工智能设备在过去十年中急剧增加。&lt;a href=&quot;https:// jamanetwork.com/journals/jama/fullarticle/2825146&quot;>;截至 10 月&lt;/a>;，FDA 已批准近 1,000 种支持人工智能的设备，其中许多旨在支持临床&lt;/p>;&lt;p dir=&quot;ltr&quot;>;然而，研究人员指出，尽管大多数美国医生（ 65%）每月使用这些工具来确定患者护理的后续步骤。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;为了解决这一缺陷，Jameel 诊所将举办另一个项目&lt;a href=&quot;https://www.aihealthgov.mit.edu/&quot;>;2025 年 3 月召开的监管会议&lt;/a>;。&lt;a href=&quot;https://news.mit.edu/2024/what-to- do-about-ai-in-health-0123&quot;>;去年的会议&lt;/a>;引发了来自世界各地的教师、监管机构和行业专家之间的一系列讨论和辩论，重点关注人工智能的监管&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“临床风险评分比‘人工智能’算法更不透明，因为它们通常只涉及简单模型中链接的少数变量，”该委员会主席 Isaac Kohane 评论道。哈佛医学院生物医学信息学系、《NEJM AI》主编。 “尽管如此，即使这些分数也只能与用于‘训练’它们的数据集以及专家在特定群体中选择或研究的变量一样好。如果它们影响临床决策，就应该与最近的、更复杂的人工智能同类产品遵循相同的标准。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;此外，虽然许多决策支持工具并不使用人工智能时，研究人员指出，这些工具同样会导致医疗保健中的偏见长期存在，因此需要监督。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“由于临床决策的激增，监管临床风险评分带来了重大挑战电子病历中嵌入的支持工具以及它们在临床实践中的广泛应用，”合著者、Equality AI 首席执行官 Maia Hightower 说道。 “为了确保透明度和非歧视，此类监管仍然是必要的。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;但是，Hightower 补充说，在即将上任的政府领导下，临床风险评分的监管可能会被证明“特别具有挑战性，因为其强调放松管制并反对《平价医疗法案》和某些非歧视政策。”&amp;nbsp;&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/ai-in-medicine.jpg?itok=y4RhyOOS" width="390"><media:credit>图片来源：Adobe Stock</media:credit></media:content><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程和计算机科学（EECS） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/jameel-clinic">贾米尔诊所</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/health">健康科学与技术</category><category domain="https://news.mit.edu/topic/medicine">药品</category><category domain="https://news.mit.edu/topic/public-health">公共卫生</category><category domain="https://news.mit.edu/topic/equity-and-inclusion">公平和包容</category><category domain="https://news.mit.edu/topic/policy">政策</category><category domain="https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0">医学工程与科学研究所 (IMES)</category></item></channel></rss>