<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 4 月 11 日星期四 15:00:00 +0000</lastbuilddate><item><title>新的人工智能方法捕捉医学图像中的不确定性</title><link/>https://news.mit.edu/2024/new-ai-method-captures-uncertainty-medical-images-0411<description>通过为一张医学图像提供合理的标签图，Tyche 机器学习模型可以帮助临床医生和研究人员捕获关键信息。</description><pubDate> Thu, 11 Apr 2024 11:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/new-ai-method-captures-uncertainty-medical-images-0411</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;在生物医学中，分割涉及对医学图像中重要结构（如器官或细胞）的像素进行注释。人工智能模型可以通过突出显示可能显示某种疾病或异常迹象的像素来帮助临床医生。&lt;/p>; &lt;p>;然而，这些模型通常只提供一个答案，而医学图像分割的问题往往远非黑与白。白色的。五位专家人类注释者可能会提供五种不同的分割，可能对肺部 CT 图像中结节边界的存在或范围存在不同意见。&lt;/p>; &lt;p>;“拥有选择可以帮助决策。即使只是看到医学图像中的不确定性也会影响某人的决定，因此考虑到这种不确定性非常重要。”麻省理工学院计算机科学博士生 Marianne Rakic 说道。&lt;/p>; &lt;p>;Rakic 是主要作者与麻省理工学院、麻省理工学院和哈佛大学博德研究所以及麻省总医院的其他人合作的一篇&lt;a href=&quot;https://arxiv.org/pdf/2401.13650.pdf&quot; target=&quot;_blank&quot;>;论文&lt;/a>;推出了一种新的人工智能工具，可以捕获医学图像中的不确定性。&lt;/p>; &lt;p>;称为 &lt;a href=&quot;https://arxiv.org/pdf/2401.13650.pdf&quot; target=&quot;_blank&quot;>;Tyche &lt;/a>;（以希腊机会神命名），该系统提供了多个看似合理的分割，每个分割都突出显示医学图像中略有不同的区域。用户可以指定 Tyche 输出的选项数量，并选择最适合其目的的选项。&lt;/p>; &lt;p>;重要的是，Tyche 可以处理新的分割任务，而无需重新训练。培其他方法。它可以“开箱即用”地应用于各种任务，从识别肺部 X 射线中的病变到查明大脑 MRI 中的异常情况。&lt;/p>; &lt;p>;最终，该系统可以改善诊断或帮助通过引起人们对其他人工智能工具可能错过的潜在关键信息的关注来进行生物医学研究。&lt;/p>; &lt;p>;“模糊性尚未得到充分研究。如果你的模型完全忽略了一个结节，而三位专家认为存在而两位专家认为不存在，那么这可能是你应该注意的事情，”哈佛医学院和麻省总医院助理教授 Adrian Dalca 和一项研究的资深作者 Adrian Dalca 补充道。麻省理工学院计算机科学和人工智能实验室 (CSAIL) 的科学家。&lt;/p>; &lt;p>;他们的合著者包括电气工程和计算机科学研究生 Hallee Wong；何塞·哈维尔·冈萨雷斯·奥尔蒂斯博士&#39;23； Beth Cimini，布罗德研究所生物图像分析副主任；约翰·古塔格 (John Guttag)，杜格尔德·杰克逊 (Dugald C. Jackson) 计算机科学和电气工程教授。 Rakic 将在 IEEE 计算机视觉和模式识别会议上介绍 Tyche，其中 Tyche 被选为一大亮点。&lt;/p>; &lt;p>;&lt;strong>;解决歧义&lt;/strong>;&lt;/p>; &lt;p>;人工智能系统医学图像分割通常使用&lt;a href=&quot;https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414&quot; target=&quot;_blank&quot;>;神经网络&lt;/a>;。神经网络松散地基于人脑，是一种机器学习模型，由许多互连的节点或神经元层组成，用于处理数据。&lt;/p>; &lt;p>;在与使用这些系统的 Broad Institute 和 MGH 的合作者交谈后，研究人员意识到有两个主要问题限制了它们的有效性。这些模型无法捕捉不确定性，即使是稍微不同的分割任务，也必须重新训练它们。&lt;/p>; &lt;p>;一些方法试图克服一个陷阱，但事实证明，用单一解决方案解决这两个问题特别棘手，Rakic 说。 ;&lt;/p>; &lt;p>;“如果你想考虑歧义性，你通常必须使用极其复杂的模型。通过我们提出的方法，我们的目标是使其易于使用相对较小的模型，以便它可以快速做出预测。&lt;/p>; &lt;p>;研究人员通过修改简单的神经网络架构构建了 Tyche .&lt;/p>; &lt;p>;用户首先向 Tyche 提供一些显示分割任务的示例。例如，示例可以包括心脏 MRI 中的多个病变图像，这些图像已由不同的人类专家分割，以便模型可以学习任务并发现是否存在歧义。&lt;/p>; &lt;p>;研究人员发现，只有 16 个示例图像（称为“上下文集”）足以让模型做出良好的预测，但可以使用的示例数量没有限制。上下文集使 Tyche 无需重新训练即可解决新任务。&lt;/p>; &lt;p>;为了让 Tyche 捕获不确定性，研究人员修改了神经网络，使其根据一幅医学图像输入和上下文集输出多个预测。他们调整了网络的层，以便当数据从一层移动到另一层时，每一步生成的候选分割可以相互“对话”，并与上下文集中的示例进行“对话”。&lt;/p>; &lt;p>;通过这种方式，模型可以确保候选分割都有点不同，但仍然可以解决任务。&lt;/p>; &lt;p>;“这就像掷骰子。如果你的模型可以掷出二、三或四，但不知道你已经有二和四，那么其中任何一个都可能会再次出现，”她说。&lt;/p>; &lt;p>;他们还修改了训练过程，因此它会通过最大化其最佳预测的质量来获得奖励。&lt;/p>; &lt;p>;如果用户要求五个预测，最后他们可以看到 Tyche 生成的所有五个医学图像分割，即使其中一个可能比&lt;/p>; &lt;p>;研究人员还开发了 Tyche 的一个版本，可以与现有的预训练模型一起用于医学图像分割。在这种情况下，Tyche 使模型能够通过对图像进行轻微的转换来输出多个候选者。&lt;/p>; &lt;p>;&lt;strong>;更好、更快的预测&lt;/strong>;&lt;/p>; &lt;p>;当研究人员使用 Tyche 进行测试时通过对带注释的医学图像的数据集进行分析，他们发现其预测捕捉到了人类注释者的多样性，并且其最佳预测优于任何基线模型。 Tyche 的表现也比大多数模型更快。&lt;/p>; &lt;p>;“输出多个候选者并确保它们彼此不同确实会给你带来优势，”Rakic 说。&lt;/p>; &lt;p>;研究人员还发现 Tyche可以超越使用大型专业数据集训练的更复杂的模型。&lt;/p>; &lt;p>;对于未来的工作，他们计划尝试使用更灵活的上下文集，可能包括文本或多种类型的图像。此外，他们希望探索可以改进 Tyche 最差预测并增强系统的方法，以便它可以推荐最佳的分割候选者。&lt;/p>; &lt;p>;这项研究的部分资金由美国国立卫生研究院 (National Institutes of Health) 资助。麻省理工学院和哈佛大学布罗德研究所的埃里克和温迪施密特中心以及广达计算机。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202404/MIT-Med-Segmentation-01-press.jpg?itok=mV4l6iH-" width="390"><media:description type="plain">来自麻省理工学院和其他地方的研究人员开发了一种机器学习框架，当被要求识别医学图像中的潜在疾病时，该框架可以生成多个看似合理的答案。通过捕获这些图像中固有的模糊性，该技术可以防止临床医生错过可以为诊断提供信息的关键信息。</media:description><media:credit>图片：麻省理工学院新闻；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/imaging">影像学</category><category domain="https://news.mit.edu/topic/health-care">卫生保健</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/broad-institute">布罗德研究所</category><category domain="https://news.mit.edu/topic/nih">美国国立卫生研究院 (NIH)</category></item><item><title>防止人工智能聊天机器人做出有毒反应的更快、更好的方法</title><link/>https://news.mit.edu/2024/faster-better-way-preventing-ai-chatbot-有毒-responses-0410<description>研究人员创建了一个好奇的机器学习模型，该模型可以找到更广泛的提示来训练聊天机器人以避免仇恨或有害的输出。</description><pubDate> Wed, 10 Apr 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/faster-better-way-preventing-ai-chatbot-有毒-responses-0410</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;用户可以要求 ChatGPT 编写计算机程序或总结文章，而 AI 聊天机器人可能能够生成有用的代码或编写令人信服的概要。然而，有人也可以请求制造炸弹的指令，而聊天机器人也可能能够提供这些指令。&lt;/p>; &lt;p>;为了防止这种安全问题和其他安全问题，构建大型语言模型的公司通常使用以下方式来保护它们：一个称为红队的过程。人类测试人员团队编写提示，旨在从正在测试的模型中触发不安全或有毒的文本。这些提示用于教导聊天机器人避免此类响应。&lt;/p>; &lt;p>;但是，只有当工程师知道要使用哪些有毒提示时，这才有效。如果人类测试人员错过了一些提示（考虑到可能性的数量），被认为安全的聊天机器人可能仍然能够生成不安全的答案。&lt;/p>; &lt;p>;麻省理工学院 Improbable AI 实验室和 MIT-IBM Watson 的研究人员AI 实验室使用机器学习来改进红队。他们开发了一种技术来训练红队大型语言模型，以自动生成各种提示，从而触发正在测试的聊天机器人发出更广泛的不良响应。&lt;/p>; &lt;p>;他们通过教导红队模型在编写提示时保持好奇心，并专注于引起目标模型毒性反应的新颖提示。&lt;/p>; &lt;p>;该技术通过生成更明显的提示来引发越来越多的毒性反应，从而优于人类测试人员和其他机器学习方法。与其他自动化方法相比，他们的方法不仅显着提高了正在测试的输入的覆盖范围，而且还可以从由人类专家内置保护措施的聊天机器人中提取有毒反应。&lt;/p>; &lt;p>;“现在，每一个大型语言模型都必须经过非常漫长的红队期，以保证其安全性。如果我们想在快速变化的环境中更新这些模型，这将是不可持续的。我们的方法提供了一种更快、更有效的方法来保证质量。”Improbable AI 实验室的电气工程和计算机科学 (EECS) 研究生、&lt;a href=&quot;https: //arxiv.org/pdf/2402.19464.pdf&quot; target=&quot;_blank&quot;>;关于这种红队方法的论文&lt;/a>;。&lt;/p>; &lt;p>;Hong 的合著者包括 EECS 研究生 Idan Shenfield、Tsun-王轩和庄永松； Aldo Pareja 和 Akash Srivastava，MIT-IBM Watson AI 实验室的研究科学家； James Glass，计算机科学与人工智能实验室（CSAIL）高级研究科学家兼口语系统组组长；资深作者 Pulkit Agrawal，Improbable AI 实验室主任，CSAIL 助理教授。该研究将在国际学习表征会议上公布。&lt;/p>; &lt;p>;&lt;strong>;自动红队&lt;/strong>; &amp;nbsp;&lt;/p>; &lt;p>;大型语言模型，例如为人工智能聊天机器人提供支持的语言模型，通常通过向他们展示来自数十亿公共网站的大量文本来进行训练。因此，他们不仅可以学会生成有毒词语或描述非法活动，而且模型还可能泄露他们可能获得的个人信息。&lt;/p>; &lt;p>;人类红队的繁琐和昂贵的本质，这通常是由于无法生成足够多的提示来完全保护模型，因此鼓励研究人员使用机器学习来自动化该过程。&lt;/p>; &lt;p>;此类技术通常使用强化学习来训练红队模型。这个试错过程会奖励红队模型生成提示，触发正在测试的聊天机器人的有毒反应。&lt;/p>; &lt;p>;但是由于强化学习的工作方式，红队模型通常会保留生成一些类似的提示，这些提示具有很高的毒性，以最大化其奖励。&lt;/p>; &lt;p>;对于他们的强化学习方法，麻省理工学院的研究人员使用了一种称为好奇心驱动探索的技术。红队模型被激励对其生成的每个提示的后果感到好奇，因此它会尝试使用不同单词、句子模式或含义的提示。&lt;/p>; &lt;p>;“如果红队模型已经看到一个特定的提示，然后复制它不会在红队模型中产生任何好奇心，因此它将被推动创建新的提示。”洪说。&lt;/p>; &lt;p>;在训练过程中，红队模型模型生成提示并与聊天机器人交互。聊天机器人做出响应，安全分类器对其响应的毒性进行评级，并根据该评级奖励红队模型。&lt;/p>; &lt;p>;&lt;strong>;奖励好奇心&lt;/strong>;&lt;/p>; &lt;p>;红队模型的目标是通过新颖的提示引发更具毒性的反应，从而最大化其奖励。研究人员通过修改强化学习设置中的奖励信号来激发红队模型的好奇心。&lt;/p>; &lt;p>;首先，除了最大化毒性之外，他们还提供了熵奖励，鼓励红队模型当它探索不同的提示时更加随机。其次，为了让代理人感到好奇，他们提供了两项新奇的奖励。一种是根据提示中单词的相似度来奖励模型，另一种是根据语义相似度来奖励模型。 （相似度越低，奖励越高。）&lt;/p>; &lt;p>;为了防止红队模型生成随机、无意义的文本（这可能会欺骗分类器授予高毒性分数），研究人员还添加了自然主义语言奖励完成这些添加后，研究人员将红队模型与其他自动化技术生成的响应的毒性和多样性进行了比较。他们的模型在这两个指标上都优于基线。&lt;/p>; &lt;p>;他们还使用红队模型来测试聊天机器人，该机器人已根据人类反馈进行了微调，因此不会给出有毒的回复。他们以好奇心为驱动的方法能够快速生成 196 个提示，从而引发这个“安全”聊天机器人的有毒反应。&lt;/p>; &lt;p>;“我们看到模型数量激增，而且预计只会增加。想象一下数千个甚至更多的模型，以及公司/实验室频繁推送模型更新。这些模型将成为我们生活中不可或缺的一部分，在发布供公众使用之前对其进行验证非常重要。模型的手动验证根本无法扩展，我们的工作是尝试减少人力，以确保更安全、值得信赖的人工智能未来。”Agrawal 说道。 &lt;/p>; &lt;p>;未来，研究人员希望使红队模型能够生成有关更广泛主题的提示。他们还想探索使用大型语言模型作为毒性分类器。通过这种方式，用户可以使用公司政策文档来训练毒性分类器，这样红队模型就可以测试聊天机器人是否违反公司政策。&lt;/p>; &lt;p>;“如果你要发布一个新的 AI Agrawal 说：“如果您正在研究模型并担心它是否会按预期运行，请考虑使用好奇心驱动的红队。”&lt;/p>; &lt;p>;这项研究的部分资金由现代汽车公司、广达电脑公司、 MIT-IBM Watson AI 实验室、Amazon Web Services MLRA 研究资助、美国陆军研究办公室、美国国防高级研究计划局机器常识计划、美国海军研究办公室、美国空军研究实验室和美国空军人工智能加速器。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202404/MIT_Red-Teaming-01-press.jpg?itok=zXW__E15" width="390"><media:description type="plain">麻省理工学院和 MIT-IBM Watson AI 实验室的研究人员利用机器学习来改进大型语言模型的保护措施。</media:description><media:credit>图片来源：Christine Daniloff，麻省理工学院；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/human-computer-interaction">人机交互</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category><category domain="https://news.mit.edu/topic/darpa">国防高级研究计划局 (DARPA)</category></item></channel></rss>