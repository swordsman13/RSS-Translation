<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2023 年 9 月 13 日星期三 04:00:00 +0000</lastbuilddate><item><title>考古方法如何帮助利用人工智能中的偏见数据来改善医学</title><link/>https://news.mit.edu/2023/how-archeological-approach-can-help-leverage-biased-data-ai-improve-medicine-0913<description>尽管计算机科学家最初可能将数据偏差和错误视为一种麻烦，但研究人员认为这是反映社会价值观的隐藏宝库。</description><pubDate> Wed, 13 Sep 2023 16:50:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/how-archeological-approach-can-help-leverage-biased-data-ai-improve-medicine-0913</guid><dc:creator>欧阳历 |安利捷健康机器学习诊所</dc:creator><content:encoded>麻省理工学院、约翰霍普金斯大学和艾伦图灵研究所的计算机科学和生物伦理学教授在一篇文章中指出，经典的计算机科学格言“垃圾进，垃圾出”在理解有偏见的医疗数据时缺乏细微差别。 “https://www.nejm.org/doi/full/10.1056/NEJMra2214964” target=&quot;_blank&quot;>;新观点文章&lt;/a>;发表在最近一期的&lt;em>;新英格兰医学杂志 (NEJM) &lt;/em>;。人工智能的普及不断增加，对导致算法歧视的有偏见的AI模型的问题进行了越来越多的审查，这是白宫科学技术办公室在最近的&lt;a href =“ https：// www中，这是一个关键问题。 Whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf&quot;>;人工智能权利法案蓝图&lt;/a>;。&lt;/p>; &lt;当遇到有偏见的数据时，特别是对于医疗环境中使用的人工智能模型，典型的反应是从代表性不足的群体中收集更多数据，或者生成弥补缺失部分的合成数据，以确保模型在一系列患者中表现同样出色人口。但作者认为，这种技术方法应该通过社会技术视角来增强，同时考虑历史和当前的社会因素。通过这样做，研究人员可以更有效地解决公共卫生方面的偏见。&lt;/p>; &lt;p>;“我们三个人一直在讨论我们经常从机器学习角度将数据问题视为烦恼的方式共同作者 Marzyeh Ghassemi 回忆道，他是电气工程和计算机科学助理教授，也是安利捷健康机器学习诊所的附属机构 (&lt;a href=&quot;https:/ /www.jclinic.mit.edu/&quot; target=&quot;_blank&quot;>;Jameel Clinic&lt;/a>;)，计算机科学和人工智能实验室 (&lt;a href=&quot;https://www.csail.mit.edu/&quot; target=&quot;_blank&quot;>;CSAIL&lt;/a>;) 和医学工程与科学研究所 (&lt;a href=&quot;https://imes.mit.edu/&quot; target=&quot;_blank&quot;>;IMES&lt;/a>;)。 “我们将数据类比为一件人工制品，它可以对过去的实践提供部分看法，或者是一面反射着镜子的破裂的镜子。在这两种情况下，信息可能并不完全准确或有利：也许我们认为我们作为一个社会以某些方式行事 - 但当你真正查看数据时，它讲述了一个不同的故事。我们可能不喜欢这个故事，但一旦你了解了过去，你就可以继续前进并采取措施解决不良做法。”&lt;/p>; &lt;p>;&lt;strong>;数据作为工件&lt;/strong >;&lt;/p>; &lt;p>;在题为“&lt;a href=&quot;https://www.nejm.org/doi/full/10.1056/NEJMra2214964&quot; target=&quot;_blank&quot;>;将有偏见的数据视为信息性工件的论文中人工智能辅助医疗保健&lt;/a>;”，Ghassemi、Kadija Ferryman 和 Maxine Mackintosh 论证了将有偏见的临床数据视为“文物”，就像人类学家或考古学家看待实物一样：揭示文明的碎片实践、信仰体系和文化价值观——就本文而言，特别是那些导致医疗保健系统中存在不平等的因素。&lt;/p>; &lt;p>;例如，&lt;a href=&quot;https:/ /pubmed.ncbi.nlm.nih.gov/31649194/&quot;>;2019 年的一项研究&lt;/a>;表明，一种被广泛认为是行业标准的算法使用医疗保健支出作为需求指标，从而得出了错误的结论：病情较重的黑人患者需要与健康的白人患者同等水平的护理。研究人员发现，算法歧视未能解释获得医疗服务的不平等。&lt;/p>; &lt;p>;在这种情况下，Ghassemi 并没有将有偏见的数据集或缺乏数据视为只需要处理或修复的问题，而是她的同事推荐使用“工件”方法来提高人们对影响数据收集方式的社会和历史因素的认识，以及临床人工智能开发的替代方法。&lt;/p>; &lt;p>;“如果模型的目标是部署在临床环境中，您应该在问题制定的早期就聘请经过适当培训的生物伦理学家或临床医生，”Ghassemi 说。 “作为计算机科学家，我们通常无法全面了解创建我们将使用的数据时所涉及的不同社会和历史因素。我们需要专业知识来辨别从现有数据推广的模型何时可能不适用于特定子组。”&lt;/p>; &lt;p>;&lt;strong>;何时更多数据实际上会损害性能&lt;/strong>;&lt;/p>; &lt;p >;作者承认，实施基于人工制品的方法更具挑战性的方面之一是能够评估数据是否经过种族纠正：即使用白人男性身体作为衡量其他身体的传统标准。该评论文章引用了 2021 年慢性肾脏病合作组织的&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7920170/&quot;>;一个例子&lt;/a>;，该合作组织开发了一种新的测量肾功能的方程，因为旧方程之前已在黑人具有更高肌肉质量的总假设下进行了“修正”。 Ghassemi 表示，研究人员应该准备好调查基于种族的校正，作为研究过程的一部分。&lt;/p>; &lt;p>;在另一篇文章中 &lt;a href=&quot;https://arxiv.org/pdf/2206.02058.pdf&quot; >;最近的论文&lt;/a>;被今年的国际机器学习会议接受，该论文由 Ghassemi 的博士生 Vinith Suriyakumar 和加州大学圣地亚哥分校助理教授 Berk Ustun 共同撰写，研究人员发现，假设包含自我属性等个性化属性，据报道，种族提高机器学习模型的性能实际上可能会导致少数族裔和少数群体的风险评分、模型和指标更差。&lt;/p>; &lt;p>;“对于是否包含自我，没有单一正确的解决方案- 临床风险评分中报告的种族。自我报告的种族是一种社会建构，它既是其他信息的代理，又在其他医疗数据中深度代理。解决方案需要符合证据。”Ghassemi 解释道。&lt;/p>; &lt;p>;&lt;strong>;如何前进&lt;/strong>;&lt;/p>; &lt;p>;这并不是说应该消除有偏见的数据集固定的或有偏见的算法不需要修复 - 高质量的训练数据仍然是开发安全、高性能临床人工智能模型的关键，&lt;em>;NEJM&lt;/em>; 文章强调了美国国立卫生研究院 (NIH) 的作用）推动道德实践。&lt;/p>; &lt;p>;“生成高质量、来源道德的数据集对于使用下一代人工智能技术至关重要，从而改变我们的研究方式，”NIH 代理主任劳伦斯塔巴克在 &lt;a href=&quot;https://www.nih.gov/news-events/news-releases/nih-launches-bridge2ai-program-expand-use-artificial-intelligence-biomedical-behavioral-research&quot;>; 中指出NIH 去年宣布其 1.3 亿美元的 Bridge2AI 计划时的新闻稿&lt;/a>;。加塞米对此表示同意，并指出美国国立卫生研究院“优先考虑以道德方式收集数据，这些数据涵盖了我们以前没有强调过的对人类健康价值的信息，例如环境因素和社会决定因素。我对他们优先考虑实现有意义的健康成果并进行大力投资感到非常兴奋。”&lt;/p>; &lt;p>;波士顿公共卫生大学副教授 Elaine Nsoesie 认为，这有很多潜在的好处将有偏见的数据集视为工件而不是垃圾，从关注上下文开始。 “乌干达一家医院为肺癌患者收集的数据集中存在的偏差可能与在美国为同一患者群体收集的数据集不同，”她解释道。 “在考虑当地情况时，我们可以训练算法以更好地服务特定人群。” Nsoesie 表示，了解塑造数据集的历史和当代因素可以更轻松地识别可能以不明显的方式编码在算法或系统中的歧视性做法。她还指出，基于工件的方法可能会导致新政策和结构的制定，确保消除特定数据集中偏见的根本原因。&lt;/p>; &lt;p>;“人们经常告诉我，他们非常害怕人工智能，尤其是在健康领域。他们会说，‘我真的很害怕人工智能误诊我’，或者‘我担心它会对我不好，’”加塞米说。 “我告诉他们，你不应该害怕明天健康领域的一些假设的人工智能，你应该害怕现在的健康状况。如果我们对从系统中提取的数据采取狭隘的技术观点，我们可能会天真地复制不良做法。这不是唯一的选择——意识到问题的存在是我们迈向更大机遇的第一步。”&amp;nbsp;&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202309/MarzyehNEJMReview1.jpg?itok=olq_YaQV" width="390"><media:description type="plain">在一篇新论文中，来自麻省理工学院、约翰霍普金斯大学和艾伦图灵研究所的计算机科学和生物伦理学教授呼吁采用另一种方法来理解医学机器学习中使用的有偏见的数据——这种方法将有偏见的临床数据视为类似于考古文物，回到社会价值观、实践和不平等模式。</media:description><media:credit>图片：Marzyeh Ghassemi 来自 Midjourney </media:credit></media:content><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/medicine">药品</category><category domain="https://news.mit.edu/topic/public-health">公共卫生</category><category domain="https://news.mit.edu/topic/health">健康科学与技术</category><category domain="https://news.mit.edu/topic/technology-society">技术与社会</category><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/ethics">伦理</category><category domain="https://news.mit.edu/topic/race-and-gender">种族和性别</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/archeology">考古学</category><category domain="https://news.mit.edu/topic/anthropology">人类学</category><category domain="https://news.mit.edu/topic/jameel-clinic">贾米尔诊所</category><category domain="https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0">医学工程与科学研究所 (IMES) </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-and-computer-science-eecs">电气工程和计算机科学（EECS）</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/nih">美国国立卫生研究院 (NIH)</category></item><item><title>帮助计算机视觉和语言模型理解他们所看到的内容</title><link/>https://news.mit.edu/2023/helping-computer-vision-language-models-see-0913<description>研究人员使用合成数据来提高模型掌握概念信息的能力，这可以增强自动字幕和问答系统。</description><pubDate> Wed, 13 Sep 2023 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/helping-computer-vision-language-models-see-0913</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;强大的机器学习算法（称为视觉和语言模型）可以学习将文本与图像进行匹配，当被要求生成字幕或总结视频时，它显示出了显着的结果。&lt;/p>; &lt;p>;虽然这些模型擅长识别对象，他们经常难以理解概念，例如对象属性或场景中项目的排列。例如，视觉和语言模型可能会识别图像中的杯子和桌子，但无法识别杯子位于桌子上。&lt;/p>; &lt;p>;来自 MIT、MIT-IBM Watson AI 实验室的研究人员，和其他地方已经展示了一种新技术，利用计算机生成的数据来帮助视觉和语言模型克服这一缺点。&lt;/p>; &lt;p>;研究人员创建了一个图像合成数据集，描绘了各种场景、物体排列和人类的行为，加上详细的文字描述。他们使用这个带注释的数据集来“修复”视觉和语言模型，以便他们可以更有效地学习概念。他们的技术确保这些模型在看到真实图像时仍然可以做出准确的预测。&lt;/p>; &lt;p>;当他们测试模型的概念理解时，研究人员发现他们的技术将准确性提高了 10%。这可以改进自动为视频添加字幕的系统，或增强为图像问题提供自然语言答案的模型，并应用于电子商务或医疗保健等领域。&lt;/p>; &lt;p>;“通过这项工作，我们将超越名词从某种意义上说，我们正在超越对象的名称，更多地涉及对象及其周围一切的语义概念。我们的想法是，当机器学习模型看到许多不同排列的对象时，它将更好地了解排列在场景中的重要性。”电气工程和计算机科学系的研究生 Khaled Shehada 说道。关于该技术的&lt;a href=&quot;http://olivalab.mit.edu/Papers/going_beyond_nouns.pdf&quot; target=&quot;_blank&quot;>;论文&lt;/a>;的合著者。&lt;/p>; &lt;p>;Shehada 写道该论文的主要作者是莱斯大学计算机科学研究生 Paola Cascante-Bonilla； Aude Oliva，麻省理工学院施瓦茨曼计算学院战略行业参与主任、麻省理工学院-IBM沃森人工智能实验室主任、计算机科学与人工智能实验室（CSAIL）高级研究科学家；资深作者 Leonid Karlinsky，MIT-IBM Watson AI 实验室的研究人员；以及麻省理工学院、麻省理工学院-IBM Watson AI 实验室、佐治亚理工学院、莱斯大学、巴黎桥大学、魏茨曼科学研究所和 IBM 研究院的其他人员。该论文将在国际计算机视觉会议上发表。&lt;/p>; &lt;p>;&lt;strong>;关注对象&lt;/strong>;&lt;/p>; &lt;p>;视觉和语言模型通常学习识别场景中的对象，并且最终可能会忽略对象属性，例如颜色和大小，或位置关系，例如哪个对象位于另一个对象之上。&lt;/p>; &lt;p>;这是由于这些模型经常训练的方法造成的，称为对比学习。这种训练方法涉及强制模型预测图像和文本之间的对应关系。在比较自然图像时，每个场景中的物体往往会产生最显着的差异。 （也许一张图片显示了田野中的一匹马，而第二张图片显示了水面上的一艘帆船。）&lt;/p>; &lt;p>;“每张图像都可以由图像中的对象唯一地定义。所以，当你进行对比学习时，只关注名词和宾语就可以解决问题。为什么模型会做出不同的事情？”卡林斯基说。&lt;/p>; &lt;p>;研究人员试图通过使用合成数据来微调视觉和语言模型来缓解这个问题。微调过程涉及调整已经过训练的模型，以提高其在特定任务上的性能。&lt;/p>; &lt;p>;他们使用计算机自动创建具有不同 3D 环境和物体（例如家具和物体）的合成视频。他们使用这些视频的各个帧生成了近 800,000 个逼真的图像，然后将每个图像与详细的标题配对。研究人员开发了一种方法来注释图像的各个方面，以在密集的字幕中清晰一致地捕获对象属性、位置关系和人与对象的交互。&lt;/p>; &lt;p>;由于研究人员创建了图像，因此他们可以控制物体的外观和位置，以及人类化身的性别、服装、姿势和动作。&lt;/p>; &lt;p>;“合成数据允许很大的多样性。使用真实图像，一个房间里可能不会有很多大象，但通过合成数据，如果你愿意，你实际上可以在一个房间里有一头粉红色的大象和一个人，”Cascante-Bonilla 说。&lt;/p>; &lt;合成数据还有其他优点。它们的生成成本比真实数据更便宜，但图像却非常逼真。他们还保护隐私，因为图像中没有显示真人。而且，由于数据是由计算机自动生成的，因此可以快速大量生成。&lt;/p>; &lt;p>;通过使用不同的相机视点，或稍微改变对象的位置或属性，研究人员创建了一个数据集，其中包含比在自然数据集中发现的场景要广泛得多。&lt;/p>; &lt;p>;&lt;strong>;微调，但不要忘记&lt;/strong>;&lt;/p>; &lt;p>;但是，当一个微调时 -使用合成数据调整模型，存在模型可能“忘记”最初使用真实数据训练时学到的内容的风险。&lt;/p>; &lt;p>;研究人员采用了一些技术来防止此问题，例如调整合成数据使颜色、光照和阴影更接近自然图像中的颜色、光照和阴影。他们还在微调后对模型的内部工作原理进行了调整，以进一步减少遗忘。&lt;/p>; &lt;p>;他们的合成数据集和微调策略将流行的视觉和语言模型准确识别概念的能力提高了高达至 10%。同时，模型并没有忘记他们已经学到的东西。&lt;/p>; &lt;p>;既然他们已经展示了如何使用合成数据来解决这个问题，研究人员希望找出提高视觉质量的方法这些数据的多样性，以及使合成场景看起来逼真的基础物理原理。此外，他们计划测试可扩展性的极限，并调查模型改进是否在更大、更多样化的合成数据集上开始趋于稳定。&lt;/p>; &lt;p>;这项研究部分由美国国防高级研究项目资助该机构、美国国家科学基金会和 MIT-IBM Watson AI 实验室。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202309/MIT-Beyond-Nouns-01-press.jpg?itok=RiJ1w3pt" width="390"><media:description type="plain">麻省理工学院的研究人员创建了一个新的带注释的合成图像数据集，描绘了各种场景，可用于帮助机器学习模型理解场景中的概念。</media:description><media:credit>由研究人员提供</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/privacy">隐私</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/nsf">美国国家科学基金会 (NSF)</category><category domain="https://news.mit.edu/topic/darpa">国防高级研究计划局 (DARPA)</category></item></channel></rss>