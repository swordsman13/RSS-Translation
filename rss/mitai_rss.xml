<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 5 月 29 日星期三 04:00:00 +0000</lastbuilddate><item><title>正在寻找视频中的特定动作？这种基于人工智能的方法可以为您找到它</title><link/>https://news.mit.edu/2024/ai-based-method-can-find-specific-video-action-0529<description>一种新方法可以简化虚拟培训流程或帮助临床医生查看诊断视频。</description><pubDate> Wed, 29 May 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/ai-based-method-can-find-specific-video-action-0529</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;互联网上充斥着教学视频，这​​些视频可以向好奇的观众传授各种知识，从烹饪完美的煎饼到执行挽救生命的海姆立克急救法。&lt;/p>;&lt;p>;但要在长视频中精确指出特定动作发生的时间和地点可能很乏味。为了简化这个过程，科学家们正在尝试教计算机执行这项任务。理想情况下，用户只需描述他们正在寻找的动作，人工智能模型就会跳到视频中的位置。&lt;/p>;&lt;p>;但是，教机器学习模型执行此操作通常需要大量的工作精心手工标记的昂贵视频数据。&lt;/p>;&lt;p>;麻省理工学院和 MIT-IBM Watson AI 实验室的研究人员采用了一种更高效的新方法来训练模型来执行此任务，称为时空模型接地，仅使用视频及其自动生成的转录本。&lt;/p>;&lt;p>;研究人员教授一个模型以两种不同的方式理解未标记的视频：通过查看小细节来找出物体所在的位置（空间信息）和查看更大的图片以了解动作何时发生（时间信息）。&lt;/p>;&lt;p>;与其他人工智能方法相比，他们的方法更准确地识别具有多个活动的较长视频中的动作。有趣的是，他们发现同时对空间和时间信息进行训练可以使模型更好地识别每个信息。&lt;/p>;&lt;p>;除了简化在线学习和虚拟培训流程之外，该技术还可以在医疗保健环境中发挥作用：例如，快速找到诊断过程视频中的关键时刻。&lt;/p>;&lt;p>;“我们解决了尝试同时编码空间和时间信息的挑战，而是像两个独立工作的专家一样思考它，这事实证明这是一种更明确的信息编码方式。我们的模型结合了这两个独立的分支，从而实现了最佳性能。”&lt;a href=&quot; https://arxiv.org/pdf/2303.16990&quot; target=&quot;_blank&quot;>;论文的主要作者 Brian Chen 说道。这项技术&lt;/a>;。&lt;/p>;&lt;p>;Chen 是哥伦比亚大学 2023 届毕业生，他在 MIT-IBM Watson AI 实验室做访问生时进行了这项研究，高级研究员 James Glass 也参与了这项研究科学家、MIT-IBM Watson AI 实验室成员、计算机科学与人工智能实验室 (CSAIL) 口语系统组组长； Hilde Kuehne，MIT-IBM Watson AI 实验室成员，隶属于法兰克福歌德大学；以及麻省理工学院、歌德大学、麻省理工学院-IBM Watson AI 实验室和 Quality Match GmbH 的其他人员。该研究将在计算机视觉和模式识别会议上公布。&lt;/p>;&lt;p>;&lt;strong>;全局和本地学习&lt;/strong>;&lt;/p>;&lt;p>;研究人员通常教授模型进行时空基础使用人类注释了特定任务的开始和结束时间的视频。&lt;/p>;&lt;p>;生成这些数据不仅成本高昂，而且人类很难准确地弄清楚要标记的内容。如果动作是“煮煎饼”，那么该动作是否在厨师开始混合面糊或将面糊倒入锅中时开始？&lt;/p>;&lt;p>;“这一次，任务可能是关于烹饪，但接下来时间，可能是关于修车。人们需要注释的领域有很多。但如果我们可以在没有标签的情况下学习所有内容，那么这就是一个更通用的解决方案。”&lt;/p>;&lt;p>;对于他们的方法，研究人员使用来自 YouTube 等网站的未标记教学视频和随附文本记录作为训练数据。这些不需要任何特殊的准备。&lt;/p>;&lt;p>;他们将训练过程分为两部分。其一，他们教授机器学习模型观看整个视频，以了解在特定时间发生的动作。这种高级信息称为全局表示。&lt;/p>;&lt;p>;第二，他们教导模型关注视频中发生动作的部分的特定区域。例如，在一个大厨房中，模型可能只需要关注厨师用来混合煎饼面糊的木勺，而不是整个柜台。这种细粒度的信息称为局部表示。&lt;/p>;&lt;p>;研究人员在他们的框架中加入了一个额外的组件，以减轻旁白和视频之间发生的不一致。也许厨师先谈论煎饼，然后再执行动作。&lt;/p>;&lt;p>;为了开发更现实的解决方案，研究人员专注于长达几分钟的未剪辑视频。相比之下，大多数人工智能技术使用几秒钟的剪辑进行训练，这些剪辑被修剪为仅显示一个动作。&lt;/p>;&lt;p>;&lt;strong>;一个新的基准&lt;/strong>;&lt;/p>;&lt;p>;但是当他们意识到在评估他们的方法时，研究人员无法找到有效的基准来在这些较长的未剪辑视频上测试模型，因此他们创建了一个。&lt;/p>;&lt;p>;为了构建基准数据集，研究人员设计了一种新的注释技术非常适合识别多步骤操作。他们让用户标记对象的交叉点，例如刀刃切番茄的点，而不是在重要对象周围画一个框。&lt;/p>;&lt;p>;“这样可以更清晰地定义并加快注释过程，从而减少了人力和成本。”Chen 说。&lt;/p>;&lt;p>;此外，让多人对同一视频进行点注释可以更好地捕捉随着时间推移发生的动作，例如倒牛奶的流量。所有注释者都不会在液体流动中标记完全相同的点。&lt;/p>;&lt;p>;当他们使用此基准来测试他们的方法时，研究人员发现它在精确定位动作方面比其他人工智能技术更准确。&lt; /p>;&lt;p>;他们的方法也更擅长关注人与物体的交互。例如，如果动作是“提供煎饼”，许多其他方法可能只关注关键对象，例如柜台上的一堆煎饼。相反，他们的方法侧重于厨师将煎饼翻转到盘子上的实际时刻。&lt;/p>;&lt;p>;现有方法严重依赖人类的标记数据，因此可扩展性不太好。这项工作朝着解决这个问题迈出了一步，通过提供使用事件中自然发生的语音来定位空间和时间中的事件的新方法。此类数据无处不在，因此理论上它将是一个强大的学习信号。然而，它通常与屏幕上的内容完全无关，这使得它很难在机器学习系统中使用。这项工作有助于解决这个问题，使研究人员在未来更容易创建使用这种形式的多模态数据的系统。”密歇根大学电气工程和计算机科学助理教授安德鲁·欧文斯（Andrew Owens）说，他没有参与这项研究。接下来，研究人员计划增强他们的方法，以便模型可以自动检测文本和旁白何时不一致，并将焦点从一种模式切换到另一种模式。他们还希望将他们的框架扩展到另一种模式。音频数据，因为动作和物体发出的声音之间通常存在很强的相关性。&lt;/p>;&lt;p>;“人工智能研究在创建像 ChatGPT 这样理解图像的模型方面取得了令人难以置信的进展，但我们在理解视频方面的进展还远远落后。这项工作代表了朝这个方向迈出的重要一步。”波士顿大学计算机科学系教授凯特·萨恩科 (Kate Saenko) 说道，她没有参与这项工作。&lt;/p>;&lt;p>;这项研究的部分资金来源是由 MIT-IBM Watson AI 实验室开发。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202405/MIT-SpatioTemporal-01-press.jpg?itok=o3abWZ5I" width="390"><media:description type="plain">麻省理工学院的研究人员开发了一种技术，可以教授机器学习模型来识别长视频中的特定动作。</media:description><media:credit>图片：麻省理工学院新闻；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/video">视频</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category></item><item><title>受控扩散模型可以改变图像中的材料属性</title><link/>https://news.mit.edu/2024/control-diffusion-model-can-change-material-properties-images-0528<description> “炼金术士”系统可以调整图像中特定对象的材质属性，从而潜在地修改视频游戏模型以适应不同的环境、微调视觉特效并使机器人训练多样化。</description><pubDate> Tue, 28 May 2024 15:30:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/control-diffusion-model-can-change-material-properties-images-0528</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p>;来自麻省理工学院计算机科学与人工智能实验室 (CSAIL) 和 Google Research 的研究人员可能刚刚施展了数字魔法——以扩散模型的形式，可以改变图像中物体的材料属性。&lt;br>;&lt;br>;该系统被称为&lt;a href=&quot;https://www.prafullsharma.net/alchemist/&quot; target=&quot;_blank&quot;>;Alchemist&lt;/a>;，允许用户改变真实图片和人工智能生成图片的四个属性：粗糙度、金属度、反照率（对象的初始基色）和透明度。作为图像到图像的扩散模型，人们可以输入任何照片，然后在-1到1的连续范围内调整每个属性以创建新的视觉效果。这些照片编辑功能可能会扩展到改进视频游戏中的模型、扩展人工智能在视觉效果方面的能力以及丰富机器人训练数据。&lt;/p>;&lt;p>;Alchemist 背后的魔力始于去噪扩散模型：在实践中，研究人员使用了 Stable Diffusion 1.5，这是一种文本到图像模型，因其逼真的结果和编辑功能而备受赞誉。之前的工作建立在流行模型的基础上，使用户能够进行更高级别的更改，例如交换对象或更改图像的深度。相比之下，CSAIL 和 Google Research 的方法应用此模型来专注于低级属性，通过独特的、基于滑块的界面修改对象材料属性的更精细细节，该界面优于同类产品。&lt;br>;&lt;br>;而先前的扩散系统可以从帽子里拉出一只众所周知的兔子来拍摄图像，炼金术士可以将同一只动物变成半透明的。该系统还可以使橡皮鸭呈现出金属质感，去除金鱼的金色，并使旧鞋子闪闪发亮。 Photoshop 等程序具有类似的功能，但该模型可以以更直接的方式更改材质属性。例如，修改照片的金属外观需要在广泛使用的应用程序中执行几个步骤。&lt;/p>;&lt;p>;“当您查看自己创建的图像时，结果通常并不完全是您想要的，麻省理工学院电气工程和计算机科学博士生、CSAIL 附属机构、描述这项工作的新论文的主要作者 Prafull Sharma 说道。 “你想在编辑图片时控制图片，但图像编辑器中的现有控件无法更改材质。通过 Alchemist，我们利用了文本到图像模型输出的真实感，并梳理出了一个滑块控件，该控件允许我们在提供初始图片后修改特定属性。”&lt;/p>;&lt;p>;&lt;strong>;精确控制&lt;/strong>;&lt;/p>;&lt;p>;“文本到图像生成模型使日常用户能够像写句子一样轻松地生成图像。然而，控制这些模型可能具有挑战性，”卡内基梅隆大学助理教授 Jun-Yan Zhu（未参与该论文）说道。 “虽然生成花瓶很简单，但合成具有特定材料属性（例如透明度和粗糙度）的花瓶需要用户花费数小时尝试不同的文本提示和随机种子。这可能会令人沮丧，尤其是对于需要精确工作的专业用户而言。 Alchemist 为这一挑战提供了一个实用的解决方案，它能够精确控制输入图像的材质，同时利用大规模扩散模型的数据驱动先验，启发未来的工作，将生成模型无缝地融入到常用内容创建的现有界面中Alchemist 的设计能力可以帮助调整视频游戏中不同模型的外观。在这个领域应用这种扩散模型可以帮助创作者加快设计过程，细化纹理以适应关卡的游戏玩法。此外，Sharma 和他的团队的项目可以协助改变图形设计元素、视频和电影效果，以增强照片真实感并精确实现所需的材料外观。&lt;/p>;&lt;p>;该方法还可以针对诸如操纵。通过向机器引入更多纹理，他们可以更好地理解他们在现实世界中掌握的各种物品。 Alchemist 甚至可以帮助图像分类，分析神经网络无法识别图像材料变化的位置。&lt;/p>;&lt;p>;Sharma 和他的团队的工作超越了类似的模型，仅忠实地编辑了所请求的感兴趣对象。例如，当用户提示不同的模型将海豚调整到最大透明度时，只有 Alchemist 实现了这一壮举，同时保持海洋背景未经编辑。当研究人员使用与他们的比较方法相同的数据训练可比较的扩散模型 InstructPix2Pix 时，他们发现 Alchemist 取得了更高的准确度分数。同样，一项用户研究表明，MIT 模型更受青睐，并且比其对应模型更逼真。&lt;/p>;&lt;p>;&lt;strong>;利用合成数据保持真实&lt;/strong>;&lt;/p>;&lt;p>;根据研究人员认为，收集真实数据是不切实际的。相反，他们在合成数据集上训练模型，在流行的计算机图形设计工具 Blender 中随机编辑应用于 100 个公开可用的独特 3D 对象的 1,200 种材质的材质属性。&lt;br>;&lt;br>;“生成式 AI 的控制迄今为止，图像合成一直受到文本描述的限制。”麻省理工学院电气工程和计算机科学系 (EECS) 的 Amar Bose 计算教授、CSAIL 成员、该论文的高级作者 Frédo Durand 说道。 “这项工作为从几十年的计算机图形学研究中继承下来的视觉属性开辟了新的、更细粒度的控制。”&lt;br>;&lt;br>;“Alchemist 是一种使机器学习和扩散模型变得实用和有用的技术。 CGI 社区和图形设计师，”Google Research 高级软件工程师兼合著者 Mark Matthews 补充道，“如果没有它，你就会陷入这种无法控制的随机性，这可能会很有趣，但在某些时候，你需要这样做。完成真正的工作并让它服从创造性的愿景。”&lt;/p>;&lt;p>;Sharma 的最新项目是在他领导 &lt;a href=&quot;https://news.mit.edu/2023/researchers- recognize-similar-materials-images-0523&quot;>;&lt;u>;Materialistic&lt;/u>;&lt;/a>;，一种可以识别图像中相似材料的机器学习方法。之前的工作演示了 AI 模型如何完善其材料理解技能，并且与 Alchemist 一样，在 Blender 的 3D 模型合成数据集上进行了微调。&lt;/p>;&lt;p>;不过，Alchemist 目前仍存在一些局限性。该模型很难正确推断光照，因此有时无法遵循用户的输入。夏尔马指出，这种方法有时也会产生物理上令人难以置信的透明度。例如，想象一只手部分位于麦片盒内 - 在 Alchemist 对此属性的最大设置下，您会看到一个透明的容器，而手指伸不进去。&lt;br>;&lt;br>;研究人员希望扩展这样的模型如何可以改进场景级别图形的 3D 资源。此外，Alchemist 可以帮助从图像推断材料属性。 Sharma 表示，这类工作可以在未来解锁物体视觉和机械特征之间的联系。&lt;/p>;&lt;p>;麻省理工学院 EECS 教授和 CSAIL 成员 William T. Freeman 也是一位资深作者，加入了 Varun Jampani，并且Google 研究科学家 Yuanzhen Li 博士 &#39;09、Xuhui Jia 和 Dmitry Lagun。这项工作部分得到了国家科学基金会的资助以及谷歌和亚马逊的捐赠的支持。该小组的工作将在 6 月份的 CVPR 会议上得到重点关注。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202404/MIT-csail-Alchemist.png?itok=h8FHUwDD" width="390"><media:description type="plain">麻省理工学院 CSAIL 研究人员帮助开发了一种扩散模型，该模型可以改变图像中物体的四种材质属性：粗糙度、金属度、反照率和透明度。</media:description><media:credit>图片来源：Alex Shipps/MIT CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/games">游戏</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/imaging">影像学</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/computer-graphics">电脑图像</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category></item></channel></rss>