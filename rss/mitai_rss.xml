<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 6 月 11 日，星期二 14:10:00 -0400</lastbuilddate><item><title>新算法仅通过观看视频即可发现语言</title><link/>https://news.mit.edu/2024/denseav-algorithm-discovers-language-just-watching-videos-0611<description> DenseAV 由麻省理工学院开发，仅通过观看人们说话的视频来学习解析和理解语言的含义，在多媒体搜索、语言学习和机器人技术方面具有潜在的应用。</description><pubDate> Tue, 11 Jun 2024 14:10:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/denseav-algorithm-discovers-language-just-watching-videos-0611</guid><dc:creator>雷切尔戈登|麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p dir=&quot;ltr&quot;>;马克·汉密尔顿 (Mark Hamilton) 是麻省理工学院电气工程和计算机科学专业的博士生，也是麻省理工学院计算机科学和人工智能实验室 (CSAIL) 的附属机构，他希望利用机器来了解动物如何交流。为此，他首先着手创建一个可以“从头开始”学习人类语言的系统。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“有趣的是，灵感的关键时刻来自电影《三月》企鹅。&#39;有一个场景，一只企鹅在穿过冰面时摔倒，然后在爬起来时发出轻微的痛苦呻吟。当你观看它时，几乎很明显这个呻吟声代表了一个四个字母的单词。那一刻我们想到，也许我们需要使用音频和视频来学习语言。”汉密尔顿说。 “有没有一种方法可以让算法整天看电视，并从中找出我们在谈论的内容？”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“我们的模型‘DenseAV’旨在学习通过根据所听到的内容预测所看到的内容来学习语言，反之亦然。例如，如果您听到有人说“以 350 度烘烤蛋糕”，那么您可能看到的是蛋糕或烤箱。为了在数百万个视频中成功完成这款音频视频匹配游戏，该模型必须了解人们在谈论什么。”Hamilton 说道。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;一旦他们在这款匹配游戏上训练了 DenseAV，汉密尔顿和他的同事们研究了模型在听到声音时会寻找哪些像素。例如，当有人说“狗”时，算法立即开始在视频流中寻找狗。通过查看算法选择了哪些像素，人们可以发现算法认为一个词的含义。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;有趣的是，当 DenseAV 听狗叫时，会发生类似的搜索过程：它会搜索对于视频流中的狗。 “这引起了我们的兴趣。我们想看看算法是否知道“狗”这个词和狗的叫声之间的区别，”汉密尔顿说。该团队通过为 DenseAV 提供“双面大脑”来探索这一问题。有趣的是，他们发现 DenseAV 大脑的一侧自然地专注于语言，例如“狗”这个词，而另一侧则专注于诸如吠叫之类的声音。这表明 DenseAV 不仅学习了单词的含义和声音的位置，还学会了区分这些类型的跨模式连接，所有这些都无需人工干预或任何书面语言知识。&lt;/p>;&lt;p dir= “ltr&quot;>;应用程序的一个分支是从每天发布到互联网上的大量视频中学习：“我们希望系统能够从大量视频内容中学习，例如教学视频，”汉密尔顿说。 “另一个令人兴奋的应用是理解新语言，例如海豚或鲸鱼的交流，它们没有书面的交流形式。我们希望 DenseAV 能够帮助我们理解这些从一开始就逃避人工翻译工作的语言。最后，我们希望这种方法可以用于发现其他信号对之间的模式，例如地球发出的地震声音及其地质情况。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;摆在面前的是艰巨的挑战团队简介：无需任何文本输入即可学习语言。他们的目标是从空白中重新发现语言的含义，避免使用预先训练的语言模型。这种方法的灵感来自于儿童如何通过观察和聆听环境来理解语言。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;为了实现这一壮举，DenseAV 使用两个主要组件来分别处理音频和视觉数据。这种分离使得算法不可能通过让视觉侧查看音频来作弊，反之亦然。它迫使算法识别物体，并为音频和视觉信号创建详细且有意义的特征。 DenseAV 通过比较音频和视觉信号对来学习，以找出哪些信号匹配、哪些信号不匹配。这种方法称为对比学习，不需要标记示例，并且允许 DenseAV 找出语言本身的重要预测模式。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;DenseAV 与以前的算法之间的一个主要区别是先前的作品集中于声音和图像之间相似性的单一概念。匹配了一个完整的音频片段，例如有人说“狗坐在草地上”到狗的完整图像。这不允许以前的方法发现细粒度的细节，比如“草”这个词和狗下面的草之间的联系。该团队的算法搜索并聚合音频剪辑和图像像素之间所有可能的匹配。这不仅提高了性能，而且使团队能够以以前的算法无法做到的方式精确定位声音。 “传统方法使用单一类别标记，但我们的方法会比较每个像素和每一秒的声音。这种细粒度的方法让 DenseAV 能够建立更详细的连接，以实现更好的本地化。”Hamilton 说道。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;研究人员在包含 200 万个 YouTube 视频的 AudioSet 上训练 DenseAV。他们还创建了新的数据集来测试模型链接声音和图像的能力。在这些测试中，DenseAV 在从名称和声音识别物体等任务中表现优于其他顶级模型，证明了其有效性。 “以前的数据集仅支持粗略评估，因此我们使用语义分割数据集创建了一个数据集。这有助于进行像素完美的注释，以精确评估我们的模型的性能。我们可以用特定的声音或图像提示算法，并获得详细的定位。”Hamilton 说道。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;由于涉及大量数据，该项目大约花了一年时间才完成。该团队表示，过渡到大型变压器架构带来了挑战，因为这些模型很容易忽略细粒度的细节。鼓励模型关注这些细节是一个重大障碍。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;展望未来，该团队的目标是创建可以从大量视频或纯音频数据中学习的系统。这对于新领域来说至关重要，因为新领域有很多两种模式，但不是同时存在。他们还旨在使用更大的骨干网来扩展此功能，并可能整合语言模型中的知识以提高性能。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“识别和分割图像中的视觉对象以及环境声音和口语单词在音频录音中，每个问题本身都是困难的。历史上，研究人员依赖昂贵的、人工提供的注释来训练机器学习模型来完成这些任务，”德克萨斯大学奥斯汀分校计算机科学助理教授 David Harwath 说，他没有参与这项工作。 “DenseAV 在开发方法方面取得了重大进展，这些方法可以通过简单地通过视觉和声音观察世界来学习同时解决这些任务 - 基于我们看到并与之互动的事物经常发出声音的洞察力，并且我们还使用口语进行交谈关于他们。该模型也不对正在使用的特定语言做出任何假设，因此原则上可以从任何语言的数据中学习。看到 DenseAV 可以通过将其扩展到数千或数百万小时的多种语言视频数据来学习什么，这将是令人兴奋的。”&lt;/p>;&lt;p dir=&quot;ltr&quot;>;&lt;a href= “https://arxiv.org/abs/2406.05629&quot;>;描述这项工作的论文&lt;/a>;是牛津大学计算机视觉工程教授 Andrew Zisserman； John R. Hershey，谷歌人工智能感知研究员； William T. Freeman，麻省理工学院电气工程和计算机科学教授兼 CSAIL 首席研究员。他们的研究部分得到了美国国家科学基金会、英国皇家学会研究教授职位和 EPSRC 视觉人工智能项目资助的支持。这项工作将于本月在 IEEE/CVF 计算机视觉和模式识别会议上展示。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202406/DenseAV.jpg?itok=VoJbcJhL" width="390"><media:description type="plain"> DenseAV 算法仅通过关联音频和视频信号来学习语言的含义</media:description><media:credit>图片：马克·汉密尔顿</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/imaging">影像学</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item><item><title>帮助机器人应对不可预测的情况</title><link/>https://news.mit.edu/2024/helping-robots-grasp-unpredictable-0603<description>麻省理工学院 CSAIL 的节俭深度学习模型推断出物体隐藏的物理属性，然后进行调整，为机器人在家庭和履行中心等非结构化环境中找到最稳定的抓握方式。</description><pubDate> Mon, 03 Jun 2024 15:20:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/helping-robots-grasp-unpredictable-0603</guid><dc:creator>亚历克斯·希普斯 |麻省理工学院CSAIL</dc:creator><content:encoded> &lt;p dir=&quot;ltr&quot; id=&quot;docs-internal-guid-a7b7b40c-7fff-662e-9296-024994db96ca&quot;>;当机器人遇到不熟悉的物体时，它们很难解释一个简单的事实：外表并不代表一切。他们可能会尝试抓住一个区块，却发现它是一个&lt;a href=&quot;https://www.businessinsider.com/cake-memes-twitter-fondant-realistic-tasty-viral-video-explained-2020- 7&quot;>;字面上的小菜一碟&lt;/a>;。该物体的误导性外观可能会导致机器人错误地计算物体的重量和质心等物理属性，使用错误的抓握方式并施加超出所需的力。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;要看清这一点麻省理工学院计算机科学与人工智能实验室 (CSAIL) 的研究人员设计了&lt;a href=&quot;http://groups.csail.mit.edu/rrg/papers/noseworthy_shaw_icra24.pdf&quot; target=&quot;_blank&quot;>;抓取神经过程&lt; /a>;，一个预测物理模型，能够实时推断这些隐藏的特征，以实现更智能的机器人抓取。基于有限的交互数据，他们的深度学习系统可以在仓库和家庭等领域为机器人提供帮助，而其计算成本仅为以前算法和统计模型的一小部分。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;抓取神经过程经过训练，可以从尝试抓取的历史中推断出不可见的物理属性，并使用推断出的属性来猜测哪些抓取在未来会发挥作用。先前的模型通常仅从视觉数据中识别机器人的抓取动作。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;通常，推断物理属性的方法建立在传统统计方法的基础上，而传统统计方法需要许多已知的抓取动作和大量的计算时间才能发挥作用出色地。抓取神经过程使这些机器能够通过使用少得多的交互数据来更有效地执行良好的抓取，并在不到十分之一秒的时间内完成计算，而传统方法则需要几秒（或几分钟）。&lt;br>;&lt;br>;研究人员指出，抓取神经过程在家庭和仓库等非结构化环境中蓬勃发展，因为两者都容纳了大量不可预测的物体。例如，由麻省理工学院模型驱动的机器人可以快速学习如何处理装有不同食物数量的紧密包装的盒子，而无需看到盒子的内部，然后将它们放置在需要的地方。在配送中心，具有不同物理属性和几何形状的物体将被放置在相应的盒子中，然后运送给客户。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;经过 1,000 个独特的几何形状和 5,000 个物体的训练，Grasping Neural Process 在模拟中对 ShapeNet 存储库中生成的新颖 3D 对象实现了稳定的掌握。然后，CSAIL 领导的小组通过两个加权块在物理世界中测试了他们的模型，他们的工作优于仅考虑对象几何形状的基线。在事先限制了 10 次实验性抓取的情况下，机械臂在 20 次尝试中分别成功抓取了 18 和 19 次盒子，而机器在毫无准备的情况下仅实现了 8 和 15 次稳定抓取。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;虽然不像演员那么戏剧化，但完成推理任务的机器人也有一个由三部分组成的行为：训练、适应和测试。在训练步骤中，机器人在一组固定的物体上进行练习，并学习如何从成功（或不成功）抓取的历史中推断物理属性。新的 CSAIL 模型分摊了对象物理的推理，这意味着它训练神经网络来学习预测原本昂贵的统计算法的输出。只需要通过具有有限交互数据的神经网络进行一次传递，就可以模拟和预测哪种抓取在不同的物体上效果最好。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;然后，在适应阶段。在此步骤中，抓取神经过程帮助机器人进行实验并相应地更新其位置，了解哪些抓取效果最好。这个修补阶段为机器准备最后一步：测试，机器人在对其属性有了新的理解的情况下正式执行一项任务。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;“作为一名工程师，这是不明智的假设机器人知道成功抓取所需的所有必要信息，”主要作者、麻省理工学院电气工程和计算机科学 (EECS) 博士生、CSAIL 附属机构 Michael Noseworthy 说道。 “如果没有人类标记物体的属性，机器人传统上需要使用成本高昂的推理过程。”主要作者、EECS 博士生和 CSAIL 附属机构 Seiji Shaw 表示，他们的抓取神经过程可能是一种简化的替代方案：“我们的模型可以帮助机器人更有效地完成这项工作，使机器人能够想象哪些抓取会带来最佳结果。 ”&amp;nbsp;&lt;br>;&lt;br>;“为了让机器人走出实验室或仓库等受控空间并进入现实世界，它们必须能够更好地处理未知事物，并且不太可能因编程的微小变化而失败。这项工作是实现机器人技术全面变革潜力的关键一步。”美国陆军 DEVCOM 陆军研究实验室的自主机器人研究员 Chad Kessens 表示，该实验室赞助了这项工作。&lt;/p>;&lt;p dir=&quot;ltr&quot;>;虽然他们的模型可以帮助机器人有效地推断隐藏的静态属性，但研究人员希望增强系统，以针对多个任务和具有动态特征的物体实时调整抓握力。他们设想他们的工作最终会协助完成长期计划中的几项任务，比如拿起一根胡萝卜并切碎它。此外，他们的模型可以适应不太静态的物体的质量分布变化，例如当你装满一个空瓶子时。&lt;br>;&lt;br>;加入该论文研究人员的还有麻省理工学院航空航天学教授兼 CSAIL 成员尼古拉斯·罗伊 (Nicholas Roy) ，是一位资深作家。该小组最近在 IEEE 国际机器人与自动化会议上&lt;a href=&quot;http://groups.csail.mit.edu/rrg/papers/noseworthy_shaw_icra24.pdf&quot; target=&quot;_blank&quot;>;展示了这项工作&lt;/a>; .&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202405/grasping-neural-process.png?itok=wjDyX09T" width="390"><media:description type="plain">抓取神经过程使用有限的交互数据来帮助机器人实时理解不清楚的物体。</media:description><media:credit>图片来源：Alex Shipps/MIT CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/robotics">机器人技术</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/aeronautics">航空航天工程</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item></channel></rss>