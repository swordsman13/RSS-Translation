<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2023 年 12 月 20 日星期三 00:00:00 -0500</lastbuilddate><item><title>平流层安全标准：航空业如何引导健康领域人工智能的监管</title><link/>https://news.mit.edu/2024/stratospheric-safety-standards-how-aviation-could-steer-ai-health-regulation-0117<description>一个跨学科的研究团队认为，健康人工智能可以从航空业悠久的历史中来之不易的经验教训中受益，这些经验教训创造了当今最安全的活动之一。</description><pubDate> Wed, 17 Jan 2024 12:50:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/stratospheric-safety-standards-how-aviation-could-steer-ai-health-regulation-0117</guid><dc:creator>欧阳历 |安利捷健康机器学习诊所</dc:creator><content:encoded>&lt;p>;死于飞机失事的可能性有多大？根据国际航空运输协会发布的2022年报告，行业死亡风险为0.11。换句话说，平均而言，一个人需要连续 25,214 年每天乘坐一次航班，才有 100% 的机会遭遇致命事故。长期以来，严格监管的航空业被誉为最安全的交通方式之一，麻省理工学院的科学家们认为，它可能是监管医疗保健领域人工智能的关键。&lt;/p>; &lt;p>;Marzyeh Ghassemi，麻省理工学院助理教授麻省理工学院电气工程与计算机科学系 (EECS) 和医学工程科学研究所以及麻省理工学院航空航天学 HN Slater 教授 Julie Shah 都对人工智能模型透明度的挑战感兴趣。 2023 年初聊天后，他们意识到航空可以作为一种模式，确保边缘化患者不会受到有偏见的人工智能模型的伤害。&lt;/p>; &lt;p>;Ghassemi，也是麻省理工学院的首席研究员安利捷健康机器学习诊所 (Jameel Clinic) 和计算机科学与人工智能实验室 (CSAIL)，Shah 随后在麻省理工学院、斯坦福大学、联合会中招募了一支由研究人员、律师和政策分析师组成的跨学科团队美国科学家、埃默里大学、阿德莱德大学、微软和加州大学旧金山分校启动了一个研究项目，&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3617694.3623224&quot; target=&quot;_blank&quot;>;其结果&lt;/a>;最近被算法、机制和优化会议的公平和访问所接受。&lt;/p>; &lt;p>;“我认为我们的许多合著者都对人工智能感到兴奋第一作者 Elizabeth Bondi-Kelly 说，她现在是密歇根大学 EECS 助理教授，项目开始时是 Ghassemi 实验室的博士后。 “但我们也持谨慎态度，希望开发框架来管理部署开始时的潜在风险，因此我们正在为此类框架寻找灵感。”&lt;/p>; &lt;p>;当今健康领域的人工智能与其中的相似之处麻省理工学院航空航天系博士生林赛·桑尼曼（Lindsay Sanneman）表示，航空业已经是一个世纪前的事了。尽管 20 年代被称为“航空黄金时代”，&lt;a href=&quot;https://www.mackinac.org/V2003-30&quot; target=&quot;_blank&quot;>;致命事故“数量惊人”&lt;/a >; 根据麦基诺公共政策中心的说法。&lt;/p>; &lt;p>;美国国家运输安全委员会 (NTSB) 安全建议部门现任负责人 Jeff Marcus 最近发布了 &lt;a href=&quot;https:/ /safetycompass.wordpress.com/2023/11/27/how-tragedy-led-to-trust-national-aviation-history-month/&quot;>;一篇全国航空月博客文章&lt;/a>;指出，虽然有一些致命的事故虽然事故发生在 20 年代，但 1929 年仍然是历史上致命航空事故最多的“有记录以来最糟糕的一年”，报告了 51 起事故。按照今天的标准，每年将发生 7,000 起事故，即每天 20 起。为了应对 20 年代大量的致命事故，卡尔文·柯立芝总统于 1926 年通过了具有里程碑意义的立法，即《航空商务法》，该法案将通过商务部规范航空旅行。&lt;/p>; &lt;p>;但是相似之处还不止于此——航空业随后的自动化之路与人工智能相似。鉴于人工智能臭名昭著的“黑匣子”问题，人工智能的可解释性一直是一个有争议的话题，人工智能研究人员争论人工智能模型必须在多大程度上向用户“解释”其结果，否则可能会导致用户盲目遵循模型的指导。 &amp;nbsp;&lt;/p>; &lt;p>;“在 20 世纪 70 年代，自动化......自动驾驶系统的数量不断增加，负责向飞行员发出风险警告，”Sanneman 补充道。 “随着自动化进入航空领域，在人类与自主系统的交互方面出现了一些成长的烦恼——当飞行员对自动化正在做什么没有敏锐的认识时，就会出现潜在的混乱。”&lt;/p>; &lt;如今，成为一名商业航空公司机长需要 1,500 小时的飞行记录以及仪表培训。根据研究人员的&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3617694.3623224&quot; target=&quot;_blank&quot;>;论文&lt;/a>;，这个严格而全面的过程大约需要 15 年，包括学士学位和副驾驶学位。研究人员认为，广泛的试点培训的成功可能成为培训医生在临床环境中使用人工智能工具的潜在模式。&lt;/p>; &lt;p>;该论文还提出了令人鼓舞的关于不安全健康人工智能工具的报告，以联邦机构的方式航空局 (FAA) 通过“有限豁免”为飞行员提供服务，允许飞行员在做出不安全的事情（只要是无意的）后保留其执照。&lt;/p>; &lt;p>;根据 &lt;a href=世界卫生组织发布的“https://iris.who.int/bitstream/handle/10665/343477/9789240032705-eng.pdf?sequence=1&quot;>;2023年报告&lt;/a>;，平均每10人中就有1人在高收入国家，患者在接受医院护理时会受到不良事件（即“医疗错误”）的伤害。&lt;/p>; &lt;p>;然而，在当前的医疗保健实践中，临床医生和卫生保健工作者常常担心报告医疗事故错误，不仅是因为与内疚和自我批评有关的担忧，还因为强调对个人的惩罚，例如吊销行医执照，而不是改革导致医疗错误更容易发生的制度的负面后果。 ;&amp;nbsp;&lt;/p>; &lt;p>;“在健康方面，当锤子失手时，患者就会受苦，”加塞米在最近的一篇文章中写道 &lt;a href=&quot;https://www.nature.com/articles/s41562-023-01721 -7&quot; target=&quot;_blank&quot;>;评论发表于&lt;em>;自然人类行为&lt;/em>;&lt;/a>;。 “这一现实给医疗人工智能社区带来了不可接受的道德风险，他们已经在努力解决复杂的护理问题、人员短缺和系统负担过重的问题。”&lt;/p>; &lt;p>;Grace Wickerson，合著者兼健康公平政策经理美国科学家联合会认为这篇新论文是对尚未到位的更广泛治理框架的重要补充。 “我认为我们可以利用现有的政府权力做很多事情，”他们说。 “医疗保险和医疗补助可以通过不同的方式支付健康人工智能的费用，以确保在购买或报销技术时考虑到公平性，NIH（美国国立卫生研究院）可以资助更多研究，使算法更加公平，并为这些算法建立标准然后，FDA [食品和药物管理局] 可以使用这些信息，因为他们试图弄清楚健康公平的含义以及如何在当前的权限内对其进行监管。”&lt;/p>; &lt;p>;除此之外，该论文列出了现有的六个可以帮助监管健康人工智能的主要政府机构，包括：FDA、联邦贸易委员会（FTC）、最近成立的健康高级研究项目局、医疗保健研究和质量局、医疗保险中心以及医疗补助、卫生与公众服务部以及民权办公室 (OCR)。&lt;/p>; &lt;p>;但威克森表示，还需要做更多的工作。在威克森看来，撰写这篇论文最具挑战性的部分是“想象我们还没有的东西。”&lt;/p>; &lt;p>;该论文还建议建立一个机制，而不是仅仅依赖现有的监管机构。一个独立的审计机构，类似于 NTSB，允许对出现故障的健康人工智能系统进行安全审计。&lt;/p>; &lt;p>;“我认为这是技术治理当前的问题 - 我们还没有真正的实体自 20 世纪 90 年代以来，该机构一直在评估技术的影响，”Wickerson 补充道。 “曾经有一个技术评估办公室......在数字时代甚至开始之前，这个办公室就已经存在，然后联邦政府允许它关闭。”&lt;/p>; &lt;p>;扎克·哈尼德 (Zach Harned)，合著者和斯坦福大学法学院的应届毕业生认为，新兴技术的主要挑战是技术发展超过监管。 “然而，人工智能技术的重要性及其带来的潜在好处和风险，特别是在医疗保健领域，已经引发了一系列监管努力，”哈内德说。 “FDA 显然是这方面的主要参与者，他们不断发布指南和白皮书，试图说明他们在人工智能方面不断变化的立场；然而，隐私将是另一个值得关注的重要领域，OCR 对 HIPAA [健康保险流通与责任法案] 方面的执法，以及 FTC 对非 HIPAA 覆盖实体的隐私侵犯行为的执法。”&lt;/p>; &lt;p>; Harned 指出，该地区正在快速发展，包括最近的白宫等发展 &lt;a href=&quot;https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order- on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/&quot;>;关于人工智能的安全和值得信赖的发展以及欧洲监管活动的第 14110 号行政命令&lt;/a>;联盟（欧盟），包括即将敲定的欧盟人工智能法案的顶点。他说：“看到这项重要技术得到开发和监管，以确保安全，同时又不会扼杀创新，这无疑是一个激动人心的时刻。”&lt;/p>; &lt;p>;除了监管活动之外，本文还提出了其他创造机会对更安全的健康人工智能工具的激励，例如按绩效付费计划，保险公司奖励表现良好的医院（尽管研究人员认识到这种方法需要额外的监督才能公平）。&lt;/p>; &lt;那么研究人员认为创建一个健康人工智能的有效监管系统需要多长时间？根据该论文，“美国国家运输安全委员会 (NTSB) 和美国联邦航空局 (FAA) 系统是由国会在数十年的时间里创建的，调查和执法由两个不同的机构负责。”&lt;/p>; &lt;p>;邦迪-凯利希望这篇论文能够人工智能监管之谜。在她看来，“梦想的场景是我们所有人都阅读了这篇论文，并受到启发，应用航空领域的一些有用的经验教训，帮助人工智能预防部署过程中的一些潜在的人工智能危害。”&lt;/p>; &lt;p >;除了 Ghassemi、Shah、Bondi-Kelly 和 Sanneman 之外，麻省理工学院这项工作的共同作者还包括高级研究科学家 Leo Anthony Celi 以及前博士后 Thomas Hartvigsen 和 Swami Sankaranarayanan。这项工作的部分资金来自麻省理工学院 CSAIL METEOR 奖学金、广达计算公司、大众基金会、美国国立卫生研究院、赫尔曼·LF·冯·亥姆霍兹职业发展教授职位和 CIFAR Azrieli 全球学者奖。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202312/airplane-laptop.jpg?itok=ankyxWam" width="390"><media:description type="plain">人工智能有潜力改善医疗保健的许多方面，从患者安全到临床医生工作流程。航空业的安全文化可以显着降低与健康领域人工智能部署相关的风险。</media:description><media:credit>图片来源：Adobe Stock</media:credit></media:content><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/digital-technology">数字技术</category><category domain="https://news.mit.edu/topic/aviation">航空</category><category domain="https://news.mit.edu/topic/technology-society">技术与社会</category><category domain="https://news.mit.edu/topic/health-care">卫生保健</category><category domain="https://news.mit.edu/topic/aeronautics">航空航天工程</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/technology-and-policy">技术与政策</category><category domain="https://news.mit.edu/topic/ethics">伦理</category><category domain="https://news.mit.edu/topic/jameel-clinic">贾米尔诊所</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0">医学工程与科学研究所 (IMES)</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item><item><title>人工智能代理帮助解释其他人工智能系统</title><link/>https://news.mit.edu/2024/ai-agents-help-explain-other-ai-systems-0103<description>麻省理工学院的研究人员介绍了一种使用人工智能自动解释复杂神经网络的方法。</description><pubDate> Wed, 03 Jan 2024 15:10:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/ai-agents-help-explain-other-ai-systems-0103</guid><dc:creator>雷切尔戈登|麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;解释经过训练的神经网络的行为仍然是一个引人注目的难题，特别是随着这些模型的规模和复杂性不断增长。与历史上的其他科学挑战一样，对人工智能系统的工作方式进行逆向工程需要大量的实验：做出假设、干预行为，甚至剖析大型网络以检查单个神经元。迄今为止，大多数成功的实验都涉及大量的人类监督。解释 GPT-4 及更大大小的模型内部的每项计算几乎肯定需要更多的自动化——甚至可能使用人工智能模型本身。&lt;/p>; &lt;p>;麻省理工学院计算机科学和人工智能实验室的研究人员为这项及时的努力提供了便利(CSAIL) 开发了一种新颖的方法，使用人工智能模型在其他系统上进行实验并解释它们的行为。他们的方法使用根据预先训练的语言模型构建的代理来对经过训练的网络内的计算产生直观的解释。&lt;/p>; &lt;p>;该策略的核心是“自动可解释性代理”（AIA），旨在模仿科学家的实验过程。可解释性代理计划并在其他计算系统上执行测试，其规模范围从单个神经元到整个模型，以便以各种形式对这些系统进行解释：对系统做什么和哪里失败的语言描述，以及重现系统行为的代码。与被动分类或总结示例的现有可解释性程序不同，AIA 主动参与假设形成、实验测试和迭代学习，从而实时完善对其他系统的理解。&lt;/p>; &lt;p>;补充 AIA 方法是新的“函数解释和描述”(&lt;a href=&quot;https://multimodal-interpretability.csail.mit.edu/FIND-benchmark/&quot; target=&quot;_blank&quot;>;FIND&lt;/a>;) 基准测试，一项测试类似于经过训练的网络内的计算的函数床，以及对其行为的附带描述。评估现实世界网络组件描述质量的一个关键挑战是，描述的好坏取决于其解释能力：研究人员无法获得单元的真实标签或描述学会了计算。 FIND 通过提供评估可解释性程序的可靠标准来解决该领域长期存在的问题：可以根据基准中的函数描述来评估函数的解释（例如，由 AIA 生成）。 &lt;/p>; &lt;例如，FIND 包含旨在模仿语言模型内真实神经元行为的合成神经元，其中一些神经元对单个概念（例如“地面交通”）具有选择性。 AIA 可以黑盒访问合成神经元和设计输入（例如“树”、“幸福”和“汽车”）来测试神经元的反应。在注意到合成神经元对“汽车”产生比其他输入更高的响应值后，AIA 可能会设计更细粒度的测试，以区分神经元对汽车的选择性与其他形式的交通工具（例如飞机和船只）的选择性。当 AIA 生成诸如“该神经元对公路运输有选择性，而不是空中或海上旅行”之类的描述时，该描述会根据 FIND 中合成神经元的真实描述（“对地面运输有选择性”）进行评估。然后可以使用该基准将 AIA 的功能与文献中的其他方法进行比较。&lt;/p>; &lt;p>;Sarah Schwettmann 博士 &#39;21，&lt;a href=&quot;https://arxiv&quot; 的共同主要作者.org/pdf/2309.03886.pdf&quot; target=&quot;_blank&quot;>;关于新工作的论文&lt;/a>;和 CSAIL 的一位研究科学家强调了这种方法的优点。 “AIA 自主假设生成和测试的能力可能能够揭示科学家难以检测到的行为。值得注意的是，当语言模型配备了用于探测其他系统的工具时，它能够进行这种类型的实验设计，”Schwettmann 说。 “干净、简单的基准和真实答案一直是语言模型中更通用功能的主要驱动力，我们希望 FIND 能够在可解释性研究中发挥类似的作用。”&lt;/p>; &lt;p>;&lt;strong>;自动化可解释性;&lt;/strong>;&lt;/p>; &lt;p>;大型语言模型仍然保持着科技界炙手可热的名人地位。法学硕士的最新进展凸显了他们跨不同领域执行复杂推理任务的能力。 CSAIL 团队认识到，鉴于这些功能，语言模型可能能够作为自动解释性通用代理的支柱。 “从历史上看，可解释性一直是一个非常多方面的领域，”施韦特曼说。 “没有一种放之四海而皆准的方法；大多数程序都非常具体地针对我们可能对系统提出的个人问题，以及视觉或语言等个人模式。标记视觉模型内单个神经元的现有方法需要在人类数据上训练专门的模型，其中这些模型仅执行单一任务。从语言模型构建的可解释性代理可以提供解释其他系统的通用接口 - 综合实验结果，集成不同的模式，甚至在非常基础的层面上发现新的实验技术。”&lt;/p>; &lt;p>;当我们进入时在进行解释的模型本身就是黑匣子的体制中，对可解释性方法的外部评估变得越来越重要。该团队的新基准通过一套具有已知结构的函数来满足这一需求，这些函数是根据在野外观察到的行为建模的。 FIND 中的函数跨越了多个领域，从数学推理到字符串的符号运算，再到从字级任务构建的合成神经元。程序化构建交互功能数据集；通过添加噪声、组合函数和模拟偏差，将现实世界的复杂性引入到简单的函数中。这样可以在转化为现实世界性能的环境中比较可解释性方法。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p>; &lt;p>;除了函数数据集之外，研究人员还引入了一种创新的方法评估协议来评估AIA和现有自动解释方法的有效性。该协议涉及两种方法。对于需要在代码中复制函数的任务，评估直接将人工智能生成的估计与原始的真实函数进行比较。对于涉及函数的自然语言描述的任务，评估变得更加复杂。在这些情况下，准确衡量这些描述的质量需要自动理解其语义内容。为了应对这一挑战，研究人员开发了一种专门的“第三方”语言模型。该模型经过专门训练，用于评估人工智能系统提供的自然语言描述的准确性和连贯性，并将其与真实函数行为进行比较。&lt;/p>; &lt;p>;FIND 使评估能够显示我们仍然距离完全自动化的解释性还很远；尽管 AIA 优于现有的可解释性方法，但它们仍然无法准确描述基准测试中几乎一半的功能。该研究的联合主要作者、CSAIL 的博士后 Tamar Rott Shaham 指出，“虽然这一代 AIA 在描述高级功能方面很有效，但它们仍然经常忽略更细粒度的细节，特别是在带有噪声或噪声的函数子域中。不规则行为。这可能源于这些地区的采样不足。一个问题是 AIA 的有效性可能会因其最初的探索性数据而受到阻碍。为了解决这个问题，我们尝试通过使用特定的相关输入来初始化搜索来指导 AIA 的探索，这显着提高了解释的准确性。”这种方法将新的 AIA 方法与以前的技术相结合，使用预先计算的示例来启动解释过程。&lt;/p>; &lt;p>;研究人员还在开发一个工具包，以增强 AIA 在神经网络上进行更精确实验的能力，在黑盒和白盒设置中。该工具包旨在为 AIAs 提供更好的工具来选择输入和完善假设检验能力，以实现更细致、更准确的神经网络分析。该团队还在解决人工智能可解释性方面的实际挑战，重点是确定在现实场景中分析模型时要提出的正确问题。他们的目标是开发自动解释程序，最终帮助人们审核系统（例如自动驾驶或人脸识别），以在部署之前诊断潜在的故障模式、隐藏的偏差或令人惊讶的行为。&lt;/p>; &lt;p>;&lt; strong>;观察观察者&lt;/strong>;&lt;/p>; &lt;p>;该团队设想有一天开发出近乎自主的AIA，可以审计其他系统，并由人类科学家提供监督和指导。先进的AIA可以开发新类型的实验和问题，可能超出人类科学家最初的考虑。重点是扩展人工智能的可解释性，以包括更复杂的行为，例如整个神经回路或子网络，并预测可能导致不良行为的输入。这一发展代表着人工智能研究向前迈出了重要一步，旨在使人工智能系统更易于理解和可靠。&lt;/p>; &lt;p>;“一个好的基准是应对困难挑战的有力工具，”计算机科学教授 Martin Wattenberg 说。哈佛大学没有参与这项研究。 “很高兴看到这个复杂的可解释性基准，这是当今机器学习中最重要的挑战之一。作者创建的自动解释代理给我留下了特别深刻的印象。这是一种可解释性柔术，将人工智能重新转向自身以帮助人类理解。”&lt;/p>; &lt;p>;Schwettmann、Rott Shaham 和他们的同事于 12 月在 NeurIPS 2023 上展示了他们的工作。麻省理工学院的其他合著者，CSAIL 和电气工程与计算机科学系 (EECS) 的所有附属机构，包括研究生 Joanna Materzynska、本科生 Neil Chowdhury、李双博士 &#39;23、助理教授 Jacob Andreas 和 Antonio Torralba 教授。东北大学助理教授 David Bau 是另一位合著者。&lt;/p>; &lt;p>;这项工作部分得到了 MIT-IBM Watson AI 实验室、开放慈善事业、亚马逊研究奖、现代 NGV、美国陆军研究中心的支持实验室、美国国家科学基金会、祖克曼 STEM 领导力计划和维特比奖学金。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202401/FIND.png?itok=DDrML3FL" width="390"><media:description type="plain"> FIND 是一个新的基准套件，用于评估神经网络中的自动可解释性方法，具有模仿现实世界网络组件及其复杂性的功能。它还提出了一种使用自动可解释性代理的新颖交互方法，该方法采用预训练的语言模型来生成功能行为的描述，展示了代理推断功能结构的能力，同时强调了在捕获局部细节方面进一步细化的需要。</media:description><media:credit>图片来源：Alex Shipps/MIT CSAIL</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/language">语言</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item></channel></rss>