<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2023 年 11 月 29 日星期三 16:00:00 -0500</lastbuilddate><item><title>生成式人工智能的未来会怎样？</title><link/> https://news.mit.edu/2023/what-does-future-hold-generative-ai-1129<description> iRobot 联合创始人 Rodney Brooks 启动了麻省理工学院研讨会，讨论 ChatGPT 等日益强大的人工智能工具的前景和潜在陷阱。</description><pubDate> Wed, 29 Nov 2023 16:00:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/what-does-future-hold-generative-ai-1129</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;在 11 月 28 日麻省理工学院&lt;a href=&quot;https://mitgenerativeaiweek.mit.edu/&quot; target=&quot;_blank&quot;>;生成人工智能周启动活动“生成人工智能：塑造未来”研讨会上发表讲话&lt;/a>;，主讲人兼 iRobot 联合创始人 Rodney Brooks 警告与会者不要不加批判地高估这项新兴技术的能力，该技术支撑着 OpenAI 的 ChatGPT 和 Google 的 Bard 等日益强大的工具。&lt;/p>; &lt;p>;“炒作导致狂妄自大” ，傲慢导致自负，自负导致失败，”布鲁克斯警告道。 p>; &lt;p>;“没有一种技术能够超越其他所有技术，”他补充道。&lt;/p>; &lt;p>;这次研讨会吸引了数百名&lt;strong>; &lt;/strong>;来自学术界的&lt;strong>; &lt;/strong>;与会者和行业到研究所的克雷斯吉礼堂，充满了对生成人工智能机会的希望信息&lt;a href=&quot;https://news.mit.edu/2023/explained-generative-ai-1109&quot; target=&quot;_blank&quot;>;生成式人工智能&lt;/a>; 致力于让世界变得更美好，包括通过艺术和创造力，其中穿插着一些警示故事，说明如果这些人工智能工具不负责任地开发，可能会出现什么问题。&lt;/p>; &lt;p>;生成式人工智能是一个术语描述机器学习模型，该模型学习生成新材料，这些材料看起来像他们所训练的数据。这些模型展示了一些令人难以置信的能力，例如能够生成类似人类的创意写作、翻译语言、生成功能性计算机代码或根据文本提示制作逼真的图像。&lt;/p>; &lt;p>;在她启动在研讨会上，麻省理工学院校长 Sally Kornbluth 重点介绍了教师和学生开展的几个项目，旨在利用生成式人工智能对世界产生积极影响。例如，&lt;a href=&quot;https://news.mit.edu/2023/introducing-axim-collaborative-online-ed-venture-0503&quot; target=&quot;_blank&quot;>;Axim Collaborative&lt;/a>; 的工作是麻省理工学院和哈佛大学发起的一项在线教育计划，包括探索生成人工智能的教育方面，以帮助服务不足的学生。&lt;/p>; &lt;p>;该研究所最近还宣布 &lt;a href=&quot;https://news.mit.edu /2023/mit-scholars-awarded-seed-grants-generative-ai-0918&quot; target=&quot;_blank&quot;>;种子基金&lt;/a>;，用于 27 个跨学科教师研究项目，重点关注人工智能将如何改变整个社会人们的生活。&lt;/ p>; &lt;p>;科恩布鲁斯表示，在举办生成人工智能周时，麻省理工学院不仅希望展示此类创新，还希望在与会者之间产生“协作碰撞”。&lt;/p>; &lt;p>;学术界、政策制定者和行业之间的合作如果我们要以人性化的方式安全地整合像生成人工智能这样快速发展的技术并帮助人类解决问题，这将是至关重要的，她告诉观众。&lt;/p>; &lt;p>;“老实说，我想不出比这更紧密相关的挑战了。与麻省理工学院的使命。这是一项重大责任，但我完全有信心我们能够面对它，如果我们正面面对它，如果我们作为一个社区面对它，”她说。&lt;/p>; &lt;p>;虽然生成式人工智能有潜力CSAIL 主任 Daniela Rus 在开幕致辞中表示，这些强大的机器学习模型有助于解决地球上一些最紧迫的问题，但它们的出现模糊了科幻小说与现实之间的区别。她说，这不再是我们是否能够制造能够产生新内容的机器的问题，而是我们如何利用这些工具来增强业务并确保可持续性。&lt;strong>;&amp;nbsp;&lt;/strong>;&lt;/p>; &lt;p>;“今天，我们将讨论未来的可能性，即生成式人工智能不仅作为技术奇迹而存在，而且作为希望的源泉和正义的力量，”罗斯说，他也是安德鲁和埃尔娜电气工程和计算机科学系的 Viterbi 教授。&lt;/p>; &lt;p>;但在讨论深入探讨生成人工智能的能力之前，与会者首先被要求思考他们的人性，麻省理工学院教授 Joshua Bennett 朗读了一首原创诗.&lt;/p>; &lt;p>;贝内特是麻省理工学院文学系教授兼人文学科杰出主席，他被要求写一首关于人类意味着什么的诗，并从他出生三周的女儿身上汲取灵感&lt;/p>; &lt;p>;这首诗讲述了他小时候与父亲一起观看&lt;em>;星际迷航&lt;/em>;&lt;em>;&amp;nbsp;&lt;/em>;的经历，并谈到了将传统传承给下一代的重要性。 &lt;/p>; &lt;p>;在他的主题演讲中，布鲁克斯着手解开围绕生成人工智能的一些深刻的科学问题，并探索该技术可以告诉我们关于我们自己的哪些信息。&lt;/p>; &lt;首先，他试图通过解释这种大型语言模型如何工作的基础知识来消除围绕 ChatGPT 等生成式人工智能工具的一些谜团。例如，ChatGPT 通过确定下一个单词在已写内容的上下文中应该是什么来一次生成一个单词的文本。布鲁克斯解释说，人类可能会通过思考整个短语来写故事，但 ChatGPT 只关注下一个单词。&lt;/p>; &lt;p>;ChatGPT 3.5 建立在机器学习模型的基础上，该模型拥有 1750 亿个参数，并且已被公开在训练期间访问网络上数十亿页的文本。 （最新的迭代，ChatGPT 4，甚至更大。）它学习这个庞大的文本语料库中单词之间的相关性，并利用这些知识来建议在给出提示时接下来可能出现的单词。&lt;/p>; &lt;p>;该模型具有展示了一些令人难以置信的能力，例如能够以莎士比亚著名的风格写一首关于机器人的十四行诗&lt;a href=&quot;https://www.poetryfoundation.org/poems/45087/sonnet-18-shall-i-compare- thee-to-a-summers-day&quot; target=&quot;_blank&quot;>;十四行诗 18&lt;/a>;。在演讲中，布鲁克斯展示了他要求 ChatGPT 与他自己并排编写的十四行诗 &lt;a href=&quot;https://spectrum.ieee.org/what-is-a-robot-rodney-brooks-sonnet&quot; target=&quot;_blank&quot;>;十四行诗&lt;/a>;。&lt;/p>; &lt;p>;但是，尽管研究人员仍然没有完全理解这些模型的工作原理，布鲁克斯向观众保证，生成人工智能看似令人难以置信的能力并不是魔法，它并不意味着这些模型可以做任何事情。&lt;/p>; &lt;p>;他对生成式人工智能最大的担忧并不在于有一天可能超越人类智能的模型。相反，他最担心的是研究人员可能会抛弃数十年接近突破的优秀工作，只是为了抓住生成人工智能领域闪亮的新进展；风险投资公司盲目地涌向能够产生最高利润的技术；或者整整一代工程师可能会忘记其他形式的软件和人工智能。&lt;/p>; &lt;p>;归根结底，那些相信生成式人工智能可以解决世界问题的人，而那些相信它只能解决世界问题的人产生新问题至少有一个共同点：他说，两个群体都倾向于高估这项技术。&lt;/p>; &lt;p>;“生成式人工智能有什么自负？人们的想法是，它会以某种方式带来通用人工智能。布鲁克斯说：“就其本身而言，事实并非如此。”&lt;/p>; &lt;p>;在布鲁克斯的演讲之后，麻省理工学院的一组教员谈论了他们使用生成人工智能的工作，并参加了关于未来进展、重要但尚未充分探索的研究主题的小组讨论以及人工智能监管和政策的挑战。&lt;/p>; &lt;p>;该小组由麻省理工学院电气工程与计算机科学系 (EECS) 副教授、CSAIL 成员 Jacob Andreas 组成； Antonio Torralba，台达电子 EECS 教授、CSAIL 成员； Ev Fedorenko，麻省理工学院麦戈文脑研究所脑与认知科学副教授、研究员；以及计算机杰出教授兼 CSAIL 副主任 Armando Solar-Lezama。会议由 EECS 的 Thomas 和 Gerd Perkins 教授、CSAIL 成员 William T. Freeman 主持。&lt;/p>; &lt;p>;小组成员讨论了围绕生成人工智能的几个潜在的未来研究方向，包括集成感知系统的可能性、利用触觉和嗅觉等人类感官，而不是主要关注语言和图像。研究人员还谈到了与政策制定者和公众合作的重要性，以确保负责任地生产和部署生成式人工智能工具。&lt;/p>; &lt;p>;“当今生成式人工智能的一大风险是数字万金油的风险。 Solar-Lezama 表示，许多产品声称具有神奇功效，但从长远来看可能非常有害，因此存在很大的风险。&lt;/p>; &lt;p>;上午的会议以摘录内容结束。物理和戏剧艺术专业大四学生 Joy Ma 朗读了 1925 年的科幻小说《大都会》，随后就生成人工智能的未来进行了圆桌讨论。参与讨论的包括脑与认知科学系教授、CSAIL 成员 Joshua Tenenbaum； Dina Katabi，EECS Thuan 和 Nicole Pham 教授，CSAIL 和 MIT Jameel Clinic 的首席研究员； Max Tegmark，物理学教授；由 Daniela Rus 主持。&lt;/p>; &lt;p>;讨论的一个焦点是开发超越人类能力的生成式人工智能模型的可能性，例如可以通过使用电磁信号感知某人情绪的工具了解一个人的呼吸和心率如何变化。&lt;/p>; &lt;p>;但是，将此类人工智能安全地融入现实世界的关键是确保我们可以信任它，Tegmark 说。如果我们知道人工智能工具能够满足我们坚持要求的规范，那么“我们就不必再害怕构建真正强大的系统，为我们在世界上做事，”他说。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202311/MIT-GenerativeAI_01-PRESS.jpg?itok=wGJkjTwp" width="390"><media:description type="plain"> iRobot 联合创始人兼 CSAIL 前总监罗德尼·布鲁克斯 (Rodney Brooks) 拿着斯蒂芬·沃尔夫拉姆 (Stephen Wolfram) 的书《ChatGPT 正在做什么……以及它为何有效》，他向参加“生成式 AI：塑造未来”的与会者建议了这本书研讨会阅读了有关该技术的背景信息。</media:description><media:credit>图片来源：杰克·贝尔彻</media:credit></media:content><category domain="https://news.mit.edu/topic/special-events">特别活动和演讲嘉宾</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/faculty">学院</category><category domain="https://news.mit.edu/topic/staff">职员</category><category domain="https://news.mit.edu/topic/students">学生</category></item><item><title>新方法使用众包反馈来帮助训练机器人</title><link/>https://news.mit.edu/2023/method-uses-crowdsourced-feedback-help-train-robots-1127<description>人类引导探索（HuGE）使人工智能代理能够在人类的帮助下快速学习，即使人类犯了错误。</description><pubDate> Mon, 27 Nov 2023 00:00:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/method-uses-crowdsourced-feedback-help-train-robots-1127</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;为了教人工智能代理一项新任务，例如如何打开厨房柜子，研究人员经常使用强化学习——这是一种试错过程，在该过程中，代理会因采取使其更接近目标的行动而获得奖励。&lt; /p>; &lt;p>;在许多情况下，人类专家必须仔细设计奖励函数，这是一种给予智能体探索动力的激励机制。当智能体探索并尝试不同的动作时，人类专家必须迭代地更新奖励函数。这可能非常耗时、效率低下，而且难以扩大规模，尤其是当任务复杂且涉及许多步骤时。&lt;/p>; &lt;p>;来自麻省理工学院、哈佛大学和华盛顿大学的研究人员开发了一种新的强化方法不依赖于专业设计的奖励函数的学习方法。相反，它利用从许多非专家用户那里收集的众包反馈来指导代理学习实现其目标。&lt;/p>; &lt;p>;虽然其他一些方法也尝试利用非专家反馈，但这种新方法使人工智能代理能够尽管从用户那里众包的数据常常充满错误，但还是能够更快地学习。这些嘈杂的数据可能会导致其他方法失败。&lt;/p>; &lt;p>;此外，这种新方法允许异步收集反馈，因此世界各地的非专家用户都可以为教授代理做出贡献。&lt;/p>; &lt;p>; “当今设计机器人代理时最耗时且最具挑战性的部分之一是设计奖励函数。如今，奖励函数是由专家研究人员设计的——如果我们想教机器人执行许多不同的任务，这种范例是不可扩展的。我们的工作提出了一种扩展机器人学习的方法，通过众包奖励函数的设计，并使非专家也能提供有用的反馈。”麻省理工学院电气工程与计算机科学系 (EECS) 助理教授 Pulkit Agrawal 说道。领导麻省理工学院计算机科学与人工智能实验室（CSAIL）的 Improbable AI 实验室。&lt;/p>; &lt;p>;未来，这种方法可以帮助机器人快速学习在用户家中执行特定任务，而无需主人的帮助向机器人展示每项任务的物理示例。机器人可以自行探索，并通过众包的非专家反馈来指导其探索。&lt;/p>; &lt;p>;“在我们的方法中，奖励函数引导代理去探索它应该探索的内容，而不是确切地告诉它应该做什么。完成任务。因此，即使人类监督有些不准确且存在噪音，智能体仍然能够探索，这有助于它更好地学习。”主要作者、Improbable AI 实验室的研究助理 Marcel Torne &#39;23 解释道。&lt;/p>; &lt;p>;Torne 与他的麻省理工学院顾问 Agrawal 一起参与了这篇论文；资深作者 Abhishek Gupta，华盛顿大学助理教授；以及华盛顿大学和麻省理工学院的其他人。该研究将于下个月的神经信息处理系统会议上公布。&lt;/p>; &lt;p>;&lt;strong>;嘈杂的反馈&lt;/strong>;&lt;/p>; &lt;p>;收集强化学习用户反馈的一种方法是向用户展示两张代理实现的状态照片，然后询问用户哪个状态更接近目标。例如，也许机器人的目标是打开厨房橱柜。一张图像可能显示机器人打开了柜子，而第二张图像可能显示它打开了微波炉。用户会选择“更好”状态的照片。&lt;/p>; &lt;p>;之前的一些方法尝试使用这种众包的二元反馈来优化代理用于学习任务的奖励函数。然而，由于非专家可能会犯错误，奖励函数可能会变得非常嘈杂，因此代理可能会陷入困境而永远无法达到目标。&lt;/p>; &lt;p>;“基本上，代理会过于认真地对待奖励函数。它会尝试完美匹配奖励函数。因此，我们不是直接优化奖励函数，而是用它来告诉机器人它应该探索哪些区域。”Torne 说。&lt;/p>; &lt;p>;他和他的合作者将这个过程分解为两个独立的部分，每个部分由自己的算法指导。他们将新的强化学习方法称为 HuGE（人类引导探索）。&lt;/p>; &lt;p>;一方面，目标选择器算法会根据众包的人类反馈不断更新。反馈不用作奖励函数，而是指导代理的探索。从某种意义上说，非专家用户留下的面包屑逐渐引导代理实现其目标。&lt;em>; &lt;/em>;&lt;/p>; &lt;p>;另一方面，代理以自我监督的方式自行探索由目标选择器引导。它收集它尝试的动作的图像或视频，然后将其发送给人类并用于更新目标选择器。&lt;/p>; &lt;p>;这缩小了代理探索的区域，使其进入更有希望的领域更接近它的目标。但如果没有反馈，或者反馈需要一段时间才能到达，代理将继续自行学习，尽管速度较慢。这使得反馈能够不频繁且异步地收集。&lt;/p>; &lt;p>;“探索循环可以继续自主进行，因为它只会探索和学习新事物。然后当你得到更好的信号时，它就会以更具体的方式进行探索。你可以让它们按照自己的节奏转动。”Torne 补充道。&lt;/p>; &lt;p>;而且由于反馈只是温和地指导智能体的行为，即使用户提供了错误的答案，它最终也会学会完成任务。&lt; /p>; &lt;p>;&lt;strong>;更快的学习&lt;/strong>;&lt;/p>; &lt;p>;研究人员在许多模拟和现实任务中测试了这种方法。在模拟中，他们使用 HuGE 有效地学习具有长动作序列的任务，例如以特定顺序堆叠块或在大迷宫中导航。&lt;/p>; &lt;p>;在现实世界的测试中，他们使用 HuGE 来训练机械臂绘制字母“U”并拾取和放置物体。在这些测试中，他们众包了来自三大洲 13 个不同国家的 109 位非专家用户的数据。&lt;/p>; &lt;p>;在现实世界和模拟实验中，HuGE 帮助智能体比其他方法更快地学习实现目标。&lt;/p>; &lt;p>; >; &lt;p>;研究人员还发现，来自非专家的众包数据比由研究人员生成和标记的合成数据具有更好的性能。对于非专家用户来说，标记 30 个图像或视频只需要不到两分钟的时间。&lt;/p>; &lt;p>;“这使得这种方法的扩展前景非常广阔，”Torne 补充道。&lt;/p>; &lt;p>;研究人员在最近的机器人学习会议上发表了一篇相关论文，他们增强了 HuGE，以便人工智能代理可以学习执行任务，然后自动重置环境以继续学习。例如，如果智能体学会打开柜子，该方法还会引导智能体关闭柜子。&lt;/p>; &lt;p>;“现在我们可以让它完全自主学习，而不需要人工重置，”他说。&lt;/p>; &lt;p>;“现在我们可以让它完全自主学习，而不需要人工重置。” p>; &lt;p>;研究人员还强调，在这种学习方法和其他学习方法中，确保人工智能代理与人类价值观保持一致至关重要。&lt;/p>; &lt;p>;未来，他们希望继续完善 HuGE，以便代理可以从其他形式的交流中学习，例如自然语言和与机器人的身体互动。他们还对应用这种方法同时教授多个智能体感兴趣。&lt;/p>; &lt;p>;这项研究部分由 MIT-IBM Watson AI 实验室资助。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202311/MIT-Guided%20Explanation-01.jpg?itok=2jOHdeI0" width="390"><media:credit>图片来源：iStock，Christine Daniloff，麻省理工学院</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/robots">机器人</category><category domain="https://news.mit.edu/topic/human-computer-interaction">人机交互</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category></item></channel></rss>