<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2023 年 12 月 20 日星期三 00:00:00 -0500</lastbuilddate><item><title>帮助艺术家改进动画的灵活解决方案</title><link/>https://news.mit.edu/2023/flexible-solution-help-artists-improve-animation-1220<description>这种新方法借鉴了 200 年历史的几何基础，让艺术家能够控制动画角色的外观。</description><pubDate> Wed, 20 Dec 2023 00:00:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/flexible-solution-help-artists-improve-animation-1220</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;得益于麻省理工学院研究人员引入的新技术，在动画电影和视频游戏中栩栩如生地呈现英雄和恶棍的艺术家可以更好地控制他们的动画。&lt;/p>; &lt;p>;他们的方法生成了称为重心的数学函数坐标，定义 2D 和 3D 形状如何在空间中弯曲、拉伸和移动。例如，使用他们的工具的艺术家可以选择使 3D 猫尾巴的运动符合他们对动画猫科动物“外观”的视觉的功能。&lt;/p>; &lt;img alt=&quot;封闭在网格中的蓝猫的动画，当它的尾巴左右卷曲时。” data-align=&quot;center&quot; data-caption=&quot;这张 gif 展示了研究人员如何使用他们的技术为猫的尾巴提供更平滑的运动。&amp;lt;br />;&amp;lt;br />;&amp;gt; &amp;lt;br />;&amp;gt; 图片：由研究人员提供” data -entity-type =“文件”data-entity-uuid =“5e04236f-2932-4207-b988-6b97f7f7118d”src =“/sites/default/files/images/inline/MIT-Barycentric-Coordinates-cat.gif”/ >; &lt;p>;&lt;/p>; &lt;p>;针对此问题的许多其他技术都是不灵活的，仅为特定动画角色的重心坐标函数提供单一选项。每个函数对于特定动画来说可能是最好的，也可能不是最好的。艺术家每次想要尝试稍微不同的外观时，都必须从头开始采用新的方法。&lt;/p>; &lt;p>;“作为研究人员，我们有时会陷入在不咨询他人的情况下解决艺术问题的循环中。艺术家。艺术家关心的是最终产品的灵活性和“外观”。他们不关心你的算法在幕后求解的偏微分方程。”该技术论文的主要作者 Ana Dodik 说道。&lt;/p>; &lt;p>;除了艺术应用之外，该技术还可用于其他领域例如医学成像、建筑、虚拟现实，甚至在计算机视觉中作为帮助机器人弄清楚物体在现实世界中如何移动的工具。&lt;/p>; &lt;p>;Dodik，电气工程和计算机科学 (EECS) 毕业生学生，与南加州大学维特比工程学院助理教授 Oded Stein 共同撰写了这篇论文； Vincent Sitzmann，EECS 助理教授，领导麻省理工学院计算机科学与人工智能实验室 (CSAIL) 场景表示小组；资深作者 Justin Solomon，EECS 副教授，CSAIL 几何数据处理组组长。这项研究最近在 SIGGRAPH Asia 上发表。&lt;/p>; &lt;p>;&lt;strong>;通用方法&lt;/strong>;&lt;/p>; &lt;p>;当艺术家制作 2​​D 或 3D 角色动画时，一种常见的技术是围绕字符的复杂形状，具有由线段或三角形连接的一组简单点，称为笼。动画师拖动这些点来移动笼子内的角色并使其变形。关键的技术问题是确定笼子修改后角色如何移动；该运动由特定重心坐标函数的设计决定。&lt;/p>; &lt;p>;传统方法使用复杂的方程来找到极其平滑的基于笼的运动，避免在拉伸或拉伸时可能在形状中出现扭结。弯曲到了极点。但是，关于“平滑”的艺术理念如何转化为数学有很多概念，每个概念都会导致一组不同的重心坐标函数。&lt;/p>; &lt;p>;麻省理工学院的研究人员寻求一种通用方法，使艺术家能够在设计或选择任何形状的平滑度能量时拥有发言权。然后，艺术家可以预览变形并选择最适合他们口味的平滑能量。&lt;/p>; &lt;p>;虽然重心坐标的灵活设计是一个现代想法，但重心坐标的基本数学构造可以追溯到几个世纪前。德国数学家奥古斯特·莫比乌斯于 1827 年提出，重心坐标规定了形状的每个角如何对形状的内部施加影响。&lt;/p>; &lt;p>;在莫比乌斯计算中使用的三角形形状中，重心坐标为很容易设计——但是当笼子不是三角形时，计算就会变得混乱。为复杂的笼子制作重心坐标尤其困难，因为对于复杂的形状，每个重心坐标必须满足一组约束，同时尽可能平滑。&lt;/p>; &lt;p>;与过去的工作不同，团队使用了一种特殊的类型神经网络对未知重心坐标函数进行建模。神经网络松散地基于人脑，使用多层互连节点处理输入。&lt;/p>; &lt;p>;虽然神经网络经常应用于模仿人类思维的人工智能应用程序，但在这个项目中，神经网络用于一个数学原因。研究人员的网络架构知道如何输出完全满足所有约束的重心坐标函数。他们将约束直接构建到网络中，因此当它生成解决方案时，它们始终有效。这种构造可以帮助艺术家设计有趣的重心坐标，而不必担心问题的数学方面。&lt;/p>; &lt;p>;“棘手的部分是构建约束。标准工具无法帮助我们一路实现目标，因此我们必须跳出框框思考。&lt;/p>; &lt;p>;&lt;strong>;虚拟三角形&lt;/strong>;&lt;/p>; &lt;p>;研究人员利用了近 200 年前引入的三角形重心坐标莫比乌斯坐标。这些三角坐标很容易计算并满足所有必要的约束，但现代笼子比三角形复杂得多。&lt;/p>; &lt;p>;为了弥合差距，研究人员的方法覆盖了一个具有连接三元组的重叠虚拟三角形的形状笼子外部的点。&lt;/p>; &lt;p>;“每个虚拟三角形定义一个有效的重心坐标函数。我们只需要一种将它们组合起来的方法，”她说。&lt;/p>; &lt;p>;这就是神经网络的用武之地。它预测如何组合虚拟三角形的重心坐标以形成更复杂但平滑的函数。 &lt;/p>; &lt;p>;使用他们的方法，艺术家可以尝试一个功能，查看最终的动画，然后调整坐标以生成不同的运动，直到获得他们想要的动画。&lt;/p>; &lt;p>;“从实际角度来看，我认为最大的影响是神经网络为您提供了以前没有的很大灵活性，”Dodik 说。&lt;/p>; &lt;p>;研究人员展示了他们的方法如何能够比其他方法生成更自然的动画，例如猫的尾巴在移动时平滑地弯曲，而不是在笼子顶点附近僵硬地折叠。&lt;/p>; &lt;p>;将来，他们希望尝试不同的策略来加速神经网络。他们还希望将这种方法构建到一个交互式界面中，使艺术家能够轻松地实时迭代动画。&lt;/p>; &lt;p>;这项研究部分由美国陆军研究办公室、美国空军资助Force Office of Scientific Research、美国国家科学基金会、CSAIL Systems that Learn Program、MIT-IBM Watson AI 实验室、丰田-CSAIL 联合研究中心、Adobe Systems、Google 研究奖、新加坡国防科学技术局，以及亚马逊科学中心。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202312/MIT-Barycentric-Coordinates-01-press.jpg?itok=H7PxQCqO" width="390"><media:description type="plain">麻省理工学院的研究人员推出了一种多功能技术，使动画师能够灵活地查看不同的数学函数如何使复杂的 2D 或 3D 角色变形。这项新技术让动画师可以选择最适合他们动画愿景的功能。</media:description><media:credit>图片：由研究人员提供</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/arts">艺术</category><category domain="https://news.mit.edu/topic/augmented-and-virtual-reality">增强现实和虚拟现实</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/mathematics">数学</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/nsf">美国国家科学基金会 (NSF)</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category></item><item><title>图像识别准确性：困扰当今人工智能的一个看不见的挑战</title><link/>https://news.mit.edu/2023/image-recognition-accuracy-minimum-viewing-time-metric-1215<description> “最短观看时间”基准通过测量准确的人类识别所需的时间来衡量人工智能系统的图像识别复杂性。</description><pubDate> Fri, 15 Dec 2023 12:35:00 -0500</pubDate><guid ispermalink="true"> https://news.mit.edu/2023/image-recognition-accuracy-minimum-viewing-time-metric-1215</guid><dc:creator>雷切尔戈登|麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;想象一下，您正在滚动浏览手机上的照片，然后看到一张您一开始无法识别的图像。沙发上看起来可能有什么毛茸茸的东西；它可以是枕头或外套吗？几秒钟后，它发出咔嗒声——当然！那个毛茸茸的球是你朋友的猫，摩卡。虽然你的一些照片可以立即被理解，但为什么这张猫的照片要困难得多？&lt;/p>; &lt;p>;麻省理工学院计算机科学与人工智能实验室 (CSAIL) 的研究人员惊讶地发现，尽管理解至关重要从医疗保健到交通再到家用设备等关键领域的视觉数据，人类识别图像的难度的概念几乎完全被忽视了。基于深度学习的人工智能进步的主要驱动力之一是数据集，但我们对数据如何推动大规模深度学习的进步知之甚少，除了越大越好。&lt;/p>; &lt;p>;在实际应用中尽管模型在当前数据集上表现良好，包括那些明确设计用于挑战具有去偏差图像或分布变化的机器的模型，但需要理解视觉数据，人类的表现优于对象识别模型。这个问题仍然存在，部分原因是我们没有关于图像或数据集的绝对难度的指导。如果不控制用于评估的图像的难度，就很难客观地评估人类水平表现的进展，覆盖人类能力的范围，并增加数据集带来的挑战。&lt;/p>; &lt;p>;在这个知识缺口中，麻省理工学院电气工程和计算机科学博士生、CSAIL 附属机构 David Mayo 深入研究了图像数据集的深层世界，探索为什么某些图像比其他图像更难被人类和机器识别。 “有些图像本质上需要更长的时间来识别，了解大脑在这个过程中的活动及其与机器学习模型的关系至关重要。也许我们当前的模型中缺少复杂的神经回路或独特的机制，只有在具有挑战性的视觉测试时才能看到“这种探索对于理解和增强机器视觉模型至关重要。”新论文的主要作者 Mayo 说道，他是一篇新论文的主要作者。 &lt;/a>;。&lt;/p>; &lt;p>;这导致了一种新指标的开发，即“&lt;a href=&quot;https://objectnet.dev/mvt/&quot; target=&quot;_blank&quot;>;最低查看时间&lt;/a>;”（MVT），它根据一个人在做出正确识别之前需要查看图像的时间来量化识别图像的难度。使用 ImageNet（机器学习中流行的数据集）和 ObjectNet 的子集是一个旨在测试对象识别鲁棒性的数据集，该团队向参与者展示了不同持续时间的图像，从短至 17 毫秒到长至 10 秒，并要求他们从一组 50 个选项中选择正确的对象。经过超过 200,000 次图像演示试验后，团队发现包括 ObjectNet 在内的现有测试集似乎偏向于更简单、更短的 MVT 图像，其中绝大多数基准性能来自于人类容易理解的图像。&lt;/p>; &lt;p>;该项目发现了模型性能的有趣趋势——特别是与缩放相关的趋势。较大的模型在更简单的图像上显示出相当大的改进，但在更具挑战性的图像上进展较小。融合了语言和视觉的 CLIP 模型在朝着更接近人类识别的方向发展时脱颖而出。&lt;/p>; &lt;p>;“传统上，对象识别数据集倾向于不太复杂的图像，这是一种实践这导致了模型性能指标的膨胀，而不能真正反映模型的稳健性或其处理复杂视觉任务的能力。我们的研究表明，较硬的图像会带来更严峻的挑战，导致标准评估中通常未考虑到的分布变化，”梅奥说。 “我们发布了按难度标记的图像集以及自动计算 MVT 的工具，使 MVT 能够添加到现有基准测试中并扩展到各种应用程序。其中包括在部署现实世界系统之前测量测试集难度，发现图像难度的神经相关性，以及改进对象识别技术以缩小基准测试和现实世界性能之间的差距。”&lt;/p>; &lt;p>;“我最大的一个结论是我们现在有另一个维度来评估模型。我们希望模型能够识别任何图像，即使——也许尤其是——人类很难识别。我们是第一个量化这意味着什么的人。我们的结果表明，这不仅不是当今最先进的情况，而且我们当前的评估方法无法告诉我们何时会出现这种情况，因为标准数据集非常倾向于简单的图像。”麻省理工学院电气工程和计算机科学专业的研究生、与 Mayo 共同撰写该论文的 Jesse Cummings 说道。&lt;/p>; &lt;p>;&lt;strong>;从 ObjectNet 到 MVT&lt;/strong>;&lt;/p>; &lt;p>;几年前，该项目背后的团队发现了机器学习领域的一个重大挑战：模型正在努力处理分布外的图像，或者在训练数据中没有得到很好体现的图像。输入 ObjectNet，这是一个由从现实生活中收集的图像组成的数据集。该数据集通过消除其他基准中存在的虚假相关性（例如物体与其背景之间的相关性），帮助阐明了机器学习模型和人类识别能力之间的性能差距。 ObjectNet 阐明了机器视觉模型在数据集上的性能与实际应用中的性能之间的差距，鼓励许多研究人员和开发人员使用，从而提高了模型性能。&lt;/p>; &lt;p>;快进到现在，并且团队通过 MVT 将他们的研究更进一步。与注重绝对性能的传统方法不同，这种新方法通过将模型的响应与最简单和最难的图像进行对比来评估模型的性能。该研究进一步探讨了如何解释图像难度并测试其与人类视觉处理的相似性。使用 c 分数、预测深度和对抗鲁棒性等指标，该团队发现网络对较难的图像的处理方式有所不同。 “虽然存在明显的趋势，例如更简单的图像变得更典型，但科学界仍然无法对图像难度进行全面的语义解释，”梅奥说。&lt;/p>; &lt;p>;例如，在医疗保健领域，理解视觉复杂性的针对性变得更加明显。人工智能模型解读 X 射线等医学图像的能力取决于图像的多样性和难度分布。研究人员主张对专为专业人士量身定制的难度分布进行细致分析，确保根据专家标准而不是外行解释来评估人工智能系统。&lt;/p>; &lt;p>;梅奥和卡明斯目前也在研究视觉识别的神经学基础，探讨大脑在处理简单图像和具有挑战性的图像时是否表现出不同的活动。这项研究旨在揭示复杂的图像是否会招募通常与视觉处理无关的额外大脑区域，希望有助于揭开我们的大脑如何准确有效地解码视觉世界的神秘面纱。&lt;/p>; &lt;p>;&lt;strong>;迈向人类水平的表现&lt;/展望未来，研究人员不仅仅专注于探索增强人工智能对图像难度的预测能力的方法。该团队正在努力识别与观看时间难度的相关性，以便生成更难或更简单的图像版本。&lt;/p>; &lt;p>;尽管这项研究取得了重大进展，但研究人员承认存在局限性，特别是在物体识别的分离方面来自视觉搜索任务。当前的方法确实专注于识别物体，忽略了杂乱图像带来的复杂性。&lt;/p>; &lt;p>;“这种综合方法解决了客观评估物体识别方面人类水平表现进展的长期挑战，并开辟了新的领域。理解和推进该领域的途径，”梅奥说。 “凭借针对各种视觉任务调整最短观看时间难度指标的潜力，这项工作为物体识别中更强大、类人的性能铺平了道路，确保模型真正接受测试并为现实世界视觉理解的复杂性。”&lt;/p>; &lt;p>;“这是一项令人着迷的研究，研究了如何利用人类感知来识别人工智能视觉模型通常基准测试方式的弱点，这些模型通过专注于简单的任务来高估人工智能的性能。约翰霍普金斯大学认知科学和计算机科学的彭博杰出教授 Alan L. Yuille 说道，他没有参与这篇论文。 “这将有助于开发更现实的基准，不仅可以改进人工智能，还可以在人工智能和人类感知之间进行更公平的比较。”&lt;/p>; &lt;p>;“人们普遍认为计算机视觉系统现在优于人类，并且Anthropic 技术人员、17 届博士 Simon Kornblith 表示，他也没有参与这项工作。 “然而，这些基准测试的许多困难来自于图像中内容的模糊性；一般人只是不知道如何对不同品种的狗进行分类。相反，这项工作关注的是人们只有在给予足够时间的情况下才能正确获得的图像。这些图像对于计算机视觉系统来说通常要困难得多，但最好的系统也只比人类差一点点。”&lt;/p>; &lt;p>;Mayo、Cummings 和 Xinyu Lin MEng &#39;22 撰写了 &lt;a href=&quot;https: //objectnet.dev/mvt/how_hard_are_computer_vision_datasets_Calibration_dataset_difficulty_to_viewing_time_neurips2023.pdf&quot; target=&quot;_blank&quot;>;论文&lt;/a>;与 CSAIL 研究科学家 Andrei Barbu、CSAIL 首席研究科学家 Boris Katz 和 MIT-IBM Watson AI 实验室首席研究员 Dan Gutfreund 合作。研究人员是麻省理工学院大脑、思维和机器中心的附属机构。&lt;/p>; &lt;p>;该团队正在 2023 年神经信息处理系统 (NeurIPS) 会议上展示他们的工作。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202312/MIT-MVT-00.jpg?itok=I4BxNthj" width="390"><media:description type="plain"> MVT（最短观看时间）是一个数据集难度指标，用于测量识别图像所需的最短呈现时间。研究人员希望该指标将用于评估模型的性能和生物学合理性，并指导创建新的更困难的数据集，从而导致新的计算机视觉技术在现实生活中表现更好。</media:description><media:credit>图片由研究人员/麻省理工学院 CSAIL 提供。</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/imageprocessing">图像处理</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/vision">想象</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/center-brains-minds-and-machines">大脑与机器中心</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item></channel></rss>