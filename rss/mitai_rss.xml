<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 6 月 3 日星期一 04:00:00 +0000</lastbuilddate><item><title>更有效的多用途机器人技术</title><link/>https://news.mit.edu/2024/technique-for-more-efficient-multi Purpose-robots-0603<description>通过生成人工智能模型，研究人员结合了来自不同来源的机器人数据，以帮助机器人更好地学习。</description><pubDate> Mon, 03 Jun 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/technique-for-more-efficient-multi Purpose-robots-0603</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;假设您想要训练一个机器人，使其了解如何使用工具，然后可以快速学会使用锤子、扳手和螺丝刀在您的房屋周围进行维修。为此，您需要大量数据来展示工具的使用情况。&lt;/p>;&lt;p>;现有的机器人数据集在模式上差异很大 - 例如，有些包含彩色图像，而另一些则由触觉印记组成。数据也可以在不同的领域收集，例如模拟或人体演示。每个数据集都可能捕获一个独特的任务和环境。&lt;/p>;&lt;p>;很难将如此多来源的数据有效地整合到一个机器学习模型中，因此许多方法仅使用一种类型的数据来训练机器人。但以这种方式训练的机器人，由于特定任务的数据量相对较少，通常无法在陌生的环境中执行新任务。&lt;/p>;&lt;p>;为了训练更好的多用途机器人，麻省理工学院的研究人员开发了一种技术使用一种称为扩散模型的生成人工智能组合跨领域、模式和任务的多个数据源。&lt;/p>;&lt;p>;他们训练一个单独的扩散模型来学习策略或政策，以使用一个模型来完成一项任务具体数据集。然后，他们将扩散模型学到的策略组合成一个通用策略，使机器人能够在各种设置中执行多项任务。&lt;/p>;&lt;p>;在模拟和现实实验中，这种训练方法使机器人能够执行多项任务工具使用任务并适应训练期间没有看到的新任务。该方法被称为策略组合 (PoCo)，与基线技术相比，任务性能提高了 20%。&lt;/p>;&lt;p>;“解决机器人数据集中的异质性就像先有鸡还是先有蛋的问题。如果我们想使用大量数据来训练通用机器人策略，那么我们首先需要可部署的机器人来获取所有这些数据。我认为，利用所有可用的异构数据，类似于研究人员对 ChatGPT 所做的事情，是机器人领域的重要一步。”电气工程和计算机科学 (EECS) 研究生、《&lt; a href=&quot;https://arxiv.org/pdf/2402.02511&quot; target=&quot;_blank&quot;>;关于 PoCo 的论文&lt;/a>;。&lt;w:sdtpr>;&lt;/w:sdtpr>; &amp;nbsp; &amp;nbsp;&lt;/p>;&lt;p>;王的合著者包括机械工程研究生赵嘉良；杜依伦，EECS研究生； Edward Adelson，脑与认知科学系视觉科学约翰和多萝西·威尔逊教授，计算机科学与人工智能实验室 (CSAIL) 成员；资深作者 Russ Tedrake，丰田 EECS、航空航天和机械工程教授，也是 CSAIL 成员。该研究将在机器人：科学与系统会议上展示。&lt;/p>;&lt;p>;&lt;strong>;组合不同的数据集&lt;/strong>;&lt;/p>;&lt;p>;机器人策略是一种接受输入的机器学习模型并使用它们来执行操作。思考政策的一种方法是将其视为战略。就机械臂而言，该策略可能是一条轨迹，或者是一系列移动手臂的姿势，以便它拿起锤子并用它敲钉子。&lt;/p>;&lt;p>;用于学习机器人的数据集策略通常很小，并且专注于一项特定的任务和环境，例如将物品装入仓库中的盒子中。&lt;/p>;&lt;p>;“每个机器人仓库都会生成数 TB 的数据，但它只属于特定的机器人安装工作在那些包裹上。如果你想使用所有这些数据来训练通用机器，这并不理想。”Wang 说。&lt;/p>;&lt;p>;麻省理工学院的研究人员开发了一种技术，可以采用一系列较小的数据集，例如从许多数据集中收集的数据集。机器人仓库，学习每个策略的单独策略，并以一种使机器人能够泛化到许多任务的方式组合这些策略。&lt;/p>;&lt;p>;它们使用一种称为扩散模型的生成人工智能模型来表示每个策略。扩散模型通常用于图像生成，通过迭代地优化输出来学习创建与训练数据集中的样本相似的新数据样本。&lt;/p>;&lt;p>;但是，研究人员不是教扩散模型生成图像，而是教它生成图像生成机器人的轨迹。他们通过向训练数据集中的轨迹添加噪声来实现这一点。扩散模型逐渐消除噪声并将其输出细化为轨迹。&lt;/p>;&lt;p>;这种技术称为&lt;a href=&quot;https://arxiv.org/pdf/2303.04137.pdf&quot; target=&quot;_blank &quot;>;扩散政策&lt;/a>;，此前由麻省理工学院、哥伦比亚大学和丰田研究院的研究人员提出。 PoCo 建立在这项扩散政策工作的基础上。&lt;/p>;&lt;p>;该团队使用不同类型的数据集训练每个扩散模型，例如一个包含人类视频演示的数据集，另一个来自机器人手臂的远程操作收集的数据集。&lt;/p >;&lt;p>;然后，研究人员对所有扩散模型学到的各个政策进行加权组合，迭代地细化输出，使组合政策满足每个政策的目标。&lt;/p>;&lt;p>;&lt;strong>;大于各部分之和&lt;/strong>;&lt;/p>;&lt;p>;“这种方法的好处之一是我们可以结合政策来实现两全其美。例如，基于真实数据训练的策略可能能够实现更高的灵活性，而基于模拟训练的策略可能能够实现更多的泛化。”Wang 说道。&lt;/p>;&lt;img src=&quot;/sites/default /files/images/inline/spatula_0.gif&quot; data-align=&quot;center&quot; data-entity-uuid=&quot;be482964-50e1-4348-a78c-617ff01da27f&quot; data-entity-type=&quot;file&quot; alt=&quot;机器人动画使用抹刀举起玩具煎饼的手臂&quot; width=&quot;300&quot; height=&quot;247&quot; data-caption=&quot;通过政策组合，研究人员能够组合来自多个来源的数据集，以便他们可以教机器人有效地使用各种工具，如锤子、螺丝刀或抹刀。&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;图片：由研究人员提供&quot;>;&lt;p>;由于策略是单独训练的，因此可以混合和匹配扩散策略，以获得更好的结果某项任务。用户还可以通过使用该数据集训练额外的扩散策略来添加新模式或域中的数据，而不是从头开始整个过程​​。&lt;/p>;&lt;img src=&quot;/sites/default/files/images/inline /hammer_0.gif&quot; data-align=&quot;center&quot; data-entity-uuid=&quot;767d5173-0540-42c6-bd46-842d3999215c&quot; data-entity-type=&quot;file&quot; alt=&quot;以玩具锤为对象的机器人手臂动画被随机放置在它周围。” width=&quot;300&quot; height=&quot;296&quot; data-caption=&quot;研究人员开发的策略组合技术可用于有效地教导机器人使用工具，即使在机器人周围放置物体试图分散其注意力，例如参见此处。&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;图片：由研究人员提供&quot;>;&lt;p>;研究人员在模拟中和在执行各种工具任务（例如使用锤子敲钉子）的真实机械臂上测试了 PoCo并用抹刀翻转物体。与基线方法相比，PoCo 使任务性能提高了 20%。&lt;/p>;&lt;p>;“令人惊讶的是，当我们完成调整并将其可视化时，我们可以清楚地看到组合轨迹看起来比任何一种都要好得多Wang 说。&lt;/p>;&lt;p>;将来，研究人员希望将这种技术应用于长期任务，其中机器人会拿起一个工具，使用它，然后切换到另一个工具。他们还希望整合更大的机器人数据集来提高性能。&lt;/p>;&lt;p>;“我们需要所有三种数据才能使机器人取得成功：互联网数据、模拟数据和真实的机器人数据。如何有效地将它们结合起来将是一个价值百万美元的问题。 PoCo 是在正确轨道上迈出的坚实一步。”NVIDIA 高级研究科学家兼 AI Agents Initiative 负责人 Jim Fan 表示，他没有参与这项工作。&lt;/p>;&lt;p>;这项研究获得了部分资助，由亚马逊、新加坡国防科学技术局、美国国家科学基金会和丰田研究所合作。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202405/MIT-Policy-Comp-A1.jpg?itok=wx82cdsY" width="390"><media:description type="plain">三个不同的数据域——模拟（上）、机器人远程操作（中）和人体演示（下）——允许机器人学习使用不同的工具。</media:description><media:credit>图片：由研究人员提供</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/robots">机器人</category><category domain="https://news.mit.edu/topic/robotics">机器人技术</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/mechanical-engineering">机械工业</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/aeronautics">航空航天工程</category><category domain="https://news.mit.edu/topic/brain-cognitive">脑与认知科学</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/nsf">美国国家科学基金会 (NSF)</category></item><item><title>正在寻找视频中的特定动作？这种基于人工智能的方法可以为您找到它</title><link/>https://news.mit.edu/2024/ai-based-method-can-find-specific-video-action-0529<description>一种新方法可以简化虚拟培训流程或帮助临床医生查看诊断视频。</description><pubDate> Wed, 29 May 2024 00:00:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/ai-based-method-can-find-specific-video-action-0529</guid><dc:creator>亚当·泽威 |麻省理工学院新闻</dc:creator><content:encoded>&lt;p>;互联网上充斥着教学视频，这​​些视频可以向好奇的观众传授各种知识，从烹饪完美的煎饼到执行挽救生命的海姆立克急救法。&lt;/p>;&lt;p>;但要在长视频中精确指出特定动作发生的时间和地点可能很乏味。为了简化这个过程，科学家们正在尝试教计算机执行这项任务。理想情况下，用户只需描述他们正在寻找的动作，人工智能模型就会跳到视频中的位置。&lt;/p>;&lt;p>;但是，教机器学习模型执行此操作通常需要大量的工作精心手工标记的昂贵视频数据。&lt;/p>;&lt;p>;麻省理工学院和 MIT-IBM Watson AI 实验室的研究人员采用了一种更高效的新方法来训练模型来执行此任务，称为时空模型接地，仅使用视频及其自动生成的转录本。&lt;/p>;&lt;p>;研究人员教授一个模型以两种不同的方式理解未标记的视频：通过查看小细节来找出物体所在的位置（空间信息）和查看更大的图片以了解动作何时发生（时间信息）。&lt;/p>;&lt;p>;与其他人工智能方法相比，他们的方法更准确地识别具有多个活动的较长视频中的动作。有趣的是，他们发现同时对空间和时间信息进行训练可以使模型更好地识别每个信息。&lt;/p>;&lt;p>;除了简化在线学习和虚拟培训流程之外，该技术还可以在医疗保健环境中发挥作用：例如，快速找到诊断过程视频中的关键时刻。&lt;/p>;&lt;p>;“我们解决了尝试同时编码空间和时间信息的挑战，而是像两个独立工作的专家一样思考它，这事实证明这是一种更明确的信息编码方式。我们的模型结合了这两个独立的分支，从而实现了最佳性能。”&lt;a href=&quot; https://arxiv.org/pdf/2303.16990&quot; target=&quot;_blank&quot;>;论文的主要作者 Brian Chen 说道。这项技术&lt;/a>;。&lt;/p>;&lt;p>;Chen 是哥伦比亚大学 2023 届毕业生，他在 MIT-IBM Watson AI 实验室做访问生时进行了这项研究，高级研究员 James Glass 也参与了这篇论文科学家、MIT-IBM Watson AI 实验室成员、计算机科学与人工智能实验室 (CSAIL) 口语系统组组长； Hilde Kuehne，MIT-IBM Watson AI 实验室成员，隶属于法兰克福歌德大学；以及麻省理工学院、歌德大学、麻省理工学院-IBM Watson AI 实验室和 Quality Match GmbH 的其他人员。该研究将在计算机视觉和模式识别会议上公布。&lt;/p>;&lt;p>;&lt;strong>;全局和本地学习&lt;/strong>;&lt;/p>;&lt;p>;研究人员通常教授模型进行时空基础使用人类注释了特定任务的开始和结束时间的视频。&lt;/p>;&lt;p>;生成这些数据不仅成本高昂，而且人类很难准确地弄清楚要标记的内容。如果动作是“煮煎饼”，那么该动作是否在厨师开始混合面糊或将面糊倒入锅中时开始？&lt;/p>;&lt;p>;“这一次，任务可能是关于烹饪，但接下来时间，可能是关于修车。人们需要注释的领域有很多。但如果我们可以在没有标签的情况下学习所有内容，那么这就是一个更通用的解决方案。”&lt;/p>;&lt;p>;对于他们的方法，研究人员使用来自 YouTube 等网站的未标记教学视频和随附文本记录作为训练数据。这些不需要任何特殊的准备。&lt;/p>;&lt;p>;他们将训练过程分为两部分。其一，他们教授机器学习模型观看整个视频，以了解在特定时间发生的动作。这种高级信息称为全局表示。&lt;/p>;&lt;p>;第二，他们教导模型关注视频中发生动作的部分的特定区域。例如，在一个大厨房中，模型可能只需要关注厨师用来混合煎饼面糊的木勺，而不是整个柜台。这种细粒度的信息称为局部表示。&lt;/p>;&lt;p>;研究人员在他们的框架中加入了一个额外的组件，以减轻旁白和视频之间发生的不一致。也许厨师先谈论煎饼，然后再执行动作。&lt;/p>;&lt;p>;为了开发更现实的解决方案，研究人员专注于长达几分钟的未剪辑视频。相比之下，大多数人工智能技术使用几秒钟的剪辑进行训练，这些剪辑被修剪为仅显示一个动作。&lt;/p>;&lt;p>;&lt;strong>;一个新的基准&lt;/strong>;&lt;/p>;&lt;p>;但是当他们意识到在评估他们的方法时，研究人员无法找到有效的基准来在这些较长的未剪辑视频上测试模型，因此他们创建了一个。&lt;/p>;&lt;p>;为了构建基准数据集，研究人员设计了一种新的注释技术非常适合识别多步骤操作。他们让用户标记对象的交叉点，例如刀刃切番茄的点，而不是在重要对象周围画一个框。&lt;/p>;&lt;p>;“这样可以更清晰地定义并加快注释过程，从而减少了人力和成本。”Chen 说。&lt;/p>;&lt;p>;此外，让多人对同一视频进行点注释可以更好地捕捉随着时间推移发生的动作，例如倒牛奶的流量。所有注释者都不会在液体流动中标记完全相同的点。&lt;/p>;&lt;p>;当他们使用此基准来测试他们的方法时，研究人员发现它在精确定位动作方面比其他人工智能技术更准确。&lt; /p>;&lt;p>;他们的方法也更擅长关注人与物体的交互。例如，如果动作是“提供煎饼”，许多其他方法可能只关注关键对象，例如柜台上的一堆煎饼。相反，他们的方法侧重于厨师将煎饼翻转到盘子上的实际时刻。&lt;/p>;&lt;p>;现有方法严重依赖人类的标记数据，因此可扩展性不太好。这项工作朝着解决这个问题迈出了一步，通过提供使用事件中自然发生的语音来定位空间和时间中的事件的新方法。此类数据无处不在，因此理论上它将是一个强大的学习信号。然而，它通常与屏幕上的内容完全无关，这使得它很难在机器学习系统中使用。这项工作有助于解决这个问题，使研究人员在未来更容易创建使用这种形式的多模态数据的系统。”密歇根大学电气工程和计算机科学助理教授安德鲁·欧文斯（Andrew Owens）说，他没有参与这项研究。接下来，研究人员计划增强他们的方法，以便模型可以自动检测文本和旁白何时不一致，并将焦点从一种模式切换到另一种模式。他们还希望将他们的框架扩展到另一种模式。音频数据，因为动作和物体发出的声音之间通常存在很强的相关性。&lt;/p>;&lt;p>;“人工智能研究在创建像 ChatGPT 这样理解图像的模型方面取得了令人难以置信的进展，但我们在理解视频方面的进展还远远落后。这项工作代表了朝这个方向迈出的重要一步。”波士顿大学计算机科学系教授凯特·萨恩科 (Kate Saenko) 说道，她没有参与这项工作。&lt;/p>;&lt;p>;这项研究的部分资金来源是由 MIT-IBM Watson AI 实验室开发。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202405/MIT-SpatioTemporal-01-press.jpg?itok=o3abWZ5I" width="390"><media:description type="plain">麻省理工学院的研究人员开发了一种技术，可以教授机器学习模型来识别长视频中的特定动作。</media:description><media:credit>图片来源：麻省理工学院新闻；股票</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/video">视频</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL） </category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/mit-ibm-watson-ai-lab">麻省理工学院-IBM沃森人工智能实验室</category></item></channel></rss>