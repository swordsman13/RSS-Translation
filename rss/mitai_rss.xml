<rss version="2.0" xml:base="https://news.mit.edu" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>麻省理工学院新闻 - 计算机科学与人工智能实验室 (CSAIL)</title><link/> https://news.mit.edu/topic/mitcomputers-rss.xml <atom:link href="https://news.mit.edu/topic/mitcomputers-rss.xml" rel="self" type="application/rss+xml"></atom:link><description>麻省理工学院新闻提要：计算机科学与人工智能实验室 (CSAIL)</description><language> zh</language><lastbuilddate> 2024 年 3 月 21 日星期四 09:30:00 -0400</lastbuilddate><item><title> AI 一步生成高质量图像的速度提高了 30 倍</title><link/>https://news.mit.edu/2024/ai-generates-high-quality-images-30-times-faster-single-step-0321<description>新颖的方法通过将图像生成过程简化为单个步骤，同时保持或增强图像质量，使稳定扩散和 DALL-E-3 等工具变得更快。</description><pubDate> Thu, 21 Mar 2024 09:30:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/ai-generates-high-quality-images-30-times-faster-single-step-0321</guid><dc:creator>雷切尔戈登|麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;在当今的人工智能时代，计算机可以通过&lt;a href=&quot;https://en.wikipedia.org/wiki/Diffusion_model&quot; target=&quot;_blank&quot;>;扩散模型生成自己的“艺术”&lt; /a>;，迭代地向嘈杂的初始状态添加结构，直到出现清晰的图像或视频。扩散模型突然在每个人的餐桌上占据了一席之地：输入几个词，在现实与幻想的交汇处体验瞬间的、令人多巴胺飙升的梦境。在幕后，它涉及一个复杂、耗时的过程，需要算法进行多次迭代才能完善图像。&lt;/p>; &lt;p>;麻省理工学院计算机科学与人工智能实验室 (CSAIL) 研究人员推出了一个新框架，可以简化将传统扩散模型的多步骤过程简化为单个步骤，解决了以前的局限性。这是通过一种师生模型来完成的：教授一个新的计算机模型来模仿生成图像的更复杂的原始模型的行为。该方法称为&lt;a href=&quot;https://tianweiy.github.io/dmd/&quot; target=&quot;_blank&quot;>;分布匹配蒸馏&lt;/a>; (DMD)，保留了生成图像的质量并允许生成速度更快。&lt;/p>; &lt;p>;“我们的工作是一种新颖的方法，可以将稳定扩散和 DALLE-3 等电流扩散模型加速 30 倍，”麻省理工学院电气工程和计算机科学博士生 Tianwei Yin 说道。计算机科学、CSAIL 附属机构以及 DMD 框架的首席研究员。 “这一进步不仅显着减少了计算时间，而且保留了（如果不是超越的话）生成的视觉内容的质量。理论上，该方法将生成对抗网络（GAN）的原理与扩散模型的原理结合起来，一步实现视觉内容生成——这与当前扩散模型所需的数百步迭代细化形成鲜明对比。它可能是一种在速度和质量方面都表现出色的新生成建模方法。”&lt;/p>; &lt;p>;这种单步扩散模型可以增强设计工具，实现更快的内容创建，并有可能支持药物发现和 3D 建模方面的进步，及时性和有效性是关键。&lt;/p>; &lt;p>;&lt;strong>;分销梦想&lt;/strong>;&lt;/p>; &lt;p>;DMD 巧妙地包含两个组成部分。首先，它使用回归损失，锚定映射以确保图像空间的粗略组织，从而使训练更加稳定。接下来，它使用分布匹配损失，确保使用学生模型生成给定图像的概率与其真实世界的出现频率相对应。为此，它利用两个扩散模型作为指导，帮助系统理解真实图像和生成图像之间的差异，并使训练快速的一步生成器成为可能。&lt;/p>; &lt;p>;系统通过训练实现更快的生成一个新的网络，用于最小化其生成的图像与传统扩散模型使用的训练数据集中的图像之间的分布差异。 “我们的主要见解是使用两个扩散模型来近似指导新模型的改进，”尹说。 “通过这种方式，我们将原始的、更复杂的模型的知识提炼成更简单、更快的模型，同时绕过 GAN 中臭名昭著的不稳定和模式崩溃问题。”&lt;/p>; &lt;p>;Yin 和同事使用 pre - 针对新学生模型训练的网络，简化了过程。通过复制和微调原始模型的参数，团队实现了新模型的快速训练收敛，能够在相同的架构基础上生成高质量的图像。 Yin 补充道：“这使得能够与基于原始架构的其他系统优化相结合，进一步加速创建过程。”&lt;/p>; &lt;p>;当使用各种基准测试对通常的方法进行测试时， DMD 显示出一致的性能。在 ImageNet 上基于特定类生成图像的流行基准中，DMD 是第一个一步扩散技术，它生成的图像与原始的、更复杂的模型中的图像几乎相当，摇动了超近的 Fréchet 起始距离（ FID）得分仅为 0.3，这令人印象深刻，因为 FID 的目的就是判断生成图像的质量和多样性。此外，DMD 在工业规模的文本到图像生成方面表现出色，并实现了最先进的一步生成性能。在处理更棘手的文本到图像应用时，仍然存在轻微的质量差距，这表明还有一些改进的空间。&lt;/p>; &lt;p>;此外，DMD 生成的图像的性能具有内在的联系蒸馏过程中使用的教师模型的功能。在当前形式中，使用 Stable Diffusion v1.5 作为教师模型，学生继承了渲染文本和小脸的详细描述等限制，这表明 DMD 生成的图像可以通过更先进的教师模型进一步增强。 &lt;/p>; &lt;p>;“自扩散模型诞生以来，减少迭代次数一直是扩散模型的圣杯”，麻省理工学院电气工程和计算机科学教授、CSAIL 首席研究员、该论文的主要作者 Fredo Durand 说道。 。 “我们非常高兴最终能够实现单步图像生成，这将大大降低计算成本并加速这一过程。”&lt;/p>; &lt;p>;“最终，一篇论文成功地将多功能性和高视觉质量结合在一起加州大学伯克利分校电气工程和计算机科学教授 Alexei Efros 说道，他没有参与这项研究。 “我希望这项工作能够为高质量实时可视化编辑开辟奇妙的可能性。”&lt;/p>; &lt;p>;Yin 和 Durand 的共同作者是麻省理工学院电气工程和计算机科学教授、CSAIL 首席研究员 William T. Freeman 以及 Adob​​e 研究科学家 Michaël Gharbi SM &#39;15、PhD &#39;18；张理查德；伊莱·谢赫特曼；和泰成公园。他们的工作部分得到了美国国家科学基金会的资助（包括人工智能和基础相互作用研究所的资助）、新加坡国防科学技术局以及光州科学技术学院和亚马逊的资助。他们的工作成果将在六月份的计算机视觉和模式识别会议上展示。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202403/computer-generated-images.png?itok=ubolh4pq" width="390"><media:description type="plain">麻省理工学院的研究人员利用 DMD 方法创建了一种一步式 AI 图像生成器，其图像质量可与 StableDiffusion v1.5 相当，同时速度提高 30 倍。</media:description><media:credit> Alex Shipps/MIT CSAIL 使用研究人员开发的六幅人工智能生成图像进行插图。</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/data">数据</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs）</category><category domain="https://news.mit.edu/topic/arts">艺术</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category></item><item><title>新算法解锁计算机视觉的高分辨率见解</title><link/>https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318<description> FeatUp 由麻省理工学院 CSAIL 研究人员开发，可提高计算机视觉系统的任何深度网络或视觉基础的分辨率。</description><pubDate> Mon, 18 Mar 2024 15:10:00 -0400</pubDate><guid ispermalink="true"> https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318</guid><dc:creator>雷切尔戈登|麻省理工学院计算机科学与人工智能实验室</dc:creator><content:encoded>&lt;p>;想象一下你自己看了一会儿繁忙的街道，然后尝试根据记忆描绘出你所看到的场景。大多数人都可以画出汽车、人和人行横道等主要物体的大致位置，但几乎没有人能够以像素完美的精度画出每个细节。大多数现代计算机视觉算法也是如此：它们非常擅长捕捉场景的高级细节，但在处理信息时会丢失细粒度的细节。&lt;/p>; &lt;p>;现在，麻省理工学院的研究人员创建了一个名为“&lt;a href=&quot;https://mhamilton.net/featup.html&quot; target=&quot;_blank&quot;>;FeatUp&lt;/a>;”的系统，可以让算法捕获场景的所有高级和低级细节同时 - 几乎就像计算机视觉的 Lasik 眼科手术一样。&lt;/p>; &lt;p>;当计算机通过查看图像和视频来学习“看”时，它们会通过称为“特征”的东西建立对场景中内容的“想法” ”。为了创建这些功能，深度网络和视觉基础模型将图像分解为小方块网格，并将这些方块作为一个组进行处理，以确定照片中发生了什么。每个小方块通常由 16 到 32 个像素组成，因此这些算法的分辨率比它们处理的图像要小得多。在尝试总结和理解照片时，算法会损失大量像素清晰度。&lt;/p>; &lt;p>;FeatUp 算法可以阻止这种信息损失，并提高任何深度网络的分辨率，而不会影响速度或质量。这使得研究人员能够快速、轻松地提高任何新的或现有算法的分辨率。例如，想象一下尝试解释肺癌检测算法的预测，以定位肿瘤。在使用类激活图 (CAM) 等方法解释算法之前应用 FeatUp，可以根据模型产生肿瘤可能所在位置的更加详细的 (16-32x) 视图。&lt;/p>; &lt;p>;FeatUp 不仅帮助从业者理解他们的模型，还可以改进一系列不同的任务，例如对象检测、语义分割（为带有对象标签的图像中的像素分配标签）和深度估计。它通过提供更准确、高分辨率的特征来实现这一目标，这对于构建从自动驾驶到医学成像等视觉应用至关重要。&lt;/p>; &lt;p>;“所有计算机视觉的本质都在于这些深层的智能特征，从深度学习架构的深处浮现出来。现代算法的一大挑战是它们将大图像缩小为麻省理工学院电气工程和计算机科学博士生、麻省理工学院计算机科学和人工智能实验室 (CSAIL) 附属机构、麻省理工学院计算机科学和人工智能实验室 (CSAIL) 附属机构、麻省理工学院计算机科学与人工智能实验室 (CSAIL) 附属机构马克·汉密尔顿 (Mark Hamilton) 说：关于该项目的&lt;a href=&quot;https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/FeatUp_ICLR_2024.pdf&quot;>;论文&lt;/a>;的主要作者。 “FeatUp 有助于实现两全其美：高度智能的表示与原始图像的分辨率。这些高分辨率功能显着提高了一系列计算机视觉任务的性能，从增强对象检测和改进深度预测到通过高分辨率分析提供对网络决策过程的更深入了解。”&lt;/p>; &lt; p>;&lt;strong>;分辨率复兴&lt;/strong>;&lt;/p>; &lt;p>;随着这些大型人工智能模型变得越来越普遍，越来越需要解释它们在做什么、在看什么以及他们在想什么。&lt;/p>; &lt;p>;但是 FeatUp 究竟如何发现这些细粒度的细节呢？奇怪的是，秘密在于图像的摆动和抖动。&lt;/p>; &lt;p>;特别是，FeatUp 会应用微小的调整（例如将图像向左或向右移动几个像素），并观察算法如何响应这些轻微的调整图像的运动。这会产生数百个略有不同的深度特征图，这些图可以组合成一个清晰的、高分辨率的深度特征集。 “我们想象存在一些高分辨率特征，当我们摆动它们并模糊它们时，它们将与摆动图像中的所有原始、较低分辨率特征相匹配。我们的目标是学习如何使用这个“游戏”将低分辨率特征细化为高分辨率特征，让我们知道我们做得有多好，”汉密尔顿说。这种方法类似于算法如何从多个 2D 图像创建 3D 模型，方法是确保预测的 3D 对象与用于创建它的所有 2D 照片相匹配。在 FeatUp 的例子中，他们预测了一个高分辨率特征图，该特征图与通过抖动原始图像形成的所有低分辨率特征图一致。&lt;/p>; &lt;p>;该团队指出，PyTorch 中可用的标准工具不足以满足他们的要求的需求，并引入了一种新型的深层网络层，以寻求快速高效的解决方案。他们的自定义层是一种特殊的联合双边上采样操作，其效率比 PyTorch 中的简单实现高 100 倍以上。该团队还表明，这个新层可以改进各种不同的算法，包括语义分割和深度预测。这一层提高了网络处理和理解高分辨率细节的能力，为任何使用它的算法带来了显着的性能提升。&lt;/p>; &lt;p>;“另一个应用程序是小对象检索，我们的算法允许物体的精确定位。例如，即使在杂乱的道路场景中，使用 FeatUp 丰富的算法也可以看到诸如交通锥、反光镜、灯光和坑洼等微小物体，而这些物体是低分辨率同类算法无法看到的。这证明了其将粗糙特征增强为精细信号的能力，”加州大学伯克利分校的博士生、新 FeatUp 论文的另一位共同主要作者 Stephanie Fu &#39;22、MNG &#39;23 说道。 “这对于时间敏感的任务尤其重要，例如在无人驾驶汽车中在杂乱的高速公路上精确定位交通标志。这不仅可以通过将广泛的猜测转化为精确的本地化来提高此类任务的准确性，而且还可以使这些系统更加可靠、可解释和值得信赖。”&lt;/p>; &lt;p>;&lt;strong>;接下来做什么？&lt;/strong>; &lt;/p>; &lt;p>;关于未来的愿望，该团队强调 FeatUp 在研究社区内外的潜在广泛采用，类似于数据增强实践。 Fu 说：“我们的目标是使这种方法成为深度学习的基本工具，丰富模型以更详细地感知世界，而不会出现传统高分辨率处理的低计算效率。”&lt;/p>; &lt;p>;“FeatUp 代表了康奈尔大学计算机科学教授诺亚·斯内夫利（Noah Snavely）没有参与这项研究，他说：“通过以全图像分辨率生成视觉表示，在使视觉表示变得真正有用​​方面取得了巨大的进步。” “在过去的几年里，学习的视觉表现已经变得非常好，但它们几乎总是以非常低的分辨率生成——你可能会放入一张漂亮的全分辨率照片，然后得到一个微小的、邮票大小的特征网格。如果您想在产生全分辨率输出的应用程序中使用这些功能，这就是一个问题。 FeatUp 通过将超分辨率的经典思想与现代学习方法相结合，以创造性的方式解决了这个问题，从而产生了漂亮的高分辨率特征图。”&lt;/p>; &lt;p>;“我们希望这个简单的想法能够得到广泛的应用。它提供了我们以前认为只能是低分辨率的图像分析的高分辨率版本，”资深作者、麻省理工学院电气工程和计算机科学教授兼 CSAIL 成员 William T. Freeman 说道。&lt;br />; &lt; br />; 主要作者 Fu 和 Hamilton 陪同的还有麻省理工学院博士生 Laura Brandt SM &#39;21 和 Axel Feldmann SM &#39;21，以及 Zhoutong Zhang SM &#39;21、PhD &#39;22，他们都是麻省理工学院 CSAIL 的现任或前任附属机构。他们的研究部分得到美国国家科学基金会研究生研究奖学金&lt;strong>;、&lt;/strong>;美国国家科学基金会和国家情报总监办公室、美国空军研究实验室以及美国的支持空军人工智能加速器。该小组将于五月在国际学习表征会议上展示他们的工作。&lt;/p>; </content:encoded><media:content height="260" medium="image" type="image/jpeg" url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202402/MIT-FeatUp-cov.png?itok=0zWUKkOf" width="390"><media:description type="plain"> FeatUp 是一种升级深度网络分辨率的算法，可提高对象识别、场景解析和深度测量等计算机视觉任务的性能。</media:description><media:credit>图片：Mark Hamilton 和 Alex Shipps/MIT CSAIL，顶部图片来自 Unsplash。</media:credit></media:content><category domain="https://news.mit.edu/topic/research">研究</category><category domain="https://news.mit.edu/topic/computer-vision">计算机视觉</category><category domain="https://news.mit.edu/topic/machine-learning">机器学习</category><category domain="https://news.mit.edu/topic/artificial-intelligence2">人工智能</category><category domain="https://news.mit.edu/topic/algorithms">算法</category><category domain="https://news.mit.edu/topic/imaging">影像学</category><category domain="https://news.mit.edu/topic/computers">计算机科学与技术</category><category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">电气工程与计算机科学（eecs） </category><category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">计算机科学与人工智能实验室（CSAIL）</category><category domain="https://news.mit.edu/topic/school-engineering">工程学院</category><category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">麻省理工学院施瓦茨曼计算学院</category><category domain="https://news.mit.edu/topic/nsf">美国国家科学基金会 (NSF)</category></item></channel></rss>