<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 6 月 13 日，星期二 18:42:45 +0000</lastbuilddate><language>英文</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1个</sy:updatefrequency><generator>https://wordpress.org/?v=6.2.2</generator><item><title>考虑过去的影像学研究：增强放射学 AI 和报告</title><link/>https://www.microsoft.com/en-us/research/blog/accounting-for-past-imaging-studies-enhancing-radiology-ai-and-reporting/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 13 Jun 2023 18:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=946080 </guid><description><![CDATA[<p>使用图像-文本对的自我监督一直是开发可扩展和灵活的视觉语言 AI ​​模型的关键推动因素，不仅在一般领域，而且在放射学等生物医学领域。放射学设置的目标是在不需要手动标记的情况下产生丰富的训练信号，这样模型就可以 […]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/accounting-for-past-imaging-studies-enhancing-radiology-ai-and-reporting/">对过去影像学研究的解释：增强放射学 AI 和报告</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>使用图像-文本对的自我监督一直是开发可扩展和灵活的视觉语言 AI ​​模型的关键推动因素，不仅在一般领域，而且在放射学等生物医学领域。放射学设置的目标是在不需要手动标记的情况下产生丰富的训练信号，以便模型可以学习准确识别和定位图像中的发现并将它们与放射学报告中的内容相关联。</p><p>放射科医生使用放射学报告来描述影像学发现并提供临床诊断或一系列可能的诊断，所有这些都可能受到以前影像学研究结果的影响。事实上，与以前的图像进行比较对于放射科医生做出明智的决定至关重要。这些比较可以提供有价值的背景，用于确定一种情况是新问题还是改善、恶化或稳定（如果现有情况），并可以提供更合适的治疗建议。尽管比较很重要，但由于无法访问先前的扫描，当前的放射学 AI 解决方案往往无法将图像与报告数据对齐。当前的人工智能解决方案通常也无法解释生物医学数据集中经常出现的疾病或影像学发现的时间顺序。这可能会导致模型训练过程中的歧义，并且在下游应用程序（例如自动报告生成）中可能存在风险，在这些应用程序中，模型可能会在无法访问过去的医学扫描的情况下构成时间内容。简而言之，这限制了此类人工智能模型在现实世界中的适用性，以增强护理人员的能力并增强现有的工作流程。 </p><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--right"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">发表</span><a href="https://www.microsoft.com/en-us/research/publication/learning-to-exploit-temporal-structure-for-biomedical-vision-language-processing/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing" data-bi-aN="margin-callout" data-bi-cN="Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing">学习利用时间结构进行生物医学视觉语言处理<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span></a></li></ul></div><p>在<a href="https://www.microsoft.com/en-us/research/publication/making-the-most-of-text-semantics-to-improve-biomedical-vision-language-processing/">我们之前的工作</a>中，我们证明了放射学图像和报告的多模式自监督学习可以在机器学习模型的下游应用中产生显着的性能改进，例如检测是否存在医疗状况并将这些发现定位在图像中。在<a href="https://cvpr2023.thecvf.com/" target="_blank" rel="noreferrer noopener">2023 年 IEEE/CVF 计算机视觉和模式识别会议 (CVPR)</a>上展示的最新研究中，我们提出了<em><a href="https://www.microsoft.com/en-us/research/publication/learning-to-exploit-temporal-structure-for-biomedical-vision-language-processing/">BioViL-T</a></em> ，这是一种自我监督的训练框架，通过利用生物医学数据集中存在的时间结构。这种方法可以结合时间信息，并有可能在不需要额外数据的情况下执行互补的自我监督，从而提高预测性能。</p><p>我们提出的方法可以处理丢失或空间未对齐的图像，并且可以扩展以处理大量先前图像。通过利用数据集中现有的时间结构，BioViL-T<em> </em>在多个下游基准测试中取得了最先进的结果。我们已将<a href="https://aka.ms/biovil-t-model" target="_blank" rel="noreferrer noopener">我们的模型</a>和<a href="https://aka.ms/biovil-t-code" target="_blank" rel="noreferrer noopener">源代码</a>开源，以便对我们研究中讨论的结果进行全面探索和验证。我们还发布了一个 <a href="https://physionet.org/content/ms-cxr-t/1.0.0/" target="_blank" rel="noreferrer noopener">新的多模式时间基准数据集 MS-CXR-T</a> ，以支持对医学图像和文本数据的纵向建模的进一步研究。 </p><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931959"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-physics-of-ai-with-sebastien-bubeck/" aria-label="AI Frontiers: The Physics of AI with Sébastien Bubeck" data-bi-cN="AI Frontiers: The Physics of AI with Sébastien Bubeck" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/Podcast_Seb-Bubeck_2023Mar_1400x788-641b52c5cf826.png" alt="塞巴斯蒂安·布贝克 (Sebastian Bubeck) 在一张黑白照片中对着镜头微笑，左边是 Microsoft Research Podcast 徽标" /></a></div><div class="msr-promo__content py-3 col-12 col-md"><h2 class="h4"> AI 前沿：AI 物理与塞巴斯蒂安·布贝克 (Sébastien Bubeck)</h2><p class="large">什么是智力？它是如何出现的，我们如何衡量它？ Ashley Llorens 和机器学习理论家 Sébastian Bubeck 讨论了加速大规模人工智能和 GPT-4 早期实验的进展。 <br><a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fmsft.it%2F61835CFKb%3Ffbclid%3DIwAR0sDyENIP-wLZvngSQmw21jreqUIHBbyv2KolZK6H4BWAtwFXsKgafg4xM&h=AT0D-GvhrGXafUSLWmOhIiLMzRcG1ATyEja5CYwPUfDZjUkzJ1I6fxNS8FwoV4imqylt08Oo8VUfdQGTptG3GJTKghii5-Edhjokhyi1Qqf4OxTHBeZ7QHYWLXLpkqnauJYK&__tn__=H-R&c[0]=AT3QF5SN7zvKGA4sdQwPrbtJsfteJuGPZqMh3uC5QsK31BqLN4cz-rtY5Zv_MkR6excR2jLuNWR4qLSSTLSKAJx2vMFxG2oQySRIlSdeR0EBAJ9cx9hLPmj2bu8BeZaNh_dFdUpiBud4lYPPpw7ihcDYAHmic4HS4l7w_Is4L3c5-PTdJC5jLm1nVgySB4mGwIhSY45yB0yJKAE" target="_blank" rel="noreferrer noopener"></a></p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-physics-of-ai-with-sebastien-bubeck/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: The Physics of AI with Sébastien Bubeck" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--></div><!--/.msr-promo--><h2 class="wp-block-heading" id="connecting-the-data-points">连接数据点</h2><p>解决视觉语言处理中的静态情况——即使用成对的<em>单个</em>图像和说明进行学习——是推进该领域的自然而然的第一步。因此，当前的生物医学视觉语言处理工作主要集中于依赖于单个时间点出现的特征或异常的任务——患者的当前状况是什么，可能的诊断是什么？——处理图像——这并不奇怪文本对（例如 X 光片）和当今数据集中的相应报告作为独立的数据点。当报告中引用先前的成像结果时，该信息通常在培训过程中被忽略或删除。此外，缺乏包含纵向系列影像检查和报告的公开数据集进一步挑战了将时间信息纳入医学影像基准。</p><p>由于我们早期与执业放射科医生的密切合作，以及我们与 Nuance 的长期合作，Nuance 是放射学领域领先的 AI 解决方案提供商， <a href="https://news.microsoft.com/2022/03/04/microsoft-completes-acquisition-of-nuance-ushering-in-new-era-of-outcomes-based-ai/" target="_blank" rel="noreferrer noopener">于 2022 年被微软收购</a>，我们能够更好地了解临床医生在放射学中的工作流程成像设置。这包括放射学数据是如何创建的，它的不同组成部分是什么，以及放射科医生在解释医学图像的背景下如何例行地参考先前的研究。有了这些见解，我们能够将跨多个图像的文本时间对齐确定为具有临床意义的研究问题。要将“胸腔积液与以前的研究相比有所改善”等报告信息与成像模式结合或关联，需要访问先前的成像研究。我们能够<em>在不</em>收集额外数据或注释的情况下应对这一挑战。</p><p>作为一种创新解决方案，我们利用了来自<a href="https://physionet.org/content/mimic-cxr/2.0.0/" target="_blank" rel="noreferrer noopener">MIMIC-CXR</a>等去识别化公共数据集的元数据。该元数据保留了研究的原始顺序和间隔，使我们能够随着时间的推移连接各种图像并观察疾病进展。如果我们想开发有意义的 AI 解决方案，那么在数据源稀缺的医疗保健领域开发更高效、更智能的解决方案非常重要。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1104" height="643" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/Nuance_BioViLt_diagram_cropped.gif" alt="BioViL-T 的动画流程图。箭头从先前的胸部 X 光片和当前的胸部 X 光片通过标记为“CNN”的框指向图像嵌入，分别用紫色立方体和棕色立方体表示，代表相关的空间和时间特征。一个箭头从这些特征通过标有“Vision Transformer Blocks”的框指向“差异嵌入”，由蓝色立方体表示。指向标记为“图像特征”的棕色和蓝色立方体的花括号表示当前图像嵌入和差异嵌入的聚合。来自“图像特征”立方体和放射学报告摘录的箭头指向文本模型，由标有“CXR-BERT”的框表示。" class="wp-image-946818"/><figcaption class="wp-element-caption">图 1：拟议的自我监督训练框架 BioViL-T 利用成对的放射学报告和医学图像序列。该训练方案不需要手动专家标签，可以扩展到大量放射学数据，以预训练下游临床应用所需的图像和文本模型。 </figcaption></figure><h2 class="wp-block-heading" id="addressing-the-challenges-of-longitudinal-analysis">应对纵向分析的挑战</h2><p>现在可以比较当前和以前的图像，问题就变成了，<em>模型如何推理来自不同时间点的图像</em>？放射成像，尤其是像 X 光片这样的平面技术，可能会显示出明显的变化。这可能会受到诸如捕获期间患者的姿势和设备定位等因素的影响。值得注意的是，当图像之间的时间间隔较长时，这些变化会变得更加明显。为了管理变化，当前的纵向分析方法主要仅用于图像模型的完全监督学习，需要大量的预处理，例如图像配准，这是一种试图对齐在不同时间从不同视点拍摄的多张图像的技术。除了更好地管理图像变化之外，我们还需要一个框架，该框架可以应用于先前图像不相关或不可用且任务仅涉及一个图像的情况。</p><p>我们在设计 BioViL-T 时考虑到了这些挑战。它的主要组件是一个多图像编码器，包括一个视觉转换器和一个卷积神经网络 (CNN)，以及一个文本编码器。如图 1 所示，在多图像编码器中，每个输入图像首先使用 CNN 模型进行编码，以独立提取每次医学扫描中出现的结果，例如混浊。在这里，CNN 通过其提取低级语义特征的效率来抵消基于 transformer 的架构的大数据需求。</p><p>在下一阶段，跨时间点的特征在视觉转换器块中进行匹配和比较，然后聚合成一个包含当前和历史放射学信息的联合表示。值得注意的是，transformer 架构可以适应单图像或多图像场景，从而更好地处理过去图像不可用的情况，例如没有相关图像历史记录的情况。此外，跨图像区域的交叉注意力机制减少了对大量预处理的需求，解决了跨图像的潜在变化。<br><br>在最后阶段，多图像编码器与文本编码器联合训练，使用掩码建模和对比监督技术将图像表示与其文本对应物进行匹配。为了改进文本表示和模型监督，我们使用特定领域的文本编码器<a href="https://huggingface.co/microsoft/BiomedVLP-CXR-BERT-general" target="_blank" rel="noreferrer noopener">CXR-BERT-general</a> ，它在临床文本语料库上进行了预训练，并建立在临床词汇表上。 </p><figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1200" height="597" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/Nuance_rollout_attention_gif.gif" alt="两张胸部 X 光片并排显示肺部受影响区域的边界框和注意力图。" class="wp-image-946827"/><figcaption class="wp-element-caption">图 2：当前（左）和之前（右）胸部 X 光扫描示例。在视觉转换器中计算的注意力图显示（紫色）模型如何通过关注这些图像区域来解释疾病进展。在这个例子中，在左肺叶中看到的气域疾病自上次采集以来有所改善。</figcaption></figure><h2 class="wp-block-heading" id="grounded-model-prediction">接地模型预测</h2><p>在我们的工作中，我们发现在预训练期间链接多个图像可以实现更好的语言和视觉表示，使 AI 模型能够更好地关联文本和图像中存在的信息。这意味着，当给出胸部 X 光放射学报告时，例如，描述为“与之前的检查相比，左下肺的不透明度增加”，模型可以更准确地识别、定位和比较发现，例如不透明度。这种改进的数据模式之间的一致性至关重要，因为它允许模型提供更准确和相关的见解，例如识别医学图像中的异常、生成更准确的诊断报告或跟踪疾病随时间的进展<em>。</em></p><p>在我们使用 BioViL-T 进行实验期间，有两个发现对我们来说特别有见地：</p><ul><li>今天的语言生成 AI 模型通常通过<em>屏蔽</em>部分文本然后提示它们填充空白来训练，以此作为鼓励模型在输出预测时考虑上下文的​​一种方式。我们将传统的掩码语言建模 (MLM) 方法扩展为以多图像上下文为指导，本质上使该方法成为多模态。这反过来帮助我们更好地分析 BioViL-T 是根据提供的图像学习进展，还是仅根据文本上下文随机预测屏蔽词。我们给模型放射学图像和报告与进展相关的语言，例如“改善”，蒙面。一个示例输入是“胸腔积液从昨天开始就被[掩盖]了。”然后，我们让模型根据单图像和多图像输入预测缺失的单词。当提供单个图像时，模型无法成功完成任务；但是，当提供当前图像和先前图像时，性能会有所提高，表明该模型的预测是基于先前图像。</li><li>此外，我们发现，对先前图像的训练减少了生成式 AI 模型的实例，这些实例产生了看似合理但实际上不正确的输出，在这种情况下，当缺乏信息时。放射学报告生成的先前工作使用单个输入图像，导致模型可能输出描述进展的文本，而无需访问过去的扫描。这严重限制了人工智能解决方案在医疗保健等高风险领域的潜在采用。然而，减少未接地的输出可能会在未来实现自动报告生成或辅助写作，这可能<a href="https://www.microsoft.com/en-us/industry/blog/healthcare/2022/03/04/microsoft-and-nuance-supporting-the-resilience-of-healthcare/" target="_blank" rel="noreferrer noopener">有助于减少行政职责并缓解医疗保健社区的倦怠</a>。请注意，这些模型目前不打算用于任何临床用途，但它们是评估医疗保健 AI 能力的重要证据。</li></ul><h2 class="wp-block-heading" id="moving-longitudinal-analysis-forward">向前推进纵向分析</h2><p>通过我们与执业放射科医生和 Nuance 的关系，我们能够确定并专注于一个临床上重要的研究问题，发现如果我们想开发有价值的 AI 解决方案，考虑患者病史很重要。为了帮助研究界推进纵向分析，我们发布了一个新的基准数据集。 <a href="https://physionet.org/content/ms-cxr-t/1.0.0/" target="_blank" rel="noreferrer noopener">MS-CXR-T</a>由经过委员会认证的放射科医师策划，由标记有时间图像分类任务进展状态的当前先验胸部 X 光图像对和关于疾病进展的成对句子组成矛盾或捕获相同的评估，但对于句子相似性任务的措辞不同。</p><p>我们专注于胸部 X 光和肺部疾病，但我们认为我们的工作有可能扩展到其他医学成像设置，在这些设置中，随着时间的推移分析图像在临床医生决策中起着重要作用，例如涉及 MRI 或 CT 的场景扫描。无论范围有多远，至关重要的是要确保 BioViL-T 等模型在不同人群中以及在捕获医学图像的各种条件下都能很好地推广。旅程的这一重要部分需要在看不见的数据集上对模型进行广泛的基准测试。这些数据集在采集设置、患者人口统计和疾病流行方面应该有很大差异。我们期待探索和监测这项工作的另一个方面是通用基础模型（如 GPT-4）在特定领域基础模型训练中的潜在作用，以及将较大的基础模型与较小的专用模型（如 BioViL-T）配对的好处。</p><p>要了解更多信息并访问我们的文本和图像模型以及源代码，请访问<a href="https://huggingface.co/microsoft/BiomedVLP-BioViL-T" target="_blank" rel="noreferrer noopener">BioViL-T Hugging Face 页面</a>和<a href="https://github.com/microsoft/hi-ml/tree/main/hi-ml-multimodal" target="_blank" rel="noreferrer noopener">GitHub</a> 。</p><div class="wp-block-buttons"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://huggingface.co/microsoft/BiomedVLP-BioViL-T" target="_blank" rel="noreferrer noopener">BioViL-T 模型</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/hi-ml/tree/main/hi-ml-multimodal" target="_blank" rel="noreferrer noopener">BioViL-T代码</a></div></div><h2 class="wp-block-heading" id="acknowledgments">致谢</h2><p>我们要感谢我们的合著者： <a href="https://www.microsoft.com/en-us/research/people/shbannur/">Shruthi Bannur</a> 、 <a href="https://www.microsoft.com/en-us/research/people/sthyland/">Stephanie Hyland</a> 、Qianchu Liu <a href="https://www.microsoft.com/en-us/research/people/fperezgarcia/">、Fernando Pérez-García</a> 、 <a href="https://www.microsoft.com/en-us/research/people/maxilse/">Maximilian Ilse</a> 、Daniel C. Castro、Benedikt Boecking、 <a href="https://www.microsoft.com/en-us/research/people/harssharma/">Harshita Sharma</a> 、 <a href="https://www.microsoft.com/en-us/research/people/t-kbouzid/">Kenza Bouzid</a> 、 <a href="https://www.microsoft.com/en-us/research/people/anthie/">Anja Thieme</a> 、 <a href="https://www.microsoft.com/en-us/research/people/antonsc/">Anton Schwaighofer</a> 、Maria Wetscherek和<a href="https://www.microsoft.com/en-us/research/people/adityan/">Aditya Nori</a> 。我们还要感谢<a href="https://www.microsoft.com/en-us/research/people/hoifung/">Hoifung Poon</a> 、Melanie Bernhardt、 <a href="https://www.microsoft.com/en-us/research/people/mebristo/">Melissa Bristow</a>和<a href="https://www.microsoft.com/en-us/research/people/naotous/">Naoto Usuyama</a>提供宝贵的技术反馈，并感谢<a href="https://www.microsoft.com/en-us/research/people/hamurfet/">Hannah Richardson</a>协助合规审查。</p><h2 class="wp-block-heading" id="medical-device-disclaimer">医疗器械免责声明</h2><p>BioViL-T 是为研究目的而开发的，并非设计、意图或作为医疗设备提供，不应用于替代或替代专业医疗建议、诊断、治疗或判断。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/accounting-for-past-imaging-studies-enhancing-radiology-ai-and-reporting/">对过去影像学研究的解释：增强放射学 AI 和报告</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2023 年 6 月 5 日那一周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-june-5-2023/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 07 Jun 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=945684 </guid><description><![CDATA[<p>本期：Peter Lee 讨论医学中的 AI。另外，关于机器学习中数据推理隐私的新研究；语言模型中的 PII 泄漏；以及具有梯度下降和波束搜索的自动提示组织。</p><p>帖子<a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-june-5-2023/">Research Focus：2023 年 6 月 5 日的那一周</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1400" height="264" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/RF17-blog-banner-1400x264_v2.jpg" alt="微软研究焦点 17 | 2023 年 6 月 5 日那一周" class="wp-image-946044" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/RF17-blog-banner-1400x264_v2.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/RF17-blog-banner-1400x264_v2-300x57.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/RF17-blog-banner-1400x264_v2-1024x193.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/RF17-blog-banner-1400x264_v2-768x145.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/RF17-blog-banner-1400x264_v2-240x45.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎阅读 Research Focus，这是一系列博客文章，重点介绍 Microsoft 整个研究社区的著名出版物、事件、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><aside id=accordion-79a621fb-ad0b-4c46-b56e-a09949ccf47f class="msr-table-of-contents-block accordion mb-5 pb-0" data-bi-aN="table-of-contents"> <button class="btn btn-collapse bg-gray-100 mb-0 display-flex justify-content-between" type="button" data-mount="collapse" data-target="#accordion-collapse-79a621fb-ad0b-4c46-b56e-a09949ccf47f" aria-expanded="true" aria-controls="accordion-collapse-79a621fb-ad0b-4c46-b56e-a09949ccf47f"><span class="msr-table-of-contents-block__label subtitle">在本文中</span><span class="msr-table-of-contents-block__current mr-4 text-gray-600 font-weight-normal" aria-hidden="true"></span></button> <div id="accordion-collapse-79a621fb-ad0b-4c46-b56e-a09949ccf47f" class="msr-table-of-contents-block__collapse-wrapper collapse show" data-parent="#accordion-79a621fb-ad0b-4c46-b56e-a09949ccf47f"><div class="accordion-body bg-gray-100 border-top pt-4"><ol class="msr-table-of-contents-block__list"><li class="msr-table-of-contents-block__list-item"> <a href="#the-gpt-x-revolution-in-medicine-with-peter-lee" class="msr-table-of-contents-block__list-item-link">GPT-x 医学革命，Peter Lee</a></li><li class="msr-table-of-contents-block__list-item"> <a href="#sok-let-the-privacy-games-begin-a-unified-treatment-of-data-inference-privacy-in-machine-learning" class="msr-table-of-contents-block__list-item-link">SoK：让隐私游戏开始吧！机器学习中数据推理隐私的统一处理</a></li><li class="msr-table-of-contents-block__list-item"><a href="#analyzing-leakage-of-personally-identifiable-information-in-language-models" class="msr-table-of-contents-block__list-item-link">分析语言模型中个人身份信息的泄漏</a></li><li class="msr-table-of-contents-block__list-item"><a href="#automatic-prompt-optimization-with-gradient-descent-and-beam-search" class="msr-table-of-contents-block__list-item-link">使用“梯度下降”和波束搜索进行自动提示优化</a></li></ul></div></div><span class="msr-table-of-contents-block__progress-bar"></span></aside><h6 class="wp-block-heading has-blue-color has-text-color" id="podcast">播客</h6><h2 class="wp-block-heading" id="the-gpt-x-revolution-in-medicine-with-peter-lee">GPT-x 医学革命，Peter Lee</h2><p> Microsoft Research 的 Peter Lee 最近坐下来讨论 GPT-4 和医学中的大型语言模型对医师科学家 Eric Topol 的<a href="https://erictopol.substack.com/p/peter-lee-and-the-impact-of-gpt-4" target="_blank" rel="noreferrer noopener">Ground Truths 播客</a>的影响。对话取材于 Lee 的新书<a href="https://www.amazon.com/AI-Revolution-Medicine-GPT-4-Beyond/dp/0138200130/ref=sr_1_1?crid=YS7O6JCQL4OR&keywords=peter+lee+ai+medicine&qid=1684788057&sprefix=peter+lee%2Caps%2C293&sr=8-1" target="_blank" rel="noreferrer noopener">《医学中的 AI 革命》</a> ，内容包括他对 GPT-4 的早期实验以及他对其潜力和弱点的看法。</p><p>例如：</p><ul><li> GPT-4 擅长评估和审查内容，深刻发现不一致和遗漏的引用，以及察觉术语缺乏包容性和多样性</li></ul><ul><li>GPT-4 可以帮助减少医疗错误并指导医生考虑不同的诊断并对患者表现出更大的同理心</li><li>GPT-4 有可能为患者提供新工具并使专家医疗信息的访问民主化</li><li>人工智能需要适当的监管，尤其是在医学领域</li></ul><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://erictopol.substack.com/p/peter-lee-and-the-impact-of-gpt-4" target="_blank" rel="noreferrer noopener">探索播客</a></div></div><div style="height:15px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="874872"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：点播活动</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/event/microsoft-research-summit-2022/?OCID=msr-researchsummit_Blog_PromoMod" aria-label="Microsoft Research Summit 2022" data-bi-cN="Microsoft Research Summit 2022" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2022/09/WebsiteHero_1400x788_B.jpg" alt="蓝色、紫色和橙色瓷砖向上移动的抽象图像" /></a></div><div class="msr-promo__content py-3 col-12 col-md"><h2 class="h4"> 2022 年微软研究院峰会</h2><p class="large"><strong>一经请求</strong><br>立即观看以了解我们的研究社区面临的一些最紧迫的问题，并收听与 120 多名研究人员的对话，讨论如何确保新技术为人类带来尽可能广泛的利益。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/event/microsoft-research-summit-2022/?OCID=msr-researchsummit_Blog_PromoMod" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Read more" data-bi-cN="Microsoft Research Summit 2022" target="_blank">探索会议</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--></div><!--/.msr-promo--><h6 class="wp-block-heading has-blue-color has-text-color" id="new-research">新研究</h6><h2 class="wp-block-heading" id="sok-let-the-privacy-games-begin-a-unified-treatment-of-data-inference-privacy-in-machine-learning"> SoK：让隐私游戏开始吧！机器学习中数据推理隐私的统一处理</h2><p>在生产中部署机器学习模型可能会让对手推断出有关训练数据的敏感信息。推理风险的范围从成员推理到数据重建攻击。受密码学游戏成功研究安全属性的启发，一些作者使用类似的基于游戏的形式主义描述了机器学习中的隐私推理风险。然而，对手的能力和目标在一次次展示中的陈述方式往往略有不同，这使得很难关联和组合结果。</p><p>在一篇新的研究论文中， <a href="https://www.microsoft.com/en-us/research/publication/sok-let-the-privacy-games-begin-a-unified-treatment-of-data-inference-privacy-in-machine-learning/">SoK：让隐私游戏开始吧！ A Unified Treatment of Data Inference Privacy in Machine Learning</a> ，Microsoft 的研究人员提出了一个基于游戏的框架，以系统化机器学习中隐私推理风险的知识体系。在<a href="https://www.ieee-security.org/TC/SP2023/%22HYPERLINK%20%22https://www.ieee-security.org/TC/SP2023/" target="_blank" rel="noreferrer noopener">2023 年 IEEE 安全与隐私研讨会</a>上发表的论文中，作者使用此框架 (1) 为推理风险的定义提供统一结构，(2) 正式建立定义之间的已知关系，以及 (3)发现迄今为止难以发现的未知关系。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/sok-let-the-privacy-games-begin-a-unified-treatment-of-data-inference-privacy-in-machine-learning/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h6 class="wp-block-heading has-blue-color has-text-color" id="new-research-1">新研究</h6><h2 class="wp-block-heading" id="analyzing-leakage-of-personally-identifiable-information-in-language-models">分析语言模型中个人身份信息的泄漏</h2><p>语言模型 (LM) 被广泛部署以执行多种不同的下游任务。然而，它们已被证明会通过句子级成员推理和重建攻击泄露有关训练数据的信息。了解 LM 泄露个人身份信息 (PII) 的风险受到的关注较少。诸如清理之类的数据集管理技术可以减少但不能防止 PII 泄漏的风险——实际上，清理是不完美的，必须在最大限度地减少披露和保留数据集的实用性之间进行权衡。另一方面，尚不清楚差分隐私等旨在保证句子或用户级隐私的算法防御在多大程度上防止 PII 泄露。</p><p>在一篇新的研究论文中， <a href="https://www.microsoft.com/en-us/research/publication/analyzing-leakage-of-personally-identifiable-information-in-language-models/">分析语言模型中个人身份信息的泄漏</a>，微软的研究人员通过黑盒提取、推理和重建攻击引入了基于游戏的三种 PII 泄漏的严格定义，只有对 LM 的 API 访问。在 2023 年 IEEE 安全与隐私研讨会上发表的论文中，他们根据经验评估了针对 GPT-2 模型的攻击，这些模型在判例法、医疗保健和电子邮件这三个领域进行了微调，有和没有防御。</p><p>他们的发现表明，差异隐私可以在很大程度上但不能完全缓解 PII 泄漏。传统的数据管理方法（如 PII 清理）仍然是实现充分保护所必需的。作者提倡设计不太激进的 PII 清理技术，以考虑 DP 提供的保护并实现更好的隐私/实用程序权衡。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/analyzing-leakage-of-personally-identifiable-information-in-language-models/">阅读论文</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/analysing_pii_leakage" target="_blank" rel="noreferrer noopener">下载代码</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h6 class="wp-block-heading has-blue-color has-text-color" id="new-research-2">新研究</h6><h2 class="wp-block-heading" id="automatic-prompt-optimization-with-gradient-descent-and-beam-search">使用“梯度下降”和波束搜索进行自动提示优化</h2><p>大型语言模型 (LLM) 作为通用代理显示出令人印象深刻的性能，但它们的能力仍然高度依赖于手写提示，这需要繁重的试错工作。自动或半自动程序将帮助人们编写最佳提示，同时减少手动工作。在最近的一篇研究论文<a href="https://www.microsoft.com/en-us/research/publication/automatic-prompt-optimization-with-gradient-descent-and-beam-search/">《Automatic Prompt Optimization with “Gradient Descent” and Beam Search》</a>中，Microsoft 的研究人员针对这个问题提出了一个简单且非参数化的解决方案。自动提示优化 (APO) 受到数值梯度下降的启发，可以自动改进提示，前提是可以访问训练数据和 LLM API。该算法使用小批量数据来形成批评当前提示的自然语言“梯度”。然后通过在梯度的相反语义方向上编辑它，将梯度“传播”到提示中。这些梯度下降步骤由波束搜索和强盗选择程序引导，可显着提高算法效率。三个基准 NLP 任务和 LLM 越狱检测新问题的初步结果表明，APO 可以胜过先前的提示编辑技术，并将初始提示的性能提高多达 31%，方法是使用数据将模糊的任务描述重写为更精确的注释指令。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/automatic-prompt-optimization-with-gradient-descent-and-beam-search/">阅读论文</a></div></div><p>帖子<a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-june-5-2023/">Research Focus：2023 年 6 月 5 日的那一周</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>