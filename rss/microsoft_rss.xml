<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 9 月 8 日星期五 00:37:02 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.1</generator><item><title>通过文本到图像生成镜头了解社会偏见</title><link/>https://www.microsoft.com/en-us/research/blog/understanding-social-biases-through-the-text-to-image- Generation-lens/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Fri, 08 Sep 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/understanding-social-biases-through-the-text-to-image- Generation-lens/ </guid><description><![CDATA[<p>人工智能生成的图像中的性别、种族和年龄差异仍然存在。这项 AIES 2023 关于文本到图像模型的研究表明，即使是基本的提示也可能导致代表性不足，因此需要采取负责任的偏见缓解策略。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/understanding-social-biases-through-the-text-to-image-generation-lens/">《通过文本到图像生成镜头了解社会偏见》</a>一文首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-left"><strong><em>这篇研究论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aies-conference.com/2023/" target="_blank" rel="noreferrer noopener">第六届 AAAI/ACM 人工智能、伦理与社会会议 (AIES) <span class="sr-only">（在新选项卡中打开）</span></a>上发表，这是讨论人工智能社会和伦理方面的首要论坛。</em></strong> </p><figure class="wp-block-image size-full"><img decoding="async" fetchpriority="high" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1.jpg" alt=""Microsoft at AIES 2023: Social Biases through the Text-to-Image Generation Lens" title to the left of the front page of said publication on a red, abstract background." class="wp-image-965313" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>文本转图像 (T2I) 技术的兴起开创了创新的新时代，为创作者、设计师和生产力软件的日常用户提供了广泛的可能性。这项技术可以将描述性文本转化为非常逼真的视觉内容，使用户能够通过生动的说明元素来丰富他们的工作。然而，这一创新背后隐藏着一个值得注意的问题——可能包含有害的社会偏见。</p><p>这些 T2I 模型根据他们所接受的广泛网络数据创建图像，而这些数据通常缺乏不同人口群体和文化的代表性，甚至可能隐藏有害内容。当这些社会偏见渗透到人工智能生成的内容中时，它们就会延续并放大先前存在的社会问题，加剧这些问题，并形成一个令人不安的循环，破坏以前和当前的缓解努力。 </p><h2 class="wp-block-heading" id="representation-of-gender-race-and-age-across-occupations-and-personality-traits">不同职业和性格特征中性别、种族和年龄的代表性</h2><p>为了解决这个问题，必须根据各种人口因素和场景严格评估这些模型。在我们在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aies-conference.com/2023/" target="_blank" rel="noreferrer noopener">AIES 2023 <span class="sr-only">（</span></a> <a href="https://www.microsoft.com/en-us/research/publication/social-biases-through-the-text-to-image-generation-lens/" target="_blank" rel="noreferrer noopener"><span class="sr-only">在新选项卡中打开）上发表的论文“文本到图像生成镜头中的社会偏见（</span></a>在新选项卡中打开）”中，我们进行了彻底的分析，以研究和量化生成的文本到图像生成镜头中反映的常见社会偏见。图片。我们专注于跨性别、年龄、种族和地理位置的职业、性格特征和日常情境的描绘。 </p><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956154"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" aria-label="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/collaborators_hero_1400x788.jpg" alt="GitHub 产品经理 Kasia Sitkiewicz 和协议实验室研究科学家 Petar Maymounkov 在 Microsoft Research 播客上讨论了他们在 Gov4git 上的合作" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Gov4git、Petar Maymounkov 和 Kasia Sitkiewicz</h2><p class="large"> Gov4git 是一种用于去中心化、开源合作的治理工具，有助于为未来奠定基础，让每个人都可以更高效、透明、轻松地进行协作，并以满足各自社区独特愿望和需求的方式进行协作。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>例如，考虑强化对首席执行官和管家角色的社会偏见的图像。这些职业作为陈规定型性别偏见的例子受到了广泛的研究——其中男性主要担任首席执行官，女性担任管家。对于所有此类案例，我们观察到三种不同的观点：</p><ol start="1"><li><strong>真实世界分布</strong>：依赖于劳动力统计数据，呈现性别、种族和年龄等各个维度的分布。</li></ol><ol start="2"><li><strong>搜索引擎结果</strong>：捕获搜索引擎结果中明显的分布，反映当代的描述。</li></ol><ol start="3"><li><strong>图像生成结果</strong>：强调图像生成输出中观察到的分布。</li></ol><p>我们测试了两种 T2I 生成器：DALLE-v2 和 Stable Diffusion，并将它们与美国劳工统计局 2022 年的数据以及 2020 年进行的 Google 图像搜索结果进行比较，研究女性在五种不同职业中的代表性。值得注意的是，与来自美国劳工统计局 (BLS) 和基于地理参考信息的网络图像搜索 (GIS) 的数据相比，对生成模型的分析揭示了代表性公平性的重大挫折。值得注意的是，DALLE-v2 生成的图像只提供了 CEO 和计算机程序员职业中女性的最少代表性。相反，在稳定扩散生成的图像中，女性在 100% 的时间里始终扮演护士和管家的角色。图 1 说明了我们的发现，图 2 显示了为显示不同职业而生成的图像示例。</p><figure class="wp-block-image aligncenter size-full is-resized"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1.png"><img decoding="async" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1.png" alt="该图表显示了 DALLE-v2、Stable Diffusion、Google Image Search 2020 和 BLS 数据的性别代表性百分比。" class="wp-image-965334" style="width:514px;height:410px" width="514" height="410" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1.png 2385w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1-300x240.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1-1024x818.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1-768x613.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1-1536x1227.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1-2048x1636.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_1-225x180.png 225w" sizes="(max-width: 514px) 100vw, 514px" /></a><figcaption class="wp-element-caption">图 1.DALLE-v2、稳定扩散、Google 图像搜索 2020 和 BLS 数据的性别表示。</figcaption></figure><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2.png"><img decoding="async" width="4819" height="1409" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2.png" alt="使用 DALL-E v2 和稳定扩散模型的“计算机程序员”和“管家”职业的世代示例。" class="wp-image-965337" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2.png 4819w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2-300x88.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2-1024x299.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2-768x225.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2-1536x449.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2-2048x599.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_2-240x70.png 240w" sizes="(max-width: 4819px) 100vw, 4819px" /></a><figcaption class="wp-element-caption">图 2. 使用 DALL-E v2 和稳定扩散模型为“计算机程序员”和“管家”职业生成的前四张图像的示例。值得注意的是，在 500 张生成的图像分布中明显缺少一种性别。</figcaption></figure><p>即使使用“人”等基本提示而不包含职业，我们也观察到模型可能无法代表跨年龄、种族和性别的某些人口群体。当我们分析 DALLE-v2 和稳定扩散时，两者都在一组 500 个生成的图像中提供了除白人之外的有限种族代表。此外，DALLE-v2 输出显示年龄多样性明显缺乏，超过 80% 的图像描绘的是年龄在 18 岁至 40 岁之间的成年人或儿童。图 3 对此进行了说明。</p><figure class="wp-block-image aligncenter size-large"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1.png"><img decoding="async" loading="lazy" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-1024x576.png" alt="三张图表显示了 DALL-E v2 和稳定扩散模型的人类注释者所解释的性别、种族和年龄分布。" class="wp-image-965310" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Social-Biases-Through-the-Text-to-Image-Lense-560x1921-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></a><figcaption class="wp-element-caption">图 3. 人类注释者解释的性别、种族和年龄分布以及在提示“人”的图像生成背景下的自动面部处理。</figcaption></figure><p>我们的研究还研究了积极和消极人格特征的相似表征的偏差，揭示了如何描述这些特征的微妙之处。虽然非白人种族的个体似乎与活力、雄心、奋斗和独立等积极品质有关，但他们也与冷漠、冷酷和自负等消极品质有关。 </p><h2 class="wp-block-heading" id="representation-of-geographical-locations-in-everyday-scenarios">日常生活场景中地理位置的表示</h2><p>我们研究的偏见的另一个方面涉及模型如何解释日常场景中不同地理位置的表示。我们使用“生日聚会的照片”或“图书馆的照片”等提示来做到这一点。尽管很难辨别生成的照片的精确位置，但仍然可以在使用一般提示和指定位置的提示（例如“哥伦比亚生日聚会的照片”）之间衡量这些表示的区别。在本文中，我们描述了每个有人居住的大陆上两个人口最多的国家的实验，考虑了围绕事件、地点、食物、机构、社区和服装的日常场景。当模型给出一般提示时，总体结果表明，为尼日利亚、巴布亚新几内亚和埃塞俄比亚等国家生成的图像在提示和图像之间差异最大，而为德国、美国和俄罗斯生成的图像最接近与一般提示一致。</p><h2 class="wp-block-heading" id="subtle-effects-of-using-expanded-prompts">使用扩展提示的微妙效果</h2><p>许多偏差缓解技术依赖于扩展提示来丰富和多样化模型生成的图像。为了解决人工智能生成图像中的偏差，我们应用了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions" target="_blank" rel="noreferrer noopener">提示工程<span class="sr-only">（在新选项卡中打开）</span></a>来增加图像反映提示中指定内容的可能性。我们使用提示扩展（一种提示工程）来向初始一般提示添加更多描述符，并引导模型走向公正的内容。快速扩展的一个例子是“女医生的肖像”而不是“医生的肖像”。我们的实验证明，即时扩展对于在人工智能生成的图像中创建更具体的内容非常有效。然而，也存在意想不到的结果，特别是在多样性和图像质量下降方面，如图 4 所示。</p><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4.png"><img decoding="async" loading="lazy" width="3511" height="2005" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4.png" alt="DALL-E v2 针对两个提示的生成输出示例：“播音员肖像”和“女播音员肖像”。" class="wp-image-965343" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4.png 3511w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4-300x171.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4-1024x585.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4-768x439.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4-1536x877.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4-2048x1170.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure_4-240x137.png 240w" sizes="(max-width: 3511px) 100vw, 3511px" /></a><figcaption class="wp-element-caption">图 4. 使用“女性”等描述符的扩展提示确实可以产生更多样化的描述，但通常以图像多样性和质量为代价。</figcaption></figure><h2 class="wp-block-heading" id="safeguarding-against-bias-in-t2i-models">防止 T2I 模型中出现偏差</h2><p>随着 T2I 一代模型越来越多地融入我们的数字生态系统，我们必须对它们可能无意中延续的偏见保持警惕，这一点至关重要。这项研究强调了不断评估和完善这些模型的重要性。我们希望本研究中提出的结果和方法为评估和构建新的生成模型提供有价值的见解。我们想强调在此过程中促进负责任的发展和确保代表性公平的重要性。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/understanding-social-biases-through-the-text-to-image-generation-lens/">《通过文本到图像生成镜头了解社会偏见》</a>一文首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>将化学家的见解与人工智能模型相结合，进行单步逆合成预测</title><link/>https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 07 Sep 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=964185 </guid><description><![CDATA[<p>逆合成分析是有机化学中的一项关键任务，也是许多重要行业的核心。它主要涉及将目标分子逐步分解为市售分子。由于合成策略可能非常多样化且具有战略性，因此利用专业知识进行逆合成规划长期以来一直被认为是一门“艺术”。最近，基于机器学习的方法已经实现了[...]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/">将化学家的见解与 AI 模型相结合进行单步逆合成预测一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img decoding="async" loading="lazy" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1024x576.png" alt="逆合成 -" class="wp-image-964194" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>逆合成分析是有机化学中的一项关键任务，也是许多重要行业的核心。它主要涉及将目标分子逐步分解为市售分子。由于合成策略可能非常多样化且具有战略性，因此利用专业知识进行逆合成规划长期以来一直被认为是一门“艺术”。</p><p>最近，基于机器学习的方法在这项任务上取得了有希望的结果，特别是在单步逆合成预测方面。在逆合成中，分子可以表示为 2D 图或 1D SMILES（简化分子输入行输入系统）序列。 SMILES 是一种用纯文本表示化学结构的符号系统，由一系列字符组成，用于描述分子内原子、键和环的排列。 SMILES可以认为是对相应分子图的遍历，如图1所示。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="720" height="480" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Fig1_SMILES.gif" alt="逆合成 -" class="wp-image-964191"/><figcaption class="wp-element-caption">图 1：分子图和 SMILES 字符串的示例</figcaption></figure><p>给定分子的表示，大多数基于机器学习的方法都采用编码器-解码器框架，其中编码器部分将分子（目标产品）序列或图编码为高维向量，解码器从编码器获取输出并生成逐个标记自回归地输出序列（预测的反应物）。</p><p>将逆合成分析作为序列解码问题可以使用在机器翻译或图神经网络中成熟的深度神经架构。虽然人工智能在预测反应物方面取得了重大进展，但承认人类化学家的专业知识至关重要。在现实世界的路线探索任务中，合成化学家依靠他们的专业经验和对潜在机制的抽象理解。它们通常从化学上与目标分子相似的分子子结构或片段开始，为可能产生目标产物的一系列化学反应提供线索。</p><p>我们的论文《 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41467-023-37969-w" target="_blank" rel="noreferrer noopener">利用普遍保留的子结构进行单步逆合成预测<span class="sr-only">》（在新选项卡中打开）</span></a>提出了一种利用有机合成中普遍保留的子结构的新方法。这种方法融合了化学家在逆合成方面的见解，使人工智能模型更接近人类专家的思维方式。</p><h2 class="wp-block-heading" id="substructure-extraction-and-modeling">子结构提取和建模</h2><p>在有机化学的背景下，“子结构”是指化学性质相似或保留在目标分子内的分子片段或较小的结构单元。这些子结构是理解复杂分子组装的重要组成部分，并在逆合成分析中发挥着重要作用。</p><p>基于这个概念，我们的框架由三个主要模块组成：</p><ol><li><strong>反应检索</strong>：该模块检索相似的反应，给定产品分子作为查询。它使用可学习的跨语言记忆检索器在高维向量空间中对齐反应物和产物。</li><li><strong>子结构提取</strong>：我们根据分子指纹从产品分子和顶部交叉比对候选物中提取常见子结构。这些子结构提供了反应物和产物之间的反应级、片段到片段的映射。</li><li><strong>子结构级序列到序列学习</strong>：我们将原始标记级序列转换为子结构级序列。新的输入序列包括子结构的 SMILES 字符串，后跟具有虚拟数字标签的其他片段的 SMILES 字符串。输出序列是带有虚拟编号的片段。虚拟数字用于指示键断裂/连接位点。 </li></ol><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="680" height="592" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2.png" alt="逆合成 -" class="wp-image-964203" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2.png 680w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2-300x261.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2-207x180.png 207w" sizes="(max-width: 680px) 100vw, 680px" /><figcaption class="wp-element-caption">图 2：方法概述，其中虚拟数字标记的原子和子结构以绿色突出显示。</figcaption></figure><p>与大多数现有工作不同，我们的模型只需要预测与子结构连接的片段，从而简化了预测任务，子结构部分保持不变。</p><p>在图2所示的例子中，子结构“COC(=O)Cc1cc2ccc(F)cc2[2cH]c1C.C[1SH](=O)=O”保持不变，模型只需要预测片段“[2BH]2OC(C)(C)C(C)(C)O2。[1cH]1ccc(Br)nc1”。然后将子结构 SMILES 和预测片段 SMILES 组合起来形成完整的反应物 SMILES。 </p><div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="932112"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/" aria-label="AI Frontiers: AI for health and the future of research with Peter Lee" data-bi-cN="AI Frontiers: AI for health and the future of research with Peter Lee" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/PeterLee_podcast-2023Mar_hero_1400x788.png" alt="Peter Lee 戴着眼镜，对着镜头微笑，左侧有 Microsoft Research Podcast 徽标" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 前沿：Peter Lee 的 AI 健康与研究的未来</h2><p class="large">微软研究院院长 Peter Lee 和 AI 科学家兼工程师 Ashley Llorens 讨论了 AI 研究的未来以及 GPT-4 作为医疗副驾驶的潜力。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: AI for health and the future of research with Peter Lee" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="retrosynthesis-prediction">逆合成预测</h2><p>我们使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.uspto.gov/patents" target="_blank" rel="noreferrer noopener">美国专利商标局完整数据集<span class="sr-only">（在新选项卡中打开）</span></a>分析了我们的方法，并将其与该领域的其他著名作品进行了比较。与之前测试的方法相比，几乎在每种情况下，我们的方法都实现了可比或更好的 top-1 准确率。在成功提取子结构的数据子集中，与总体结果相比，模型性能显着提高。</p><p>我们方法的改进可归因于两个主要因素：</p><ol><li>我们的方法成功地从 USPTO 完整测试数据集中 82.2% 的产品中提取了子结构，证明了该方法的普遍适用性。</li><li>我们只需要生成连接到子结构中虚拟标记原子的片段，这缩短了分子的字符串表示，并显着减少了要预测的原子数量。 </li></ol><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="671" height="588" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3.png" alt="逆合成 -" class="wp-image-964206" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3.png 671w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3-300x263.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3-205x180.png 205w" sizes="(max-width: 671px) 100vw, 671px" /><figcaption class="wp-element-caption">图 3：产品分子特定的子结构。这些反应物均含有邻苯二甲酰亚胺，其子结构以绿色突出显示。</figcaption></figure><p>我们的一步逆合成方法的一个关键方面是提取产品特定的子结构。通过这样做，我们可以更好地捕捉每个反应特有的从反应物到产物的微妙结构变化。以常见的杂环亚结构邻苯二甲酰亚胺为例。我们分析了反应物含有邻苯二甲酰亚胺的四个示例性反应（见图 3）。提取的子结构因不同的反应类型而异，证明了子结构的产物特异性。</p><p>在反应 (a) 和反应 (b) 中，邻苯二甲酰亚胺不被视为子结构的一部分，因为它包含了该反应。然而，在反应(c)和反应(d)中，子结构不同，但它们都含有邻苯二甲酰亚胺。这些结果表明子结构确实是特定于产品的，这符合我们的预期。</p><h2 class="wp-block-heading" id="incorporating-human-insights-into-decision-making">将人类洞察纳入决策</h2><p>此外，利用普遍保留的子结构还具有另一个好处：为用户提供逆合成规划决策的宝贵见解。与现有方法相比，我们的方法可以帮助人类专家利用他们的化学知识评估潜在的途径并消除不可行的反应。</p><p>对于每个输入产物分子，我们从检索到的反应中提取多个子结构（请参阅我们论文中的详细信息），并且在某些情况下，并非所有子结构都是正确的。因此，我们可以按子结构对预测进行分组。如图 4 所示，预测的反应物和反应组为专家提供了有价值的信息。例如，他们可以通过比较与检索到的候选者相关的反应来完善预测，从而使我们的预测比现有的“黑盒”模型更可解释且更值得信赖。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="647" height="854" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4.png" alt="逆合成 -" class="wp-image-964209" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4.png 647w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4-227x300.png 227w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4-136x180.png 136w" sizes="(max-width: 647px) 100vw, 647px" /><figcaption class="wp-element-caption">图 4：按子结构分组的子结构和预测。检索到的候选反应物（#2、#3 和 #4）表明从检索到的反应物 #1 中提取的子结构可能不正确，因为三键可能是反应位点。提取的子结构以绿色突出显示。</figcaption></figure><p>我们希望我们的工作能够激发人们对逆合成预测和其他相关主题这一快速发展且高度跨学科领域的兴趣。通过突破化学和机器学习的可能性界限，我们可以在理解复杂的化学反应和设计更有效的逆合成策略方面继续取得进展。</p><div class="wp-block-buttons"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/single-step-retrosynthesis-prediction-by-leveraging-commonly-preserved-substructures/">阅读论文</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/">将化学家的见解与 AI 模型相结合进行单步逆合成预测一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>