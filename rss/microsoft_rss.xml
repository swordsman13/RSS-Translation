<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 10 月 5 日星期四 13:36:29 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.1</generator><item><title> HoloAssist：物理世界下一代人工智能副驾驶的多模式数据集</title><link/>https://www.microsoft.com/en-us/research/blog/holoassist-a-multimodal-dataset-for-next-gen-ai-copilots-for-the-physical-world/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Thu, 05 Oct 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=972234 </guid><description><![CDATA[<p> HoloAssist 是一个新的多模式数据集，由 222 名参与者的 166 小时交互式任务执行组成。了解它如何提供宝贵的数据来提高下一代人工智能副驾驶执行实际任务的能力。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/holoassist-a-multimodal-dataset-for-next-gen-ai-copilots-for-the-physical-world/">HoloAssist：物理世界下一代人工智能副驾驶的多模态数据集</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-center">这篇研究论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://iccv2023.thecvf.com/" target="_blank" rel="noreferrer noopener"><strong><em>2023 年 IEEE/CVF 国际计算机视觉会议</em></strong><span class="sr-only">（在新选项卡中打开）</span></a> <strong><em>(ICCV)</em></strong><strong><em>上发表</em></strong>，这是计算机视觉领域的顶级学术会议。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" fetchpriority="high" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1.png" alt=""ICCV23 PARIS" to the left of a picture of the first page of the HoloAssist publication on a blue and purple gradient background." class="wp-image-972549" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>您最后一次面对不知道如何解决的任务是什么时候？也许是在修理坏掉的自行车、更换打印机碳粉，或者制作一杯浓缩咖啡？在这种情况下，您通常的选择可能包括向知识渊博的朋友或亲戚寻求帮助。或者，您可以求助于互联网、进行网络搜索、在在线论坛上提出问题或寻找相关的教学视频。但如果还有另一种选择呢？如果你可以向人工智能助手或<em>副驾驶</em>寻求帮助怎么办？</p><h2 class="wp-block-heading" id="ai-in-the-real-world">现实世界中的人工智能</h2><p>我们的日常生活充满了各种各样的任务，无论是工作还是休闲，跨越数字和物理领域。我们经常发现自己需要指导才能有效地学习和执行这些任务。人工智能的最新进展，特别是在大语言和多模式模型领域，催生了智能数字代理。然而，在我们执行大量任务的物理世界中，人工智能系统历来面临着更大的挑战。</p><p>人工智能社区长期以来的愿望是开发一种交互式人工智能助手，能够感知、推理并与现实世界中的人们协作。无论是自动驾驶、机器人导航和操纵、工业环境中的危险检测，还是混合现实任务的支持和指导等场景，与全数字化活动相比，物理活动的进展速度更慢、增量更大。 </p><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956154"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" aria-label="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/collaborators_hero_1400x788.jpg" alt="GitHub 产品经理 Kasia Sitkiewicz 和协议实验室研究科学家 Petar Maymounkov 在 Microsoft Research 播客上讨论了他们在 Gov4git 上的合作" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Gov4git、Petar Maymounkov 和 Kasia Sitkiewicz</h2><p class="large"> Gov4git 是一种用于去中心化、开源合作的治理工具，有助于为未来奠定基础，让每个人都可以更高效、透明、轻松地进行协作，并以满足各自社区独特愿望和需求的方式进行协作。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="the-promise-and-challenge-of-interactive-ai-copilots">交互式人工智能“副驾驶”的承诺和挑战</h2><p>开发交互式人工智能副驾驶来协助人们完成现实世界的任务有巨大的潜力，但也存在障碍。关键的挑战是当前最先进的人工智能助手缺乏物理世界的第一手经验。因此，他们无法感知现实世界的状态并在必要时积极干预。这种限制源于缺乏对此类场景中感知、推理和建模所需的特定数据的培训。在人工智能发展方面，有句话叫“数据为王”。这次挑战也不例外。为了推进用于物理任务的交互式人工智能代理，我们必须彻底了解问题领域并为副驾驶的能力建立黄金标准。</p><h2 class="wp-block-heading" id="a-new-multimodal-interactive-dataset">一个新的多模态交互式数据集</h2><p>作为朝这个方向迈出的第一步，我们很高兴分享我们在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://iccv2023.thecvf.com/" target="_blank" rel="noreferrer noopener">ICCV <span class="sr-only">2023</span></a>上发表的论文“ <a href="https://www.microsoft.com/en-us/research/publication/holoassist-an-egocentric-human-interaction-dataset-for-interactive-ai-assistants-in-the-real-world/">HoloAssist：现实世界中交互式人工智能助手的以自我为中心的人类交互数据集<span class="sr-only">（在新选项卡中打开）</span></a> ”（在新选项卡中打开） 。 HoloAssist 是一个大规模的以自我为中心或第一人称的人类交互数据集，两个人协作执行物理操作任务。任务执行者戴着混合现实耳机执行任务，该耳机捕获七个同步数据流，如图 1 所示。同时，任务指导员实时观察执行者的第一人称视频并提供口头指导。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="480" height="498" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig1.png" alt="该图像展示了 HoloAssist 数据集的设置，该数据集具有两人交互式辅助任务完成设置。任务执行者戴着混合现实耳机，而教练则观看第一人称视频并提供说明。捕获八种模式：RGB、眼睛注视、手部姿势、头部姿势、深度、IMU、音频、文本转录。" class="wp-image-972576" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig1.png 480w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig1-289x300.png 289w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig1-173x180.png 173w" sizes="(max-width: 480px) 100vw, 480px" /><figcaption class="wp-element-caption">图 1：HoloAssist 具有两人交互式辅助任务完成设置。</figcaption></figure><p> HoloAssist 包含大量数据，包括 222 名不同参与者长达 166 小时的录音。这些参与者组成 350 个不同的指导者-表演者对，执行 20 项以对象为中心的操作任务。视频 1 显示了如何记录任务，而图 2 提供了任务分解。这些物品的范围从常见的电子设备到工厂和专业实验室中发现的稀有物品。这些任务通常要求很高，通常需要教练的帮助才能成功完成。为了提供全面的见解，我们捕获了七种不同的原始传感器模式：RGB、深度、头部姿势、3D 手势、眼睛注视、音频和 IMU。这些模式有助于理解人类意图、估计世界状态、预测未来行动等等。最后，第八种模式是第三人称手动注释的增强，包括文本摘要、干预类型、错误注释和动作片段，如图 3 所示。 </p><figure class="wp-block-video aligncenter"><video controls src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/holoassist4kzoom.mp4"></video><figcaption class="wp-element-caption">视频 1：展示颜色和深度（八种模式中的两种）的任务记录样本。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="624" height="263" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig2.png" alt="HoloAssist 中捕获的数据分布。左侧显示每项活动的会话数，右侧显示会话总时长（以分钟为单位）。有 20 个任务：GoPro、Nintendo Switch、DSLR、便携式打印机、电脑、Nespresso 机、独立打印机、大咖啡机、宜家家具（凳子、实用车、托盘桌、床头柜）、NavVis 激光扫描仪、ATV 摩托车、轮带和断路器。每项活动有 25 到 180 节课，课时从 47 到 1390 分钟不等。" class="wp-image-972573" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig2.png 624w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig2-300x126.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig2-240x101.png 240w" sizes="(max-width: 624px) 100vw, 624px" /><figcaption class="wp-element-caption">图 2：HoloAssist 中捕获的数据分布。左侧是每个活动的会话数。右侧显示总会话时长（以分钟为单位）。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="480" height="414" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig3.png" alt="HoloAssist 包括动作和对话注释，并提供指示任务期间错误和干预的视频摘要。每个动作都标有“错误”或“正确”属性，而口头陈述则标有干预类型。该图显示了其中每一个的示例。" class="wp-image-972570" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig3.png 480w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig3-300x259.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Fig3-209x180.png 209w" sizes="(max-width: 480px) 100vw, 480px" /><figcaption class="wp-element-caption">图 3：HoloAssist 包括动作和对话注释，还提供指示任务期间错误和干预的视频摘要。每个动作都标有“错误”或“正确”属性，而口头陈述则标有干预类型。</figcaption></figure><h2 class="wp-block-heading" id="towards-proactive-ai-assistants">迈向主动的人工智能助手</h2><p>我们的工作建立在以自我为中心的愿景和具体人工智能方面的先前进步的基础上。与早期的数据集（例如表 1 中列出的数据集）不同，HoloAssist 因其多人、交互式任务执行设置而脱颖而出。任务执行过程中的人机交互为设计人工智能助手提供了宝贵的资源，这些助手具有前瞻性和主动性，可以提供基于环境的精确定时指令，这与当前等待您提问的“基于聊天”的人工智能助手形成鲜明对比。这种独特的场景非常适合开发辅助人工智能代理，并补充了现有的数据集，提供了丰富的知识和表示。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="508" height="325" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Table1.png" alt="该表显示了九个相关数据集和模拟平台的比较，以及每个数据集的设置，是否是协作和交互、指导和程序以及视频的小时数。 HoloAssist 具有多人辅助设置，这是对现有第一人称（以自我为中心）数据集的独特补充。" class="wp-image-972567" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Table1.png 508w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Table1-300x192.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/HoloAssist_Table1-240x154.png 240w" sizes="(max-width: 508px) 100vw, 508px" /><figcaption class="wp-element-caption">表1：相关数据集和模拟平台的比较。 HoloAssist 具有多人辅助设置，这是对现有自我中心（第一人称）数据集的独特补充。</figcaption></figure><p>最后，我们评估了数据集在动作分类和预期任务上的表现，提供了实证结果，阐明了不同模式在各种任务中的作用。借助该数据集，我们引入了新的任务和基准，重点关注错误检测、干预类型预测和 3D 手势预测，这些都是开发智能助手的关键要素。</p><h2 class="wp-block-heading" id="looking-forward">期待</h2><p>这项工作代表了更广泛研究的第一步，探索智能代理如何在现实世界的任务中与人类协作。我们很高兴与社区分享这项工作和我们的数据集，并预测许多未来的方向，例如注释对象姿势、研究人工智能辅助中以对象为中心的可供性和操作模型，以及人工智能辅助规划和状态跟踪等其他的。我们相信 HoloAssist 及其相关基准和工具将有利于未来的研究工作，重点是为现实世界的日常任务构建强大的人工智能助手。您可以在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://holoassist.github.io/" target="_blank" rel="noreferrer noopener">GitHub 上访问 HoloAssist 数据集和代码<span class="sr-only">（在新选项卡中打开）</span></a> 。</p><h3 class="wp-block-heading" id="contributors">贡献者</h3><p>Taein Kwon、 <a href="https://www.microsoft.com/en-us/research/people/mahdirad/">Mahdi Rad</a> 、Bowen Pan、 <a href="https://www.microsoft.com/en-us/research/people/ischakra/">Ishani Chakraborty</a> 、 <a href="https://www.microsoft.com/en-us/research/people/sandrist/">Sean Andrist</a> 、 <a href="https://www.microsoft.com/en-us/research/people/dbohus/">Dan Bohus</a> 、 <a href="https://www.microsoft.com/en-us/research/people/ashleyf/">Ashley Feniello</a> 、Bugra Tekin、 <a href="https://www.microsoft.com/en-us/research/people/fevieira/">Felipe Vieira Frujeri</a> 、 <a href="https://www.microsoft.com/en-us/research/people/mapoll/">Marc Pollefeys</a></p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/holoassist-a-multimodal-dataset-for-next-gen-ai-copilots-for-the-physical-world/">HoloAssist：物理世界下一代人工智能副驾驶的多模态数据集</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </content:encoded><enclosure length="120799231" type="video/mp4" url="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/holoassist4kzoom.mp4"></enclosure></item><item><title>加速基础模型研究：支持全球人工智能学术研究生态系统</title><link/>https://www.microsoft.com/en-us/research/blog/accelerate-foundation-models-research-supporting-a-global-academic-research-ecosystem-for-ai/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 03 Oct 2023 16:06:59 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=971679 </guid><description><![CDATA[<p>多样化的研究生态系统对于实现人工智能的前景至关重要。加速基础模型研究旨在扩大对强大模型的访问，吸引计算机科学以外的学者寻求广泛的重要机会。</p><p>这篇文章<a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/accelerate-foundation-models-research-supporting-a-global-academic-research-ecosystem-for-ai/">《加速基础模型研究：支持人工智能的全球学术研究生态系统》</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img decoding="async" loading="lazy" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-1024x576.jpg" alt="AFMR 绿色渐变图像" class="wp-image-972624" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/AFMR-in-post-1400x788-1.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>人工智能的最新进展引发了公众的广泛兴趣和兴奋，科学也不例外。功能日益强大的基础模型正在推动计算研究、自然科学、社会科学甚至计算教育本身的根本性转变。随着行业主导的人工智能进步不断达到新的高度，微软研究院认为，充满活力和多样化的研究生态系统对于实现人工智能的前景至关重要。这意味着确保学术研究界，尤其是计算机科学以外的研究人员，能够利用这些能力。他们跨学科、文化和语言的专业知识的深度和广度可以为我们利用人工智能解决世界上一些最大的技术、科学和社会挑战的能力做出有意义的贡献。</p><p>为此，微软研究院建立了加速基础模型研究 (AFMR)，这是一项新举措，汇集了跨学科研究社区来实现三个目标：</p><ul><li><strong>通过模型研究</strong><strong>将</strong>人工智能与人类共同的目标、价值观和偏好结合起来，从而增强安全性、稳健性、可持续性、责任感和透明度，同时探索新​​的评估方法来衡量新模型快速增长的能力。</li><li><strong>通过社会技术研究改善人类互动，</strong>使人工智能能够扩展人类的聪明才智、创造力和生产力，同时努力减少机会不平等，并努力确保为全世界人民和社会带来积极利益。</li><li>通过主动知识发现、假设生成和多尺度多模式数据生成，<strong>加速</strong><strong>自然科学领域的科学发现</strong>。</li></ul><p> AFMR 是一个全球研究网络和资源平台，使计算机科学和许多其他学科的研究人员能够应对当今时代一些最大的技术和社会挑战。这包括一项资助计划，提供对通过 Microsoft Azure AI 托管的最先进基础模型的访问权限。 </p><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="935415"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：人工智能聚焦领域</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" aria-label="AI and Microsoft Research" data-bi-cN="AI and Microsoft Research" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2020/07/newsletter-option-8-neural-network-3-1.png" alt="深蓝色背景上的抽象神经网络模式" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能和微软研究院</h2><p class="large">详细了解 Microsoft 人工智能研究的广度</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Learn more" data-bi-cN="AI and Microsoft Research" target="_blank">了解更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>其目标是促进跨学科、机构和部门的更多合作，并充分释放人工智能在广泛的研究问题、应用和社会背景下的潜力。</p><p>在成功试点计划和初步征求建议书 (CFP)（详情如下）之后，我们致力于继续这项工作，并有望在来年征集更多建议书。访问<a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/">AFMR 网站</a><a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/"></a>要了解有关即将开展的计划和活动的更多信息，请阅读该计划产生的同行评审工作，并查找资源以加速研究和合作。</p><h2 class="wp-block-heading" id="inspiring-research-in-the-era-of-ai">人工智能时代的启发性研究</h2><p>当 ChatGPT 于 2022 年秋季发布时，人们很快就意识到这项新技术和工具将在人工智能计算研究和应用中发挥核心作用。</p><blockquote class="wp-block-quote is-style-spectrum"><p> “作为一名自然语言处理 (NLP) 研究员，我首先对 ChatGPT 刺激人工智能革命的潜力感到兴奋，”微软研究院研究参与高级总监 Evelyne Viegas 说道。 “很快，我开始担心在行业之外可能无法获得这种资源，这可能会延迟学术环境的重要进展。”</p></blockquote><p>当 Microsoft 通过 Azure AI 服务启用对 OpenAI 模型（Embeddings 系列、GPT-3.5-Turbo 系列和 GPT-4 系列）的访问时，它创造了一个与学术界互动的机会，了解他们的需求和愿望，并开始启用他们。微软研究院的一个团队开展了一项试点计划，向少数参与者提供模型访问权限，这项工作的成功激发了更广泛、更持续的计划。</p><p>作为试点的一部分进行的研究主题反映了微软人工智能研究在理解通用人工智能、推动模型创新、确保社会效益、转变科学发现以及跨不同领域（例如天文学、教育、健康、法律）扩展人类能力方面的雄心。 ， 社会）。</p><p>尽管该试点项目支持的研究仍在进行中，但以下示例说明了向不同研究人员群体开放前沿模型的可能性： </p><h3 class="wp-block-heading h4" id="integrating-chatgpt-into-english-as-a-foreign-language-efl-writing-education-korea-advanced-institute-of-science-and-technology-kaist">将 ChatGPT 融入英语作为外语 (EFL) 写作教育 – 韩国科学技术院 (KAIST)</h3><p>该项目探讨了学生如何利用生成式人工智能在英语写作中进行交互式复习。由于 KAIST 的大部分课程均以英语授课，因此非英语人士越早学习语言，他们就能更好地参与课程。虽然早期的聊天机器人已用于英语教学，但语言学习者发现它们缺乏吸引力。借助 Azure OpenAI 服务，KAIST 团队正在收集数据，以展示基于 GPT-4 的聊天机器人的独特功能如何加速学习，同时使学习者的体验更具吸引力。 </p><h3 class="wp-block-heading h4" id="lightweight-adaptation-of-llms-for-healthcare-applications-stanford-university">法学硕士针对医疗保健应用的轻量级调整——斯坦福大学</h3><p>这项工作的重点是加快放射科医生的报告总结任务，以改进工作流程并减少生成准确报告所需的时间。它通过对生物医学文本或临床文本进行预训练以及离散提示或微调来使用领域适应。初步结果很有希望，显示了使用基础模型执行某些临床任务的附加值。 </p><h3 class="wp-block-heading h4" id="ai-based-traffic-monitoring-system-using-physics-informed-neural-networks-and-gpt-models-north-carolina-a-t-state-university">使用物理信息神经网络和 GPT 模型的基于人工智能的交通监控系统 – 北卡罗来纳州 A&amp;T 州立大学</h3><p>研究人员正在创建一个交通监控系统，利用从无人机 (UAV) 收集的数据来微调视频分析和交通状态估计的基础模型。这项工作可以直接使交通机构和城市规划者受益，帮助他们了解交通模式、拥堵和安全隐患。</p><h3 class="wp-block-heading h4" id="forging-new-horizons-in-astronomy-harvard-university">开拓天文学新视野——哈佛大学</h3><p>该项目旨在利用大语言模型 (LLM)（特别是 GPT-4）的功能来增强人类与天文学文献的交互。这项工作采用上下文提示技术将模型暴露给天文学论文，以构建一个以天文学为中心的聊天应用程序，以吸引更广泛的社区。</p><h2 class="wp-block-heading" id="expanding-afmr">扩大 AFMR</h2><p>基础模型仍需进行大量实验。 AFMR CFP 邀请社群针对以下目标和问题制定提案：</p><ul><li>使人工智能系统与人类目标和偏好保持一致</li><li>推进人工智能的有益应用</li><li>加速自然科学和生命科学领域的科学发现</li></ul><p>AFMR 秋季 CFP 的反响非常热烈，来自 33 个国家的 170 所大学提出了近 400 份提案。</p><blockquote class="wp-block-quote"><p>维加斯说：“主要研究人员进行的研究有望在比我们想象的更广泛的研究追求、应用领域和社会背景上推进研究。” “它涵盖了广泛的科学和社会技术主题：创造力、文化、经济、教育、金融、健康、因果关系、评估、增强和适应、多模式、负责任的人工智能、机器人、科学发现、软件和社会。看到来自不同国家、不同文化、语言、机构和部门（包括计算机科学、社会科学、自然科学、人文、医学、音乐）的专家齐聚一堂，共同致力于人工智能的民主化，并致力于解决一些问题，这是令人鼓舞的。明天最大的技术和社会挑战。” <a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/"></a></p></blockquote><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>这篇文章<a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/accelerate-foundation-models-research-supporting-a-global-academic-research-ecosystem-for-ai/">《加速基础模型研究：支持人工智能的全球学术研究生态系统》</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>