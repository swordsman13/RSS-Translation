<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 7 月 2 日，星期二 13:37:46 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.5</generator><item><title> GraphRAG：用于复杂数据发现的新工具现已在 GitHub 上发布</title><link/>https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 02 Jul 2024 13:37:44 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p> GraphRAG 是一种基于图的检索增强生成 (RAG) 方法，可显着改善私有或以前未见过的数据集的问答能力，现已在 GitHub 上提供。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/">GraphRAG：GitHub 上的复杂数据发现新工具</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1.png" alt="GraphRAG 博客英雄" class="wp-image-1052106" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--left"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">下载</span><a href="https://github.com/microsoft/graphrag" target="_blank" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="GraphRAG" data-bi-aN="margin-callout" data-bi-cN="GraphRAG">GraphRAG<span class="glyph-append glyph-append-share glyph-append-xsmall"></span></a> </li></ul></div><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--right"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">下载</span><a href="https://github.com/Azure-Samples/graphrag-accelerator/" target="_blank" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="GraphRAG Accelerator" data-bi-aN="margin-callout" data-bi-cN="GraphRAG Accelerator">GraphRAG 加速器<span class="glyph-append glyph-append-share glyph-append-xsmall"></span></a></li></ul></div><p>今年早些时候，我们推出了<a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">GraphRAG <span class="sr-only">（在新选项卡中打开）</span></a> ，这是一种基于图的检索增强生成 (RAG) 方法，可以对私有或以前未见过的数据集进行问答。今天，我们很高兴地宣布 GraphRAG 现已在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/graphrag" target="_blank" rel="noreferrer noopener">GitHub 上提供<span class="sr-only">（在新选项卡中打开）</span></a> ，提供比简单的 RAG 方法更结构化的信息检索和全面的响应生成。 GraphRAG 代码存储库由<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/Azure-Samples/graphrag-accelerator/" target="_blank" rel="noreferrer noopener">解决方案加速器<span class="sr-only">（在新选项卡中打开）</span></a>进行补充，提供托管在 Azure 上的易于使用的 API 体验，只需单击几下即可免代码部署。</p><p> GraphRAG 使用大型语言模型 (LLM) 自动从任何文本文档集合中提取丰富的知识图谱。这种基于图形的数据索引最令人兴奋的功能之一是它能够在任何用户查询之前报告数据的语义结构。它通过以分层方式检测密集连接节点的“社区”，将图从高级主题到低级主题划分为多个级别来实现这一点，如图 1 所示。使用 LLM 来总结每个社区会创建数据的分层摘要，提供数据集的概述，而无需提前知道要问哪些问题。每个社区都是描述其实体及其关系的<em>社区摘要</em>的基础。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="1400" height="721" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1.png" alt="图 1：并排显示的两个网络图，布局相同但节点颜色不同。左侧的图具有较少的较大颜色簇，而右侧的图具有较多的较小颜色簇。" class="wp-image-1052112" style="width:900px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-300x155.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-1024x527.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-768x396.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-240x124.png 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 1. 源自<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/yixuantt/MultiHop-RAG/" target="_blank" rel="noreferrer noopener">新闻数据集的实体节点和关系边的知识图<span class="sr-only">（在新选项卡中打开）</span></a> ，用不同的颜色代表不同的社区。 0 级社区（左）代表数据集的最高级别主题，而 1 级社区（右）显示这些主题中出现的更细粒度的主题。 </figcaption></figure><h2 class="wp-block-heading" id="advantages-of-community-summaries-for-global-questions"> “全球问题”社区总结的优势</h2><p>在最近的<a href="https://www.microsoft.com/en-us/research/publication/from-local-to-global-a-graph-rag-approach-to-query-focused-summarization/">预印本</a>中，我们探讨了这些社区摘要如何帮助回答<em>全局问题</em>（解决整个数据集而不是专注于特定的文本块），而基于向量搜索的简单 RAG 方法则无法满足这些问题。例如，考虑这个问题“数据集中的主要主题是什么？”这是一个合理的起点，但天真的 RAG 总是会给出误导性的答案。这是因为它从语义上与问题相似的文本块生成答案，而不一定从回答问题所需的输入文本子集生成答案。</p><p>但是，如果问题涉及整个数据集，则应考虑<em>所有</em>输入文本。由于朴素 RAG 仅考虑输入文本中前<em>k 个</em>最相似的块，因此它会失败。更糟糕的是，它将问题与表面上与该问题相似的文本块进行匹配，从而导致误导性的答案。社区摘要有助于回答此类全局问题，因为实体和关系描述的图形索引在其构造中已经考虑了所有输入文本。因此，我们可以使用映射减少方法进行问答，保留全局数据上下文中的所有相关内容：</p><ol start="1"><li>团体社区报告最多可达 LLM 上下文窗口大小。</li><li>将问题映射到每个组以创建社区答案。</li><li>将所有相关的社区答案简化为最终的全局答案。</li></ol><h2 class="wp-block-heading" id="evaluation-and-results">评价及结果</h2><p>为了针对朴素的 RAG 和分层源文本摘要评估这种方法，我们使用 LLM GPT-4 从两个数据集（播客成绩单和新闻文章）的简短描述中生成一组多样化的以活动为中心的意义建构问题。然后，我们选择了三个指标来对生成的答案进行正面比较，并由法学硕士法官进行评估：全面性（详细涵盖所有方面）、多样性（提供不同的观点）和授权（支持明智的决策）。</p><p>结果表明，当在社区层次结构的任何级别使用社区摘要时，GraphRAG 在全面性和多样性方面都优于 Naive RAG（约 70-80% 的获胜率）。使用中级和低级社区摘要的 GraphRAG 在这些指标上的表现也比源文本摘要更好，且令牌成本较低（每个查询使用约 20-70% 的令牌）。与最高级别社区的分层源文本摘要相比，性能具有竞争力，且令牌成本大幅降低（每个查询使用约 2-3% 的令牌）。如图 2 所示。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/Responses_GraphRAG.png" alt="问：各种娱乐文章中反复提及哪些公众人物？天真的RAG回应：各种娱乐文章中反复提及的公众人物有&lt;公众人物1、2、3、4>;。这些人因各种原因而受到关注，从他们的职业成就到他们的个人生活。 &lt;公开图 1>; [...] &lt;公开图 2>; [...] &lt;公开图 3>; [...] &lt;公开图 4>; [...] 这些数字由于其高个人资料状况以及公众对其职业和个人生活的兴趣。他们的活动，无论是在音乐、体育还是人际关系方面，都具有重大的文化和经济影响，媒体报道和公众反应就证明了这一点。 GraphRAG 回应：娱乐产业广阔且多样化，包括电影、电视、音乐、体育和数字媒体。某些公众人物因其在这些领域的重大贡献和影响力而脱颖而出。以下摘要重点介绍了在各种娱乐文章中反复提及的关键人物，反映了他们在行业中的影响力和影响力。演员和导演 [...20 位人物...] 争议中的公众人物 [...3 位人物...] 音乐家和高管 [...5 位人物...] 运动员和教练 [...7 位人物。 ..] 影响者和企业家 [...3 位人物...] 在娱乐文章中反复提及这些人物表明他们的持续相关性以及公众对其工作的兴趣。他们的影响力遍及娱乐业的各个方面，从塑造电影和电视中的文化叙事到推动音乐和数字媒体的趋势。这些人不仅对各自的领域做出了贡献，而且影响了更广泛的文化景观，往往成为社会讨论和公共话语的核心人物。 LLM评估：综合性：优胜者= GraphRAG；多样性：获胜者 = GraphRAG；赋权：获胜者 = GraphRAG。" class="wp-image-1052745"/><figcaption class="wp-element-caption">图 2. 朴素 RAG 和 GraphRAG 对有关<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/yixuantt/MultiHop-RAG/" target="_blank" rel="noreferrer noopener">新闻数据集的全局问题的回答<span class="sr-only">（在新选项卡中打开）</span></a>的比较表明，GraphRAG 在全面性、多样性和赋权方面优于朴素 RAG。 </figcaption></figure><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044948"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/whats-your-story-weishung-liu/" aria-label="What’s Your Story: Weishung Liu" data-bi-cN="What’s Your Story: Weishung Liu" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Weishung-Liu_WYS_Hero_Feature_1400x788.png" alt="微软研究院播客 |你的故事是什么 |刘伟雄" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">你的故事是什么：刘伟雄</h2><p class="large">首席项目经理刘伟雄分享了提供产品和客户体验的职业生涯如何与她对人和讲故事的热爱相一致，以及尽管她努力违背在硅谷成长过程中的期望，但她是如何进入科技行业的。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/whats-your-story-weishung-liu/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="What’s Your Story: Weishung Liu" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="research-insights-and-future-directions">研究见解和未来方向</h2><p>通过最初的研究周期，我们证明了法学硕士可以成功地从非结构化文本输入中派生出丰富的知识图，并且这些图可以支持一类新的全局查询，对于这些查询（a）朴素的 RAG 无法生成适当的响应，以及（b）分层源每个查询的文本摘要成本高昂。然而，GraphRAG 对于任何给定用例的整体适用性取决于结构化知识表示、现成的社区摘要和对全局查询的支持的好处是否超过图索引构建的前期成本。</p><p>我们目前正在探索各种方法来降低这些成本，同时保持响应质量。我们关于自动调整问题域的 LLM 提取提示的最新工作是我们如何减少自定义这些提示、枚举实体类型、创建少量示例等所需的前期工作的一个示例。为了能够以最小的前期索引成本评估 GraphRAG，我们还在研究基于 NLP 的方法来近似由完整索引过程生成的知识图谱和社区摘要。我们的目标是确保，无论部署环境有什么限制，都有一个 GraphRAG 配置可以适应这些限制，同时仍然提供卓越的响应质量。 </p><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--right"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">下载</span><a href="https://github.com/Azure-Samples/graphrag-accelerator/" target="_blank" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="GraphRAG Accelerator" data-bi-aN="margin-callout" data-bi-cN="GraphRAG Accelerator">GraphRAG 加速器<span class="glyph-append glyph-append-share glyph-append-xsmall"></span></a></li></ul></div><p>通过公开提供 GraphRAG 和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/Azure-Samples/graphrag-accelerator/">解决方案加速器<span class="sr-only">（在新选项卡中打开）</span></a> ，我们的目标是使基于图的 RAG 方法更容易被用户和使用案例使用，在这些情况下，在全球范围内理解数据至关重要。我们鼓励社区对代码存储库和解决方案加速器提供反馈和建议，共同努力实现下一代 RAG 体验。</p><h2 class="wp-block-heading" id="acknowledgements">致谢</h2><p><a href="https://www.microsoft.com/en-us/research/people/joshbradley/">约书亚·布拉德利</a>,克里斯汀·卡吉亚诺,莫妮卡·卡瓦哈尔,亚历克斯·赵,纽曼·程,<a href="https://www.microsoft.com/en-us/research/people/achao/">艾德·克拉克</a>,本<a href="https://www.microsoft.com/en-us/research/people/bcutler/">·卡特勒</a>,<a href="https://www.microsoft.com/en-us/research/people/andresmor/">安德烈斯·莫拉莱斯·埃斯基维尔</a>,<a href="https://www.microsoft.com/en-us/research/people/amhoak/">内森</a><a href="https://www.microsoft.com/en-us/research/people/alonsog/">·埃文斯</a>,阿隆索·格瓦拉·费尔南德斯,安布尔·霍克,<a href="https://www.microsoft.com/en-us/research/people/kalytv/">凯特·利特维涅茨</a><a href="https://www.microsoft.com/en-us/research/people/amhoak/" target="_blank" rel="noreferrer noopener">,</a><a href="https://www.microsoft.com/en-us/research/people/gaudyb/">高迪·布兰科·梅内塞斯</a>,<a href="https://www.microsoft.com/en-us/research/people/moapurva/">阿普尔瓦·莫迪</a>,<a href="https://www.microsoft.com/en-us/research/people/chtrevin/">罗伯特·内斯</a>,加布里埃尔·尼维斯-庞塞、道格拉斯·奥贝克、理查德·奥尔特加、罗德里戈·拉卡尼奇、比莉·里纳尔迪、凯蒂·史密斯、<a href="https://www.microsoft.com/en-us/research/people/smithsarah/">莎拉·史密斯</a>、肖恩·所罗门、<a href="https://www.microsoft.com/en-us/research/people/ddesouza/">达耶恩·苏扎、大卫</a><a href="https://www.microsoft.com/en-us/research/people/datittsw/">·蒂茨沃斯</a>、 <a href="https://www.microsoft.com/en-us/research/people/chtrevin/" target="_blank" rel="noreferrer noopener">克里斯·特维诺</a>、德里克·沃森</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/">GraphRAG：GitHub 上的复杂数据发现新工具</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 6 月 24 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-june-24-2024/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 26 Jun 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1048935 </guid><description><![CDATA[<p>本期：RENC让5G vRAN服务器更加节能； CoExplorer 使用 AI 让视频会议保持正常进行； LLM 支持的基于文本的游戏中的自动错误检测； MAIRA-2：生成基础放射学报告。</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-june-24-2024/">研究焦点：2024 年 6 月 24 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p>欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。 </p></blockquote></figure><figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2.png" alt="研究重点：2024 年 6 月 24 日" class="wp-image-1048971" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF44-BlogHeroFeature-1400x788-_v2-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="towards-energy-efficient-5g-vran-servers">迈向节能 5G vRAN 服务器</h2><p>虚拟化无线电接入网络 (vRAN) 在商用服务器而不是专用硬件上运行蜂窝无线电堆栈，由于具有多供应商生态系统、更易于维护和更快的功能升级。在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/towards-energy-efficient-5g-vran-servers/" target="_blank" rel="noreferrer noopener">走向节能的 5G vRAN 服务器</a>中，来自 Microsoft 的研究人员和外部同事提出了 RENC，这是一种通过使用三种技术调整 CPU 频率以响应蜂窝工作负载的亚秒级变化来节省能源的系统。首先，尽管vRAN CPU负载在亚毫秒时间尺度上波动很大，RENC还是建立了安全的低负载间隔，例如，通过将媒体访问控制（MAC）层速率限制与CPU频率变化相结合。这可以防止低功耗操作期间出现高流量，否则会损害性能。其次，他们设计了计算 CPU 频率的技术，这些频率在这些低负载间隔内是安全的，这是通过使用 Linux eBPF 挂钩测量 vRAN 线程截止时间的裕度或对 vRAN 软件进行少量二进制重写来实现的。第三，它们演示了处理由控制操作（例如新用户连接到网络）触发的 CPU 负载峰值的需要。他们在最先进的 vRAN 测试台中进行的评估表明，他们的技术可将 vRAN 服务器的 CPU 功耗降低高达 45%（服务器范围内为 29%）。</p><p> RENC 纯粹是一个研究项目，目前没有计划将 RENC 纳入产品中。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/towards-energy-efficient-5g-vran-servers/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-21d8108ee594aad478409a8aa618b2ee" id="new-research-1">新研究</h3><h2 class="wp-block-heading" id="the-coexplorer-technology-probe-a-generative-ai-powered-adaptive-interface-to-support-intentionality-in-planning-and-running-video-meetings"> CoExplorer 技术探针：一种由 AI 驱动的生成式自适应界面，支持规划和运行视频会议的意向性</h2><p>视频会议开启了分布式工作的新时代，但召开有效的会议可能具有挑战性。传统的视频会议系统对于减少规划和进行视频会议的工作量提供的支持很少。生成式人工智能有潜力通过增强有意的会议行为来从根本上重新定义会议。</p><p>在最近的一篇论文<a href="https://www.microsoft.com/en-us/research/publication/the-coexplorer-technology-probe-a-generative-ai-powered-adaptive-interface-to-support-intentionality-in-planning-and-running-video-meetings/" target="_blank" rel="noreferrer noopener">《CoExplorer 技术探针：一种由人工智能驱动的生成式自适应界面，支持规划和运行视频会议中的意向性》</a>中，微软的研究人员提出了一种新颖的自适应会议原型。它预先生成 (1) 会议可能经历的阶段，(2) 允许在会议前捕获与会者想法的工具，以及 (3) 会议每个阶段及其窗口布局的适当文件和应用程序。他们的研究结果表明，使用 CoExplorer 作为引导演练中的技术探针，生成式人工智能有可能使会议保持正常进行并减少工作量。研究人员提出了他们的研究结果的一些设计含义，并讨论了一些问题，例如用户的代理、信任以及对传统会议规范的可能破坏。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/the-coexplorer-technology-probe-a-generative-ai-powered-adaptive-interface-to-support-intentionality-in-planning-and-running-video-meetings/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044939"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">点播活动</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/quarterly-brief/jun-2024-brief/" aria-label="Microsoft Research Forum Episode 3" data-bi-cN="Microsoft Research Forum Episode 3" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF-Ep3-Recap-BlogHeroFeature-1400x788-1.jpg" alt="微软研究论坛|第 3 集 |小组讨论会" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究论坛第 3 集</h2><p class="large">深入探讨全球包容性和公平人工智能的重要性、AutoGen 和 MatterGen 的更新、探索人工智能的新用例等等。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/quarterly-brief/jun-2024-brief/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch on-demand" data-bi-cN="Microsoft Research Forum Episode 3" target="_blank">点播观看</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-73123c9697b9c6db2728fb2f179fa924" id="new-research-2">新研究</h3><h2 class="wp-block-heading" id="automatic-bug-detection-in-llm-powered-text-based-games-using-llms">使用 LLM 在 LLM 支持的基于文本的游戏中自动检测错误</h2><p>大语言模型 (LLM) 的进步正在彻底改变交互式游戏设计，实现动态情节以及玩家与非玩家角色 (NPC) 之间的交互。然而，法学硕士可能会表现出幻觉、健忘或对提示的误解等缺陷，导致逻辑不一致和与预期设计的意外偏差。用于检测此类游戏错误的自动化技术仍然不够。</p><p>在最近的一篇论文中： <a href="https://www.microsoft.com/en-us/research/publication/automatic-bug-detection-in-llm-powered-text-based-games-using-llms/" target="_blank" rel="noreferrer noopener">使用 LLM 在 LLM 支持的基于文本的游戏中进行自动错误检测<span class="sr-only">（在新选项卡中打开）</span></a> ，该论文被接受在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2024.aclweb.org/" target="_blank" rel="noreferrer noopener">计算语言学协会 (ACL) 2024 年<span class="sr-only">（在新选项卡中打开）</span></a>会议上进行演示，来自 Microsoft 和外部同事提出了一种基于 LLM 的系统方法，用于从玩家游戏日志中自动识别此类错误，从而无需收集额外数据（例如游戏后调查）。应用于基于文本的游戏 DejaBoom! 时，他们的方法可以识别由 LLM 驱动的互动游戏中固有的错误，超越了由 LLM 驱动的非结构化错误捕获方法，并填补了逻辑和设计缺陷自动检测方面的空白。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/automatic-bug-detection-in-llm-powered-text-based-games-using-llms/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-0663ba4d11b1a8df4b8ebb08832c118e" id="new-research-3">新研究</h3><h2 class="wp-block-heading" id="maira-2-grounded-radiology-report-generation">MAIRA-2：生成基础放射学报告</h2><p>放射学报告是一项复杂的任务，需要详细的图像理解、多种输入的集成（包括与先前成像的比较）以及精确的语言生成。这使其成为生成多模态模型的开发和使用的理想选择。在最近的预印本： <a href="https://www.microsoft.com/en-us/research/publication/maira-2-grounded-radiology-report-generation/" target="_blank" rel="noreferrer noopener">MAIRA-2：基础放射学报告生成</a>中，微软的研究人员扩展了报告生成，以包括图像上单个发现的本地化，或基础报告生成。之前的研究表明，接地有助于澄清图像理解和解释人工智能生成的文本。因此，扎根的报告应该提高自动报告起草的实用性和透明度。</p><p>为了能够评估有依据的报告，研究人员提出了一个新的框架——RadFact——利用法学硕士的推理能力。 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/radfact" target="_blank" rel="noreferrer noopener">RadFact <span class="sr-only">（在新选项卡中打开）</span></a>评估各个生成句子的真实性，以及生成的空间定位（如果存在）的正确性。研究人员介绍了 MAIRA-2，这是一种大型多模态模型，将放射学专用图像编码器与法学硕士相结合，针对胸部 X 光检查报告生成的新任务进行了训练。 MAIRA-2 使用比之前探索的更全面的输入：当前正面图像、当前侧面图像、之前的正面图像和之前的报告，以及当前报告的指示、技术和比较部分。这些新增内容显着提高了报告质量并减少了模型幻觉，在 MIMIC-CXR 上建立了新的研究成果生成（无接地）技术，同时证明了接地报告作为一项新颖且更丰富的任务的可行性。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/maira-2-grounded-radiology-report-generation/">阅读论文</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/radfact">获取代码</a></div></div><div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section"><div class="container"><div class="wp-block-msr-immersive-section__inner"><div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-center" data-bi-aN="microsoft-research-in-the-news"><div class="msr-cards__inner"><div class="heading-wrapper"><h2 class="mb-5 ">微软研究院新闻报道</h2></div><div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3"><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Microsoft technology could help store "insane" supply of new data" href="https://www.bbc.com/news/articles/cd116m3jyn1o"><span>微软技术可以帮助存储“疯狂”的新数据供应</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>英国广播公司 | 2004 年 6 月 11 日</p><p>Project Silica 使用强大的激光使一块 DVD 大小的玻璃能够存储超过 7 TB 的数据，从而帮助管理快速增长的供应量。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Microsoft's secret weapon - research leader Peter Lee" href="https://www.joongang.co.kr/article/25255863#home"><span>微软的秘密武器——研究负责人彼得·李</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>中央 | 2004 年 6 月 13 日</p><p>微软研究院院长彼得·李（Peter Lee）是微软在生成式人工智能时代实现飞跃的主导力量。</p></div></div></div></div><div class="justify-content-center text-center mb-4"> <a href="https://www.microsoft.com/en-us/research/news-and-awards/" class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta" data-bi-cN="View more news and awards" data-bi-type="button">查看更多新闻和奖项</a></div></div></div></div></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-june-24-2024/">研究焦点：2024 年 6 月 24 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>