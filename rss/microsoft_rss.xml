<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 5 月 3 日星期五 14:44:38 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.2</generator><item><title> LoftQ：通过更智能的初始化重新构想 LLM 微调</title><link/>https://www.microsoft.com/en-us/research/blog/loftq-reimagining-llm-fine-tuning-with-smarter-initialization/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 07 May 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/loftq-reimagining-llm-fine-tuning-with-smarter-initialization/ </guid><description><![CDATA[<p> LoftQ 通过简化微调过程来提高法学硕士效率，减少计算需求，同时保持高性能。此类创新有助于提高人工智能技术的能源效率。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/loftq-reimagining-llm-fine-tuning-with-smarter-initialization/">《LoftQ：通过更智能的初始化重新想象 LLM 微调》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-center">这篇研究论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://iclr.cc/Conferences/2024" target="_blank" rel="noreferrer noopener"><strong><em><sup>第十二届</sup>学习表示国际会议</em></strong><span class="sr-only">（在新选项卡中打开）</span></a> （ICLR 2024）<strong><em>上发表</em></strong><strong><em>，这是致力于推进深度学习的重要会议。</em></strong> </p><figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1401" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1.png" alt="青色背景，右侧（头部和面部）带有 ICLR 徽标，右侧为 LoftQ 纸。" class="wp-image-1027119" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1.png 1401w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1401px) 100vw, 1401px" /></figure><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--right"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">出版物</span><a href="https://www.microsoft.com/en-us/research/publication/loftq-lora-fine-tuning-aware-quantization-for-large-language-models/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models" data-bi-aN="margin-callout" data-bi-cN="LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models">LoftQ：大型语言模型的 LoRA 微调感知量化<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span></a></li></ul></div><p>大型语言模型 (LLM) 使用广泛的数据集和高级算法来生成细致入微、上下文相关的内容。然而，它们的开发需要大量的计算资源。为了解决这个问题，我们开发了 LoftQ，这是一种简化微调过程的创新技术，用于调整预先训练的语言模型，以便在分析医疗文档等专业应用中表现良好。在微调过程中，模型会在较小的特定于任务的数据集上接受额外的训练。这会提高性能，例如更准确的预测、更好地理解特定领域的语言以及在专业领域的背景下做出更相关的响应。</p><p> LoftQ的优势在于它能够在微调过程中结合量化和自适应初始化。量化降低了模型参数的精度，从而降低了内存和计算需求。这不仅加速了处理速度，还降低了功耗。自适应初始化将模型的参数与其最佳预训练状态紧密结合，保留其功能，同时最大限度地减少资源使用。我们在 ICLR 2024 上发表的论文“ <a href="https://www.microsoft.com/en-us/research/publication/loftq-lora-fine-tuning-aware-quantization-for-large-language-models/" target="_blank" rel="noreferrer noopener">LoftQ：大型语言模型的 LoRA 微调感知量化</a>”详细介绍了该方法如何帮助提高 AI 技术的效率和可持续性。</p><h2 class="wp-block-heading" id="how-loftq-works"> LoftQ 的工作原理</h2><p>LoftQ 建立在<a href="https://www.microsoft.com/en-us/research/publication/lora-low-rank-adaptation-of-large-language-models/" target="_blank" rel="noreferrer noopener">LoRA <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/artidoro/qlora" target="_blank" rel="noreferrer noopener">QLoRA <span class="sr-only">（在新选项卡中打开）</span></a>的原则之上。 LoRA 是一种大大减少训练所需参数数量、降低微调所需内存的方法。 QLoRA 是一种微调方法，使用 4 位量化、冻结权重和低等级适配器，显着降低内存需求，同时保持高性能。表 1 对此进行了说明，其中显示了微调具有 70 亿个参数的 LLM 所需的内存量以及 LoRA 和 QLoRA 的内存要求。 LoRA 将内存使用量减少了四倍，而 QLoRA 则进一步减少了两倍。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="3053" height="1210" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1.png" alt="LoftQ - 表 1：该表显示了 70 亿参数 LLM 的 GPU 内存使用情况，配置如下：左侧完全微调，中间 LoRA，右侧 QLoRA。" class="wp-image-1029312" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1.png 3053w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-300x119.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-1024x406.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-768x304.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-1536x609.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-2048x812.png 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-240x95.png 240w" sizes="(max-width: 3053px) 100vw, 3053px" /><figcaption class="wp-element-caption">表 1：此表显示了具有以下配置的 70 亿参数 LLM 的 GPU 内存使用情况：左侧为完全微调，中间为 LoRA，右侧为 QLoRA。</figcaption></figure><p>与 LoRA 不同，QLoRA 需要权衡，即由于权重量化而牺牲了预训练模型的某些质量。 LoftQ 认识到这一点并优化量化和低秩适应矩阵的初始化。也就是说，LoftQ 寻求识别量化矩阵和低秩矩阵的组合，使得它们的总和非常接近原始的预训练权重。对模型中要调整的每个矩阵都执行此操作。</p><p> LoftQ 算法在两个主要步骤之间交替。首先，它量化（简化）权重，然后找到近似预训练权重和低秩权重之间量化的最佳低秩因子。该过程重复几个步骤。这种方法使微调过程能够从更有效的初始状态开始，从而在使用更少的计算能力和更简化的权重的同时保持准确性。</p><p> LoftQ 需要一次性设置来简化和准备这些权重，从而允许调整模型参数的固定部分（例如 5%）。一旦建立，当模型在各种任务和设置之间转换时，可以重复应用此配置。</p><h2 class="wp-block-heading" id="evaluating-loftq">评估 LoftQ</h2><p>使用各种类型的 LLM（包括具有不同编码和解码功能组合的 Llama-2）进行的测试表明，使用 LoftQ 初始化的模型始终能够实现强大的性能，通常匹配或超过使用 QLoRA 配置的模型。</p><p>实际上，使用 Llama-2 模型系列比较 LoftQ 和 QLoRA 在不同任务上的性能会产生不同的结果，如表 2 所示。对于 WikiText-2 数据集，它衡量模型的困惑度（越低越好）， GSM8K 数据集测试模型解决基本数学问题的能力（越高越好），我们展示了不同程度的权重简化的有效性 - 每个权重平均 3、2.5 和 2.25 位。我们的<a href="https://www.microsoft.com/en-us/research/publication/loftq-lora-fine-tuning-aware-quantization-for-large-language-models/" target="_blank" rel="noreferrer noopener">论文</a>更详细地讨论了结果。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="1605" height="1196" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2.png" alt="LoftQ - 表 2。该表比较了在 Wikitext-2 和 GSM8K 数据集上微调两个 Llama-2 模型期间的 LoftQ 和 QLoRA。" class="wp-image-1027116" style="width:731px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2.png 1605w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-300x224.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-1024x763.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-768x572.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-1536x1145.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-80x60.png 80w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-240x180.png 240w" sizes="(max-width: 1605px) 100vw, 1605px" /><figcaption class="wp-element-caption">表 2。该表比较了在 Wikitext-2 和 GSM8K 数据集上微调两个 Llama-2 模型期间的 LoftQ 和 QLoRA。 </figcaption></figure><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="999693"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：活动系列</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum" data-bi-cN="Microsoft Research Forum" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png" alt="浅蓝色背景上的各种抽象 3D 形状" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究论坛</h2><p class="large">加入我们，持续交流有关通用人工智能时代研究的想法。点播观看第 1 集和第 2 集。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Register for series" data-bi-cN="Microsoft Research Forum" target="_blank">注册系列</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="implications-and-looking-forward"> 影响和展望</h2><p>LoftQ 承诺通过加速研究和促进尖端工具的创建，同时支持可持续发展，推动人工智能领域的发展。虽然最初专注于法学硕士，但 LoftQ 的灵活设计还支持其他类型模型的微调，例如视觉和语音技术模型。随着研究的进展，我们期望进一步增强功能，以提高下游任务的性能。我们希望这些改进将导致各种人工智能应用程序得到更广泛的采用。我们对这项技术的广泛适用性感到兴奋，并鼓励人工智能社区探索其优势。 LoftQ 可通过<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/huggingface/peft/blob/56773b9a92b141111d65fe3548d0c30233358868/examples/loftq_finetuning/README.md" target="_blank" rel="noreferrer noopener">Hugging Face PEFT 库<span class="sr-only">（在新选项卡中打开）</span></a>开源。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/loftq-reimagining-llm-fine-tuning-with-smarter-initialization/">《LoftQ：通过更智能的初始化重新想象 LLM 微调》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 4 月 29 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-29-2024/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 02 May 2024 16:50:43 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1029624 </guid><description><![CDATA[<p>在本版本中：法学硕士能否将自然语言转换为形式方法后置条件？语义一致的问题+代码生成，用于自动生成洞察力；解释盲人/低视力数据上的 CLIP 性能差异；加上最近的新闻。</p><p>帖子《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-29-2024/">研究焦点：2024 年 4 月 29 日一周》</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1.png" alt="研究重点：2024 年 4 月 29 日当周" class="wp-image-1029753" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF40-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="can-large-language-models-transform-natural-language-intent-into-formal-method-postconditions">大型语言模型能否将自然语言意图转化为形式方法后置条件？</h2><p>描述代码功能的非正式自然语言（例如代码注释或函数文档）可能包含有关程序意图的大量信息。但是，不能保证程序的实现与其自然语言文档一致。在发生冲突的情况下，利用与代码相邻的自然语言中的信息有可能增强故障定位、调试和代码可信度。然而，由于自然语言固有的模糊性，使得以编程方式检查自然语言意图变得困难，因此这些信息通常没有得到充分利用。大型语言模型（LLM）的“新兴能力”有可能促进自然语言意图转化为可编程检查的断言。然而，由于缺乏基准和评估指标，目前还不清楚法学硕士是否可以正确地将非正式的自然语言规范翻译成符合程序员意图的正式规范，以及这种翻译在实践中是否有用。</p><p>在一篇新论文中： <a href="https://www.microsoft.com/en-us/research/publication/formalizing-natural-language-intent-into-program-specifications-via-large-language-models/" target="_blank" rel="noreferrer noopener">大型语言模型能否将自然语言意图转换为形式方法后置条件？ <span class="sr-only">（在新选项卡中打开）</span></a> ，来自 Microsoft 的研究人员描述了 nl2postcond，该问题利用 LLM 将非正式自然语言转换为正式方法后置条件，并表示为程序断言。该论文将在即将召开的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2024.esec-fse.org/" target="_blank" rel="noreferrer noopener">ACM 软件工程基础国际会议<span class="sr-only">（在新选项卡中打开）</span></a>上发表<strong><em>，</em></strong>介绍并验证了使用生成后置条件的正确性和判别力来测量和比较不同 nl2postcond 方法的指标。研究人员表明，通过 LLM 进行的 nl2postcond 有可能在实践中提供帮助，证明 LLM 生成的规范可用于发现现实项目中的历史错误。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/formalizing-natural-language-intent-into-program-specifications-via-large-language-models/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="semantically-aligned-question-and-code-generation-for-automated-insight-generation">语义一致的问题和代码生成，用于自动生成洞察</h2><p>处理数据的人员（例如工程师、分析师和数据科学家）通常必须手动查看数据以找到有价值的见解或编写复杂的脚本来自动探索数据。自动洞察生成为这些工作人员提供了立即收集有关其数据的洞察并确定编写探索脚本的有价值的起点的机会。不幸的是，法学硕士产生的自动化见解有时会生成与见解不正确对应（或对齐）的代码。在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/semantically-aligned-question-and-code-generation/" target="_blank" rel="noreferrer noopener">自动洞察生成的语义对齐问题和代码生成<span class="sr-only">（在新选项卡中打开）中</span></a>，微软的研究人员利用法学硕士的语义知识来生成有关数据的有针对性和有洞察力的问题以及回答这些问题的相应代码。通过对<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2305.07288" target="_blank" rel="noreferrer noopener">Open-WikiTable <span class="sr-only">（在新选项卡中打开）</span></a>中的数据进行实证研究，他们表明嵌入可以有效地用于过滤掉语义上不对齐的问题和代码对。研究还表明，一起生成问题和代码可以产生更有趣、更多样化的数据见解。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/semantically-aligned-question-and-code-generation/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="explaining-clip-s-performance-disparities-on-data-from-blind-low-vision-users">解释 CLIP 在盲人/低视力用户数据上的性能差异</h2><p>基于人工智能的应用程序有潜力帮助盲人或弱视 (BLV) 人士完成日常视觉任务。然而，由于所需的帮助种类繁多且可用图像的质量各不相同，因此通常需要人工帮助。大型多模态模型（LMM）的最新进展可能会解决这些挑战，从而开启自动视觉辅助的新时代。然而，很少有工作来评估 LMM 在 BLV 用户数据上的表现。</p><p>在最近的一篇论文中： <a href="https://www.microsoft.com/en-us/research/publication/explaining-clips-performance-disparities-on-data-from-blind-low-vision-users/" target="_blank" rel="noreferrer noopener">解释 CLIP 在盲人/弱视用户数据上的性能差异<span class="sr-only">（在新选项卡中打开）</span></a> ，来自 Microsoft 和世界银行的研究人员通过评估<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://openai.com/research/clip" target="_blank" rel="noreferrer noopener">CLIP <span class="sr-only">（在新选项卡中打开）</span></a>来解决这个问题，CLIP 是一种广泛使用的 LMM，具有具有支撑许多辅助技术的潜力。在零样本分类任务中测试了 25 个 CLIP 变体，结果表明，残障物体（如拐杖和盲文显示器）的识别准确度明显低于常见物体（如电视遥控器和咖啡杯），在某些情况下高达 28百分点差异。</p><p>研究人员对三个大型数据集中的字幕进行了分析，这些数据集通常用于训练 CLIP 等模型，结果表明与 BLV 相关的内容（例如手杖）很少被提及。这是造成巨大性能差距的潜在原因。研究人员表明，使用少至 5 个残疾物体示例图像的少量学习方法可以提高其识别该物体的能力，从而有可能减轻 CLIP 对 BLV 用户的性能差异。然后他们讨论其他可能的缓解措施。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/explaining-clips-performance-disparities-on-data-from-blind-low-vision-users/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1002645"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：人工智能驱动的体验</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo" aria-label="Microsoft research copilot experience" data-bi-cN="Microsoft research copilot experience" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MSR-Chat-Promo.png" alt="" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究院副驾驶经历</h2><p class="large">通过我们的人工智能体验，了解有关 Microsoft 研究的更多信息</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Microsoft research copilot experience" data-bi-cN="Microsoft research copilot experience" target="_blank">现在开始</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="closed-form-bounds-for-dp-sgd-against-record-level-inference">DP-SGD 针对记录级推理的闭式界限</h2><p>部署机器学习 (ML) 模型时，训练数据的隐私是一个核心考虑因素。事实证明，经过差分隐私 (DP) 保证训练的模型可以抵御各种攻击。尽管可以仅从 DP 保证中得出针对特定隐私威胁的界限或安全限制，但有意义的界限需要不切实际的小隐私预算，这会导致效用的巨大损失。<br><br>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/closed-form-bounds-for-dp-sgd-against-record-level-inference/" target="_blank" rel="noreferrer noopener">DP-SGD 与记录级推理的封闭形式边界</a>中，微软的研究人员提出了一种新方法，用于根据<strong>成员资格</strong>推理（推断数据记录是否在训练数据中）和<strong>属性</strong>来量化 ML 模型的隐私性。<strong>推理</strong>（重建有关记录的部分信息），无需通过 DP 间接进行。他们专注于流行的 DP-SGD 算法，将其建模为信息论通道，其输入是攻击者想要推断的秘密（例如数据记录的成员资格），其输出是迭代优化产生的中间模型参数。他们获得了与最先进的技术相匹配的隶属推理的封闭形式边界，但计算速度要快几个数量级。他们还提出了第一个针对属性推断生成数据相关边界的算法。与通过数字 DP 预算会计师间接计算的界限相比，这些界限更严格地描述了部署在特定数据集上训练的 ML 模型的隐私风险。这项研究提供了一种直接、可解释且实用的方法来评估经过训练的模型针对推理威胁的隐私性，而无需牺牲实用性。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/closed-form-bounds-for-dp-sgd-against-record-level-inference/">阅读论文</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/dpsgd-calculator/" target="_blank" rel="noreferrer noopener">获取代码</a></div></div><div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section"><div class="container"><div class="wp-block-msr-immersive-section__inner"><div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-the-news"><div class="msr-cards__inner"><div class="heading-wrapper"><h2 class="mb-5 ">微软研究院新闻报道</h2></div><div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3"><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="TIME100 Most Influential People in Health" href="https://time.com/collection/time100-health/"><span>TIME100 健康领域最具影响力人物</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>时间 | 2024 年 5 月 2 日</p><p>微软研究院院长 Peter Lee 作为创新者入选 2024 年《TIME100 健康》榜单，这是《时代》杂志今年首次列出的 100 名对全球健康影响最大的个人。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Sanctuary AI Announces Microsoft Collaboration to Accelerate AI Development for General Purpose Robots" href="https://sanctuary.ai/resources/news/sanctuary-ai-announces-microsoft-collaboration-to-accelerate-ai-development-for-general-purpose-robots/"><span>Sanctuary AI 宣布与微软合作加速通用机器人的人工智能开发</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>庇护所人工智能 | 2024 年 5 月 1 日</p><p>Sanctuary AI 和微软正在合作开发通用人形机器人的人工智能模型。 Sanctuary AI 将利用微软的 Azure 云资源来处理其人工智能工作负载。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Tiny but mighty: The Phi-3 small language models with big potential" href="https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/"><span>微小而强大：具有巨大潜力的 Phi-3 小语言模型</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>微软来源| 2024 年 4 月 23 日</p><p>法学硕士为人工智能创造了令人兴奋的机会，以提高生产力和创造力。但它们需要大量的计算资源。 Phi-3 模型的性能比两倍大小的模型更好，现已从 Microsoft 公开提供。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="AI Is Unearthing New Drug Candidates, But It Still Needs Human Oversight" href="https://www.drugdiscoveryonline.com/doc/ai-is-unearthing-new-drug-candidates-but-it-still-needs-human-oversight-0001"><span>人工智能正在挖掘新的候选药物，但仍需要人类监督</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>在线药物发现| 2024 年 4 月 11 日</p><p>Drug Discovery Online 发表了 Junaid Bajwa 的一篇投稿文章，讨论了人工智能的最新进展如何提供以前所未有的方式简化和优化药物开发的潜力。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="How AI is helping create sustainable farms of the future" href="https://www.thegrocer.co.uk/technology-and-supply-chain/how-ai-is-helping-create-sustainable-farms-of-the-future/690248.article"><span>人工智能如何帮助创建未来的可持续农场</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>杂货店| 2024 年 4 月 16 日</p><p>Ranveer Chandra 撰写了一篇关于人工智能如何帮助英国贸易商店 The Grocer 创建未来可持续农场的文章。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="The Future of AI and Mental Health" href="https://psychnews.psychiatryonline.org/doi/10.1176/appi.pn.2024.05.5.10"><span>人工智能和心理健康的未来</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>精神病学在线 | 2024 年 4 月 16 日</p><p>《精神病学新闻》发表了一篇与 Jina Suh 进行问答的文章，强调了精神病学家和心理健康专业人员使用人工智能技术的重要考虑因素。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="MatterGen&#039;s Breakthroughs: How AI Shapes the Future of Materials Science" href="https://www.turingpost.com/p/mattergen"><span>MatterGen 的突破：人工智能如何塑造材料科学的未来</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>图灵邮报 | 2024 年 4 月 19 日</p><p>图灵邮报在谢天的采访中报道了 MatterGen。详细了解这种有影响力的无机材料设计生成模型。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Machine Learning Street Talk interview with Chris Bishop" href="https://www.youtube.com/watch?app=desktop&v=kuvFoXzTK3E&t=2603s"><span>Chris Bishop 的机器学习街头谈话采访</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>机器学习街头谈话 | 2024 年 4 月 10 日</p><p>Chris Bishop 与 Tim Scarfe 博士一起接受了有关深度学习和人工智能科学进展的广泛采访。</p></div></div></div></div><div class="justify-content-center text-center mb-4"> <a href="https://www.microsoft.com/en-us/research/news-and-awards/" class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta" data-bi-cN="View more news and awards" data-bi-type="button">查看更多新闻和奖项</a></div></div></div></div></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>帖子《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-29-2024/">研究焦点：2024 年 4 月 29 日一周》</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>