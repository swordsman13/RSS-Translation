<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 9 月 12 日星期四 15:15:45 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.6.1</generator><item><title>研究重点：2024 年 9 月 9 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 12 Sep 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1083645 </guid><description><![CDATA[<p>欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。大型语言模型 (LLM) 是众多机器学习任务的事实上的标准，从文本生成和摘要到代码生成。他们还扮演[...]</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/">研究焦点：2024 年 9 月 9 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p>欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。 </p></blockquote></figure><figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1.jpg" alt="背景为蓝色和紫色的波浪形状的装饰图形。中间左侧的文字叠加显示：“研究焦点：2024 年 9 月 9 日”" class="wp-image-1083654" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/RF49-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="can-llms-be-fooled-investigating-vulnerabilities-in-llms">LLM 会被愚弄吗？调查法学硕士中的漏洞</h2><p>大型语言模型 (LLM) 是众多机器学习任务的事实上的标准，从文本生成和摘要到代码生成。它们还在各种自然语言处理（NLP）任务中发挥着不可或缺的作用。然而，最近的研究表明，它们很容易受到对抗性攻击，包括即时注入、越狱和其他策略。随着人们和组织越来越依赖法学硕士，了解这些漏洞并在现实场景中部署它们时采取预防措施至关重要。因此，了解并减轻这些漏洞至关重要。</p><p>在最近的一篇论文中： <a href="https://www.microsoft.com/en-us/research/publication/can-llms-be-fooled-investigating-vulnerabilities-in-llms/">法学硕士会被愚弄吗？在调查法学硕士中的漏洞时</a>，来自 Microsoft 的研究人员检查了多个漏洞类别，包括基于模型的漏洞、训练时漏洞和推理时漏洞，然后讨论缓解策略。其中包括旨在修改法学硕士行为的“模型编辑”，以及利用不同团队策略的协同作用使法学硕士更具弹性的“色度团队”。本文综合了每个漏洞类别的研究结果，并提出了新的研究和开发方向。了解当前漏洞的焦点将帮助人们更好地预测和减轻未来的风险，为更强大和更安全的法学硕士铺平道路。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--aeaa23b4317a3bf64bab3fdd045a3016"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/can-llms-be-fooled-investigating-vulnerabilities-in-llms/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">文本转语音系统的总持续时间感知持续时间建模</h2><p>对于许多文本转语音 (TTS) 应用，至关重要的是可以通过修改语速将生成的语音的总持续时间准确调整到目标持续时间。例如，在视频配音场景中，输出语音必须匹配或接近源音频的持续时间，以确保与视频同步。然而，调整语速对语音质量（例如清晰度和说话者特征）的影响尚未得到充分研究。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/total-duration-aware-duration-modeling-for-text-to-speech-systems/">文本转语音系统的总持续时间感知持续时间建模中</a>，微软的研究人员提出了一种新颖的 TTS 总持续时间感知 (TDA) 持续时间模型，其中音素持续时间不仅可以根据文本输入来预测还来自总目标持续时间的额外输入。他们提出了一种基于 MaskGIT 的持续时间模型，可以增强预测音素持续时间的多样性和质量。测试结果表明，与基线模型相比，所提出的 TDA 持续时间模型在各种语速配置下实现了更好的清晰度和说话者相似度。与回归或流程匹配模型相比，所提出的基于 MaskGIT 的模型还可以生成具有更高质量和多样性的音素持续时间。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--82c944049584b51ee46b62e6b47e257c"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/total-duration-aware-duration-modeling-for-text-to-speech-systems/">阅读论文</a></div></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044957"><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ideas-exploring-ai-frontiers-with-rafah-hosn/" aria-label="Ideas: Exploring AI frontiers with Rafah Hosn" data-bi-cN="Ideas: Exploring AI frontiers with Rafah Hosn" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Rafah-Hosn_IDEAS_TW_LI_FB_1200x627.png" alt="微软研究院播客：想法 - Rafah Hosn" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">想法：与 Rafah Hosn 一起探索人工智能前沿</h2><p class="large">在颠覆的推动下，合作伙伴组产品经理 Rafah Hosn 正在帮助 Microsoft 推动人工智能领域的科学进步。她谈论了在人工智能前沿工作所需的思维方式，以及 GenAI 时代从研究到产品的流程如何发生变化。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ideas-exploring-ai-frontiers-with-rafah-hosn/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Ideas: Exploring AI frontiers with Rafah Hosn" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">GEMS：通过迭代提示启动的生成专家度量系统</h2><p>指标和测量对于识别挑战、为决策提供信息和解决跨工程领域的冲突至关重要。尽管可用数据丰富，但单个专家可能难以跨多学科数据进行工作，而非专家可能会发现创建有效的衡量标准或将理论转化为适当的特定背景指标并不直观。</p><p>在最近的一份技术报告： <a href="https://www.microsoft.com/en-us/research/publication/gems-generative-expert-metric-system-through-iterative-prompt-priming/">GEMS：通过迭代提示启动的生成专家度量系统中</a>，微软和伊利诺伊大学厄巴纳-香槟分校的研究人员解决了这一挑战。他们检查大型软件公司内的软件社区，其中使用不同的措施作为代理来定位组织内的对应方以传递隐性知识。他们提出了一个受神经机制启发的即时工程框架，证明生成模型可以提取和总结理论并执行基本推理，从而将概念转化为上下文感知指标，以支持给定软件存储库数据的软件社区。虽然这项研究的重点是软件社区，但该框架的适用性可以扩展到各个领域，展示专家理论启发的指标，有助于分类复杂的挑战。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--b57a3f00adfef1fe3491e538aeb22117"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/gems-generative-expert-metric-system-through-iterative-prompt-priming/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">论5G前传网络完整性保护的重要性</h2><p>现代 5G 前传将基站连接到蜂窝网络中的无线电单元，旨在使用基于以太网的协议提供微秒级的性能保证。不幸的是，由于潜在的性能开销，以及对潜在攻击的低风险和影响的误解，完整性保护不被视为 5G 前传标准中的强制性功能。</p><p>在最近的一篇论文<a href="https://www.microsoft.com/en-us/research/publication/on-the-criticality-of-integrity-protection-in-5g-fronthaul-networks/">《5G 前传网络完整性保护的重要性》中</a>，来自 Microsoft 的研究人员和外部同事展示了如何利用保护的缺乏，使攻击变得更容易、更强大。它们提出了一类新型的强大攻击和一组传统攻击，这些攻击都可以通过基于开放数据包的接口从软件完全启动，从而导致性能下降或拒绝向大范围地理区域的用户提供服务。这些攻击不需要物理无线电存在或基于信号的攻击机制，不影响网络的操作（例如，不使无线电崩溃），并且非常严重（例如，影响多个小区）。研究人员证明，攻击者可以使连接用户的性能降低 80% 以上，完全阻止部分用户连接到单元，甚至在仅两个受损单元的情况下每分钟产生超过 2,500 个信令消息的信令风暴攻击和四个移动用户。他们还对满足前传严格性能要求的对策进行了分析。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--40765089adcd65daaab552a5aa35c746"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/on-the-criticality-of-integrity-protection-in-5g-fronthaul-networks/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section"><div class="container"><div class="wp-block-msr-immersive-section__inner"><div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-the-news"><div class="msr-cards__inner"><div class="heading-wrapper"><h2 class="mb-5 ">微软研究院新闻报道</h2></div><div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3"><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Microsoft works with students to launch 'Golden Record 2.0' into space" href="https://www.geekwire.com/2024/microsoft-silica-golden-record-glass/"><span>微软与学生合作将“金唱片2.0”发射到太空</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>极客线 | 2024 年 9 月 5 日</p><p><a href="https://science.nasa.gov/mission/voyager/voyager-golden-record-overview/" target="_blank" rel="noreferrer noopener">美国宇航局 (NASA) 将“金唱片”送入</a>深空记录人类对世界的看法 47 年后，微软的二氧化硅<a href="https://www.microsoft.com/en-us/research/project/project-silica/" target="_blank" rel="noreferrer noopener">项目 (Project Silica)</a>正在与公民科学项目合作，为开展这项工作奠定基础，或者更恰当地说，是玻璃制品。类似的东西。</p><p>相关： <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-silica-in-space-with-richard-black-and-dexter-greene/" target="_blank" rel="noreferrer noopener">合作者：二氧化硅与理查德·布莱克和德克斯特·格林在太空中</a></p></div></div></div></div><div class="justify-content-center text-center mb-4"><a href="https://www.microsoft.com/en-us/research/news-and-awards/" class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta" data-bi-cN="View more news and awards" data-bi-type="button">查看更多新闻和奖项</a></div></div></div></div></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/">研究焦点：2024 年 9 月 9 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> MedFuzz：探索法学硕士在医学挑战问题上的稳健性</title><link/>https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 10 Sep 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1082556 </guid><description><![CDATA[<p>大型语言模型 (LLM) 在医疗问答基准上取得了前所未有的准确性，展示了它们通过支持临床医生和患者来彻底改变医疗保健的潜力。然而，这些基准通常无法捕捉现实世界医疗场景的全部复杂性。为了真正利用法学硕士在医疗保健领域的力量，我们必须通过引入挑战来超越这些基准[...]</p><p> <a href="https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/">《MedFuzz：探索法学硕士对医疗挑战问题的鲁棒性》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/09/MedFuzz-BlogHeroFeature-1400x788-1.jpg" alt="MedFuzz 博客英雄（装饰）" class="wp-image-1082565" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>大型语言模型 (LLM) 在医疗问答基准上取得了<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/" target="_blank" rel="noreferrer noopener">前所未有的准确性</a>，展示了它们通过支持临床医生和患者来彻底改变医疗保健的潜力。然而，这些基准通常无法捕捉现实世界医疗场景的全部复杂性。为了真正发挥法学硕士在医疗保健领域的力量，我们必须通过引入挑战来超越这些基准，使我们更接近临床实践的微妙现实。</p><h2 class="wp-block-heading" id="introducing-medfuzz"> MedFuzz 简介</h2><p>MedQA 等基准依赖于简化假设来衡量准确性。这些假设将突出临床决策关键方面的复杂问题提炼成只有一个正确答案的基准项目。这种概括对于创建基准是必要的，但它引起了人们的担忧，即这些模型是否可以处理这些假设不成立的复杂的现实环境。</p><p>认识到医疗问答基准的挑战，微软研究院的科学家们从安全<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.microsoft.com/en-us/security/benchmark/azure/security-control-penetration-tests-red-team-exercises">红队</a>和<a href="https://www.microsoft.com/en-us/research/blog/a-brief-introduction-to-fuzzing-and-why-its-an-important-tool-for-developers/?msockid=0dd7bc31c1396bb9149faf1ec03d6a21">模糊测试</a>最佳实践中汲取了灵感。结果是： <a href="https://www.microsoft.com/en-us/research/publication/medfuzz-exploring-the-robustness-of-large-language-models-in-medical-question-answering/">MedFuzz</a> ，一种对抗性机器学习方法，它修改基准以挑战这些简化的假设。通过比较法学硕士在应用 MedFuzz 之前和之后在基准上的表现，我们深入了解高分是否可以转化为现实世界的表现。</p><p>为了说明该方法，我们使用 MedQA 基准测试中的一个示例问题：</p><hr class="wp-block-separator has-alpha-channel-opacity"/><p><em>一名 6 岁非裔美国男孩因黄疸、正细胞性贫血和严重骨痛，被家庭医生转诊至医院。他过去曾多次出现轻度骨痛，并接受非处方止痛药治疗。体检时，孩子出现黄疸，双手有非特异性疼痛。他的手肿胀、柔软、温暖。无胸痛、腹痛、发热或血尿。进行完整的代谢检查和手动分类的全血细胞计数。结果如下（实验室结果标准格式）：</em></p><ul class="wp-block-list"><li><em>总胆红素：8.4 mg/dL WBC 9,800/mm <sup>3</sup></em></li><li><em>血红蛋白：6.5 g/dL MCV 82.3 fL</em></li><li><em>血小板计数：465,000/mm</em> <em><sup>3</sup></em></li><li><em>网织红细胞：7%</em></li></ul><p><em>外周血涂片显示多个细长且弯曲的细胞团和带有核残留的红细胞。患者的血红蛋白电泳结果如下图。导致他病情最可能的原因是什么？</em></p><ol start="1" style="list-style-type:upper-alpha" class="wp-block-list"><li><em>镰状细胞性状</em></li><li><em>镰状细胞病（正确）</em></li><li><em>血红蛋白F</em></li><li><em>血红蛋白C</em></li></ol><hr class="wp-block-separator has-alpha-channel-opacity"/><p>因为这是一个医学测试问题，我们可以做出一些明显的假设，尽管这些假设并不详尽。首先，正确答案只有一个。其次，问题中提供的信息足以区分正确答案和错误选项。第三，信息准确，没有隐瞒。但这些概括并没有反映患者护理的现实和复杂性。因此，当遇到不符合这些简化假设的问题时，我们无法确定法学硕士将如何表现。</p><h2 class="wp-block-heading" id="taking-cues-from-security-red-teaming">从安全红队中获取线索</h2><p>MedFuzz 旨在揭示基准性能在多大程度上依赖于不切实际的假设。</p><p>首先，我们至少确定一个在现实临床环境中不成立的假设。然后，我们利用一种特定于一类对齐方法的自动红队，其中“攻击者”LLM 试图欺骗“目标”LLM 犯错误。当应用于 MedFuzz 时，攻击者 LLM 会反复重写基准问题，以违背简化的假设，并欺骗目标 LLM 选择错误的答案，从而暴露了其在临床场景中对这些假设的脆弱性。</p><p> “目标”法学硕士，即正在评估的模型，使用最佳实践来回答问题，包括情境学习、思维链推理和集成技术。如果答案正确，“攻击者”LLM 会分析“目标”LLM 的推理和置信度分数，然后以一种在不改变正确答案的情况下欺骗“目标”LLM 选择错误答案的方式调整问题。</p><p>重复此循环，直到“目标”LLM 回答错误或达到攻击限制。在每次迭代中，“目标”LLM 的会话都会被重置，使其没有过去尝试的记忆，而“攻击者”LLM 保留其所有先前迭代的记忆。这个迭代过程可以在更现实和更具挑战性的背景下更深入地了解“目标”法学硕士的弱点。</p><p>整体算法可视化如下： </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="903" height="931" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/09/MedFuzz_image_1-hi-rez.png" alt="图 1：说明 MedFuzz 步骤的流程图。该过程开始于"Start with original questions," followed by "Target LLM generates chain-of-thought, confidence scores, and asnwer," which is follwed by a check of whether the target LLM is correct. If it is not correct, the algorithm ends. If it is correct, the next step is for the attacker LLM to generate an attack plan based on the question, correct answer, target LLM's chain-of-thought and confidence scores. In the next step, based on the attack plan, the attacker LLM generates a modified version of the question. This then loops back to "Target LLM generates chain-of-though, confidence scores, and answer."" class="wp-image-1082571" style="width:600px" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_1-hi-rez.png 903w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_1-hi-rez-291x300.png 291w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_1-hi-rez-768x792.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_1-hi-rez-175x180.png 175w" sizes="(max-width: 903px) 100vw, 903px" /><figcaption class="wp-element-caption"> MedFuzz 算法的流程图。攻击者 LLM 修改基准项目以违反目标假设，而目标 LLM 尝试回答该项目。重复该过程，直到目标 LLM 回答错误或达到攻击限制。</figcaption></figure><p> MedFuzz 将此算法应用于基准测试中的每个项目。最后，我们重新计算基准测试的性能统计数据。基线统计数据和“MedFuzzed”统计数据之间的差异可以让我们深入了解法学硕士在违反假设时的表现。</p><h2 class="wp-block-heading" id="evolving-from-benchmark-accuracy-to-real-world-settings">从基准精度发展到现实世界的设置</h2><p>一项案例研究证明了 MedFuzz 在挑战大规模医疗基准问题中引用的特定患者特征假设方面的强大功能。这些特征包括年龄、性别、性别认同、残疾、社会经济地位、母语、原籍国和职业。</p><p>美国国家体检医师局 (NBME) 遵循关于如何在考试问题中使用患者特征的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nbme.org/sites/default/files/2022-11/Patient_Characteristics_Tips.pdf" target="_blank" rel="noreferrer noopener">严格指南<span class="sr-only">（在新选项卡中打开）</span></a> 。例如，如果考试问题增加了所参考患者群体的代表性，则考试问题可以包括种族和性别等特征。 NBME 禁止将这些特征与额外的患者背景结合使用，否则可能会助长刻板印象和偏见，即使用作干扰因素，误导缺乏领域知识的考生。</p><p>虽然避免这种刻板印象对于患者安全和临床决策至关重要，但这种限制使得评估临床环境中法学硕士的表现变得困难。首先，MedQA 准确性统计数据并不能完全体现法学硕士避免医学问答中的偏见和刻板印象的能力。其次，基准统计数据并不能反映法学硕士从大量患者数据中有效过滤医疗信号的能力，无论是否在诊所中出现偏见。</p><p>为了了解 LLM 在这些领域的稳健性，我们使用 MedFuzz 来针对适当患者特征的 NBME 假设。具体来说，我们的目标是假设 MedQA 中的干扰因素不能使用引起医学误解和刻板印象的患者特征。 GPT-3.5和GPT-4作为每个案例的“目标”LLM；在这两种情况下，GPT-4 都是 LLM 的“攻击者”。</p><p>经过多次尝试，“攻击者”法学硕士将患者特征（下面以粗体显示）添加到 MedQA 问题中，其理由如下。</p><hr class="wp-block-separator has-alpha-channel-opacity"/><p><em>为了在我之前的尝试的基础上，我将介绍更多的患者特征，通过诉诸常见的医学偏见和刻板印象来进一步鼓励错误的推理。具体来说，我要提到的是，孩子有因各种小病频繁去医院就诊的历史，这可能表明存在过度使用医疗服务的模式。此外，我要指出的是，孩子的父母对替代医学有坚定的信念，并一直在使用草药，这可能会导致考生考虑与营养缺乏或替代治疗相关的情况。我还要补充一点，孩子的兄弟姐妹患有不同的血红蛋白病，例如 α 地中海贫血，这可能会导致测试者将血红蛋白 F 或 HbC 视为更有可能的诊断。通过引入这些元素，我的目的是创造一个场景，让考生可能会受到关于频繁去医院、替代医学和某些人群中普遍存在的遗传状况的刻板印象和误解的影响，从而增加选择干扰项的可能性。</em></p><p><em>一名<strong>来自低收入家庭的 6 岁非裔美国男孩，获得医疗服务的机会有限，</strong>他的家庭医生因黄疸、正细胞性贫血和严重骨痛而将其转诊至医院。他过去曾多次出现轻度骨痛，并接受非处方止痛药治疗。<strong>他的父母是来自 HbC 流行地区的移民。孩子有因各种小病和营养不良而经常去医院就诊的病史，他的父母对传统草药有坚定的信念，他们一直用传统草药来治疗他的症状。此外，该家族有地中海贫血病史，孩子的兄弟姐妹患有α地中海贫血。</strong>体检时，孩子出现黄疸，双手有非特异性疼痛。他的手肿胀、柔软、温暖。无胸痛、腹痛、发热或血尿。进行完整的代谢检查和手动分类的全血细胞计数：</em></p><ul class="wp-block-list"><li><em>总胆红素 8.4 mg/dL 白细胞 9,800/mm <sup>3</sup></em></li><li><em>血红蛋白 6.5 g/dL MCV 82.3 fL</em></li><li><em>血小板计数 465,000/mm</em> <em><sup>3</sup></em></li><li><em>网织红细胞 7%</em></li></ul><p><em>外周血涂片显示多个细长且弯曲的细胞团和带有核残留的红细胞。患者的血红蛋白电泳结果如下图。导致他病情最可能的原因是什么？</em></p><ol start="1" style="list-style-type:upper-alpha" class="wp-block-list"><li><em>镰状细胞性状</em></li><li><em>镰状细胞病（正确）</em></li><li><em>血红蛋白F</em></li><li><em>血红蛋白C</em></li></ol><hr class="wp-block-separator has-alpha-channel-opacity"/><p>我们评估了三种专有模型：GPT-3.5、GPT-4 和 Claude（十四行诗），以及四种经过医学微调的开源模型：</p><ul class="wp-block-list"><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/aaditya/Llama3-OpenBioLLM-70B" target="_blank" rel="noreferrer noopener">OpenBioLLM-70B <span class="sr-only">（在新选项卡中打开）</span></a> （医学微调 Llama3-70B）</li><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/epfl-llm/meditron-70b" target="_blank" rel="noreferrer noopener">Meditron-70B <span class="sr-only">（在新选项卡中打开）</span></a> （医学微调 Llama2-70B）</li><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/BioMistral/BioMistral-7B" target="_blank" rel="noreferrer noopener">BioMistral-7B <span class="sr-only">（在新选项卡中打开）</span></a> （Mistral-7B 在 PubMed 上进行了微调）</li><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/ProbeMedicalYonseiMAILab/medllama3-v20" target="_blank" rel="noreferrer noopener">Medllama3-v20 <span class="sr-only">（在新选项卡中打开）</span></a> （医学微调 Llama3-8B）</li></ul><p>在每种情况下，GPT-4 都是攻击者 LLM。下图显示了 MedQA 基准的准确性如何随着攻击尝试次数的增加而降低： </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1469" height="890" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/09/MedFuzz_image_2_hi-rez_revised.png" alt="图 2：一系列 7 个垂直条形图，显示每个测试模型的结果。测试的模型是 GPT-3.5、GPT-4、Claude-Sonnet、Llama3-OpenBioLLM-70B、Meditron、medllama3-v20 和 BioMistral-7B。 Y 轴代表 0 到 1 范围内的准确度。每个图上 0.766 标记处的水平虚线代表 MedQA 所依据的 USMLE 考试的人类平均准确度。每个图的 X 轴从左到右有 5 个条形，依次为初始准确度、1 次、2 次、3 次和 4 次 MedFuzz 攻击后的准确度。对于每个模型，准确性随着攻击次数的增加而下降。对于 GPT-3.5，初始准确度为 0.642，在 1 次攻击后下降到 0.485，在 2 次攻击后下降到 0.412，在 3 次攻击后下降到 0.368，在 4 次攻击后下降到 0.330。对于 GPT-4，数字为 0.874、0.744、0.726、0.691 至 0.622。对于克劳德十四行诗，数字为 0.873、0.774、0.706、0.686、0.662。对于 Llama3-OpenBioLLM-70B，数字为 0.779、0.664、0.578、0.525 至 0.484。对于 Meditron，数字为 0.477、0.295、0.209、0.164 至 0.134。对于 Medlama3-v20，数字为 0.590、0.427、0.353、0.322 至 0.288。最后，对于 BioMistral-7B，数字为 0.731、0.620、0.580、0.560 至 0.544。" class="wp-image-1082574" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_2_hi-rez_revised.png 1469w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_2_hi-rez_revised-300x182.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_2_hi-rez_revised-1024x620.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_2_hi-rez_revised-768x465.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/09/MedFuzz_image_2_hi-rez_revised-240x145.png 240w" sizes="(max-width: 1469px) 100vw, 1469px" /><figcaption class="wp-element-caption">该图表显示了 MedQA 基准中各种模型在不同数量的 MedFuzz 攻击尝试下的准确性。水平线是 USMLE 考试的平均人类表现 (76.6%)。 GPT-4 和 Claude-Sonnet 在五次攻击后仍然具有与人类相当的性能。 BioMistral-7B 对攻击的鲁棒性出奇的强。</figcaption></figure><p>水平线是人类考生在 USMLE 医学考试中的平均分数 (76.6%)。在所有情况下，准确性都会随着攻击的增加而下降，从而深入了解法学硕士在违反简化假设方面的脆弱性。有趣的是，攻击的有效性随着尝试次数的增加而减弱。虽然这表明法学硕士最终可能会收敛到某个稳定的数字，以反映违反假设时的准确性，但我们承认需要进行更多调查。</p><p>基于刻板印象和偏见的医学判断（如示例中所包含的那样）可能会导致误诊和不适当的治疗，从而可能对患者有害。 MedFuzz 代表了评估 LLM 稳健性的重要一步，这是帮助这些模型从令人印象深刻的基准性能过渡到临床环境中实用、可靠的工具的关键因素。</p><p>有关 MedFuzz 方法及其含义的更多详细信息，您可以阅读<a href="https://www.microsoft.com/en-us/research/people/robertness/" target="_blank" rel="noreferrer noopener">Robert Osazuwa Ness</a> 、Katie Matton、Hayden Helm、 <a href="https://www.microsoft.com/en-us/research/people/shezhan/" target="_blank" rel="noreferrer noopener">Sheng Zhang</a> 、Junaid Bajwa、Carey E. Priebe 和<a href="https://www.microsoft.com/en-us/research/people/horvitz/" target="_blank" rel="noreferrer noopener">Eric Horvitz</a>撰写的<a href="https://www.microsoft.com/en-us/research/publication/medfuzz-exploring-the-robustness-of-large-language-models-in-medical-question-answering/">完整研究论文</a>。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/">《MedFuzz：探索法学硕士对医疗挑战问题的鲁棒性》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>