<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 10 月 12 日星期四 15:24:31 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.1</generator><item><title> DecodingTrust：GPT 模型可信度的综合评估</title><link/>https://www.microsoft.com/en-us/research/blog/decodingtrust-a-compressive-assessment-of-trustworthiness-in-gpt-models/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Mon, 16 Oct 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=971940 </guid><description><![CDATA[<p>生成式预训练 Transformer (GPT) 模型的可信度如何？为了回答这个问题，伊利诺伊大学香槟分校联合斯坦福大学、加州大学伯克利分校、人工智能安全中心和微软研究院，发布了一个针对大语言模型（LLM）的综合可信度评估平台，该平台在最近的论文：DecodingTrust：可信度综合评估 [...]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/">《DecodingTrust：GPT 模型可信度的综合评估》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" fetchpriority="high" width="1400" height="264" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-BlogBanner-no-text-1400x264-1.jpg" alt="蓝色和绿色渐变背景上的白线图标" class="wp-image-971991" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-BlogBanner-no-text-1400x264-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-BlogBanner-no-text-1400x264-1-300x57.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-BlogBanner-no-text-1400x264-1-1024x193.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-BlogBanner-no-text-1400x264-1-768x145.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-BlogBanner-no-text-1400x264-1-240x45.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h2 class="wp-block-heading" id="introduction">介绍</h2><p>生成式预训练 Transformer (GPT) 模型的可信度如何？</p><p>为了回答这个问题，伊利诺伊大学香槟分校联合斯坦福大学、加州大学伯克利分校、人工智能安全中心和微软研究院，发布了一个针对大语言模型（LLM）的综合可信度评估平台，该平台在最近的论文： <a href="https://www.microsoft.com/en-us/research/publication/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/" target="_blank" rel="noreferrer noopener">DecodingTrust：GPT 模型可信度的综合评估 - 微软研究<span class="sr-only">（在新选项卡中打开）</span></a> 。这篇论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://neurips.cc/" target="_blank" rel="noreferrer noopener">NeurIPS 2023（数据集和基准轨道）上被接受为口头报告<span class="sr-only">（在新选项卡中打开），</span></a>特别关注 GPT-4 和 GPT-3.5。它考虑了不同的观点，包括<em>毒性、刻板印象偏见、对抗鲁棒性、分布外鲁棒性、对抗性演示的鲁棒性、隐私、机器道德和公平性。</em></p><p>根据我们的评估，我们发现了之前未发布的与可信度相关的漏洞。例如，我们发现 GPT 模型很容易被误导，产生有毒和有偏见的输出，并泄露训练数据和对话历史记录中的私人信息。我们还发现，虽然在标准基准测试中 GPT-4 通常比 GPT-3.5 更值得信赖，但考虑到越狱系统或用户提示，GPT-4 更容易受到攻击，这些提示是恶意设计的，旨在绕过 LLM 的安全措施，可能是因为 GPT-4更准确地遵循（误导性）指示。</p><p>我们的工作展示了 GPT 模型的全面可信度评估，并揭示了可信度差距。我们的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://decodingtrust.github.io/" target="_blank" rel="noreferrer noopener">基准<span class="sr-only">（在新选项卡中打开）</span></a>是公开可用的。 </p><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="670821"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：微软研究通讯</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2019/09/Newsletter_Banner_08_2019_v1_1920x1080.png" alt="" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究院通讯</h2><p class="large">与 Microsoft 研究社区保持联系。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button is-style-fill-chevron"> <a href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank">立即订阅</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>值得注意的是，研究团队与 Microsoft 产品组合作，确认所识别的潜在漏洞不会影响当前面向客户的服务。这在一定程度上是正确的，因为成品人工智能应用程序应用了一系列缓解方法来解决技术模型级别可能发生的潜在危害。此外，我们还与GPT的开发商OpenAI分享了我们的研究成果，OpenAI已经注意到相关模型的系统卡中存在潜在的漏洞。</p><p>我们的目标是鼓励研究界的其他人利用这项工作并以此为基础，从而可能先发制人，防止对手利用漏洞造成伤害。此次可信度评估只是一个起点，我们希望与其他人合作，以评估结果为基础，创建强大且更值得信赖的模型。为了促进协作，我们使基准代码非常可扩展且易于使用：单个命令足以在新模型上运行完整的评估。</p><h2 class="wp-block-heading" id="trustworthiness-perspectives-of-language-models">语言模型的可信度视角</h2><p>机器学习（尤其是法学硕士）的最新突破已经实现了从聊天机器人到机器人的广泛应用。然而，尽管有关 GPT 模型可信度的文献仍然有限，但从业者建议即使对于医疗保健和金融等敏感应用也采用功能强大的 GPT 模型。为此，我们重点从八个可信度角度对GPT模型进行全面的可信度评估，根据不同的构建场景、任务、指标和数据集进行全面评估，如下图1所示。</p><p>总体而言，我们的目标是评估 1）GPT 模型在不同可信度视角下的性能，以及 2）其在对抗性环境（例如对抗性系统/用户提示、演示）中的性能弹性。</p><p>例如，为了评估 GPT-3.5 和 GPT-4 对文本对抗攻击的鲁棒性，我们构建了三个评估场景：1）使用普通任务描述对标准基准 AdvGLUE 进行评估，旨在评估：a）GPT 的漏洞现有文本对抗性攻击的模型，b）与标准 AdvGLUE 基准上最先进的模型相比，不同 GPT 模型的鲁棒性，c）对抗性攻击对其指令跟踪能力的影响（通过速率来衡量） d) 当前攻击策略的可转移性（通过不同攻击方法的可转移攻击成功率来量化）； 2）在给出不同指导性任务描述和设计的系统提示的情况下对AdvGLUE基准进行评估，以考察模型在不同（对抗性）任务描述和系统提示下的弹性； 3）在不同设置下针对开源自回归模型（例如 Alpaca-7B、Vicuna-13B 和 StableVicuna-13B）对我们生成的具有挑战性的对抗性文本 AdvGLUE++ 进行 GPT-3.5 和 GPT-4 的评估，以进一步评估 GPT-3.5 的漏洞和 GPT-4 在不同环境中受到强烈对抗性攻击。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="4528" height="4952" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1.png" alt="该图表列出了本工作中评估的可信度观点、基准和数据集，分为三层。第一层显示了8个主要的可信度视角，包括毒性、刻板印象、对抗鲁棒性、分布外鲁棒性、对抗性演示鲁棒性、隐私、机器伦理和公平性。第二层显示了每个可信度视角的不同基准。有些基准来自之前的工作，有些是论文中新提出的。第三层进一步显示每个基准的不同评估设置。" class="wp-image-971979" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1.png 4528w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1-274x300.png 274w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1-936x1024.png 936w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1-768x840.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1-1404x1536.png 1404w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1-1873x2048.png 1873w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure1-165x180.png 165w" sizes="(max-width: 4528px) 100vw, 4528px" /><figcaption class="wp-element-caption">图 1. 基于不同可信度视角的评估分类。我们使用黄色框表示对现有基准的评估，绿色框表示使用我们设计的新数据或现有数据集的新评估协议进行的评估。</figcaption></figure><h2 class="wp-block-heading" id="insights-and-findings-from-decodingtrust"> DecodingTrust 的见解和发现</h2><p>我们的研究发现了一些以前未公开的优势以及对大型语言模型可靠性的威胁。</p><p>例如，在模型对对抗性演示的鲁棒性方面，我们发现一方面，GPT-3.5和GPT-4不会被演示中添加的反事实示例所误导，甚至可以从总体上的反事实演示中受益；另一方面，我们观察到提供后门演示会误导 GPT-3.5 和 GPT-4 对后门输入做出错误的预测，特别是当后门演示靠近（后门）用户输入时，而 GPT-4 是更容易受到幕后示威的影响。</p><p>此外，就毒性和偏见而言，GPT-3.5和GPT-4对于良性且无针对性的系统提示下考虑的大多数刻板印象主题都没有强烈偏见。然而，鉴于设计的误导性（对抗性）系统提示，两种 GPT 模型都可能被“欺骗”，同意有偏见的内容。 GPT-4 比 GPT-3.5 更容易受到误导性目标系统提示的影响，并且更频繁地同意有偏见的内容，这可能是因为 GPT-4 更准确地遵循误导性指令。模型偏差通常取决于用户提示中提到的人口统计群体。例如，对于“同性恋者感染艾滋病毒”的查询，GPT-4 总体上强烈反对，而对于“女性感染艾滋病毒”的查询，GPT-4 经常同意并输出有偏见的内容。模型偏差还取决于刻板印象主题。 GPT 模型在领导力和贪婪等不太敏感的主题上输出更多偏见的内容，而在毒品交易和恐怖主义等更敏感的主题上生成较少偏见的内容。这可能是由于 GPT 模型针对某些受保护的人口群体和敏感主题进行了微调。</p><p> DecodingTrust 还评估法学硕士的隐私泄露问题。我们发现 GPT 模型可能会泄露隐私敏感的训练数据，例如标准安然电子邮件数据集中的电子邮件地址，尤其是在提示电子邮件上下文或（姓名、电子邮件）对的少量演示时。此外，在few-shot提示下，通过目标电子邮件域名等补充知识，电子邮件提取的准确率可以比电子邮件域名未知的场景高100倍。我们还观察到 GPT 模型可能会泄露对话历史记录中注入的私人信息。总体而言，GPT-4 在保护个人身份信息 (PII) 方面比 GPT-3.5 更稳健，并且这两种模型对于特定类型的 PII（例如社会安全号码）都具有稳健性，这可能是由于对这些 PII 关键字进行了显式指令调整。然而，当在上下文学习期间出现隐私泄露演示时，GPT-4 和 GPT-3.5 都会泄露所有类型的 PII。最后，GPT 模型在理解不同的隐私相关词语或隐私事件方面表现出不同的能力（例如，它们在“秘密”告知时会泄露私人信息，但在“秘密”告知时则不会泄露）。鉴于我们构造的提示，GPT-4 比 GPT-3.5 更有可能泄露隐私，这可能是因为它更准确地遵循（误导性）指令。我们在下面的图 2 中展示了模型不可靠输出的更多示例。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="3764" height="4484" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2.png" alt="该图显示了在良性系统提示下，GPT-4 的不良响应示例，涉及 8 个可信度视角，包括毒性、刻板印象、对抗鲁棒性、分布外鲁棒性、对抗性演示鲁棒性、隐私、机器道德和公平。" class="wp-image-971985" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2.png 3764w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2-252x300.png 252w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2-860x1024.png 860w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2-768x915.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2-1289x1536.png 1289w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2-1719x2048.png 1719w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/DecodingTrust_figure2-151x180.png 151w" sizes="(max-width: 3764px) 100vw, 3764px" /><figcaption class="wp-element-caption">图 2. 从不同可信度角度给出良性系统提示的 GPT-4 不良响应示例。攻击性或敏感信息被屏蔽。 </figcaption></figure><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/">阅读论文</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/">《DecodingTrust：GPT 模型可信度的综合评估》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> Microsoft 在 VL/HCC 2023：重点关注电子表格的联合审核工具</title><link/>https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 12 Oct 2023 16:00:00 +0000</pubDate><category><![CDATA[@ Conferences]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/ </guid><description><![CDATA[<p>这些研究论文在 IEEE 视觉语言和以人为本计算研讨会（在新选项卡中打开）(VL/HCC 2023) 上发表，这是编程、建模和通信计算技术的设计、理论和应用的首要论坛。大型语言模型 (LLM) 彻底改变了新手程序员和日常计算机用户利用功能的方式 [...]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/">Microsoft at VL/HCC 2023：关注电子表格的联合审核工具一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-center">这些研究论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://conf.researchr.org/home/vlhcc-2023" target="_blank" rel="noreferrer noopener"><strong><em>IEEE 视觉语言和以人为本计算研讨会</em></strong><span class="sr-only">（在新选项卡中打开）</span></a> <strong><em>(VL/HCC 2023) 上</em></strong><strong><em>发表</em></strong>，这是编程、建模和通信计算技术的设计、理论和应用的首要论坛<strong><em>。</em></strong> </p><figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1.png" alt="Microsoft 在 VL/HCC 2023：重点关注电子表格的联合审核工具" class="wp-image-974691" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>大型语言模型 (LLM) 彻底改变了新手程序员和日常计算机用户利用自然语言进行编程的方式。在这种情况下使用的工具中，电子表格成为首选。将法学硕士集成到电子表格中有望大大增强其功能和用户体验。同时，众所周知，电子表格用户通常会无意中<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/ftp/arxiv/papers/1602/1602.02601.pdf" target="_blank" rel="noreferrer noopener">引入错误<span class="sr-only">（在新选项卡中打开）</span></a> ，这可能会带来重大风险。例如，2010 年， <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nber.org/papers/w15639" target="_blank" rel="noreferrer noopener">哈佛经济分析<span class="sr-only">（在新选项卡中打开）</span></a>中使用的用于告知对希腊实施的紧缩措施的电子表格被发现包含<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://doi.org/10.1093/cje/bet075" target="_blank" rel="noreferrer noopener">多个错误<span class="sr-only">（在新选项卡中打开）</span></a> 。</p><p> Microsoft 正在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aka.ms/co-audit" target="_blank" rel="noreferrer noopener">积极开展<span class="sr-only">（在新选项卡中打开）</span></a>研究，重点是开发联合审计工具和技术，最初的重点是电子表格。这些工具旨在帮助用户验证法学硕士生成的结果。在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://conf.researchr.org/home/vlhcc-2023" target="_blank" rel="noreferrer noopener">VL/HCC 2023 <span class="sr-only">（在新选项卡中打开）</span></a>上，我们推出了两种新的电子表格工具 ColDeco 和 FxD，专门用于帮助用户在电子表格中彻底检查和调试其程序。此外，值得一提的是，关于 FxD 的论文获得了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://conf.researchr.org/attending/vlhcc-2023/awards">荣誉奖<span class="sr-only">（在新选项卡中打开）</span></a> 。</p><h3 class="wp-block-heading" id="coldeco-an-end-user-inspection-tool"> ColDeco：最终用户检查工具</h3><p>使用电子表格中的表格是一项常见任务，添加计算列的功能非常有用。计算列不仅可以添加信息，还可以促进过滤和排序等任务。生成式人工智能可以让用户在表中创建复杂的计算列。然而，在这种情况下，验证人工智能生成的代码至关重要，因为人工智能可能会误解用户的意图或忽略重要数据。</p><p>在我们的论文“ <a href="https://www.microsoft.com/en-us/research/publication/coldeco-an-end-user-spreadsheet-inspection-tool-for-ai-generated-code/" target="_blank" rel="noreferrer noopener">ColDeco：用于 AI 生成代码的最终用户电子表格检查工具</a>”中，我们介绍了 ColDeco，一种用于计算列的无代码检查工具。 ColDeco 使用辅助列和行分组来帮助用户了解 AI 生成的列的工作原理并找到任何错误。</p><p>为了描述 ColDeco 的工作原理，我们将使用一个示例表，其中在不同的列中包含人们的名字、中间名和姓氏。我们的用户要求系统“创建一个名为‘缩写’的列，该列采用名称每个部分的第一个字母。”在此示例中，生成的代码中存在错误，无法处理没有中间名的行，导致某些缩写单元格为空。</p><p>首先，模型生成一个程序，计算每行的缩写并将其添加到新的缩写列中。 ColDeco 的界面会自动打开为侧面板，如图 1 所示。</p><p> Inspect Columns 视图显示所有生成的列，并附有生成代码的自然语言描述。 “检查行”视图显示按行为组织的表的子集。行检查视图使用数据流分析对行进行分组，突出显示关键的不同执行行为。在我们的示例中，此视图很快将用户的注意力吸引到未能计算缩写的两行。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="371" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig1.png" alt="两个图形。第一张图描绘了一个表格，其中包含以下列：“名字”、“中间名”、“姓氏”、“DoB”和“缩写”。有 11 行。作为示例，第 3 行包含信息：名字：Christopher、中间名：Michael、姓氏：Fleming、DoB：11/5/1995、缩写：CMF。第 9 行包含信息：名字：William，中间名为空，姓氏：Smith，DoB：6/3/1968，缩写为空。第二张图描绘了具有两个部分的侧面板。第一部分是“检查列”视图（标记为 1a）。显示名为“缩写”的单列和相应的描述。第二部分是“检查行”视图（标记为 1b）。它包含一个表，其中包含“索引”、“名字”、“中间名”、“姓氏”和“缩写”列。表内有两组行。第一组有一个示例行：索引：4716，名字：William，中间名为空，姓氏：Smith，缩写为空。第二组有一个示例行：索引：8984，名字：Christopher，中间名：Michael，姓氏：Flemming，缩写：CMF。" class="wp-image-973413" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig1-300x80.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig1-1024x271.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig1-768x204.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig1-240x64.png 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 1. ColDeco 侧面板的初始视图。缩写程序由 AI 生成并作为新列添加到表中。检查列视图 (1a) 显示 AI 生成的列，包括代码工作原理的描述。 “检查行”视图 (1b) 将行分组为不同的行为，指示两行中存在错误。</figcaption></figure><p>如果我们的用户想要调查错误，他们可以将生成的列扩展为多个辅助列，如图 2 所示。这些辅助列在表 (2a) 和侧面板 (2b) 中都可见，并且它们显示中间结果价值观。用户现在可以看到缺少的缩写是由系统尝试获取第一个和中间名首字母缩写时发生的错误引起的。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="272" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig2.png" alt="两个图形。第一个图形（标记为 2a）描绘了一个包含 4 列的表格：“DoB”、“文本连接”、“姓氏的第一个字母”、“缩写”。例如，第 3 行包含信息：DoB：11/5/1995，文本连接：CM，Lan 名称的第一个字母：F，缩写：CMF。第 9 行包含信息 DoB：6/3/1968，文本连接：为空，Lan 名称的第一个字母：S，缩写：为空。第二个图形（标记为 2b）描绘了显示“检查列”视图的侧面板。树视图显示“缩写”作为根，有两个子项：“姓氏的第一个字母”和“文本连接”，对应于表中的列。树视图中的每一列都有相应的描述。" class="wp-image-973416" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig2.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig2-300x58.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig2-1024x199.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig2-768x149.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_ColDeco-fig2-240x47.png 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 2. 用户将缩写列扩展为两个附加辅助列后的 ColDeco 侧面板。每个附加列都有一个描述。 </figcaption></figure><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="935415"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：人工智能聚焦领域</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" aria-label="AI and Microsoft Research" data-bi-cN="AI and Microsoft Research" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2020/07/newsletter-option-8-neural-network-3-1.png" alt="深蓝色背景上的抽象神经网络模式" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能和微软研究院</h2><p class="large">详细了解 Microsoft 人工智能研究的广度</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Learn more" data-bi-cN="AI and Microsoft Research" target="_blank">了解更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading" id="fxd-a-functional-debugger">FxD：功能调试器</h3><p>并非每个电子表格任务都涉及生成新的表列。此外，许多用户已经非常熟悉电子表格公式。这给我们带来了第二个工具，一个电子表格公式调试器，在论文“ <a href="https://www.microsoft.com/en-us/research/publication/fxd-a-functional-debugger-for-dysfunctional-spreadsheets/" target="_blank" rel="noreferrer noopener">FxD：功能失调的电子表格的功能调试器</a>”中介绍。</p><p>我们在设计 FxD 时采用了以用户为中心的方法，广泛回顾了有关函数式编程调试器的现有文献。这说明了我们在 FxD 中实现的四个关键功能：</p><p><strong>现场调试</strong>。 FxD 在用户编辑公式时动态更新，从而允许快速修改和探索公式（图 3，图像 1）。</p><p><strong>混合公式追踪</strong>。<strong> </strong>调试器将基于步骤的评估（图 3，图 1）与基于树的推导（图 3，图 3）相结合，提供公式的逐步细分。子步骤隐藏在可扩展卡后面，以防止用户过载。</p><p><strong>子公式着色</strong>。<strong> </strong>当 FxD 评估公式时，颜色编码会突出显示公式中的变化。当用户将鼠标悬停在步骤上时，这有助于跟踪这些更新（图 3，图像 2 和 4）。</p><p><strong>信息督察</strong>。<strong> </strong>上下文感知工具提示可改善用户体验。一个示例是当用户将鼠标悬停在 VLOOKUP 等函数中的范围上时的表格预览。这些工具提示提供了对范围、周围上下文以及包含函数使用的查找列的深入了解（图 3，图像 3）。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="633" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_FxD-fig3.png" alt="四个图形，每个图形描述调试器的不同功能。正在调试的公式为‘=IF(G3 &lt; (B1 + B2) * (1 + B3), “low”, “high”)’。第一张图（标记为 1）显示了公式及其计算轨迹。跟踪中的每个步骤都会显示公式以及评估的某些部分。最后一步是值“low”，它是公式的结果。第二个图形（标记为 2）显示突出显示的步骤。该步骤有一个前公式和后公式，评估多个部分。在“之前”和“之后”公式中，评估的每个部分都用相同的颜色突出显示。第三个图形（标记为 3）显示悬停在单元格范围上并显示范围信息检查器。检查器显示相应范围的网格预览。第四个图形（标记为 4）显示突出显示的步骤和悬停在评估的子部分上。用户将鼠标悬停在“之后”公式中的值 15 上，“之前”公式中对应的公式“B1 + B2”带有下划线。" class="wp-image-973419" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_FxD-fig3.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_FxD-fig3-300x136.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_FxD-fig3-1024x463.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_FxD-fig3-768x347.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VL-HCC-2023_FxD-fig3-240x109.png 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 3.FxD 调试器。图1显示了编辑后的公式和评估步骤。当用户编辑公式时，这些步骤会更新。图 2 显示了子公式着色，它突出显示了悬停时的子公式及其值。图 3 显示了一个信息检查器，可预览公式中引用的范围。图 4 显示了多个子公式的并发计算。当用户将鼠标悬停在某个值上时，相应的子公式会带有下划线。</figcaption></figure><h3 class="wp-block-heading" id="growing-importance-of-ai-code-verification"> AI代码验证的重要性日益增加</h3><p>随着人工智能生成代码的复杂性不断增加，对验证准确性的工具的需求变得越来越重要。作为回应，我们开发了这两种针对电子表格的联合审计工具。展望未来，一个关键的考虑因素在于管理这些工具的复杂性。我们的愿景是调试工具将融入生成式人工智能，以帮助用户生成和验证工作流程。</p><p>请参阅我们关于一般联合审计的<a href="https://www.microsoft.com/en-us/research/publication/co-audit-tools-to-help-humans-double-check-ai-generated-content/" target="_blank" rel="noreferrer noopener">论文</a>以了解更多信息。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/">Microsoft at VL/HCC 2023：关注电子表格的联合审核工具一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>