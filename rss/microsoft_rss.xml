<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 12 月 13 日星期五 18:15:30 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.7.1</generator><item><title>转向 GraphRAG 1.0 – 为开发人员和用户简化人体工程学</title><link/>https://www.microsoft.com/en-us/research/blog/moving-to-graphrag-1-0-streamlined-ergonomics-for-developers-and-users/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Mon, 16 Dec 2024 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1111143 </guid><description><![CDATA[<p> GraphRAG 有助于推进人工智能在科学等复杂领域的应用。由于热烈的采用和社区的参与，我们升级了预发布版本。查看 GraphRAG 1.0 中主要的人体工程学和结构更新。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/moving-to-graphrag-1-0-streamlining-ergonomics-for-developers-and-users/">《转向 GraphRAG 1.0 – 为开发人员和用户简化人体工程学》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1.png" alt="GraphRAG 博客英雄 - 蓝色/绿色渐变背景上的小圆形节点簇" class="wp-image-1111170" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/GraphRAG-1.0-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h2 class="wp-block-heading" id="introducing-graphrag-1-0"> GraphRAG 1.0 简介</h2><p>Microsoft 于 2024 年 7 月<a href="https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/" target="_blank" rel="noreferrer noopener">首次推出<span class="sr-only">（在新选项卡中打开）</span></a> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/graphrag" target="_blank" rel="noreferrer noopener">GraphRAG 的预发布版本<span class="sr-only">（在新选项卡中打开），</span></a>以推进 AI 在复杂领域的使用。从那时起，我们看到了令人难以置信的采用和社区参与（截至撰写本文时，GitHub 上有超过 20k 个 star 和 2k 个 fork），核心团队和社区贡献者进行了大量修复和改进。我们对收到的贡献和反馈深表感谢，并很高兴与大家分享一些重大的人体工程学和结构改进，这些改进最终导致 GraphRAG 1.0 的正式发布。</p><h2 class="wp-block-heading" id="ergonomic-refactors">人体工学重构</h2><h3 class="wp-block-heading" id="easier-setup-for-new-projects">更轻松地设置新项目</h3><p>当我们第一次启动 GraphRAG 时，大多数配置都是使用环境变量完成的，考虑到可用的选项很多，这可能会令人望而生畏。我们通过添加<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/graphrag/config/init/" target="_blank" rel="noreferrer noopener">init 命令<span class="sr-only">（在新选项卡中打开）</span></a>减少了设置过程中的麻烦，该命令生成一个简化的启动器 settings.yml 文件，其中所有核心所需的配置都已设置。我们建议开发人员从这里开始，以确保他们获得最清晰的初始配置。通过此更新，最小的启动配置不需要用户具备 GraphRAG 的专业知识即可快速设置，只需要在其环境中使用 OpenAI API 密钥。</p><h3 class="wp-block-heading" id="new-and-expanded-command-line-interface">新的和扩展的命令行界面</h3><p>我们扩展了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/graphrag/cli/" target="_blank" rel="noreferrer noopener">命令行界面<span class="sr-only">（在新选项卡中打开）</span></a> (CLI) 的功能和易用性，并采用了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/fastapi/typer" target="_blank" rel="noreferrer noopener">Typer <span class="sr-only">（在新选项卡中打开）</span></a>来提供更好的内联文档和更丰富的 CLI 体验。最初的 CLI 旨在作为入门演示，供用户在示例数据集上尝试 GraphRAG。我们从社区了解到，大多数人实际上希望使用它作为 GraphRAG 的主要交互模式，因此作为这个里程碑版本的一部分，我们引入了增强功能，从而带来更简化的体验。通过这项工作，CLI 启动时间从平均 148 秒缩短到 2 秒。</p><h3 class="wp-block-heading" id="consolidated-api-layer">整合API层</h3><p>2024 年 8 月，我们引入了独立的 API 层来简化开发人员的使用。原始 CLI 包含实例化和执行基本索引和查询命令所需的所有代码，用户经常需要复制这些代码。当我们收集反馈时，API 层仍然被认为是临时的，但旨在成为希望将 GraphRAG 功能集成到自己的应用程序中而无需深度管道或查询类自定义的开发人员的主要入口点。事实上，CLI 和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/azure-samples/graphrag-accelerator" target="_blank" rel="noreferrer noopener">加速器<span class="sr-only">（在新选项卡中打开）</span></a>完全构建在 API 层之上，充当如何与 API 交互的文档示例。我们还在我们的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/graphrag/query/notebooks/overview/" target="_blank" rel="noreferrer noopener">笔记本集合中添加了如何使用此 API 的示例<span class="sr-only">（在新选项卡中打开）</span></a> ，我们将在未来版本中迭代时继续更新这些示例。</p><h3 class="wp-block-heading" id="simplified-data-model">简化的数据模型</h3><p>GraphRAG 创建多个输出工件来存储索引知识模型。初始模型包含大量基于早期研究期间实验想法的文件、字段和交叉引用，这对于新用户和常规用户来说可能是难以承受的。我们对数据模型进行了全面审查，并进行了修复，以提高清晰度和一致性、删除冗余或未使用的字段、改善存储空间并简化数据模型。以前，输出缺乏标准化，相关输出很容易与非关键中间输出文件混淆。现在，使用 GraphRAG 1.0，输出将仅包括易于读取和追踪的相关输出。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1061244"><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/about-microsoft-research/" aria-label="About Microsoft Research" data-bi-cN="About Microsoft Research" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/About-page-promo_1066x600.jpg" alt="" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">关于微软研究院</h2><p class="large">推动科学技术造福人类</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/about-microsoft-research/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="View our story" data-bi-cN="About Microsoft Research" target="_blank">查看我们的故事</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading" id="streamlined-vector-stores">简化的矢量存储</h3><p>嵌入及其矢量存储是 GraphRAG 存储需求的一些主要驱动因素。我们的原始数据模型在数据摄取和索引后将所有嵌入存储在 parquet 输出文件中。这使得文件变得可移植，这对于早期研究来说很方便，但对于许多用户来说，随着他们配置自己的向量存储并且数据摄取规模的增长，这变得不必要。我们更新了 GraphRAG 管道，以<em>在索引期间创建默认向量存储，</em>因此不需要后处理，并且查询库共享此配置以实现无缝使用。此更改的好处是，从磁盘读取输出文件时不再需要加载这些向量（可能非常大），从而在每次查询期间节省读取时间和内存。再加上简化的数据模型，输出 Parquet 磁盘节省了 80%，总磁盘空间（包括矢量存储中的嵌入）减少了 43%。 GraphRAG 支持开箱即用的向量存储 LanceDB 和 Azure AI 搜索。为了简单启动，默认使用 LanceDB，并与知识模型工件一起写入本地数据库。</p><h3 class="wp-block-heading" id="flatter-clearer-code-structure">更扁平、更清晰的代码结构</h3><p>通往 1.0 版本之路上的一项关键举措是简化代码库，使其更易于维护且更易于第三方用户使用。我们已经从组织中删除了大部分代码深度，以使其更易于浏览，并且将我们自己的使用模式表明不需要位于单独功能区域中的更多代码放在一起。</p><p>我们还发现，很少有用户需要底层<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/datashaper" target="_blank" rel="noreferrer noopener">DataShaper <span class="sr-only">（在新选项卡中打开）</span></a>引擎提供的声明性配置，因此我们将这 88 个详细工作流定义折叠为较小的一组 11 个工作流，这些工作流以功能性方式而不是组合方式运行。这使得管道更容易理解，并且是朝着更适合我们未来研究计划并全面提高性能的架构迈出的一步。通过折叠工作流程，我们现在可以减少未使用的输出工件、减少数据重复以及减少磁盘 I/O 操作。这种简化还减少了管道的内存占用，使用户能够使用 GraphRAG 索引和分析更大的数据集。</p><h3 class="wp-block-heading" id="incremental-ingest">增量摄取</h3><p>到目前为止，每次获取新信息时，不断发展的数据集都需要完全重新索引，以便重新生成知识模型。在 GraphRAG 1.0 中，我们在 CLI 中包含了一个新的<strong>更新</strong>命令，该命令计算现有索引和新添加的内容之间的增量，并智能地合并更新以最大程度地减少重新索引。 GraphRAG 使用 LLM 缓存机制在重新索引时尽可能节省成本，因此数据集的重新运行通常比初始运行更快、更便宜。添加全新内容可能会改变社区结构，从而需要重新计算大部分索引 - <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/graphrag/cli/#update" target="_blank" rel="noreferrer noopener">更新命令<span class="sr-only">（在新选项卡中打开）</span></a>解决了这个问题，同时还提高了答案质量。</p><h2 class="wp-block-heading" id="availability">可用性</h2><p>GraphRAG 版本 1.0 现已在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/graphrag" target="_blank" rel="noreferrer noopener">GitHub <span class="sr-only">（在新选项卡中打开）</span></a>上提供，并发布到<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://pypi.org/project/graphrag/">PyPI <span class="sr-only">（在新选项卡中打开）</span></a> 。立即查看<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/graphrag/get_started/" target="_blank" rel="noreferrer noopener">入门<span class="sr-only">（在新选项卡中打开）</span></a>指南以使用 GraphRAG 1.0。今天。</p><h3 class="wp-block-heading" id="migrating">迁移</h3><p>我们建议用户迁移到 GraphRAG 1.0，它为用户和开发人员提供了简化的体验，包括多项改进。然而，由于其更新范围广泛，1.0 版不向后兼容。如果您在 1.0 版之前使用过 GraphRAG 并且已有索引，则需要解决一些重大更改，但这应该是一个简单的过程。为了支持社区进行此迁移，我们在存储库中创建了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/graphrag/blob/main/v1-breaking-changes.md" target="_blank" rel="noreferrer noopener">迁移指南<span class="sr-only">（在新选项卡中打开），</span></a>其中包含更多信息。</p><h3 class="wp-block-heading" id="future-directions">未来方向</h3><p>我们最近发布了一种名为<a href="https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/" target="_blank" rel="noreferrer noopener">LazyGraphRAG</a>的全新 GraphRAG 方法，该方法执行最少的预先索引以避免在执行用户查询之前使用 LLM。这避免了基于 LLM 的对用户可能不感兴趣的大量内容的总结，因此即使在昂贵的处理之后也从未探索过。这种方法以 GraphRAG 成本的一小部分展示了强大的性能，并将在不久的将来作为用户的新选项添加​​到 GraphRAG 核心代码库中。</p><p>此外，Microsoft 一直在积极探索 GraphRAG 如何提高科学进步的速度，并且正在构建相关的 GraphRAG 功能，以与我们在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://blogs.microsoft.com/blog/2024/06/18/empowering-every-scientist-with-ai-augmented-scientific-discovery/" target="_blank" rel="noreferrer noopener">人工智能支持的科学发现方面的更广泛工作保持一致<span class="sr-only">（在新选项卡中打开）</span></a> 。</p><p>我们将继续完善代码库并研究架构更改，使用户能够使用自己的语言模型 API、存储提供程序和向量存储。我们对这一重大里程碑感到非常兴奋，这次重构为我们在 GraphRAG 领域的持续研究奠定了基础。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/moving-to-graphrag-1-0-streamlining-ergonomics-for-developers-and-users/">《转向 GraphRAG 1.0 – 为开发人员和用户简化人体工程学》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 12 月 2 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-2-2024/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 04 Dec 2024 17:07:27 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1106934 </guid><description><![CDATA[<p>新的 SOS-RMT 协议能否实现更高效的 CL-MPC？；一个公平设计、基于云的算法交易平台； LLM2CLIP解锁更丰富的视觉表现；新技术增强了Low-Rank Adaptation的表达能力、泛化能力。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-2-2024/">《研究焦点：2024 年 12 月 2 日一周</a>》一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p>欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。 </p></blockquote></figure><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1.jpg" alt="研究重点：2024 年 12 月 2 日当周" class="wp-image-1106946" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/11/RF54-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2></div><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading" id="heading">通信本地 MPC 中的自适应安全、擦除和网络假设</h2><p>n 方多方计算 (MPC) 是一种加密协议技术，允许各方在其联合数据上安全地计算函数，同时保持其输入的私密性。为了构建这样的协议，大多数工作都要求所有参与方能够安全可靠地相互通信。最近，人们对本地通信 (CL) MPC 的问题进行了探讨，该假设被更现实地建模——例如，仅要求参与方能够安全可靠地与其他一些参与方进行通信（例如在区块链等网络中） 。然而，很少有解决方案能够保证适应性安全（即对各方动态腐败的抵御能力），并且大多数解决方案都依赖于对各方行为的强有力假设。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/adaptive-security-erasures-and-network-assumptions-in-communication-local-mpc/">通信本地 MPC 中的自适应安全、擦除和网络假设中</a>，来自 Microsoft 的研究人员和外部合作者重新审视了早期工作中所做的假设。作者得出的结论是，对于安全、自适应 CL-MPC，一些先前假定的功能（如安全擦除和多重发送）在某些条件下可以被绕过；然而，如果没有一些最低限度的假设，在 CL 设置中完全减少多对多到多对一的通信仍然无法实现。他们提出了一种新的 SOS-RMT 协议，在特定的可行性边界和额外的加密假设下实现更高效的 CL-MPC。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--1"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/adaptive-security-erasures-and-network-assumptions-in-communication-local-mpc/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">Cuttlefish：云托管金融交易所的公平、可预测的执行环境</h2><p>低延迟算法交易通过促进准确/及时的证券定价、更高的流动性和更低的投资者交易成本，正在提高现代金融市场的效率。目标是尽快处理传入的市场数据并发出交易，以利用短暂的做市和套利机会。人们对云托管金融交易所的兴趣日益浓厚，因为它们承诺为市场参与者提供一个更容易访问的经济高效的平台，以及其他好处。</p><p>不幸的是，云环境中的主要障碍之一是确保平等的网络和计算，尽管网络延迟不可预测且计算时间不确定。</p><p>在最近的预印本《 <a href="https://www.microsoft.com/en-us/research/publication/cuttlefish-a-fair-predictable-execution-environment-for-cloud-hosted-financial-exchanges/" target="_blank" rel="noreferrer noopener">Cuttlefish：云托管金融交易所的公平、可预测的执行环境》</a>中，来自 Microsoft 的研究人员和外部合作者提出了一个可以在云环境中运行的公平设计算法交易平台。 Cuttlefish 旨在将真实操作的高效且稳健的映射应用到“虚拟时间”的新颖表述中。这使得 Cuttlefish 能够将公平性推向极致，无论底层网络通信和计算硬件如何。研究人员的实施和评估验证了Cuttlefish的实用性，并展示了其在公共云平台上的运行效率。本文以之前的工作为基础： <a href="https://www.microsoft.com/en-us/research/publication/rethinking-cloud-hosted-financial-exchanges-for-response-time-fairness/" target="_blank" rel="noreferrer noopener">重新思考云托管金融交易所的响应时间公平性</a>和<a href="https://www.microsoft.com/en-us/research/publication/dbo-fairness-for-cloud-hosted-financial-exchanges/" target="_blank" rel="noreferrer noopener">DBO：云托管金融交易所的公平性。</a> </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--2"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/cuttlefish-a-fair-predictable-execution-environment-for-cloud-hosted-financial-exchanges/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1085523"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/abstracts-august-15-2024/" aria-label="Abstracts: August 15, 2024" data-bi-cN="Abstracts: August 15, 2024" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Episode-15_Abstracts_Hero_Feature_No_Text_1400x788.jpg" alt="程式化的麦克风和声波插图。" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">摘要：2024 年 8 月 15 日</h2><p class="large">先进的人工智能可能会让坏人更容易在网上欺骗他人。一个多学科研究团队正在探索一种解决方案：一种允许人们在不共享身份信息的情况下证明自己不是机器人的凭证。施瑞·贾恩 (Shrey Jain) 和佐伊·希齐格 (Zoë Hitzig) 进行了解释。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/abstracts-august-15-2024/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Abstracts: August 15, 2024" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">LLM2CLIP：强大的语言模型解锁更丰富的视觉表示</h2><p>CLIP 是一个著名的多模态基础模型，它将视觉和文本信号对齐到共享的特征空间中。它支持各种任务，包括零样本分类、检测、分割和跨模态检索，显着影响整个多模态领域。作为特征提取器，它在图像理解、视频理解和文本到图像/视频生成等跨模态表示任务中占据主导地位。然而，大型语言模型（LLM）的快速进步正在不断突破语言理解和生成的界限。能否利用法学硕士的能力来进一步改进多模式表示学习？</p><p>在最近的一篇文章： <a href="https://www.microsoft.com/en-us/research/publication/llm2clip-powerful-language-model-unlock-richer-visual-representation/">LLM2CLIP：强大的语言模型解锁更丰富的视觉表示</a>中，来自 Microsoft 和外部合作者的研究人员提出了 LLM2CLIP，这是一种释放 CLIP 潜力的新颖方法，重点关注有前途的基础模型的基本优化。通过使用对比学习对标题空间中的 LLM 进行微调，他们将其文本功能提取到输出嵌入中，从而显着提高了输出层的文本辨别能力。然后，研究人员设计了一个训练过程，其中经过微调的法学硕士充当 CLIP 视觉编码器的强大老师。 LLM 的存在使他们能够合并更长、更复杂的字幕，而不受 CLIP 文本编码器的上下文窗口和能力限制的限制。他们的实验表明，这种方法给跨模式任务带来了实质性的改进。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--3"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/llm2clip-powerful-language-model-unlock-richer-visual-representation/">阅读论文</a></div><div class="wp-block-button is-style-outline is-style-outline--4"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/llm2clip" target="_blank" rel="noreferrer noopener">了解有关 LLM2CLIP 的更多信息</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">LORASC：通过慢速级联学习对大型模型进行富有表现力和可推广的低秩适应</h2><p>基础模型是在广泛的数据集上预先训练的大型模型，随后适用于特定的下游任务，已成为当代机器学习框架的组成部分。微调这些模型至关重要，但全参数微调通常会遇到严重的内存和计算瓶颈。参数高效微调（PEFT）技术旨在最大限度地减少可训练参数的数量，以降低训练成本并提高训练稳定性。在这些技术中，低秩适应（LoRA）非常有效，尽管它在表达性和泛化方面存在局限性。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/lorasc-expressive-and-generalizable-low-rank-adaptation-for-large-models-via-slow-cascaded-learning/">LORASC：通过慢速级联学习对大型模型进行表达性和可泛化的低阶适应</a>，来自 Microsoft 和外部合作者的研究人员提出了一种创新技术，旨在增强 LoRA 的表达性和泛化能力，同时保持其训练效率。他们的级联学习策略可以实现低等级适应的混合，从而提高模型捕获复杂模式的能力。他们还引入了慢速更新机制和级联噪声调整来增强泛化能力。他们对各种语言和视觉数据集以及鲁棒性基准进行的广泛实验表明，所提出的方法显着优于现有基线，同时还减轻了过度拟合，增强了模型稳定性，并提高了分布外（OOD）鲁棒性。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--5"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/lorasc-expressive-and-generalizable-low-rank-adaptation-for-large-models-via-slow-cascaded-learning/">阅读论文</a></div></div></div><div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section"><div class="container"><div class="wp-block-msr-immersive-section__inner"><div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-the-news"><div class="msr-cards__inner"><div class="heading-wrapper"><h2 class="mb-5 ">微软研究院新闻报道</h2></div><div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3"><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a
						class="text-decoration-none text-black"
						data-bi-cN="Can AI spot the next bomb cyclone far in advance? Microsoft hopes so"
						href="https://www.seattletimes.com/business/can-ai-spot-the-next-bomb-cyclone-far-in-advance-microsoft-hopes-so/"
					><span>人工智能能否提前发现下一个炸弹旋风？微软希望如此</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><div class="card__description card__citation small"><p>西雅图时报 | 2024 年 11 月 23 日</p><p>微软声称，Aurora 是一种不断接受训练的深度学习模型，它可以比传统预测模型更快地生成天气预报，并且准确度达到或超过传统预测模型。 </p></div></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a
						class="text-decoration-none text-black"
						data-bi-cN="How Microsoft's next-gen BitNet architecture is turbocharging LLM efficiency "
						href="https://venturebeat.com/ai/how-microsofts-next-gen-bitnet-architecture-is-turbocharging-llm-efficiency/"
					><span>微软的下一代 BitNet 架构如何提高 LLM 效率</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><div class="card__description card__citation small"><p>创业节拍| 2024 年 11 月 13 日</p><p>一位大语言模型 (LLM) 已成为一种有前途的方法，可以使生成式人工智能更容易获得且更便宜。在一篇新论文中，微软研究人员介绍了 Binet a4.8，这是一种新技术，可以在不牺牲性能的情况下进一步提高一位 LLM 的效率。 </p></div></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a
						class="text-decoration-none text-black"
						data-bi-cN="2024 Ellison Cliffe Lecture: AI in science and medicine with Christopher Bishop"
						href="https://www.youtube.com/watch?v=lB3K4pk5jN4"
					><span>2024 年 Ellison Cliffe 讲座：Christopher Bishop 的人工智能在科学和医学领域的应用</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><div class="card__description card__citation small"><p>英国皇家医学会 | 2024 年 11 月 13 日</p><p>微软人工智能科学研究院技术研究员兼主任 Christopher Bishop 讨论了支撑人工智能革命的深度学习技术的非凡进步，包括科学发现和医学领域的关键进展。最近在英国皇家医学会的演讲包括人工智能在材料设计、药物发现和医疗保健方面影响的最新例子。</p></div></div></div></div></div><div class="justify-content-center text-center mb-4"> <a
					href="https://www.microsoft.com/en-us/research/news-and-awards/"
					class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta"
					data-bi-cN="View more news and awards"
					data-bi-type="button"
				>查看更多新闻和奖项</a></div></div></div></div></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-2-2024/">《研究焦点：2024 年 12 月 2 日一周</a>》一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>