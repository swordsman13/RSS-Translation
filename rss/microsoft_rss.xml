<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 12 月 19 日星期二 16:14:32 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.2</generator><item><title>研究重点：2023 年 12 月 18 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-18-2023/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 20 Dec 2023 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-18-2023/ </guid><description><![CDATA[<p>本期研究焦点：优化退出增强模型以实现可扩展的高效推理； NeurIPS LLM 效率挑战赛；法学硕士授权的自动化数据探索；通过数据驱动的决策和优化来提高云效率。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-18-2023/">《研究焦点：2023 年 12 月 18 日一周》一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1.png" alt="研究焦点 2023 年 12 月 18 日" class="wp-image-992748" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RF31-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="naserex-optimizing-early-exits-via-automl-for-scalable-efficient-inference-in-big-image-streams"> NASerEx：通过 AutoML 优化早期退出，以在大图像流中进行可扩展的高效推理</h2><p>深度神经网络 (DNN) 本质上是堆叠的转换函数（层），可生成逐渐复杂的特征/编码。这使得它们成为通用逼近器，并在复杂任务中取得前所未有的成功。这种推理有效性是以计算复杂性增加为代价的，使得 DNN 难以扩展以提高 AI 应用程序的运行效率，尤其是在资源受限的硬件上运行时。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/naserex-optimizing-early-exits-via-automl-for-scalable-efficient-inference-in-big-image-streams/" target="_blank" rel="noreferrer noopener">NASerEx：通过 AutoML 优化早期退出以实现大图像流中可扩展的高效推理中，</a>微软的研究人员及其合作者提出了一个新的框架来解决这个问题。 NASerEX 利用神经架构搜索 (NAS) 和新颖的显着性约束搜索空间和退出决策度量来学习合适的早期退出结构，以增强深度神经模型，从而对大图像流进行可扩展的高效推理。优化的退出增强模型凭借智能自适应推理的功能，执行速度提高了约 2.5 倍，聚合的有效 FLOP 降低了约 4 倍，并且没有显着的准确性损失。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/naserex-optimizing-early-exits-via-automl-for-scalable-efficient-inference-in-big-image-streams/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="980709"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-madeleine-daepp-with-jennifer-scurrell-and-alejandro-cuevas/" aria-label="Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas" data-bi-cN="Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Madeline_Insights_Hero_Feature_No_Text_1400x788-651ecfa4ebcf8.png" alt="MSR：播客实习生见解" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">实习生见解：Madeleine Daepp 博士、Jennifer Scurrell 和 Alejandro Cuevas</h2><p class="large">在本集中，博士生<a href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcss.ethz.ch%2Fen%2Fcenter%2Fpeople%2Fjennifer-victoria-scurrell.html&data=05%7C01%7Cv-amelfi%40microsoft.com%7Cdeb2b53d3b8d4c3a3ccf08dbbdec0d9e%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638312593774254107%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=s8N98lzOV4kJIp2nzGFTx74SU%2BZQCxgXvyXGoIxk6S0%3D&reserved=0" target="_blank" rel="noreferrer noopener">Jennifer Scurrell</a>和<a href="https://www.alejandrocuevas.me/" target="_blank" rel="noreferrer noopener">Alejandro Cuevas</a>与高级研究员<a href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fpeople%2Fmdaepp%2F&data=05%7C01%7Cv-amelfi%40microsoft.com%7Cdeb2b53d3b8d4c3a3ccf08dbbdec0d9e%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638312593774410340%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=PRbEab7C9R6Lv%2BwVQqz2Md1rE4WVmcPirGHNq9aqzYQ%3D&reserved=0" target="_blank" rel="noreferrer noopener">Madeleine Daepp 博士</a>进行了交谈。他们讨论了微软研究院的实习文化，从与研究人员联系的机会到他们所说的帮助他们取得成功的团队合作，以及他们希望对工作产生的影响。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-madeleine-daepp-with-jennifer-scurrell-and-alejandro-cuevas/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-21d8108ee594aad478409a8aa618b2ee" id="new-research-1">新研究</h3><h2 class="wp-block-heading" id="insightpilot-an-llm-empowered-automated-data-exploration-system"> InsightPilot：法学硕士授权的自动化数据探索系统</h2><p>有效的数据探索需要深入了解数据集和用户意图，以及数据分析技术的专业知识。对任何一个都不熟悉都会造成障碍，使整个过程变得耗时且难以承受。</p><p>在最近的一篇论文<a href="https://www.microsoft.com/en-us/research/publication/insightpilot-an-llm-empowered-automated-data-exploration-system/" target="_blank" rel="noreferrer noopener">《InsightPilot：法学硕士授权的自动化数据探索系统》中，</a>微软的研究人员解决了这个问题。 InsightPilot 是一个基于大型语言模型 (LLM) 的自动化系统，旨在简化数据探索过程。它具有一组精心设计的分析操作，可简化数据探索过程。给定一个自然语言问题，InsightPilot 与法学硕士合作发出一系列分析操作、探索数据并生成见解。作者在用户研究和案例研究中展示了 InsightPilot 的有效性，展示了它如何帮助用户从数据集中获得有价值的见解。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/insightpilot-an-llm-empowered-automated-data-exploration-system/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-12d24ec3c423365af157b03da27206ad" id="blog-post">博客文章</h3><h2 class="wp-block-heading" id="boosting-cloud-efficiency-harnessing-data-driven-decision-making-and-optimization-techniques">提高云效率：利用数据驱动的决策和优化技术</h2><p>Microsoft 的云系统是数十万组织日常运营的支柱，可提高生产力和协作。基础设施要求高<em>可靠性</em>和<em>高效率</em>。在一篇新的<a href="https://www.microsoft.com/en-us/research/group/systems-innovation/articles/boosting-cloud-efficiency-harnessing-data-driven-decision-making-and-optimization-techniques/">博客文章</a>中，微软的系统创新团队探讨了一些最新的创新，以不断提高超大规模云容量效率，为客户节省大量运营成本。</p><p> <a href="https://www.microsoft.com/en-us/research/group/systems-innovation/" target="_blank" rel="noreferrer noopener">系统创新</a>是 Microsoft 365、Microsoft Research 和 Azure 之间的合作。该研究小组致力于利用他们共同的深入的工作负载理解，并将算法研究与人工智能/机器学习技术和硬件创新相结合，以提高运营可靠性和效率。</p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/group/systems-innovation/articles/boosting-cloud-efficiency-harnessing-data-driven-decision-making-and-optimization-techniques/">阅读博客</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-204f3500ef0b32d03ecf52013a43473b" id="community-challenge">社区挑战</h3><h2 class="wp-block-heading" id="neurips-large-language-model-efficiency-challenge">NeurIPS 大型语言模型效率挑战</h2><p>在大量文本上训练的大型语言模型 (LLM) 可以用很少的监督示例来解决任务。这些少量模型在自然语言处理 (NLP) 任务、语言翻译、标准化考试和编码挑战以及聊天机器人等主观领域中表现出了最先进的成功。所有这些领域都涉及引导一个称为基础模型的单一法学硕士，其中包含来自相关任务的特定知识的示例。</p><p>使用有限的特定领域数据更新模型的过程称为微调。然而，访问、微调和查询基础模型以执行新任务的成本可能很大。</p><p>为了帮助实现语言模型的民主化，微软和其他行业领导者很高兴赞助<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://llm-efficiency-challenge.github.io/index" target="_blank" rel="noreferrer noopener">NeurIPS 大型语言模型效率挑战赛<span class="sr-only">（在新选项卡中打开）</span></a> ，该挑战赛解决了三个主要问题：</p><ol><li>模型训练方法缺乏透明度导致大多数模型不可重现。</li><li>缺乏标准基准来并行评估这些模型。</li><li>对专用硬件的访问不足会阻碍这些模型的广泛可用性和使用。</li></ol><p>社区面临的挑战是，通过在 24 小时（1 天）时间范围内对 4090 或 A100 (40GB) 的单个 GPU 进行微调，使基础模型适应特定任务，同时保持这些所需任务的高精度。任务。</p><p>每个提交的内容都在商品硬件规模上进行了准确性和计算性能权衡的评估。见解和经验教训被提炼成一组记录良好的步骤和易于遵循的教程。机器学习社区将提供有关如何实现与获奖作品相同性能的文档，这将作为帮助他们构建自己的法学硕士解决方案的起点。</p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://llm-efficiency-challenge.github.io/leaderboard" target="_blank" rel="noreferrer noopener">查看获奖者</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-18-2023/">《研究焦点：2023 年 12 月 18 日一周》一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>前沿指导：扩大提示的力量</title><link/>https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 12 Dec 2023 14:40:31 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=991758 </guid><description><![CDATA[<p>我们看到前沿基础模型令人兴奋的功能，包括跨众多知识和专业领域的抽象、泛化和组合的有趣能力。即使是经验丰富的人工智能研究人员也对通过简单的零样本提示来引导模型的能力印象深刻。除了基本的、开箱即用的提示之外，我们一直在探索新的提示策略，并在我们的 Medprompt 工作中展示，以 [...]</p><p> <a href="https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/">前沿引导：扩展提示的力量一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1.jpg" alt="蓝色、紫色和粉色渐变背景上的三个对话气泡" class="wp-image-991947" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>我们看到前沿基础模型令人兴奋的功能，包括跨众多知识和专业领域的抽象、泛化和组合的有趣能力。即使是经验丰富的人工智能研究人员也对通过简单的零样本提示来引导模型的能力印象深刻。除了基本的、开箱即用的提示之外，我们一直在探索新的提示策略（在我们的<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">Medprompt</a>工作中展示），以激发专家的力量。</p><p>今天，我们在<em><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/promptbase" target="_blank" rel="noreferrer noopener">Promptbase <span class="sr-only">（在新选项卡中打开）（</span></a></em> GitHub 上的资源集合）中分享有关 Medprompt 和其他引导前沿模型的方法的信息。我们的目标是为工程师和客户提供信息和工具，以激发基础模型的最佳性能。我们将首先包含一些脚本，这些脚本可以使用我们在此介绍的提示策略来复制我们的结果。我们将在未来几周内添加更复杂的通用工具和信息。</p><p>为了说明前沿模型的功能以及通过指导 GPT-4 来利用和扩展最近的努力以达到最先进 (SoTA) 结果的机会，我们将根据 Google 选择的基准审查 SoTA 结果用于评估 Gemini Ultra。我们的端到端探索、快速设计和性能计算只花了几天时间。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="979233"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/" aria-label="Abstracts: October 9, 2023" data-bi-cN="Abstracts: October 9, 2023" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode1_Abstracts_Hero_Feature_No_Text_1400x788.png" alt="微软研究院播客 - 摘要" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">摘要：2023 年 10 月 9 日</h2><p class="large">研究员张盛博士加入“摘要”（您的前沿研究简述来源），讨论最近一篇关于将大型语言模型提炼成更小、更高效、能够在广泛应用类别中表现出色的论文。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Abstracts: October 9, 2023" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>让我们重点关注著名的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2009.03300" target="_blank" rel="noreferrer noopener">MMLU <span class="sr-only">（在新选项卡中打开）</span></a> （测量大规模多任务语言理解）挑战，该挑战是为了测试大型语言模型的常识和推理能力而设立的。完整的 MMLU 基准包含数以万计的不同形式的挑战问题，涉及从基础数学到美国历史、法律、计算机科学、工程、医学等 57 个领域。</p><p>在我们的<a href="https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/">Medprompt 研究</a>中，我们专注于医疗挑战问题，但发现即时策略可以具有更通用的应用，并在几个域外基准上检查其性能——尽管其工作根源在于医疗挑战。今天，我们报告使用 Medprompt 的修改版本引导 GPT-4 取得<em>了完整 MMLU 上有史以来的最高分。</em> </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1215" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt.jpg" alt="该图显示了 MMLU 基准上基线多个模型和方法的报告性能。从左到右，Palm 2-L（5 次）实现了 78.4% 的准确率，Claude 2（5 次 CoT）实现了 78.5% 的准确度，Inflection-2（5 次）实现了 79.6% 的准确度，Google Pro（CoT） @8) 实现了 79.13% 的准确度，Gemini Ultra (CoT@32) 实现了 90.04% 的准确度，GPT-4-1106 (5-Shot) 实现了 86.4% 的准确度，GPT-4-1106 (Medprompt @ 5) 实现了 89.1% 的准确度， GPT-4-1106 (Medprompt @ 20) 的准确率达到 89.56%，GPT-4-1106 (Medprompt @ 31) 的准确率达到 90.10%。" class="wp-image-991926" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt.jpg 1215w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-300x142.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-1024x485.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-768x364.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-240x114.jpg 240w" sizes="(max-width: 1215px) 100vw, 1215px" /><figcaption class="wp-element-caption">图1。报告了多种模型和方法在 MMLU 基准上的性能。</figcaption></figure><p>在我们的探索中，我们初步发现将原始的 Medprompt 应用到 GPT-4 在综合 MMLU 上取得了 89.1% 的分数。通过将 Medprompt 中的集成调用数量从 5 个增加到 20 个，GPT-4 在 MMLU 上的性能进一步提高到 89.56%。为了在 MMLU 上实现新的 SoTA，我们将 Medprompt 扩展为 Medprompt+，添加了更简单的提示方法，并制定了一个策略，通过集成基本 Medprompt 策略和简单提示的输出来得出最终答案。最终答案的合成由 GPT-4 控制的控制策略和候选答案的推断置信度指导。 Promptbase 存储库中提供了有关 Medprompt+ 的更多详细信息。 Google Gemini 团队利用了一种耦合复杂和简单查询的相关方法。使用修改后的 Medprompt+ 引导的 GPT-4 达到了 90.10% 的创纪录分数。我们注意到 Medprompt+ 依赖于从 GPT-4 获取置信度分数 (logprobs)。这些功能尚未通过当前 API 公开提供，但将在不久的将来向所有人开放。</p><p>虽然系统的提示工程可以产生最大的性能，但我们继续探索具有简单提示的前沿模型的开箱即用性能。重要的是要密切关注 GPT-4 的原生功能以及我们如何通过零或几次提示策略来引导模型。如表 1 所示，从简单的提示开始有助于在采用更复杂和更昂贵的方法之前建立基准性能。</p><figure class="wp-block-table"><table><thead><tr><th>基准</th><th>GPT-4 提示</th><th>GPT-4 结果</th><th>双子座超结果</th></tr></thead><tbody><tr><td>MMLU</td><td>医疗提示+</td><td> <strong>90.10%</strong></td><td> 90.04%</td></tr><tr><td> GSM8K</td><td>零射击</td><td><strong>95.27%</strong></td><td> 94.4%</td></tr><tr><td>数学</td><td>零射击</td><td><strong>68.42%</strong></td><td> 53.2%</td></tr><tr><td>人类评估</td><td>零射击</td><td><strong>87.8</strong> %</td><td> 74.4%</td></tr><tr><td>大板凳硬</td><td>少量射击 + CoT*</td><td> <strong>89.0%</strong></td><td> 83.6%</td></tr><tr><td>降低</td><td>零射击+CoT</td><td> <strong>83.7%</strong></td><td> 82.4%</td></tr><tr><td>海拉斯瓦格</td><td>10 发**</td><td> <strong>95.3%**</strong></td><td> 87.8%</td></tr></tbody></table><figcaption class="wp-element-caption"><center> <sup>* 遵循评估规范并使用数据集创建者提供的标准少数样本示例<br>** 来源：谷歌</sup><br>表 1：模型、策略和结果</center></figcaption></figure><p>我们鼓励您查看 GitHub 上的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/promptbase" target="_blank" rel="noreferrer noopener">promptbase 存储库<span class="sr-only">（在新选项卡中打开），</span></a>了解有关提示技术和工具的更多详细信息。这一工作领域正在不断发展，有很多值得学习和分享的地方。我们对未来的方向和可能性感到兴奋。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/">前沿引导：扩展提示的力量一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>