<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 6 月 18 日星期二 18:46:36 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.3</generator><item><title> MicroCode：BBC micro:bit 的便携式编程</title><link/>https://www.microsoft.com/en-us/research/blog/microcode-portable-programming-for-the-bbc-microbit/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 18 Jun 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1044072 </guid><description><![CDATA[<p> MicroCode 提供了一种经济实惠的方式来对 BBC micro:bit 进行编程，无需连接互联网，从而促进探索性学习。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/microcode-portable-programming-for-the-bbc-microbit/">《MicroCode：BBC micro:bit 的便携式编程》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-center">这篇研究论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://idc.acm.org/2024/" target="_blank" rel="noreferrer noopener"><strong><em>第 23 届年度 ACM 交互设计和儿童会议</em></strong><span class="sr-only">（在新选项卡中打开）</span></a> (IDC 2024)<strong><em>上发表，该</em></strong><strong><em>会议是以儿童为中心的包容性设计和学习的首要论坛。</em></strong> </p><figure class="wp-block-image aligncenter size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1.png" alt=""ACM Interaction Design and Children Conference" in white to the left of the front page of the publication "Meet MicroCode: a Live and Portable Programming Tool for the BBC micro:bit" on a purple background" class="wp-image-1048434" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/ACM_IDC24-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p> 2016 年至 2018 年间，微软研究院和开发人员部门开发了<a href="https://www.microsoft.com/en-us/makecode">Microsoft MakeCode</a> ，这是一个多功能、免费的基于 Web 的平台，旨在教授编码。虽然 MakeCode 支持各种设备，但一个值得注意的应用是 BBC micro:bit，这是一款紧凑、功能丰富的计算机，主要为 11 至 14 岁的学生设计。尽管该平台取得了成功，但目前已在 60 多个国家/地区使用，其中有 10 多个国家/地区使用该平台。万微：比特，它面临着挑战，例如需要持续的互联网连接和访问计算机，这可能会限制非课堂环境，并由于竞争的在线内容而分散注意力。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="624" height="252" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/micro-bit.png" alt="BBC micro:bit（版本 2），正面和背面。" class="wp-image-1044138" style="width:624px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/micro-bit.png 624w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/micro-bit-300x121.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/micro-bit-240x97.png 240w" sizes="(max-width: 624px) 100vw, 624px" /><figcaption class="wp-element-caption">图 1. micro:bit V2 的大小只有信用卡的一半。 micro:bit 的正面在左侧，背面在右侧。 micro:bit 具有按钮、传感器、LED、麦克风、扬声器、无线电天线，并由电池供电。在底部，micro:bit 的连接器允许将其插入提供附加功能的各种设备（<em>屏蔽</em>）中。 </figcaption></figure><h2 class="wp-block-heading" id="microcode-mobility-focused-visual-programming"> MicroCode：以移动性为中心的可视化编程</h2><p>我们在 IDC 2024 上发表的论文“<a href="https://www.microsoft.com/en-us/research/publication/meet-microcode-idc2024/">认识 MicroCode：适用于 BBC micro:bit 的实时便携式编程工具</a>”通过 MicroCode 解决了这些问题，MicroCode 是一种<em>便携式编程</em>方法，可以在任何地方对 micro:bit 进行编程 - 无论是在教室、户外或公共汽车上，无需单独的联网计算机。 MicroCode 系统利用两项技术进步来实现便携式编程：</p><ul><li> <strong>micro:bit V2</strong> ：micro:bit V2 具有 128 KB RAM 和比其前身更快的处理器，使其能够支持小型外部彩色屏幕。</li><li> <strong>Arcade Shield</strong> ：这是一种低成本、电池供电的手持设备，可以插入 micro:bit V2。它提供彩色屏幕和输入，支持实时和便携式编程。图 2 中所示的扩展板是 micro:bit V2 的三种市售 Arcade 扩展板之一。 </li></ul><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="744" height="591" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure2.png" alt="BBC micro:bit 插入 Arcade 护罩中，该护罩有一个小型彩色屏幕和额外的输入。" class="wp-image-1044108" style="width:484px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure2.png 744w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure2-300x238.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure2-227x180.png 227w" sizes="(max-width: 744px) 100vw, 744px" /><figcaption class="wp-element-caption">图 2. micro:bit V2（顶部）插入 Game Bit（一种商用 Arcade 扩展板），可显示 MicroCode 程序。街机盾牌提供小型彩色屏幕和额外功能，使用户能够获得更广泛的体验。该扩展板没有用户可编程处理器——micro:bit 提供了此功能。</figcaption></figure><p>研究表明，新手采用新编程工具的意愿通常取决于这些工具的简单程度、熟悉程度和可理解程度。这促使我们决定为幼儿和初学者使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.kodugamelab.com/" target="_blank" rel="noreferrer noopener">Kodu <span class="sr-only">（在新选项卡中打开）</span></a>可视化编程模型。我们专门为 micro:bit V2 创建了迷你版 Kodu 编辑器，使用户能够充分利用设备的硬件功能来创建简单的程序。</p><p>完整的系统（编辑器、用户程序、编译器和运行时）集成到 micro:bit V2 的永久存储器中。这使得程序即使在设备断开连接时也能继续运行，并在重新连接后再次编辑，从而加快了开发过程并使可移植性成为现实。用户友好的界面支持基于光标的编辑，用于创建和修改 Kodu 的“何时执行”规则以及编辑 5×5 图像，如图 3 所示。盾牌的方向键和按钮可实现流畅的导航和选择。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="288" height="203" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure3.png" alt="一个微代码程序，用于根据用户输入显示快乐/悲伤的面孔。" class="wp-image-1044111" style="width:392px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure3.png 288w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/MicroCode_Figure3-240x169.png 240w" sizes="(max-width: 288px) 100vw, 288px" /><figcaption class="wp-element-caption">图 3. MicroCode 程序（快乐/悲伤）由四个规则组成：前两个规则通过按 micro:bit 的 A 按钮激活。后两个可通过按 B 按钮激活。</figcaption></figure><h2 class="wp-block-heading" id="evaluation-and-findings">评估和结果</h2><p>为了评估微代码的影响，兰卡斯特大学的教育研究人员对三所英国学校进行了一项研究。我们<a href="https://www.microsoft.com/en-us/research/publication/meet-microcode-idc2024/" target="_blank" rel="noreferrer noopener">论文</a>中报道的研究结果表明，MicroCode 有效支持小学阶段基于 micro:bit 的学习，吸引儿童并赋予他们一种能动性。通过简化实时更新程序的过程，MicroCode 扩展了学习环境，包括户外数据收集等活动。此外，这种创新工具激发了教师探索将物理计算整合到更广泛的课程中，超越计算教育的传统界限。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044954"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/whats-your-story-jacki-oneill/" aria-label="What’s Your Story: Jacki O’Neill" data-bi-cN="What’s Your Story: Jacki O’Neill" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_TW_LI_FB_1200x627.png" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">你的故事是什么：杰基·奥尼尔</h2><p class="large">杰基·奥尼尔 (Jacki O&#39;Neill) 看到了将微软研究工作扩展到非洲的机会。她现在领导位于内罗毕的微软非洲研究院（原 MARI）。奥尼尔谈到了她的选择、实验室的影响以及国外生活如何有利于创新。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/whats-your-story-jacki-oneill/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="What’s Your Story: Jacki O’Neill" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="implications-and-looking-forward"> 影响和展望</h2><p>MicroCode 改变了 micro:bit 的编程环境，提供了可移植性并能够改善课堂体验。 MicroCode 与<a href="https://www.microsoft.com/en-us/research/project/jacdac-connect-and-code-electronics/" target="_blank" rel="noreferrer noopener">Jacdac 即插即用系统</a>兼容，通过易于连接的外围设备（如传感器和执行器）扩展其功能。这种集成扩展了 micro:bit 的功能，使其能够检测环境变化并控制各种设备。此外，MicroCode 现在可以通过 micro:bit 的无线电协议远程操作一系列机器人配件。</p><p>我们与学术和行业合作伙伴的合作才刚刚开始，我们渴望探索该工具的全部潜力。例如，我们目前正在测试新的 MicroCode 背包套件，以方便在传统环境之外进行学习。我们的目标是让教育工作者能够将便携式编程方法扩展到课堂之外。</p><p>展望未来，我们设想 MicroCode 成为学校的基石，提供适用于多个学科的可扩展创意计算平台。 MicroData 是一个令人兴奋的发展，这是兰卡斯特大学的一名学生首创的新应用程序。 MicroData 源自 MicroCode，专注于数据科学，使学生能够收集和分析环境数据或实时评估化学反应的影响。这项创新凸显了该平台的多功能性以及促进快速实验和交互式学习体验的潜力。</p><p> MicroCode 可在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/microcode" target="_blank" rel="noreferrer noopener">GitHub <span class="sr-only">（在新选项卡中打开）</span></a>上使用，并使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arcade.makecode.com/" target="_blank" rel="noreferrer noopener">Microsoft MakeCode Arcade <span class="sr-only">（在新选项卡中打开）</span></a>构建。没有防护罩的用户也可以使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/microcode/" target="_blank" rel="noreferrer noopener">网络应用程序<span class="sr-only">（在新选项卡中打开）</span></a>版本。</p><h3 class="wp-block-heading" id="acknowledgements">致谢</h3><p>我们要感谢 Micro:bit 教育基金会、Microsoft MakeCode 团队以及兰卡斯特大学的同事对这项工作的支持和贡献。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/microcode-portable-programming-for-the-bbc-microbit/">《MicroCode：BBC micro:bit 的便携式编程》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>微软在 CVPR 2024：计算机视觉和人工智能研究的创新</title><link/>https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2024-innovations-in-computer-vision-and-ai-research/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Mon, 17 Jun 2024 16:30:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1045767 </guid><description><![CDATA[<p> Microsoft 很荣幸能够赞助于 6 月 17 日至 21 日举行的第 41 届计算机视觉和模式识别年度会议 (CVPR 2024)。这次重要会议涵盖了该领域的广泛主题，包括 3D 重建和建模、动作和运动分析、视频和图像处理、合成数据生成、神经网络和[...]</p><p> <a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2024-innovations-in-computer-vision-and-ai-research/">微软在 CVPR 2024 上的帖子：计算机视觉和人工智能研究的创新</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="2917" height="1642" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788.png" alt="绿色和紫色抽象背景上的 CVPR 2024 徽标" class="wp-image-1046742" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788.png 2917w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-1536x865.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-2048x1153.png 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/CVPR_Blog_1400x788-1920x1080.png 1920w" sizes="(max-width: 2917px) 100vw, 2917px" /></figure><p> Microsoft 很荣幸能够赞助于 6 月 17 日至 21 日举行的第 41 届<a href="https://www.microsoft.com/en-us/research/event/cvpr-2024/overview/" target="_blank" rel="noreferrer noopener">计算机视觉和模式识别年度会议</a>(CVPR 2024)。这次重要会议涵盖了该领域的广泛主题，包括 3D 重建和建模、动作和运动分析、视频和图像处理、合成数据生成、神经网络等等。今年，微软有 63 篇论文被接受，其中 6 篇论文被选为口头报告。这篇文章重点介绍了这些贡献。</p><p>这些研究项目的多样性反映了 Microsoft 研究团队采取的跨学科方法，从精确重建 3D 人物形象和增强现实 (AR) 视角的技术到将高级图像分割与合成数据相结合以更好地复制现实世界场景。其他项目展示了研究人员如何将机器学习与自然语言处理和结构化数据相结合，开发不仅可以可视化而且可以与环境交互的模型。总的来说，这些项目旨在改善机器感知，并实现与世界更准确、响应更灵敏的交互。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1045002"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：活动</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/event/cvpr-2024/" aria-label="Microsoft at CVPR 2024" data-bi-cN="Microsoft at CVPR 2024" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CVPR_WebBanner_1920x720.png" alt="青色背景三角形图案" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软在 CVPR 2024</h2><p class="large"> Microsoft 是<a href="https://cvpr2023.thecvf.com/Conferences/2024" target="_blank" rel="noreferrer noopener">CVPR 2024</a>的赞助商和积极参与者，该会议重点关注计算机视觉和模式识别领域的进步。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/event/cvpr-2024/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Learn more" data-bi-cN="Microsoft at CVPR 2024" target="_blank">了解更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="oral-presentations">口头报告</h2><h3 class="wp-block-heading h5" id="bioclip-a-vision-foundation-model-for-the-tree-of-life"><a href="https://www.microsoft.com/en-us/research/publication/bioclip-a-vision-foundation-model-for-the-tree-of-life/">BIOCLIP：生命之树的视觉基础模型</a></h3><p><em>塞缪尔·史蒂文斯、吴嘉曼、马修·J·汤普森、伊丽莎白·G·坎波隆戈、宋陈熙、大卫·卡林、李东</em><a href="https://www.microsoft.com/en-us/research/people/lidong1/"><em>、</em></a> <em>W. Dahdul、查尔斯·斯图尔特、Tanya Y. Berger-Wolf、赵伟伦、苏宇</em></p><p>从无人机到智能手机等不同来源捕获的图像数量激增，提供了丰富的生物数据源。为了利用这一潜力，我们引入了 TreeOfLife-10M（最大、最多样化的 ML 就绪生物图像数据集）和 BioCLIP（用于生物科学的基础模型）。 BioCLIP 利用 TreeOfLife-10M 的大量生物体图像和结构化知识，在细粒度生物分类方面表现出色，大幅优于现有模型，并表现出强大的通用性。</p><h3 class="wp-block-heading h5" id="egogen-an-egocentric-synthetic-data-generator"> <a href="https://www.microsoft.com/en-us/research/publication/egogen-an-egocentric-synthetic-data-generator/">EgoGen：以自我为中心的综合数据生成器</a></h3><p><em>李根、赵凯峰、张思伟、吕晓忠、</em> <a href="https://www.microsoft.com/en-us/research/people/mihaidusmanu/"><em>Mihai Dusmanu</em></a> <em>、张岩、</em> <a href="https://www.microsoft.com/en-us/research/people/mapoll/"><em>Marc Pollefeys</em></a></p><p>增强现实 (AR) 的一个关键挑战是模拟真实的解剖运动，以引导摄像机拍摄真实的以自我为中心的视图。为了克服这个问题，作者开发了 EgoGen，这是一种复杂的合成数据生成器，它不仅提高了以自我为中心的任务的训练数据准确性，而且还改进了运动和感知的集成。它为创建现实的以自我为中心的训练数据提供了一个实用的解决方案，其目标是成为以自我为中心的计算机视觉研究的有用工具。 </p><h3 class="wp-block-heading h5" id="florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks"> <a href="https://www.microsoft.com/en-us/research/publication/florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2：推进各种视觉任务的统一表示</a></h3><p><a href="https://www.microsoft.com/en-us/research/people/bixi/"><em>肖斌</em></a><em>、吴海平、徐伟建</em>、<a href="https://www.microsoft.com/en-us/research/people/xidai/"><em>戴希阳</em></a><em>、胡厚东、陆玉茂、</em><a href="https://www.microsoft.com/en-us/research/people/nzeng/"><em>曾敏</em></a><em>、刘策、</em><a href="https://www.microsoft.com/en-us/research/people/luyuan/"><em>袁璐</em></a></p><p>Florence-2 引入了一个统一的、基于提示的视觉基础模型，能够处理从字幕到对象检测和分割等各种任务。 Florence-2 旨在将文本提示解释为任务指令，可生成一系列视觉和视觉语言任务的文本输出。该模型的训练利用 FLD-5B 数据集，其中包括 1.26 亿张图像的 54 亿个注释，使用自动图像注释和持续模型细化的迭代策略开发。</p><h3 class="wp-block-heading h5" id="lisa-reasoning-segmentation-via-large-language-model"> <a href="https://www.microsoft.com/en-us/research/publication/lisa-reasoning-segmentation-via-large-language-model/">LISA：通过大语言模型进行推理分割</a></h3><p><em>赖鑫、田卓涛、陈宇康、李彦伟、</em><a href="https://www.microsoft.com/en-us/research/people/yuyua/"><em>袁宇辉</em></a><em>、刘书、贾佳雅</em></p><p>这项工作引入了<em>推理分割</em>，这是一种使用复杂查询文本生成分割掩码的新分割任务。作者还建立了一个新的基准，包括一千多个图像指令掩模数据样本，结合复杂的推理和世界知识进行评估。最后，作者提出了大型语言指导分割助手（LISA），这是一种将大型语言模型的语言功能与生成分割掩码的能力相结合的工具。 LISA 有效地处理复杂的查询，并显示出强大的零样本学习能力，并通过最小的微调进一步增强。 </p><h3 class="wp-block-heading h5" id="multiply-reconstruction-of-multiple-people-from-monocular-video-in-the-wild"> <a href="https://www.microsoft.com/en-us/research/publication/multiply-reconstruction-of-multiple-people-from-monocular-video-in-the-wild/">MultiPly：从野外单目视频重建多人</a></h3><p><em>江泽仁、陈果、Manuel Kaufmann、江天健、</em> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/in/julien-valentin/" target="_blank" rel="noreferrer noopener"><em>Julien Valentin</em> <span class="sr-only">（在新选项卡中打开）</span></a> <em>、Otmar Hilliges、宋杰</em></p><p>MultiPly 是一个新框架，用于在自然环境中从单摄像头视频中重建多个 3D 人物。该技术对整个场景采用分层神经表示，并通过分层可微体积渲染进行细化。通过结合自监督 3D 和提示 2D 技术的混合实例分割进行增强，即使在密切交互的情况下，它也能提供可靠的分割。该过程使用置信引导优化来交替细化人体姿势和形状，从而实现高保真、一致的 3D 模型。 </p><h3 class="wp-block-heading h5" id="scenefun3d-fine-grained-functionality-and-affordance-understanding-in-3d-scenes"> <a href="https://www.microsoft.com/en-us/research/publication/scenefun3d-fine-grained-functionality-and-affordance-understanding-in-3d-scenes/">SceneFun3D：3D 场景中的细粒度功能和可供性理解</a></h3><p><em>亚历山德罗斯·德利察斯、艾萨·塔克马兹、费德里科·托姆巴里、罗伯特·萨姆纳、</em><a href="https://www.microsoft.com/en-us/research/people/mapoll/"><em>马克·波勒菲斯</em></a><em>、弗朗西斯·恩格尔曼</em></p><p>传统的 3D 场景理解方法主要关注 3D 语义和实例分割，但真正的挑战在于与手柄、旋钮和按钮等功能交互元素进行交互以实现特定任务。输入 SceneFun3D：一个强大的数据集，包含 710 个高分辨率真实 3D 室内场景中的 14,800 多个精确交互注释。该数据集通过运动参数和特定于任务的自然语言描述丰富了场景理解，促进了功能分割、任务驱动的可供性基础和 3D 运动估计方面的高级研究。</p><p>在我们的会议<a href="https://www.microsoft.com/en-us/research/event/cvpr-2024/overview/">网页</a>上了解有关我们的工作和对 CVPR 2024 的贡献的更多信息，包括我们的<a href="https://www.microsoft.com/en-us/research/event/cvpr-2024/publications/">出版物</a>和<a href="https://www.microsoft.com/en-us/research/event/cvpr-2024/sessions/">会议</a>的完整列表。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2024-innovations-in-computer-vision-and-ai-research/">微软在 CVPR 2024 上的帖子：计算机视觉和人工智能研究的创新</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>