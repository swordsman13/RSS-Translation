<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 7 月 29 日星期一 17:11:01 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.5</generator><item><title>追踪自适应人工智能代理的路径</title><link/>https://www.microsoft.com/en-us/research/blog/tracing-the-path-to-self-adapting-ai-agents/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Thu, 25 Jul 2024 19:04:25 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/tracing-the-path-to-self-adapting-ai-agents/ </guid><description><![CDATA[<p>隆重推出 Trace，这是 Microsoft 和斯坦福大学的新颖 AI 优化框架，现已作为 Python 库提供。 Trace 动态适应并优化从语言模型到机器人控制的广泛应用。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/tracing-the-path-to-self-adapting-ai-agents/">《追踪自适应 AI 代理之路》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1.jpg" alt="蓝色和绿色渐变背景上的白线图标" class="wp-image-1060101" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/Trace-2024-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>游戏行业长期以来一直是人工智能创新的前沿。在 2000 年代初，程序员手工编写神经网络，为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://galciv3.fandom.com/wiki/History_of_the_Galactic_Civilizations_franchise" target="_blank" rel="noreferrer noopener">虚拟世界注入生命<span class="sr-only">（在新选项卡中打开）</span></a> ，创建与玩家互动的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.alanzucconi.com/2020/07/27/the-ai-of-creatures/" target="_blank" rel="noreferrer noopener">引人入胜的 AI 角色<span class="sr-only">（在新选项卡中打开）</span></a> 。快进二十年，神经网络已经从不起眼的开始发展成为拥有数十亿参数的庞大架构，为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2303.08774" target="_blank" rel="noreferrer noopener">ChatGPT 等现实世界的应用程序提供支持<span class="sr-only">（在新选项卡中打开）</span></a><strong> </strong>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.bing.com/chat?q=Microsoft+Copilot&FORM=hpcodx" target="_blank" rel="noreferrer noopener">Microsoft Copilots <span class="sr-only">（在新选项卡中打开）</span></a> 。人工智能规模和能力发生巨大变化的催化剂是自动优化的出现。 AutoDiff 框架，例如<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noreferrer noopener">PyTorch <span class="sr-only">（在新选项卡中打开）</span></a><strong> </strong>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.tensorflow.org/" target="_blank" rel="noreferrer noopener">Tensorflow <span class="sr-only">（在新选项卡中打开）</span></a><strong> </strong>使基于梯度的可扩展端到端优化民主化。这一突破对于大型基础模型 (LFM) 的开发发挥了重要作用，该模型现在是人工智能的核心。</p><p>如今，我们与之交互的人工智能系统不仅仅是神经网络模型。它们包含复杂的工作流程，无缝集成定制的机器学习模型、编排代码、检索模块以及各种工具和功能。这些组件协同工作，创造出复杂的人工智能体验，这些体验已成为我们数字生活不可或缺的一部分。尽管如此，到目前为止，我们还没有工具来自动训练这些额外的组件。它们是通过广泛的工程手工制作的，就像 2000 年代初神经网络的设计方式一样。</p><h2 class="wp-block-heading" id="end-to-end-automatic-optimization-of-ai-systems-1"> AI系统端到端自动优化</h2><p>微软和斯坦福大学的最新研究推出了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/Trace/" target="_blank" rel="noreferrer noopener">Trace <span class="sr-only">（在新选项卡中打开）</span></a> ，这是一个突破性的框架，有望彻底改变人工智能系统的自动优化。以下是 Trace 变革潜力的三个亮点：</p><ul><li><em>端到端优化</em>：Trace 将人工智能系统视为类似于神经网络的计算图，并通过广义反向传播方法对其进行端到端优化。</li><li><em>动态适应</em>：它处理人工智能系统的动态特性，其中图形可以随着输入和参数的变化而变化，并且需要适应各种反馈。</li><li><em>多功能应用</em>：Trace可以优化AI系统中的异构参数（例如提示和代码）。实证研究展示了 Trace 优化各种问题的能力，包括超参数调整、大语言模型 (LLM) 代理和机器人控制，通常优于专门的优化器。</li></ul><p>简而言之，Trace 是一种类似于 AutoDiff 的新工具，用于在不使用梯度的情况下训练 AI 系统。这种泛化是通过一种新的优化数学公式“Optimization with Trace Oracle (OPTO)”实现的，它可以通过一般反馈（例如数值损失、自然语言和错误）来描述人工智能系统的端到端优化。 Trace 不是传播梯度（对于神经网络之外的人工智能系统来说没有明确定义），而是传播最小子图，然后可以在适用的情况下使用最小子图来恢复梯度。 Trace 被实现为类似 PyTorch 的 Python 库，用户可以使用它轻松创建人工智能系统并对其进行改进，类似于训练神经网络。</p><p>在这篇博文中，我们很高兴地宣布发布<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/Trace" target="_blank" rel="noreferrer noopener">Trace Python 库<span class="sr-only">（在新选项卡中打开）</span></a> 。在演示的帮助下，我们将向您展示如何使用这个强大的工具来构建人工智能代理，这些代理可以从经验中学习和适应，从而无需专门的工程。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044957"><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ideas-exploring-ai-frontiers-with-rafah-hosn/" aria-label="Ideas: Exploring AI frontiers with Rafah Hosn" data-bi-cN="Ideas: Exploring AI frontiers with Rafah Hosn" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Rafah-Hosn_IDEAS_TW_LI_FB_1200x627.png" alt="微软研究院播客：想法 - Rafah Hosn" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">想法：与 Rafah Hosn 一起探索人工智能前沿</h2><p class="large">在颠覆的推动下，合作伙伴组产品经理 Rafah Hosn 正在帮助 Microsoft 推动人工智能领域的科学进步。她谈论了在人工智能前沿工作所需的思维方式，以及 GenAI 时代从研究到产品的流程如何发生变化。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ideas-exploring-ai-frontiers-with-rafah-hosn/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Ideas: Exploring AI frontiers with Rafah Hosn" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="warm-up-building-a-battleship-game-ai-agent-through-learning">热身：通过学习构建战舰游戏 AI 代理</h2><p>首先，考虑为经典战舰棋盘游戏构建一个 AI 代理。在《战舰》中，玩家需要制定策略，尽快巧妙地定位并攻击隐藏棋盘上的对手战舰。要使用 Trace 构建人工智能代理，只需对工作流程进行编程并声明参数，就像对神经网络架构进行编程一样。在这里，我们将设计一个具有两个组件的代理：<strong>推理</strong>函数和<strong>行为</strong>函数，如图 1a 所示。我们以文档字符串的形式提供了这两个函数应执行的操作的基本描述。我们将函数的内容留空并将它们设置为可训练。此时，代理不知道 Battleship API 是如何工作的。它不仅要学会如何玩游戏，还要学会如何使用未知的API。 </p><div class="wp-block-columns are-vertically-aligned-center is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex"><div class="wp-block-column is-vertically-aligned-center is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1440" height="1464" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-a-TRACE.png" alt="代理的策略被定义为原因步骤和行动步骤的组合。这两个步骤的代码都被标记为可训练，并被初始化为简单函数。每个函数的行为的基本描述在函数定义中以文档字符串的形式提供。" class="wp-image-1059996" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-a-TRACE.png 1440w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-a-TRACE-295x300.png 295w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-a-TRACE-1007x1024.png 1007w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-a-TRACE-768x781.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-a-TRACE-177x180.png 177w" sizes="(max-width: 1440px) 100vw, 1440px" /><figcaption class="wp-element-caption">图 1a：编写可跟踪训练的策略。 </figcaption></figure></div><div class="wp-block-column is-vertically-aligned-center is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1440" height="1464" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-b-TRACE.png" alt="代理的策略通过一个简单但通用的训练循环进行优化，该循环模仿神经网络训练。首先声明代理的策略和迭代优化器。在每次迭代中，代理的策略将板配置作为输入并输出目标位置。环境返回有关目标是否成功击中船只的反馈。或者，当代理的策略触发任何执行错误时，该错误将用作反馈。然后反馈被传播到可训练策略中的参数以进行更新。" class="wp-image-1059999" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-b-TRACE.png 1440w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-b-TRACE-295x300.png 295w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-b-TRACE-1007x1024.png 1007w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-b-TRACE-768x781.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-1-b-TRACE-177x180.png 177w" sizes="(max-width: 1440px) 100vw, 1440px" /><figcaption class="wp-element-caption">图 1b：使用类似 PyTorch 的 API 进行优化。</figcaption></figure></div></div><p>我们迭代地训练这个 AI 代理，通过一个简单的 Python <em><u>for</u></em>循环来玩游戏，如图 1b 所示。在每次迭代中，代理（即策略）都会看到板配置并尝试射击训练板上的目标位置。无论成功还是失败，环境都会以文本形式返回。然后，我们运行 Trace，通过代理的决策逻辑传播此环境反馈，以更新参数（例如，策略就像具有<strong>原因</strong>层和<strong>行为</strong>层的两层网络）。这些迭代模仿了人类程序员处理问题的方式。他们运行策略并根据观察到的反馈更改代码，尝试不同的启发式方法来解决此问题，并且可能会重写代码几次以使用堆栈跟踪来修复任何执行错误。</p><p>在图 2 中，我们展示了该学习代理的结果，其中该代理由 Trace 中基于 LLM 的优化器<a href="https://www.microsoft.com/en-us/research/publication/trace-is-the-new-autodiff-unlocking-efficient-optimization-of-computational-workflows/">OptoPrime</a>进行训练。性能以智能体在新的随机生成的游戏（不同于训练板）上的得分来衡量。我们看到智能体理解了战舰游戏并在一次迭代后提出了枚举策略；然后，经过几次尝试，它开始制定复杂的游戏策略。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="2276" height="1094" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2.png" alt="实验结果表明，Trace 可以通过几次迭代快速学习战舰的复杂行为。在迭代 0 时，代理被初始化以输出常量坐标。在第 1 次迭代中，代理学习了枚举棋盘的简单策略。经过几次迭代（例如，迭代 7）后，代理学习了一种复杂的策略来平衡未探索的方块与先前命中的相邻方块。相比之下，最先进的 LLM 优化器 OPRO 在此问题上的性能仅为 Trace 的不到 1/3。" class="wp-image-1059918" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2.png 2276w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2-300x144.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2-1024x492.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2-768x369.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2-1536x738.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2-2048x984.png 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-2-240x115.png 240w" sizes="(max-width: 2276px) 100vw, 2276px" /><figcaption class="wp-element-caption">图 2：与最先进的基于 LLM 的优化器 OPRO 相比，Trace 优化了“代码即参数”，从头开始创建复杂的战舰 AI。 </figcaption></figure><h2 class="wp-block-heading" id="super-fast-reinforcement-learning-agent-for-robot-control">用于机器人控制的超快速强化学习代理</h2><p>我们可以扩展端到端优化的相同想法来训练更复杂的人工智能系统。在此示例中，我们想要学习控制机器人操纵器的策略代码。与战舰示例相比，这里的问题具有更长的视野，因为该策略需要在收到任何反馈之前驱动机器人多个时间步长。传统上，此类问题被视为强化学习 (RL) 问题，通常使用 RL 学习策略需要数万个训练集。我们展示了 Trace 可以用来有效地解决这样的问题，只需几十集——速度提高了 1,000 倍。我们跟踪整个事件并通过这些步骤执行端到端更新（使用相同的 OptoPrime 优化器）。通过这种方式，Trace 可以有效地随时间执行反向传播（ <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://en.wikipedia.org/wiki/Backpropagation_through_time" target="_blank" rel="noreferrer noopener">BPTT <span class="sr-only">（在新选项卡中打开）</span></a> ）。</p><p>我们在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/LLF-Bench/" target="_blank" rel="noreferrer noopener">LLF- <span class="sr-only">Bench</span></a> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://meta-world.github.io/" target="_blank" rel="noreferrer noopener"><span class="sr-only">（在新选项卡中打开）的Meta-World（在新选项卡中打开）</span></a>环境中使用模拟的Sawyer机器人手臂进行实验，如图3所示。代理需要确定机器人的目标姿势，然后，它将用作位置控制器的设定点，以执行拾取和放置任务。每个情节有 10 个时间步长，从而产生深度约为 30 的图表。智能体接收语言反馈作为中间观察（来自 LLF-Bench），最后在文本中接收有关成功和情节返回（即 RL 的累积奖励）的反馈。与战舰示例一样，我们将策略代码初始化为虚拟函数，并让它通过交互进行调整，如图 4 所示。我们从一个初始条件开始重复训练代理，然后在 10 个新的保留初始条件上对其进行测试概括。很快，经过 13 个回合，我们看到智能体学习了复杂的规则来解决问题，如图 3 和图 4 所示。 </p><div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex"><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="480" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-4-iter-0.gif" alt="该视频展示了机器人代理如何在训练期间未看到的新配置上执行操作。在迭代 0 时，机器人的策略被初始化以保持在其初始位置。" class="wp-image-1060080"/></figure></div><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="480" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-4-iter-1.gif" alt="该视频展示了机器人代理如何在训练期间未看到的新配置上执行操作。在第 1 次迭代中，机器人学会了到达目标，但没有抓住物体，这导致拾取和放置任务失败。" class="wp-image-1060083"/></figure></div><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="480" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-4-iter-3.gif" alt="该视频展示了机器人代理如何在训练期间未看到的新配置上执行操作。机器人从第 3 次迭代开始学习抓取物体，但未能成功地将物体正确放置并扔到目标处。尽管如此，在错误地放下物体后，机器人会尝试捡起物体并重试。此行为一直持续到迭代 12。" class="wp-image-1060086"/></figure></div><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="480" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-4-iter-9.gif" alt="该视频展示了机器人代理如何在训练期间未看到的新配置上执行操作。机器人从第 3 次迭代开始学习抓取物体，但未能成功地将物体正确放置并扔到目标处。尽管如此，在错误地放下物体后，机器人会尝试捡起物体并重试。此行为一直持续到迭代 12。" class="wp-image-1060089"/></figure></div><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="480" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-4-iter-13.gif" alt="该视频展示了机器人代理如何在训练期间未看到的新配置上执行操作。在第 13 次迭代中，机器人学习了一个通用策略来成功执行拾取和放置。" class="wp-image-1060092"/></figure></div></div><p class="has-text-align-center"><sup>图 3：Trace 在 MetaWorld 模拟环境中快速学习机器人控制器，并推广到新的初始条件。视频显示，Trace 在 13 集之后学会了成功执行拾取任务的策略。</sup><sup>从左到右，迭代 0、迭代 1、迭代 3、迭代 9、迭代 13。</sup> </p><p></p><figure class="wp-block-image size-full is-resized"><img loading="lazy" decoding="async" width="1832" height="436" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a.png" alt="机器人的控制策略被初始化为简单地输出一个零向量，这将使机器人保持在初始配置。" class="wp-image-1060008" style="width:900px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a.png 1832w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a-300x71.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a-1024x244.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a-768x183.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a-1536x366.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-a-240x57.png 240w" sizes="(max-width: 1832px) 100vw, 1832px" /><figcaption class="wp-element-caption"><strong>初始控制码</strong></figcaption></figure><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1832" height="1250" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b.png" alt="经过13次迭代学习到的控制策略是复杂的决策逻辑，有很多规则来决定何时抓取、如何抓取、何时释放。决策边界永远不会告诉机器人，而是通过环境中的反复试验来学习的。" class="wp-image-1060011" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b.png 1832w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b-300x205.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b-1024x699.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b-768x524.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b-1536x1048.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-5-b-240x164.png 240w" sizes="(max-width: 1832px) 100vw, 1832px" /><figcaption class="wp-element-caption"> <strong>13集后学会了控制密码</strong><br><br><center>图 4.Trace 将初始虚拟控制策略调整为复杂的、通用的控制策略。 </center></figcaption></figure><h2 class="wp-block-heading" id="finale-self-adapting-multi-agent-llm-systems">结局：自适应多代理法学硕士系统</h2><p>跟踪不仅限于代码优化。 Trace框架支持优化异构参数，包括代码、提示和超参数。在这里，我们展示了 Trace 在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://virtual-home.org/" target="_blank" rel="noreferrer noopener">VirtualHome <span class="sr-only">（在新选项卡中打开）</span></a>模拟环境中解决复杂家庭任务时优化多个 LLM 代理提示的能力。</p><p>许多任务需要多智能体协作才能有效解决。但为多个 LLM 代理制定正确的提示需要仔细设计。 Trace 可以根据环境反馈无缝优化代理的行为。 Trace 自动构建代理的交互图，并根据其他代理的行为更新每个代理的行为。然后，代理可以自动进化以获得行为角色等专门功能，从而将系统设计人员从手动调整多个 LLM 提示的艰苦过程中解放出来。</p><p>我们使用 Trace 和 OptoPrime 来改进经过<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/tobeatraceur/Organized-LLM-Agents" target="_blank" rel="noreferrer noopener">精心编排<span class="sr-only">（在新选项卡中打开）</span></a>的 ReAct 代理，以完成 VirtualHome 任务。在每个步骤中，代理可以与环境交互（例如打开柜子）或在看到对方时向另一个代理发送消息。我们将每个基于 LLM 的代理的计划（其提示的一部分）声明为可训练参数，并使用奖励作为反馈。实验结果如图 5 所示，其中经过 Trace 优化的代理可以使用更少的操作和环境交互来完成任务。我们观察到智能体在没有被明确告知进行交流的情况下出现的令人着迷的亲社会行为，如图 6 所示。这种亲社会交互行为随着不同的任务而变化。例如，智能体在“读书”任务中不会相互沟通，但当被要求“将叉子和盘子放入洗碗机中”时，他们会进行协作，如图 7 所示。我们还观察到其他模式，例如角色专业化，其中一名特工成为特定任务的领导者，然后由另一名特工提供协助。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1168" height="1166" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6.png" alt="Trace 优化的多智能体系统需要更少的步骤来完成每项任务（读书从 22 步减少到 10 步；放入洗碗机从 21 步减少到 19 步；准备食物从 21 步减少到 18 步）。" class="wp-image-1059942" style="width:406px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6.png 1168w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6-300x300.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6-1024x1022.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6-150x150.png 150w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6-768x767.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6-180x180.png 180w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/TRACE_fig-6-360x360.png 360w" sizes="(max-width: 1168px) 100vw, 1168px" /><figcaption class="wp-element-caption">图 5：我们显示了为成功完成每项任务而采取的环境交互行动的数量。跟踪优化代理只需更少的步骤即可成功，因此在此环境中效率更高。 </figcaption></figure><div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-3 wp-block-columns-is-layout-flex"><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="360" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-7-a.gif" alt="该视频显示了 VirtualHome 中三个任务中代理的行为示例。" class="wp-image-1060035"/></figure></div><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="360" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-7-b.gif" alt="该视频显示了 VirtualHome 中三个任务中代理的行为示例。" class="wp-image-1060038"/></figure></div><div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="480" height="360" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/fig-7-c.gif" alt="该视频显示了 VirtualHome 中三个任务中代理的行为示例。" class="wp-image-1060041"/></figure></div></div><p class="has-text-align-center figcaption"><sup>图 6：演示视频，展示 Trace 代理如何完成这三个任务。</sup></p><pre class="wp-block-code"> <code>[send_message] &lt; Agent 1 >; to &lt; Agent 2 >;: I am handing you the &lt; cutleryfork >;. Please grab another piece of cutlery or plate to help! [send_message] &lt; Agent 2 >; to &lt; Agent 1 >;: Can you also hand me the &lt; plate >; you are holding? [send_message] &lt; Agent 1 >; to &lt; Agent 2 >;: Here&#39;s the &lt; cutleryfork >;. I&#39;ll go grab the &lt; plate >; now. ... [send_message] &lt; Agent 1 >; to &lt; Agent 2 >;: Let&#39;s head to the kitchen and put the &lt; cutleryfork >; and &lt; plate >; into the dishwasher.</code></pre><p class="has-text-align-center"><sup>图 7：Trace 在洗碗机任务中学习亲社会行为。跟踪优化代理发送消息以尝试协作，而简单的 ReAct 代理只会执行任务。</sup></p><p> Trace 预示着交互式代理的新时代，可以使用各种反馈类型自动适应。这项创新可能是释放人工智能系统全部潜力的关键，使它们比以往任何时候都更加高效和响应。在见证了深度神经网络的强大力量之后，请继续关注人工智能设计的下一次革命——<strong>深度代理网络</strong>！</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/tracing-the-path-to-self-adapting-ai-agents/">《追踪自适应 AI 代理之路》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> Microsoft 在 ICML 2024：机器学习的创新</title><link/>https://www.microsoft.com/en-us/research/blog/microsoft-at-icml-2024-innovations-in-machine-learning/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Mon, 22 Jul 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/microsoft-at-icml-2024-innovations-in-machine-learning/ </guid><description><![CDATA[<p> AI 代理的竞争动态以及学习和应用时间动作抽象的方法只是 Microsoft 对 ICML 2024 的部分贡献。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-icml-2024-innovations-in-machine-learning/">微软在 ICML 2024 上的帖子：机器学习的创新</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788.png" alt="微软参加 ICML 2024" class="wp-image-1057344" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/ICML2024_BlogHero_1400x788-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>在数据日益主导的时代，机器学习是一股关键力量，能够以前所未有的速度和准确性将大量信息转化为可操作的情报。例如，机器学习的最新进展带来了<a href="https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/">精准健康</a>方面的突破，帮助医生在患者护理方面做出更明智的决策。同样，在气候科学中，机器学习正在提高科学家<a href="https://www.microsoft.com/en-us/research/blog/introducing-aurora-the-first-large-scale-foundation-model-of-the-atmosphere/">预测和减轻极端天气事件影响</a>的能力。这些创新表明，机器学习不仅简化了工作流程，还为人们提供了有效和创新解决当今一些最紧迫挑战的工具。</p><p>随着该领域的不断发展， <a href="https://www.microsoft.com/en-us/research/event/icml-2024/overview/" target="_blank" rel="noreferrer noopener">国际机器学习会议</a>(ICML 2024) 成为展示最新突破和创新的首要论坛，汇集了来自全球各地的研究人员、学者和行业专业人士。 Microsoft 很荣幸作为回归赞助商支持 ICML 2024，并很高兴地宣布今年 Microsoft 研究人员及其合作者的 68 篇论文已被接受，其中包括 4 篇被选为口头报告的论文。</p><p>这篇文章重点介绍了这些演示，每个演示都探讨了机器学习在完善决策过程、提高自动化和建模复杂行为方面的潜力。 NaturalSpeech 3 就是一个很好的例子，它引入了一种新的语音合成方法，可以改变机器的通信方式。总之，这些进步不仅展示了机器学习应用的多功能性和深度，而且强调了对解决实际和理论挑战的持续承诺。继续阅读以了解有关这项研究的更多信息，并探索 Microsoft 对 ICML 2024 的一些贡献。</p><h2 class="wp-block-heading" id="oral-sessions">口头会议</h2><h3 class="wp-block-heading" id="competeai-understanding-the-competition-dynamics-in-large-language-model-based-agents"> <a href="https://www.microsoft.com/en-us/research/publication/competeai-understanding-the-competition-behaviors-in-large-language-model-based-agents/">CompeteAI：了解基于大型语言模型的代理的竞争动态</a></h3><p><em>赵钦霖、</em><a href="https://www.microsoft.com/en-us/research/people/jindwang/"><em>王金东</em></a><em>、张艺轩、金艺侨、朱凯杰、陈浩、</em><a href="https://www.microsoft.com/en-us/research/people/xingx/"><em>谢星</em></a></p><p>本研究旨在探索使用法学硕士代理人帮助加速社会科学研究的可能性。为此，作者提出了一个通过实施竞争环境来研究代理竞争的框架，使用 GPT-4 来模拟以餐厅和客户代理为特色的虚拟城镇。餐厅代理商竞相吸引顾客，促使他们制定新的运营策略。研究结果强调了社会学习和积累优势的影响等现象，与现有的社会学和经济学理论相一致。对代理人竞争的进一步调查可以使我们更好地了解社会。 </p><h3 class="wp-block-heading" id="naturalspeech-3-zero-shot-speech-synthesis-with-factorized-codec-and-diffusion-models"> <a href="https://www.microsoft.com/en-us/research/publication/naturalspeech-3-zero-shot-speech-synthesis-with-factorized-codec-and-diffusion-models/">NaturalSpeech 3：使用分解编解码器和扩散模型的零样本语音合成</a></h3><p><em>鞠泽谦、王远成、沉凯、谭旭、辛德泰、杨东超、刘彦青、冷一冲、宋凯涛、唐思良、吴志正、秦涛、李向阳、叶伟</em><a href="https://www.microsoft.com/en-us/research/people/kaitaosong/"><em>、</em></a><em>张世坤</em><a href="https://www.microsoft.com/en-us/research/people/taoqin/"><em>、</em></a><em>边</em><a href="https://www.microsoft.com/en-us/research/people/jiabia/"><em>江</em></a><em>、何磊、</em><a href="https://www.microsoft.com/en-us/research/people/jinyli/"><em>李金玉</em></a><em>、</em> <a href="https://www.microsoft.com/en-us/research/people/szhao/" target="_blank" rel="noreferrer noopener"><em>赵盛</em></a></p><p>这项工作介绍了 NaturalSpeech 3，这是一种文本转语音 (TTS) 系统，使用新型分解扩散模型进行零样本语音生成。首先，研究团队开发了一种具有因子向量量化（FVQ）功能的神经编解码器，可将语音波形分离为内容、韵律、音色和声学细节。其次，分解扩散模型根据相应的提示生成每个子空间中的属性。这种分而治之的方法使 NaturalSpeech 3 能够有效且高效地对复杂的语音进行建模。实验结果表明，NaturalSpeech 3 在质量、相似性、韵律和清晰度方面超越了最先进的 TTS 系统。 </p><h3 class="wp-block-heading" id="position-rethinking-post-hoc-search-based-neural-approaches-for-solving-large-scale-traveling-salesman-problems"> <a href="https://www.microsoft.com/en-us/research/publication/position-rethinking-post-hoc-search-based-neural-approaches-for-solving-large-scale-traveling-salesman-problems/">立场：重新思考基于事后搜索的神经方法来解决大规模旅行商问题</a></h3><p><em>夏一凡、</em><a href="https://www.microsoft.com/en-us/research/people/xianya/"><em>杨贤良</em></a><em>、刘紫川、刘志浩、</em><a href="https://www.microsoft.com/en-us/research/people/lesong/"><em>宋雷</em></a><em>、</em><a href="https://www.microsoft.com/en-us/research/people/jiabia/"><em>边江</em></a></p><p>解决复杂路由问题（例如旅行商问题（TSP））的最新进展使用了一种新颖的方法，其中机器学习（ML）模型生成热图来指导蒙特卡罗树搜索（MCTS）算法。这些热图表明每条路线成为最佳解决方案一部分的可能性。然而，作者的分析对机器学习生成的热图的有效性提出了质疑。他们发现简单的方法通常优于复杂的机器学习方法。此外，热图引导的 MCTS 不如传统的 LKH-3 启发式有效。作者建议未来的研究重点是更好的热图方法和更通用的机器学习方法来解决组合问题。 </p><h3 class="wp-block-heading" id="prise-llm-style-sequence-compression-for-learning-temporal-action-abstractions-in-control"> <a href="https://www.microsoft.com/en-us/research/publication/prise-learning-temporal-action-abstractions-as-a-sequence-compression-problem/">PRISE：用于学习控制中的时间动作抽象的 LLM 式序列压缩</a></h3><p><em>郑瑞杰、</em><a href="https://www.microsoft.com/en-us/research/people/chinganc/"><em>程庆安</em></a><em>、</em> <a href="https://www.microsoft.com/en-us/research/people/hal3/"><em>Hal Daumé III</em></a> <em>、黄芙蓉、</em> <a href="https://www.microsoft.com/en-us/research/people/akolobov/"><em>Andrey Kolobov</em></a></p><p>时间动作抽象有望实现更有效的人工智能决策和大型机器人模型的数据高效训练。这项工作在时间动作抽象和文本标记化之间进行了新颖的类比——LLM 中看似不相关的顺序数据压缩机制，通常使用字节对编码 (BPE) 实现。基于此，作者提出了原始序列编码（PRISE），一种将动作量化与 BPE 相结合的方法，用于连续控制的技能学习。结果表明，PRIZE 从机器人操作演示中学到的高级技能极大地提高了下游任务中的行为克隆性能。</p><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><p>在我们的会议<a href="https://www.microsoft.com/en-us/research/event/icml-2024/overview/">网页</a>上了解有关我们对 ICML 2024 的工作和贡献的更多信息，包括我们的<a href="https://www.microsoft.com/en-us/research/event/icml-2024/publications/">出版物</a>和<a href="https://www.microsoft.com/en-us/research/event/icml-2024/sessions/">会议</a>的完整列表。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044936"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究博客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-3-globally-inclusive-and-equitable-ai-new-use-cases-for-ai-and-more/" aria-label="Microsoft Research Forum Episode 3: Globally inclusive and equitable AI, new use cases for AI, and more" data-bi-cN="Microsoft Research Forum Episode 3: Globally inclusive and equitable AI, new use cases for AI, and more" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF-Ep3-Recap-BlogHeroFeature-1400x788-1.jpg" alt="微软研究论坛|第 3 集 |小组讨论会" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究院论坛第 3 集：全球包容且公平的人工智能、人工智能的新用例等</h2><p class="large">在最新一期的微软研究论坛中，研究人员探讨了全球包容性和公平人工智能的重要性，分享了 AutoGen 和 MatterGen 的最新动态，介绍了人工智能的新用例，包括工业应用和多模式模型改善辅助技术的潜力。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-3-globally-inclusive-and-equitable-ai-new-use-cases-for-ai-and-more/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Read more" data-bi-cN="Microsoft Research Forum Episode 3: Globally inclusive and equitable AI, new use cases for AI, and more" target="_blank">阅读更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-icml-2024-innovations-in-machine-learning/">微软在 ICML 2024 上的帖子：机器学习的创新</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>