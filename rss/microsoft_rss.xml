<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 11 月 15 日星期五 04:55:14 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.6.2</generator><item><title> Orca-AgentInstruct：代理流可以成为有效的合成数据生成器</title><link/>https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be- effective-synthetic-data-generators/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 14 Nov 2024 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1063530 </guid><description><![CDATA[<p>来自 Microsoft Research 的 Orca-AgentInstruct 可以大规模生成多样化的高质量合成数据，以便对基础 LLM 进行后期训练和微调，以扩展功能、持续学习和提高性能。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/">Orca-AgentInstruct：代理流可以是有效的合成数据生成器</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1.jpg" alt="Orca-3 博客 - 抽象波浪图" class="wp-image-1063551" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3-2024-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>我们在<a href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/" target="_blank" rel="noreferrer noopener">Orca</a>和<a href="https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/" target="_blank" rel="noreferrer noopener">Orca 2</a>上的工作证明了使用合成数据对小型语言模型进行后期训练的强大功能，并使它们达到以前只有在更大的语言模型中才能找到的性能水平。 Orca-AgentInstruct 是朝这个方向迈出的又一步，我们探索使用代理流来大规模生成多样化的高质量数据。 Orca-AgentInstruct 是一种用于生成合成数据的代理解决方案。通过利用代理框架，AgentInstruct 可以从原始数据源生成定制数据集，包括提示和响应，为构建用于模型微调的合成数据工厂铺平道路。</p><p>通过微调基础 Mistral 70 亿参数模型并使用 AgentInstruct 生成 2500 万对数据集，观察到的显着改进证明了该方法的有效性。经过微调的模型（我们称为 Orca-3-Mistral）在多个基准测试中显示出显着的性能提升。例如，它显示 AGIEval 提高了 40%，MMLU 提高了 19%，GSM8K 提高了 54%，BBH 提高了 38%，AlpacaEval 提高了 45%，多个汇总基准的不准确或不可靠结果减少了 31.34%。</p><p>我们正在公开该数据集的 100 万对子集 ( <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/datasets/microsoft/orca-agentinstruct-1M-v1" target="_blank" rel="noreferrer noopener">orca-agentinstruct-1M</a> )，以及描述数据生成过程的<a href="https://www.microsoft.com/en-us/research/publication/agentinstruct-toward-generative-teaching-with-agentic-flows/" target="_blank" rel="noreferrer noopener">报告</a>，以鼓励对合成数据生成和语言模型微调的研究。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="3300" height="1320" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1.png" alt="比较 Mistral-Instruct-7B 模型和 Mistral-7B 训练后 AgentInstruct 数据 (Orca-3) 分数的条形图。基准测试包括 AGIEval、MMLU、BBH、GSM8K、AlpaceEval、FOFO 和 Mirage-RAG。该图显示了使用 AgentInstruct 数据微调的模型在不同基准测试中的显着改进。" class="wp-image-1063923" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1.png 3300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1-300x120.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1-1024x410.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1-768x307.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1-1536x614.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1-2048x819.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2024/08/Figure-1-1-240x96.png 240w" sizes="(max-width: 3300px) 100vw, 3300px" /><figcaption class="wp-element-caption">图 1：使用 AgentInstruct 对 Mistral-7B 进行后训练的效果。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1661" height="498" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2.png" alt="该图显示了 AgentInstruct 中使用的三个流程： 1) 内容转换流程将原始种子转换为中间表示，从而简化了针对特定目标定制的指令的创建。 2) 种子指令生成流，包括多个代理，将来自内容转换流的转换后的种子作为输入，并生成一组不同的指令。 3) 指令细化流程将来自种子指令流程的指令作为输入，并迭代地增强其复杂性和质量。" class="wp-image-1063545" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2.png 1661w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2-300x90.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2-1024x307.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2-768x230.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2-1536x461.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/Orca-3_Figure-2-240x72.png 240w" sizes="(max-width: 1661px) 100vw, 1661px" /><figcaption class="wp-element-caption">图 2。该图提供了不同代理组所扮演的角色的主题概述。内容转换流将种子转换为中间表示形式，从而更轻松地创建高质量和多样化的数据。种子指令生成流程按照分类法创建目标任务的实例。指令细化流程通过从这些初始数据点开始并探索邻域来进一步探索空间。我们期望通过选择随机种子，我们将能够覆盖整个数据点区域。</figcaption></figure><p><strong>合成数据加速了 LLM 的开发：</strong>在过去的一年里，合成数据的使用极大地推进了大型语言模型 (LLM) 的训练。它加速了各个阶段的模型训练，从预训练（例如，Phi-3）到指令调整（例如，Orca 和 WizardLM）以及根据人类反馈进行强化学习（例如，直接纳什优化）。 <span data-contrast="auto" xml:lang="EN-US" lang="EN-US" class="TextRun EmptyTextRun SCXW48469235 BCX8" style="-webkit-user-drag: none; -webkit-tap-highlight-color: transparent; margin: 0px; padding: 0px; user-select: text; font-size: 11pt; line-height: 18.3458px; font-family: Aptos, Aptos_EmbeddedFont, Aptos_MSFontService, sans-serif; font-weight: bold; font-variant-ligatures: none !important;"></span></p><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--left"><li class="annotations__list-item"> <a href="https://www.microsoft.com/en-us/research/video/agentinstruct-methodology/" target="_blank" aria-label="AgentInstruct Methodology" data-bi-type="annotated-link" data-bi-cN="AgentInstruct Methodology" class="annotations__list-thumbnail" ><img loading="lazy" decoding="async" width="172" height="96" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-240x135.jpg" class="mb-2" alt="特工指示视频缩略图" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/07/j-hYRmUUbLU.jpg 1280w" sizes="(max-width: 172px) 100vw, 172px" /></a> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">演示视频</span><a href="https://www.microsoft.com/en-us/research/video/agentinstruct-methodology/" target="_blank" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="AgentInstruct Methodology" data-bi-aN="margin-callout" data-bi-cN="AgentInstruct Methodology">AgentInstruct 方法<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span></a></li></ul></div><p><strong>生成高质量的合成数据很困难：</strong>另一方面，研究表明，对其他模型生成的合成数据进行预训练模型可能会导致模型崩溃，导致模型逐渐退化。对于在训练后使用合成数据也提出了类似的担忧，这表明这可能会导致模仿过程，训练后的模型只学习风格特征而不是实际能力。 <span data-contrast="auto" xml:lang="EN-US" lang="EN-US" class="TextRun EmptyTextRun SCXW155638626 BCX8" style="-webkit-user-drag: none; -webkit-tap-highlight-color: transparent; margin: 0px; padding: 0px; user-select: text; font-size: 11pt; line-height: 18.3458px; font-family: Aptos, Aptos_EmbeddedFont, Aptos_MSFontService, sans-serif; font-variant-ligatures: none !important;"></span></p><p>这种差异可能归因于生成高质量和多样化的合成数据的挑战。  合成数据的成功使用需要大量的人力来整理和过滤数据以确保高质量。</p><p><strong>合成数据遇见代理：</strong>我们在过去一年见证的另一个重大发展是代理（尤其是多代理）工作流程的兴起，例如 AutoGen。代理工作流程可以生成高质量的数据，这超越了底层法学硕士的能力，通过使用具有反射和迭代的流程，使代理能够回顾解决方案、提出批评并改进解决方案。他们还可以使用搜索 API、计算器和代码解释器等工具来解决 LLM 限制。</p><p>多代理工作流程还带来了额外的好处，例如模拟我们可以生成新提示和相应响应的场景。它们还可以实现数据生成工作流程的自动化，从而减少或消除对某些任务进行不必要的人工干预的需要。</p><p> <strong>AgentInstruct：</strong>生成用于训练后或微调的合成数据通常依赖于现有的提示集，该提示集可以按原样使用，也可以用作生成更多指令的种子。在这项工作中，我们将问题设置概括为更广泛的目标，即生成大量多样化、具有挑战性的高质量数据，以向人工智能模型教授特定技能。我们将这种设置称为<em>生成式教学</em>。</p><p> AgentInstruct 是生成式教学的代理解决方案。 AgentInstruct 使用原始文档作为输入来创建演示和反馈数据。当通用数据用作种子时，AgentInstruct 可用于教授法学硕士一般能力，例如写作、推理或检索增强生成 (RAG)。特定领域的数据（例如零售或金融）也可以用作种子来改进特定专业领域的模型。 AgentInstruct 可以创建：</p><ol class="wp-block-list"><li><strong>高质量数据：</strong> AgentInstruct 使用 GPT-4 并结合搜索和代码解释器等工具来创建高质量数据。</li><li><strong>多样化的数据：</strong> AgentInstruct 使用一组专业代理（具有强大的 LLM、工具和反射流）和分类法（超过 100 个子类别）创建提示和响应，确保多样性和质量。</li><li><strong>大数据量：</strong> AgentInstruct可以自主运行。和 applyiflows 用于验证和数据过滤。它不需要种子提示并使用原始文档进行种子。</li></ol><p>使用原始数据作为种子有两个优点：它数量充足，允许 AgentInstruct 生成大规模且多样化的数据集；它鼓励学习通用技能，而不是通过避免使用现有提示来学习特定于基准的技能。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="999693"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：活动系列</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum" data-bi-cN="Microsoft Research Forum" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png" alt="浅蓝色背景上的各种抽象 3D 形状" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究论坛</h2><p class="large">加入我们，持续交流有关通用人工智能时代研究的想法。点播观看前四集。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Register for series" data-bi-cN="Microsoft Research Forum" target="_blank">注册系列</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>我们预计代理流在整个模型训练生命周期中变得越来越重要，包括训练前、训练后和专业化，并最终支持创建用于模型定制和持续改进的合成数据工厂。通过使高质量的模型训练更加高效和易于访问，这有可能推动多个行业的人工智能进步。</p><h2 class="wp-block-heading" id="contributors">贡献者：</h2><p> <a href="https://www.microsoft.com/en-us/research/people/armitra/" target="_blank" rel="noreferrer noopener">Arindam Mitra</a> 、Luciano Del Corro、 <a href="https://www.microsoft.com/en-us/research/people/zheng/" target="_blank" rel="noreferrer noopener">郑国庆</a>、 <a href="https://www.microsoft.com/en-us/research/people/shmahaj/" target="_blank" rel="noreferrer noopener">Shweti Mahajan</a> 、 <a href="https://www.microsoft.com/en-us/research/people/danyr/" target="_blank" rel="noreferrer noopener">Dany Rouhana</a> 、 <a href="https://www.microsoft.com/en-us/research/people/andrescodas/" target="_blank" rel="noreferrer noopener">Andres Codas</a> 、亚东、陈伟革、 <a href="https://www.microsoft.com/en-us/research/people/olvrousg/" target="_blank" rel="noreferrer noopener">Olga Vrousgou</a> 、 <a href="https://www.microsoft.com/en-us/research/people/corbyrosset/" target="_blank" rel="noreferrer noopener">Corby Rosset</a> 、Fillipe Silva、 <a href="https://www.microsoft.com/en-us/research/people/hakhanpo/" target="_blank" rel="noreferrer noopener">Hamed Khanpour</a> 、 <a href="https://www.microsoft.com/en-us/research/people/yashlara/" target="_blank" rel="noreferrer noopener">Yash Lara</a>和<a href="https://www.microsoft.com/en-us/research/people/hassanam/" target="_blank" rel="noreferrer noopener">Ahmed Awadallah</a></p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/">Orca-AgentInstruct：代理流可以是有效的合成数据生成器</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>迈向模块化模型：协作人工智能开发实现模型问责和持续学习</title><link/>https://www.microsoft.com/en-us/research/blog/toward-modular-models-collaborative-ai-development-enables-model-accountability-and-continuous-learning/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 13 Nov 2024 17:30:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1098456 </guid><description><![CDATA[<p>模块化模型可以使人工智能开发民主化，同时释放新的优势和用例。模块化人工智能可以更灵活、更合规、开发成本更低——训练专家模型所需的数据和计算资源更少。</p><p>文章<a href="https://www.microsoft.com/en-us/research/blog/toward-modular-models-collaborative-ai-development-enables-model-accountability-and-continuous-learning/">《迈向模块化模型：协作 AI 开发实现模型问责和持续学习》</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-1024x576.jpg" alt="模块化模型博客英雄" class="wp-image-1098480" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models-BlogHeroFeature-1400x788-1.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>如今，通用人工智能模型的开发需要获得足够的数据和计算资源，这可能会给一些研究人员带来挑战。整个研究界对技术的民主化可以促进通用人工智能模型的发展。通过将模块化的核心软件开发理念应用于人工智能，我们可以构建强大、高效、适应性强且透明的模型。</p><p>直到最近，人工智能模型主要是使用整体架构构建的。尽管功能强大，但与具有易于解释的功能组件的模块化模型相比，这些模型的定制和编辑可能具有挑战性。如今，开发人员利用模块化来使服务更可靠、更快地完善，并且更容易让多个用户同时做出贡献。支持这一点的一个有前景的研究方向涉及将人工智能开发转向<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html" target="_blank" rel="noreferrer noopener">模块化方法<span class="sr-only">（在新选项卡中打开）</span></a> ，这可以增强灵活性并提高可扩展性。</p><p>其中一种方法是使用为特定任务设计的众多微调模型（称为<em>专家模型</em>），并协调它们来解决更广泛的任务（请参阅<a href="https://www.microsoft.com/en-us/research/publication/towards-modular-llms-by-building-and-reusing-a-library-of-loras/">通过构建和重用 LoRA 库实现模块化 LLM – 微软研究院<span class="sr-only">（在新选项卡中打开）</span></a> ， <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2402.05859" target="_blank" rel="noreferrer noopener">学习在专业专家之间进行路由以实现零样本泛化<span class="sr-only">（在新选项卡中打开）</span></a> 。这些专家模型可以以分散的方式开发。与使用微服务架构的好处类似，这种模块化人工智能方法可以更灵活、开发成本更低，并且更符合相关隐私和法律政策。然而，虽然在训练优化方面已经进行了大量研究，但协调方法在很大程度上仍未得到探索。</p><p>我们的团队正在通过关注两个主题来探索模块化模型的潜力：i）优化专家模型的训练，ii）完善专家模型如何协调以形成协作模型。协调专家模型的一种方法是针对特定任务或查询自适应地选择最相关的独立开发的专家模型。这种方法称为<em>MoErging</em> ，与专家混合 (MoE) 方法类似，但不同之处在于，路由机制是在个别专家接受培训<em>后</em>学习的。作为第一步，我们致力于创建一个分类法来组织最近的 MoErging 方法，目的是帮助研究界建立一种共享语言，并促进不同方法之间更容易、更公平的比较。</p><h2 class="wp-block-heading" id="assessing-existing-moerging-methods">评估现有的 MoErging 方法</h2><p>大多数 MoErging 方法都是在过去一年内开发的，因此它们没有引用每种方法，并且很难进行比较。为了能够比较 MoErging 方法，我们最近合作开展了一项<a href="https://www.microsoft.com/en-us/research/publication/a-survey-on-model-moerging-recycling-and-routing-among-specialized-experts-for-collaborative-learning/" target="_blank" rel="noreferrer noopener">调查</a>，该调查建立了比较方法的分类法，并将 MoErging 设计选择分为三个步骤：</p><ul class="wp-block-list"><li><strong>专家设计：</strong>识别并使用由分布式贡献者异步训练的专家模型。</li><li><strong>路由设计：</strong>将任务路由到适当的专家模型。</li><li><strong>应用程序设计：</strong>将合并的模型应用于特定任务或领域。</li></ul><p>每个步骤都分为更详细的选择。例如，在<em>专家设计</em>中，专家培训可以是<em>定制的</em>或<em>标准的</em>，培训数据可以是<em>私有的</em>或<em>共享的</em>。定制培训需要MoErging有特定的培训程序，而标准培训则没有。同样，<em>共享数据</em>意味着训练数据必须可用于路由访问。否则，训练数据被视为私有。</p><p>下面讨论的模块化模型的好处假设不需要共享训练数据。然而，对当前 MoErging 方法的回顾发现，某些方法确实需要共享训练数据，从而使得某些好处不再适用。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="999693"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：活动系列</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum" data-bi-cN="Microsoft Research Forum" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png" alt="浅蓝色背景上的各种抽象 3D 形状" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究论坛</h2><p class="large">加入我们，持续交流有关通用人工智能时代研究的想法。点播观看前四集。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Register for series" data-bi-cN="Microsoft Research Forum" target="_blank">注册系列</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>该调查使用其分类法评估了 29 种不同的 MoErging 方法，该分类法将设计选择分为两种专家设计选择、五种路由设计选择和两种应用程序设计选项，如图 1 所示。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1017" height="1056" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models_Figure1.png" alt="MoErging 模型设计选择的分类。叶节点中的参考文献链接到做出某些特定设计选择的特定论文的部分。我们省略了对给定选择不适用的方法的引用。" class="wp-image-1098477" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models_Figure1.png 1017w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models_Figure1-289x300.png 289w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models_Figure1-986x1024.png 986w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models_Figure1-768x797.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Modular-Models_Figure1-173x180.png 173w" sizes="(max-width: 1017px) 100vw, 1017px" /><figcaption class="wp-element-caption">图 1：MoErging 模型设计选择的分类。叶节点中的参考文献链接到实现每个选择的特定论文的部分。我们省略了对不适用特定选择的方法的引用。</figcaption></figure><p>调查得出的一个结论是，大多数 MoErging 方法可以根据其路由设计选择分为四类：</p><ol class="wp-block-list"><li><strong>基于分类器的路由：</strong>使用专家数据集或看不见的数据将路由器训练为分类器的方法。</li><li><strong>基于嵌入的路由：</strong>计算专家训练集的嵌入并将其与路由的查询嵌入进行比较的方法。</li><li><strong>非路由器方法：</strong>不显式训练路由器而是以无监督方式初始化路由器的方法。</li><li><strong>特定于任务的路由：</strong>学习目标数据集上特定于任务的路由分布以提高特定任务性能的方法。</li></ol><p>虽然每个类别内的差异很小，但类别之间的差异却很大，因为它们决定了实施所需的数据访问级别。因此，数据访问是确定哪些方法在各种设置中适用且可行的主要因素。</p><p>我们的分类法还涵盖了构建代理系统的最新方法，这些方法可以被视为特定类型的 MoErging 方法，其中专家是完整的语言模型，并且路由决策是在逐步或逐个示例的基础上做出的。 MoErging 的最佳级别可能会有所不同，具体取决于任务和每个利益相关者可用的计算资源。</p><h2 class="wp-block-heading" id="potential-benefits-and-use-cases-of-modular-models">模块化模型的潜在好处和用例</h2><p>模块化模型可以释放人工智能的新优势和用例，为解决当前人工智能开发中的挑战提供一种有前景的方法。展望未来，需要进一步进行大量研究来验证这种潜力并评估可行性。</p><p>模块化人工智能可以：</p><ul class="wp-block-list"><li><strong>允许注重隐私的贡献。</strong>拥有敏感或专有数据（例如个人身份信息 (PII) 和受版权保护的内容）的团队可以贡献专家模型并从大型项目中受益，而无需共享数据。这种能力可以使遵守数据隐私和法律标准变得更加容易，这对于医疗保健团队来说非常有价值，他们可以从通用模型功能中受益，而无需将敏感数据与其他训练数据相结合。</li><li><strong>推动模型透明度和问责制。</strong>模块化模型允许识别特定的专家模型，并在必要时删除或重新训练。例如，如果识别出经过 PII、受版权保护或有偏见数据训练的模块，则可以更轻松地将其删除，从而无需重新训练，并有助于确保遵守隐私和道德标准。</li><li><strong>促进模型的可扩展性和持续改进。</strong>模块化支持持续改进，允许集成专家模型的新功能。这种方法类似于进行本地化编辑，从而实现持续、经济高效的改进。</li><li><strong>为那些计算和数据资源有限的人降低人工智能开发的障碍。</strong>模块化人工智能可以通过创建一个可以重复使用经过预先培训的专家的系统来减少对大量数据和计算的需求，从而使学术界、初创公司和专注于利基用例的团队受益。例如，负责在训练数据有限的特定网站上预订航班的人工智能代理可以利用其他训练有素的人工智能专家的一般导航和预订技能，从而无需特定领域的训练数据即可实现通用且广泛适用的技能。我们在论文“ <a href="https://www.microsoft.com/en-us/research/publication/multi-head-adapter-routing-for-cross-task-generalization/%22%20%EF%B7%9FHYPERLINK%20%22https://www.microsoft.com/en-us/research/publication/multi-head-adapter-routing-for-cross-task-generalization/">跨任务泛化的多头路由</a>”中探讨了跨任务转移技能的过程。</li><li><strong>支持个性化。</strong>模块化模型使得为人工智能代理配备针对个人用户或系统量身定制的专家成为可能。例如，旨在模仿五届世界国际象棋冠军马格努斯·卡尔森的人工智能可以增强玩家与他进行比赛的准备。实验表明，在按需模块中存储知识或用户配置文件可以匹配或超越检索增强生成 (RAG) 的性能，从而有可能减少延迟并改善用户在自定义 AI 应用程序中的体验。</li></ul><h2 class="wp-block-heading" id="current-limitations-and-looking-forward">当前的局限性和展望</h2><p>在本博客中，我们重点关注一种涉及训练基础模型的模块化方法，这需要大量的计算能力和大量数据。尽管模块化具有提高灵活性、效率和适应性等优点，但基础模型的开发仍然是资源密集型的，需要高性能计算和强大的数据集来支持微调。</p><p>最近的工作已经开始通过<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2311.08105" target="_blank" rel="noreferrer noopener">分布式基础模型的预训练过程来解决这些挑战<span class="sr-only">（在新选项卡中打开）</span></a> 。展望未来，一个有前途的研究方向侧重于探索如何创建最小数据集来训练“空基础模型”，同时将其大部分功能转移到外部可插拔模块。</p><p>模块化方法正在迅速发展，我们对它们的潜力感到兴奋。模块化能够使人工智能开发民主化、改进模型问责制并支持高效的持续学习。通过 MoErging 分类法，我们的目标是建立一种共享语言，促进研究社区的参与。这项研究还处于早期阶段，我们欢迎社区合作。如果您有兴趣与我们合作，请联系<a href="mailto:ModularModels@microsoft.com" target="_blank" rel="noreferrer noopener">ModularModels@microsoft.com</a> 。</p><h2 class="wp-block-heading" id="acknowledgements">致谢</h2><p>我们要感谢论文合作者：Prateek Yadav、Colin Raffel、Mohammed Muqeeth、Haokun Liu、Tianlong Chen、Mohit Bansal、Leshem Choshen、Edoardo Ponti、Zhan Su、 <a href="https://www.microsoft.com/en-us/research/people/matpereira/">Matheus Pereira</a> 、Nicolas Le Roux、Nabil Omi、 <a href="https://www.microsoft.com/en-us/research/people/sidsen/">Siddhartha Sen</a> 、Anurag Sarkar 、乔丹·T·阿什、奥列克西·奥斯塔彭科和洛朗·查林。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>文章<a href="https://www.microsoft.com/en-us/research/blog/toward-modular-models-collaborative-ai-development-enables-model-accountability-and-continuous-learning/">《迈向模块化模型：协作 AI 开发实现模型问责和持续学习》</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>