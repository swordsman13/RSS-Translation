<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 12 月 11 日星期一 16:12:01 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.2</generator><item><title> NeurIPS 2023 凸显了微软机器学习创新的广度</title><link/>https://www.microsoft.com/en-us/research/blog/neurips-2023-highlights-breadth-of-microsofts-machine-learning-innovation/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Mon, 11 Dec 2023 15:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=989523 </guid><description><![CDATA[<p>我们很自豪能在 NeurIPS 2023 上收到 100 多篇论文，并举办 18 场研讨会。一些提交的作品被选为口头报告和重点海报，反映了突破性的概念、方法或应用。以下是这些提交内容的概述。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/neurips-2023-highlights-breadth-of-microsofts-machine-learning-innovation/">NeurIPS 2023 强调了微软机器学习创新的广度，该文章</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1.png" alt="研究重点：NeurIPS 2023 年 12 月 11 日" class="wp-image-990225" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p> Microsoft 很荣幸能够赞助<a href="https://www.microsoft.com/en-us/research/event/neurips-2023/" target="_blank" rel="noreferrer noopener">第 37 届神经信息处理系统会议</a>(NeurIPS 2023)。这个跨学科论坛汇集了机器学习、神经科学、统计学、优化、计算机视觉、自然语言处理、生命科学、自然科学、社会科学和其他相邻领域的专家。我们很高兴地告诉大家，Microsoft 已接受 100 多篇论文，并在 NeurIPS 2023 上举办了 18 个研讨会。</p><p>今年的会议包括来自 Microsoft 的三篇论文，这些论文被选为口头演讲，其特点是突破性的概念、方法或应用程序，解决了该领域的紧迫问题。此外，我们的重点海报（也在下面突出显示）是由会议组织者精心策划的，展示了新颖性、技术严谨性以及对机器学习领域产生重大影响的潜力。这篇博文庆祝了这些成就。</p><h2 class="wp-block-heading" id="oral-presentations">口头报告</h2><h3 class="wp-block-heading" id="bridging-discrete-and-backpropagation-straight-through-and-beyond"><a href="https://www.microsoft.com/en-us/research/publication/bridging-discrete-and-backpropagation-straight-through-and-beyond/" target="_blank" rel="noreferrer noopener">连接离散和反向传播：直通和超越</a></h3><p>梯度计算对于深度学习的成功至关重要，但它们主要依赖于反向传播，这是一种仅限于连续变量的技术。论文<a href="https://www.microsoft.com/en-us/research/publication/bridging-discrete-and-backpropagation-straight-through-and-beyond/" target="_blank" rel="noreferrer noopener">《桥接离散和反向传播：直通及超越》</a>解决了这一限制。它引入了 ReinMax，扩展了反向传播的能力来估计包含离散变量采样的模型的梯度。在本研究的大量实验中，ReinMax 表现出了比现有技术一致且显着的性能提升。该论文不仅仅是一个实用的解决方案，还阐明了现有的深度学习实践。它阐明了“直通”方法曾经被认为仅仅是一种启发式技巧，实际上是一般多项式情况的可行的一阶近似。相应地，ReinMax 在这种情况下实现了二阶精度，而没有二阶导数的复杂性，因此计算开销可以忽略不计。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="979233"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/" aria-label="Abstracts: October 9, 2023" data-bi-cN="Abstracts: October 9, 2023" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode1_Abstracts_Hero_Feature_No_Text_1400x788.png" alt="微软研究院播客 - 摘要" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">摘要：2023 年 10 月 9 日</h2><p class="large">研究员张盛博士加入“摘要”（您的前沿研究简述来源），讨论最近一篇关于将大型语言模型提炼成更小、更高效、能够在广泛应用类别中表现出色的论文。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Abstracts: October 9, 2023" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading" id="the-minerl-basalt-competition-on-learning-from-human-feedback"> <a href="https://www.microsoft.com/en-us/research/publication/the-minerl-basalt-competition-on-learning-from-human-feedback/" target="_blank" rel="noreferrer noopener">MineRL BASALT 竞赛：从人类反馈中学习</a></h3><p>深度学习研究的发展，包括将其融入商业产品，带来了一个新的挑战：在缺乏清晰、明确定义的规范的情况下，我们如何构建能够解决任务的人工智能系统？为了鼓励对这一类重要技术的研究，微软的研究人员领导了<a href="https://www.microsoft.com/en-us/research/publication/the-minerl-basalt-competition-on-learning-from-human-feedback/" target="_blank" rel="noreferrer noopener">MineRL BASALT 人类反馈学习竞赛<span class="sr-only">（在新选项卡中打开）</span></a> ，这是该大学研究人员<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://proceedings.mlr.press/v176/shah22a/shah22a.pdf" target="_blank" rel="noreferrer noopener">于 2021 年首次发起的竞赛<span class="sr-only">（在新选项卡中打开）</span></a>的更新加州大学伯克利分校和其他地方。本次比赛的挑战是仅根据英语语言描述完成模糊任务，重点是鼓励从人类反馈中学习的不同方式作为传统奖励信号的替代方案。</p><p>研究人员在《我的世界》中设计了一套包含四个任务的套件，为这些任务编写硬编码的奖励函数会很困难。这些任务由自然语言定义：例如，“创建一个瀑布并为其拍摄一张风景照片”，并附有额外的澄清细节。参与者必须为每项任务训练一个单独的代理。然后，由阅读了任务描述的人员对代理进行评估。</p><p>该竞赛旨在鼓励人工智能系统的开发，即使其意图无法轻易形式化，也能实现设计者的意图。除了让人工智能能够解决更多任务之外，这还可以更有效地监管人工智能系统，并在价值调整问题上取得进展，在这些问题中，人工智能代理的具体目标与其用户的目标不同。</p><h4 class="wp-block-heading" id="related">有关的</h4><div class="annotations " data-bi-aN="citation"><ul class="annotations__list card depth-16 bg-body p-4 "><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">出版物《</span> <a href="https://www.microsoft.com/en-us/research/publication/towards-solving-fuzzy-tasks-with-human-feedback-a-retrospective-of-the-minerl-basalt-2022-competition/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Towards Solving Fuzzy Tasks with Human Feedback: A Retrospective of the MineRL BASALT 2022 Competition" data-bi-aN="citation" data-bi-cN="Towards Solving Fuzzy Tasks with Human Feedback: A Retrospective of the MineRL BASALT 2022 Competition">利用人类反馈解决模糊任务：MineRL BASALT 2022 竞赛回顾》<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span></a> </li></ul></div><div style="height:15px" aria-hidden="true" class="wp-block-spacer"></div><h3 class="wp-block-heading" id="decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models"> <a href="https://www.microsoft.com/en-us/research/publication/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/">DecodingTrust：GPT 模型可信度的综合评估</a></h3><p>这个综合评估平台旨在回答以下问题：生成式预训练 Transformer (GPT) 模型的可信度如何？在<a href="https://www.microsoft.com/en-us/research/publication/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/" target="_blank" rel="noreferrer noopener">DecodingTrust：GPT 模型可信度的综合评估中</a>，研究人员特别关注 GPT-4、GPT-3.5 和一系列开放式法学硕士。他们考虑了不同的观点，包括<em>毒性、刻板印象偏见、对抗鲁棒性、分布外鲁棒性、对抗性演示的鲁棒性、隐私、机器道德和公平性。</em></p><p>研究人员的评估发现了之前未发布的与可信度相关的漏洞。该团队与 Microsoft 产品组合作，确认所发现的潜在漏洞不会影响当前面向客户的服务。这在一定程度上是正确的，因为成品人工智能应用程序应用了一系列缓解方法来解决技术模型级别可能发生的潜在危害。他们还与 GPT 的开发商 OpenAI 分享了他们的发现，后者注意到了相关模型的系统卡中的潜在漏洞。</p><p>这项研究旨在鼓励研究界的其他人利用这项工作并以此为基础，从而可能先发制人，利用漏洞造成伤害。为了促进协作，基准测试代码非常可扩展且易于使用：单个命令足以在新模型上运行完整的评估。</p><h2 class="wp-block-heading" id="spotlight-posters">聚光灯海报</h2><h3 class="wp-block-heading" id="differentially-private-approximate-near-neighbor-counting-in-high-dimensions"> <a href="https://www.microsoft.com/en-us/research/publication/differentially-private-approximate-near-neighbor-counting-in-high-dimensions/" target="_blank" rel="noreferrer noopener">高维差分隐私近似近邻计数</a></h3><p>差分隐私（DP）是一种广泛使用的工具，用于保护敏感个人信息的隐私。它允许数据结构为其所保存的数据的查询提供近似答案，同时确保删除或添加单个数据库条目不会显着影响任何分析的结果。</p><p>差分隐私下的范围计数（计算落入给定查询球的数据点的数量）已被广泛研究。然而，当前解决该问题的算法面临着挑战。一类算法会遭受加性误差，该误差是点数的固定多项式。另一类算法允许多对数加性误差，但误差在维度上呈指数增长。为了实现后者，问题被放宽以允许范围边界的“模糊”定义，例如，对于某些 c >; 1，半径为 r 的球中的点的计数也可能包括半径为 cr 的球中的点。</p><p>在<a href="https://www.microsoft.com/en-us/research/publication/differentially-private-approximate-near-neighbor-counting-in-high-dimensions/" target="_blank" rel="noreferrer noopener">《高维差分隐私近似近邻计数》</a>中，研究人员提出了一种有效的算法，可以在这两个类别之间提供最佳平衡点。该算法具有一个加性误差，该误差是数据集大小的任意小幂，具体取决于范围边界的模糊程度，以及一个小的 (1 + o(1)) 乘性误差。至关重要的是，添加的噪声量与尺寸无关。这种新算法引入了局部敏感哈希的变体，以一种新颖的方式利用它。</p><h3 class="wp-block-heading" id="exposing-attention-glitches-with-flip-flop-language-modeling"> <a href="https://www.microsoft.com/en-us/research/publication/exposing-attention-glitches-with-flip-flop-language-modeling/" target="_blank" rel="noreferrer noopener">通过触发器语言模型揭示注意力缺陷</a></h3><p>为什么大型语言模型有时会输出不准确的事实并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，似乎是为其连贯地综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。</p><p>为了帮助理解这个根本上未解决的问题， <a href="https://www.microsoft.com/en-us/research/publication/exposing-attention-glitches-with-flip-flop-language-modeling/" target="_blank" rel="noreferrer noopener">使用触发器语言模型暴露注意力故障</a>识别并分析了注意力故障现象，其中 Transformer 架构的归纳偏差间歇性地无法捕获稳健的推理。为了解决这个问题，研究人员引入了触发器语言模型（FFLM），这是一个参数化的综合基准系列，旨在探测神经语言模型的外推行为。这个简单的生成任务需要一个模型来复制远程依赖关系上的二进制符号，忽略之间的标记。这项研究展示了 Transformer FFLM 如何遭受长尾的零星推理错误，其中一些错误可以使用各种正则化技术来消除。初步的机制分析表明为什么剩余的错误可能很难诊断和解决。研究人员推测，注意力缺陷是自然法学硕士中发生的一些闭域错误的原因。</p><h3 class="wp-block-heading" id="in-context-learning-unlocked-for-diffusion-models"> <a href="https://www.microsoft.com/en-us/research/publication/in-context-learning-unlocked-for-diffusion-models/" target="_blank" rel="noreferrer noopener">为扩散模型解锁情境学习</a></h3><p>大型语言模型（LLM）的一个新兴行为是从上下文中学习或<em>上下文中学习的能力。</em>通过正确设计的提示结构和情境学习，法学硕士可以结合多种语言任务的预训练，并很好地推广到以前未见过的任务。虽然上下文学习在自然语言处理（NLP）领域得到了广泛的研究，但其在计算机视觉领域的应用仍然有限。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/in-context-learning-unlocked-for-diffusion-models/" target="_blank" rel="noreferrer noopener">为扩散模型解锁的上下文学习</a>提出了 Prompt Diffusion，这是一个在基于扩散的生成模型中实现上下文学习的框架。给定一对特定于任务的示例图像和文本指导，该模型可以理解底层任务，并按照文本指导对新的查询图像执行相同的任务。为了实现这一目标，研究人员提出了一种可以模拟各种视觉语言任务的视觉语言提示，以及一种将其作为输入的扩散模型。使用这些提示对六个不同任务联合训练扩散模型。由此产生的即时扩散模型是第一个能够进行上下文学习的基于扩散的视觉语言基础模型。它展示了在训练任务上的高质量上下文生成，并推广到新的、未见过的视觉任务及其各自的提示。该模型还显示了引人注目的文本引导图像编辑结果。</p><h3 class="wp-block-heading" id="optimizing-prompts-for-text-to-image-generation"> <a href="https://www.microsoft.com/en-us/research/publication/optimizing-prompts-for-text-to-image-generation/" target="_blank" rel="noreferrer noopener">优化文本到图像生成的提示</a></h3><p>可以提示生成基础模型遵循用户指令，包括语言模型和文本到图像模型。精心设计的提示可以指导文本到图像模型生成令人惊叹的图像。然而，性能提示通常是特定于模型的并且与用户输入不一致。 <a href="https://www.microsoft.com/en-us/research/publication/optimizing-prompts-for-text-to-image-generation/" target="_blank" rel="noreferrer noopener">优化文本到图像生成的提示</a>提出了提示适应，而不是费力的人类工程，这是一个通用框架，可以自动使原始用户输入适应模型首选的提示。</p><p>研究人员使用强化学习来探索更好的语言模型提示。他们定义了一个奖励函数，鼓励策略网络（即语言模型）生成更美观的图像，同时保留原始的用户意图。 Stable Diffusion 的实验结果表明，该方法在自动指标和人类偏好评级方面均优于手动提示工程。强化学习进一步提高了性能，尤其是在域外提示下。 </p><h3 class="wp-block-heading" id="pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck"> <a href="https://www.microsoft.com/en-us/research/publication/pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck/" target="_blank" rel="noreferrer noopener">神经特征学习中的帕累托前沿：数据、计算、宽度和运气</a></h3><p>深度学习中的算法设计看起来更像是“黑客攻击”，而不是工程实践。有许多架构选择和训练启发式方法，它们通常可以以不可预测和复杂的方式调节模型性能和资源成本。因此，在训练大规模神经网络（例如最先进的语言模型）时，算法决策和资源分配首先是经验驱动的，涉及<em>缩放定律</em>的测量和外推。对这一过程的精确数学理解是难以捉摸的，并且不能通过孤立的统计或优化来解释。</p><p>在<a href="https://www.microsoft.com/en-us/research/publication/pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck/" target="_blank" rel="noreferrer noopener">《神经特征学习的帕累托前沿：数据、计算、宽度和运气》一书中，</a>来自微软、哈佛大学和宾夕法尼亚大学的研究人员通过单个合成任务的视角探索了这些算法的复杂性和权衡：有限样本稀疏奇偶校验学习问题。在这种情况下，上述复杂性不仅是显而易见的，而且是可证明的：直观上，由于任务的计算难度，神经网络需要足够的资源<em>组合</em>（“数据×模型大小×训练时间×运气”）才能成功。这项研究表明，深度学习中的标准算法选择会产生<em>帕累托前沿</em>，其中成功的学习是通过这些资源的可互换组合“购买”的。他们表明，对这个玩具问题的算法改进可以转移到现实世界，从而提高神经网络在小型表格数据集上的数据效率。 </p><h3 class="wp-block-heading" id="pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers"> <a href="https://www.microsoft.com/en-us/research/publication/pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers/" target="_blank" rel="noreferrer noopener">PDE-Refiner：使用神经 PDE 求解器实现精确的长推出</a></h3><p>瞬态偏微分方程 (PDE) 在科学和工程中无处不在。传统求解技术的高计算成本激发了人们对基于深度神经网络的偏微分方程代理的兴趣。这种神经偏微分方程求解器的实用性取决于它们在长时间范围内提供准确、稳定的预测的能力，这是一个众所周知的难题。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers/" target="_blank" rel="noreferrer noopener">PDE-Refiner：使用神经 PDE 求解器实现准确的长时间推出</a>，对常见的时间推出策略进行了大规模分析，确定了对非主导空间频率信息（通常与 PDE 解决方案中的高频相关）的忽视，这是限制稳定的主要缺陷，准确的推出性能。受扩散模型最新进展的推动，研究人员开发了 PDE-Refiner，这是一种新颖的模型类，可以通过多步细化过程对所有频率分量进行更准确的建模。他们在复杂流体动力学的挑战性基准上验证了 PDE-Refiner，展示了稳定且准确的推出，始终优于最先进的模型，包括神经、数值和混合神经数值架构。他们还证明，PDE-Refiner 极大地提高了数据效率，因为去噪目标隐式地引入了一种新形式的光谱数据增强。最后，PDE-Refiner 与扩散模型的连接能够准确有效地评估模型的预测不确定性，使研究人员能够估计替代变量何时变得不准确。 </p><h3 class="wp-block-heading" id="should-i-stop-or-should-i-go-early-stopping-with-heterogeneous-populations"> <a href="https://www.microsoft.com/en-us/research/publication/should-i-stop-or-should-i-go-early-stopping-with-heterogeneous-populations/" target="_blank" rel="noreferrer noopener">我应该停止还是应该离开：异质人群的早期停止</a></h3><p>随机实验是确定因果效应的黄金标准方法，无论是在评估医学治疗的临床试验中还是在评估在线产品的 A/B 测试中。但是，当治疗或测试引起意外的有害影响时，随机实验通常需要提前停止。确定何时提前停止实验的现有方法通常应用于汇总数据，并且不考虑治疗效果异质性。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/should-i-stop-or-should-i-go-early-stopping-with-heterogeneous-populations/" target="_blank" rel="noreferrer noopener">我应该停止还是应该离开：异质群体的早期停止</a>研究了早期停止实验对异质群体的伤害。该论文表明，当治疗伤害少数参与者时，当前的方法通常无法阻止实验。研究人员使用因果机器学习开发了异构停止因果潜在分析（CLASH），这是第一个广泛适用的异构早期停止方法。他们展示了 CLASH 在模拟和真实数据上的性能，并表明它可以为临床试验和 A/B 测试提供有效的早期停止。</p><h3 class="wp-block-heading" id="survival-instinct-in-offline-reinforcement-learning"> <a href="https://www.microsoft.com/en-us/research/publication/survival-instinct-in-offline-reinforcement-learning-2/" target="_blank" rel="noreferrer noopener">离线强化学习中的生存本能</a></h3><p>在离线强化学习（RL）中，代理在给定离线数据集的情况下优化其性能。 <a href="https://www.microsoft.com/en-us/research/publication/survival-instinct-in-offline-reinforcement-learning-2/" target="_blank" rel="noreferrer noopener">离线强化学习中的生存本能</a>提出了一个新颖的观察结果：在许多基准数据集上，离线强化学习可以产生性能良好且安全的策略，即使使用“错误”的奖励标签进行训练，例如那些处处为零或真实奖励为负数的标签。这种现象无法简单地用离线强化学习的回报最大化目标来解释。此外，它还为离线强化学习提供了一定程度的鲁棒性，这与在线强化学习相对应的特征不同，众所周知，在线强化学习对奖励设计很敏感。</p><p>这项研究表明，这种令人惊讶的鲁棒性属性可归因于离线强化学习算法中的悲观主义概念与常见数据收集实践中隐含的某种偏见之间的相互作用。这项工作表明，这种悲观主义赋予了智能体一种“生存本能”，即长期留在数据支持范围内的激励，而有限且有偏见的数据覆盖范围进一步限制了生存策略的设定。研究人员认为，在解释现有离线 RL 基准的结果以及创建未来的基准时，应考虑生存本能。 </p><h3 class="wp-block-heading" id="timewarp-transferable-acceleration-of-molecular-dynamics-by-learning-time-coarsened-dynamics"> <a href="https://www.microsoft.com/en-us/research/publication/timewarp-transferable-acceleration-of-molecular-dynamics-by-learning-time-coarsened-dynamics/" target="_blank" rel="noreferrer noopener">时间扭曲：通过学习时间粗化动力学实现分子动力学的可转移加速</a></h3><p>分子动力学 (MD) 是一种成熟的原子级物理系统模拟技术。当准确执行时，它可以提供对分子运动详细力学的无与伦比的洞察力，而无需进行湿实验室实验。 MD 通常用于计算平衡属性，这需要从平衡分布中采样，例如<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://en.wikipedia.org/wiki/Boltzmann_distribution" target="_blank" rel="noreferrer noopener">玻尔兹曼分布<span class="sr-only">（在新选项卡中打开）</span></a> 。然而，许多重要的过程，例如结合和折叠，发生的时间尺度为毫秒或更长，并且无法使用传统 MD 进行有效采样。此外，需要对每个研究的分子系统从头开始进行新的分子动力学模拟。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/timewarp-transferable-acceleration-of-molecular-dynamics-by-learning-time-coarsened-dynamics/" target="_blank" rel="noreferrer noopener">时间扭曲：通过学习时间粗化动力学实现分子动力学的可转移加速</a>提出了一种增强采样方法，该方法使用归一化流作为针对玻尔兹曼分布的马尔可夫链蒙特卡罗方法中的建议分布。该流程在 MD 轨迹上进行离线训练，并学习及时迈出大步，模拟 10^5−10^6fs 的分子动力学。至关重要的是，Timewarp 可以在分子系统之间转移：研究人员表明，经过训练，Timewarp 可以推广到看不见的小肽（2-4 个氨基酸），探索它们的亚稳态，并在采样时与标准 MD 相比提供挂钟加速。这种新方法是开发通用的、可转移的加速 MD 算法的重要一步。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/neurips-2023-highlights-breadth-of-microsofts-machine-learning-innovation/">NeurIPS 2023 强调了微软机器学习创新的广度，该文章</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item><item><title> MatterGen：属性引导的材料设计</title><link/>https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Thu, 07 Dec 2023 20:32:32 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=990009 </guid><description><![CDATA[<p>材料科学的中心问题是发现具有所需特性的材料。 MatterGen 支持广泛的属性引导材料设计。</p><p><a href="https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/">《MatterGen：属性引导材料设计》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1.jpg" alt="物质生成器" class="wp-image-990387" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/MatterGen-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p><a href="https://www.microsoft.com/en-us/research/wp-admin/edit.php?post_type=post"></a>生成式人工智能彻底改变了我们创建文本和图像的方式。设计新颖的材料怎么样？<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/">微软研究院 AI4Science</a>很高兴地宣布推出<a href="https://www.microsoft.com/en-us/research/publication/mattergen-a-generative-model-for-inorganic-materials-design/">MatterGen</a> ，这是我们的生成模型，可实现广泛的属性引导材料设计。</p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/mattergen-a-generative-model-for-inorganic-materials-design/">阅读论文</a></div></div><div class="wp-block-columns aligncenter"><div class="wp-block-column is-vertically-aligned-center aligncenter" style="flex-basis:45%"><figure class="wp-block-video aligncenter"><video autoplay controls loop src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/paper_final_video_firstframe.mp4" playsinline></video></figure></div></div><p>材料科学的核心挑战是发现具有所需特性的材料，例如电池材料的高锂离子电导率。传统上，这是通过首先寻找新颖材料，然后根据应用进行过滤来完成的。这就像尝试通过首先生成一百万个不同的图像，然后搜索有猫的图像来创建猫的图像。在 MatterGen 中，我们直接生成具有所需特性的新型材料，类似于 DALL·E 3 处理图像生成的方式。</p><p> MatterGen 是一种扩散模型，专门用于生成新颖、稳定的材料。 MatterGen 还拥有适配器模块，可以在给定广泛的限制（包括化学、对称性和属性）的情况下进行微调以生成材料。 MatterGen 生成的结构比 SOTA 模型 (CDVAE) 稳定 2.9 倍（训练 + 测试数据凸包的≤ 0.1 eV/原子）、新颖、独特的结构。它还生成接近能量局部最小值 17.5 倍的结构。 MatterGen 可以通过无分类器的指导直接生成满足所需磁性、电子、机械性能的材料。我们使用基于 DFT 的工作流程验证生成的材料。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="1600" height="2133" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1.jpg" alt="图 1（替代文本）该图显示了六对晶体结构，每个属性约束有两对。属性约束从上到下、从左到右为：高空间群对称性、高体积模量、目标化学体系、目标带隙、高磁密度、组合高磁密度和低 HHI 指数。" class="wp-image-990054" style="width:698px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1.jpg 1600w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1-225x300.jpg 225w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1-768x1024.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1-1152x1536.jpg 1152w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1-1536x2048.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/blog_figure_1-135x180.jpg 135w" sizes="(max-width: 1600px) 100vw, 1600px" /><figcaption class="wp-element-caption"><em>图 1：MatterGen 生成的稳定的新材料，但属性受到限制。</em></figcaption></figure><p>此外，MatterGen 可以不断生成满足高体积模量等目标特性的新型材料，而筛选方法却因数据库中的材料耗尽而饱和。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1637" height="955" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1.jpg" alt="这是一个线图。 x轴表示DFT属性计算调用次数； y 轴报告找到的结构的数量。剧情标题说"Bulk modulus greater than 400 gigapascal". 
The plot has three lines, one for MatterGen, one for Screening, and one for Labeled Data. The line for MatterGen increases linearly and reaches a y value of 260 at the x value of 500. The line for screening increases until an x value of 300 and then remains almost flat, plateauing at a level of y equaling 140 for x equaling 500. 
The line for Labeled Data remains flat at the y value of 2 for every value of x." class="wp-image-990024" style="width:672px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1.jpg 1637w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1-300x175.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1-1024x597.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1-768x448.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1-1536x896.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1-480x280.jpg 480w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/bulk_modulus_line-1-240x140.jpg 240w" sizes="(max-width: 1637px) 100vw, 1637px" /><figcaption class="wp-element-caption"><em>图 2：MatterGen 发现了比筛选基线更新颖的稳定高体积模量材料，并且不会因计算资源的增加而停滞不前。 MatterGen 可以找到超过 250 种体积模量 >; 400 GPa 的材料，而在参考数据集中只找到 2 种这样的材料。</em></figcaption></figure><p> MatterGen 还可以在给定目标化学系统的情况下生成材料。它的性能优于配备 MLFF 过滤的替换和随机结构搜索基线，特别是在具有挑战性的 5 元素系统中。 MatterGen 还可以生成给定目标空间群的结构。最后，我们解决了寻找低供应链风险磁铁的多属性材料设计问题。 MatterGen 提出了具有高磁场密度和低供应链风险化学成分的结构。</p><p>我们相信 MatterGen 是材料设计人工智能领域向前迈出的重要一步。我们的结果目前通过 DFT 进行验证，但它有许多已知的局限性。实验验证仍然是实际影响的最终检验，我们希望后续能有更多结果。</p><p>如果没有<a href="https://www.microsoft.com/en-us/research/people/fowlerandrew/">Andrew Fowler</a> 、 <a href="https://www.microsoft.com/en-us/research/people/claudiozeni/">Claudio Zeni</a> 、 <a href="https://www.microsoft.com/en-us/research/people/dzuegner/">Daniel Zügner</a> 、 <a href="https://www.microsoft.com/en-us/research/people/mahorton/">Matthew Horton</a> 、 <a href="https://www.microsoft.com/en-us/research/people/rpinsler/">Robert Pinsler</a> 、 <a href="https://www.microsoft.com/en-us/research/people/ryoto/">Ryota Tomioka</a> 、 <a href="https://www.microsoft.com/en-us/research/people/tianxie/">Tian Xie</a>以及我们出色的实习生 Fu 翔、Sasha Shysheya、Jonathan Crabbé 以及<a href="https://www.microsoft.com/en-us/research/people/jakesmith/">Jake</a>之间的高度协作，这一切都是不可能实现的<a href="https://www.microsoft.com/en-us/research/people/jakesmith/">Smith</a> 、 <a href="https://www.microsoft.com/en-us/research/people/lixinsun/">Lixin Sun</a>和整个 AI4Science 材料设计团队。</p><p>我们还感谢 Microsoft Research、 <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/">AI4Science</a>和 Azure Quantum 的所有帮助。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/">《MatterGen：属性引导材料设计》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </content:encoded><enclosure length="15811037" type="video/mp4" url="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/paper_final_video_firstframe.mp4"></enclosure></item></channel></rss>