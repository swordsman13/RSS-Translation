<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 9 月 7 日星期四 14:00:21 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.1</generator><item><title>将化学家的见解与人工智能模型相结合，进行单步逆合成预测</title><link/>https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 07 Sep 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=964185 </guid><description><![CDATA[<p>逆合成分析是有机化学中的一项关键任务，也是许多重要行业的核心。它主要涉及将目标分子逐步分解为市售分子。由于合成策略可能非常多样化且具有战略性，因此利用专业知识进行逆合成规划长期以来一直被认为是一门“艺术”。最近，基于机器学习的方法已经实现了[...]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/">将化学家的见解与 AI 模型相结合进行单步逆合成预测一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img decoding="async" fetchpriority="high" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1024x576.png" alt="逆合成 -" class="wp-image-964194" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog-hero-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>逆合成分析是有机化学中的一项关键任务，也是许多重要行业的核心。它主要涉及将目标分子逐步分解为市售分子。由于合成策略可能非常多样化且具有战略性，因此利用专业知识进行逆合成规划长期以来一直被认为是一门“艺术”。</p><p>最近，基于机器学习的方法在这项任务上取得了有希望的结果，特别是在单步逆合成预测方面。在逆合成中，分子可以表示为 2D 图或 1D SMILES（简化分子输入行输入系统）序列。 SMILES 是一种用纯文本表示化学结构的符号系统，由一系列字符组成，用于描述分子内原子、键和环的排列。 SMILES可以认为是对相应分子图的遍历，如图1所示。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="720" height="480" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Fig1_SMILES.gif" alt="逆合成 -" class="wp-image-964191"/><figcaption class="wp-element-caption">图 1：分子图和 SMILES 字符串的示例</figcaption></figure><p>给定分子的表示，大多数基于机器学习的方法都采用编码器-解码器框架，其中编码器部分将分子（目标产品）序列或图编码为高维向量，解码器从编码器获取输出并生成逐个标记自回归地输出序列（预测的反应物）。</p><p>将逆合成分析作为序列解码问题可以使用在机器翻译或图神经网络中成熟的深度神经架构。虽然人工智能在预测反应物方面取得了重大进展，但承认人类化学家的专业知识至关重要。在现实世界的路线探索任务中，合成化学家依靠他们的专业经验和对潜在机制的抽象理解。它们通常从化学上与目标分子相似的分子子结构或片段开始，为可能产生目标产物的一系列化学反应提供线索。</p><p>我们的论文《 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41467-023-37969-w" target="_blank" rel="noreferrer noopener">利用普遍保留的子结构进行单步逆合成预测<span class="sr-only">》（在新选项卡中打开）</span></a>提出了一种利用有机合成中普遍保留的子结构的新方法。这种方法融合了化学家在逆合成方面的见解，使人工智能模型更接近人类专家的思维方式。</p><h2 class="wp-block-heading" id="substructure-extraction-and-modeling">子结构提取和建模</h2><p>在有机化学的背景下，“子结构”是指化学性质相似或保留在目标分子内的分子片段或较小的结构单元。这些子结构是理解复杂分子组装的重要组成部分，并在逆合成分析中发挥着重要作用。</p><p>基于这个概念，我们的框架由三个主要模块组成：</p><ol><li><strong>反应检索</strong>：该模块检索相似的反应，给定产品分子作为查询。它使用可学习的跨语言记忆检索器在高维向量空间中对齐反应物和产物。</li><li><strong>子结构提取</strong>：我们根据分子指纹从产品分子和顶部交叉比对候选物中提取常见子结构。这些子结构提供了反应物和产物之间的反应级、片段到片段的映射。</li><li><strong>子结构级序列到序列学习</strong>：我们将原始标记级序列转换为子结构级序列。新的输入序列包括子结构的 SMILES 字符串，后跟具有虚拟数字标签的其他片段的 SMILES 字符串。输出序列是带有虚拟编号的片段。虚拟数字用于指示键断裂/连接位点。 </li></ol><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="680" height="592" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2.png" alt="逆合成 -" class="wp-image-964203" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2.png 680w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2-300x261.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure2-207x180.png 207w" sizes="(max-width: 680px) 100vw, 680px" /><figcaption class="wp-element-caption">图 2：方法概述，其中虚拟数字标记的原子和子结构以绿色突出显示。</figcaption></figure><p>与大多数现有工作不同，我们的模型只需要预测与子结构连接的片段，从而简化了预测任务，子结构部分保持不变。</p><p>在图2所示的例子中，子结构“COC(=O)Cc1cc2ccc(F)cc2[2cH]c1C.C[1SH](=O)=O”保持不变，模型只需要预测片段“[2BH]2OC(C)(C)C(C)(C)O2。[1cH]1ccc(Br)nc1”。然后将子结构 SMILES 和预测片段 SMILES 组合起来形成完整的反应物 SMILES。 </p><div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="932112"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/" aria-label="AI Frontiers: AI for health and the future of research with Peter Lee" data-bi-cN="AI Frontiers: AI for health and the future of research with Peter Lee" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/PeterLee_podcast-2023Mar_hero_1400x788.png" alt="Peter Lee 戴着眼镜，对着镜头微笑，左侧有 Microsoft Research Podcast 徽标" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 前沿：Peter Lee 的 AI 健康与研究的未来</h2><p class="large">微软研究院院长 Peter Lee 和 AI 科学家兼工程师 Ashley Llorens 讨论了 AI 研究的未来以及 GPT-4 作为医疗副驾驶的潜力。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: AI for health and the future of research with Peter Lee" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="retrosynthesis-prediction">逆合成预测</h2><p>我们使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.uspto.gov/patents" target="_blank" rel="noreferrer noopener">美国专利商标局完整数据集<span class="sr-only">（在新选项卡中打开）</span></a>分析了我们的方法，并将其与该领域的其他著名作品进行了比较。与之前测试的方法相比，几乎在每种情况下，我们的方法都实现了可比或更好的 top-1 准确度。在成功提取子结构的数据子集中，与总体结果相比，模型性能显着提高。</p><p>我们方法的改进可归因于两个主要因素：</p><ol><li>我们的方法成功地从 USPTO 完整测试数据集中 82.2% 的产品中提取了子结构，证明了该方法的普遍适用性。</li><li>我们只需要生成连接到子结构中虚拟标记原子的片段，这缩短了分子的字符串表示，并显着减少了要预测的原子数量。 </li></ol><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="671" height="588" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3.png" alt="逆合成 -" class="wp-image-964206" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3.png 671w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3-300x263.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure3-205x180.png 205w" sizes="(max-width: 671px) 100vw, 671px" /><figcaption class="wp-element-caption">图 3：产品分子特定的子结构。这些反应物均含有邻苯二甲酰亚胺，其子结构以绿色突出显示。</figcaption></figure><p>我们的一步逆合成方法的一个关键方面是提取产品特定的子结构。通过这样做，我们可以更好地捕捉每个反应特有的从反应物到产物的微妙结构变化。以常见的杂环亚结构邻苯二甲酰亚胺为例。我们分析了反应物含有邻苯二甲酰亚胺的四个示例性反应（见图 3）。提取的子结构因不同的反应类型而异，证明了子结构的产物特异性。</p><p>在反应 (a) 和反应 (b) 中，邻苯二甲酰亚胺不被视为子结构的一部分，因为它包含了该反应。然而，在反应(c)和反应(d)中，子结构不同，但它们都含有邻苯二甲酰亚胺。这些结果表明子结构确实是特定于产品的，这符合我们的预期。</p><h2 class="wp-block-heading" id="incorporating-human-insights-into-decision-making">将人类洞察纳入决策</h2><p>此外，利用普遍保留的子结构还具有另一个好处：为用户提供逆合成规划决策的宝贵见解。与现有方法相比，我们的方法可以帮助人类专家利用他们的化学知识评估潜在的途径并消除不可行的反应。</p><p>对于每个输入产物分子，我们从检索到的反应中提取多个子结构（请参阅我们论文中的详细信息），并且在某些情况下，并非所有子结构都是正确的。因此，我们可以按子结构对预测进行分组。如图 4 所示，预测的反应物和反应组为专家提供了有价值的信息。例如，他们可以通过比较与检索到的候选者相关的反应来完善预测，从而使我们的预测比现有的“黑盒”模型更可解释且更值得信赖。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="647" height="854" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4.png" alt="逆合成 -" class="wp-image-964209" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4.png 647w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4-227x300.png 227w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-blog_figure4-136x180.png 136w" sizes="(max-width: 647px) 100vw, 647px" /><figcaption class="wp-element-caption">图 4：按子结构分组的子结构和预测。检索到的候选反应物（#2、#3 和 #4）表明从检索到的反应物 #1 中提取的子结构可能不正确，因为三键可能是反应位点。提取的子结构以绿色突出显示。</figcaption></figure><p>我们希望我们的工作能够激发人们对逆合成预测和其他相关主题这一快速发展且高度跨学科领域的兴趣。通过突破化学和机器学习的可能性界限，我们可以在理解复杂的化学反应和设计更有效的逆合成策略方面继续取得进展。</p><div class="wp-block-buttons"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/single-step-retrosynthesis-prediction-by-leveraging-commonly-preserved-substructures/">阅读论文</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/">将化学家的见解与 AI 模型相结合进行单步逆合成预测一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>多模式学习的前沿：负责任的人工智能方法</title><link/>https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 06 Sep 2023 19:53:53 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>如果我们要构建推进人类目标的多模式人工智能系统，就必须采用新的评估方法并致力于持续改进。了解 Microsoft 对多模式 AI 负责任的开发和使用的前沿研究。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/">多模态学习的前沿：负责任的人工智能方法</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[<aside id=accordion-0db0636a-7f49-438e-8f59-d2fa6ee07da1 class="msr-table-of-contents-block accordion mb-5 pb-0" data-bi-aN="table-of-contents"> <button class="btn btn-collapse bg-gray-100 mb-0 display-flex justify-content-between" type="button" data-mount="collapse" data-target="#accordion-collapse-0db0636a-7f49-438e-8f59-d2fa6ee07da1" aria-expanded="true" aria-controls="accordion-collapse-0db0636a-7f49-438e-8f59-d2fa6ee07da1"><span class="msr-table-of-contents-block__label subtitle">在本文中</span><span class="msr-table-of-contents-block__current mr-4 text-gray-600 font-weight-normal" aria-hidden="true"></span></button> <div id="accordion-collapse-0db0636a-7f49-438e-8f59-d2fa6ee07da1" class="msr-table-of-contents-block__collapse-wrapper collapse show" data-parent="#accordion-0db0636a-7f49-438e-8f59-d2fa6ee07da1"><div class="accordion-body bg-gray-100 border-top pt-4"><ol class="msr-table-of-contents-block__list"><li class="msr-table-of-contents-block__list-item"> <a href="#unmasking-hidden-societal-biases-across-modalities" class="msr-table-of-contents-block__list-item-link">揭露各种模式中隐藏的社会偏见</a></li><li class="msr-table-of-contents-block__list-item"><a href="#navigating-distributional-shifts-and-spurious-correlations" class="msr-table-of-contents-block__list-item-link">应对分布变化和虚假相关性</a></li><li class="msr-table-of-contents-block__list-item"><a href="#decomposing-evaluation-for-controllability-and-precision-in-multimodal-generation" class="msr-table-of-contents-block__list-item-link">多模态生成中可控性和精度的分解评价</a></li><li class="msr-table-of-contents-block__list-item"><a href="#beyond-offline-benchmarks-leveraging-adaptation-and-continual-learning-approaches" class="msr-table-of-contents-block__list-item-link">超越离线基准：利用适应和持续学习方法</a></li><li class="msr-table-of-contents-block__list-item"><a href="#related-reading" class="msr-table-of-contents-block__list-item-link">相关阅读</a></li></ul></div></div><span class="msr-table-of-contents-block__progress-bar"></span></aside><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1.png" alt="负责任的 AI 博客 - 带有连接圆圈的英雄图形，其中的图标描绘了隐藏式字幕、日历、图像和圆圈内的文档" class="wp-image-965712" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>在人工智能领域，新领域并不局限于单一的表达形式；快节奏的发展正在多种模式的交汇处发生。多模态人工智能系统可以跨文本、图像和其他数据类型进行分析、合成和生成，正在为生产力、医疗保健、创造力和自动化等领域令人兴奋的应用铺平道路。由于人类在物理世界中的感知和解决问题会利用多种模式，因此与跨单一模式运行的系统相比，这种多模式系统提供了更加自然和无缝的支持。这些新兴的人工智能系统由大量数据集和变压器等先进架构的融合提供支持。然而，当我们测试和推进这些系统的功能时，出现了一个关键问题：我们如何确保它们负责任的开发和部署？一种方法是通过对其基础模型进行严格评估。</p><p>当你穿越数字世界时，内容的丰富性是显而易见的——视频与文本交织在一起，图像为文章提供背景，音频文件通常带有转录。在这个数字挂毯中，多模态模型就像编织者，将不同的线程组合成一个连贯的整体。然而，与所有工具一样，它们也并非没有挑战。他们的评估需要超越传统指标的细致入微的理解。</p><p>在 Microsoft，我们尝试并以开源模型为基础进行构建。我们还有机会和荣幸研究 Microsoft 和 OpenAI 开发的尖端模型。尽早访问这些模型有助于我们研究模型的功能，了解它们的局限性和故障模式，并在将它们集成到产品中或更广泛发布之前制定缓解计划。几年前，微软的<a href="https://www.microsoft.com/en-us/ai/principles-and-approach/#tabs-pill-bar-ocb9d4_tab1" target="_blank" rel="noreferrer noopener">以太委员会</a>建立了特殊的跨公司工作流程，以便尽早严格研究基础模型和基础模型的新应用，重点<em>调查</em>和<em>识别</em>潜在的风险和危害。由此产生的报告和简报为 Microsoft 提供了两个关键的后续步骤：对模型功能和限制进行进一步深入<em>调查的研究工作</em>，以及衡量和缓解这些风险的<em>工程工作</em>。</p><p>一项研究旨在探索多模式文本到图像模型。这项研究是与 OpenAI 的同事共同完成的，包括具有不同背景和不同专业知识的贡献者，例如工程、人工智能和负责任的人工智能研究、安全和政策。该研究包括红队合作，以了解故障模式并提供此类故障更常见的示例；研究负责任地部署多模式模型的交互范式和最佳实践；建立测量和缓解技术以纳入模型开发和部署生命周期的初步工程工作；以及对这些模式的长期考虑，例如它们对艺术家权利和工作的影响。这些发现激发了进一步调查，更正式地量化这些失败，特别是因为它们与公平相关的损害有关。在本博客中，我们将介绍 Microsoft Research 的一些研究和其他针对多模态 AI 的突破性工作，研究评估多模态模型的复杂性及其改进路径。我们的观点由四个关键观察构成：</p><ol><li>不同内容类型的组合带来了新的意外伤害风险，即使使用“安全”系统输入也可能发生这种风险。</li><li>互联网规模数据的庞大规模和多样性使得能够开发能够执行多种任务的模型。但这些数据并不能反映现实的各个方面，导致模型在存在分布变化和虚假相关性的情况下表现不佳。</li><li>当前基准测试中使用的通用分数无法完全评估生成能力的可控性，或者用户在获得他们想要的精确输出方面有多大影响力。评估可控性需要新的协议，通过关注基本技能（即在许多场景中重要的技能）来分解评估。</li><li>为了弥合离线测量可以捕获的内容与开放世界中模型的功能之间的差距，研究人员和开发人员必须采用适应和持续学习方法，这也带来了挑战。</li></ol><h2 class="wp-block-heading" id="unmasking-hidden-societal-biases-across-modalities">揭露各种模式中隐藏的社会偏见</h2><p><strong>观察 1</strong> ：不同内容类型的组合带来了新的意外伤害风险，即使使用“安全”系统输入也可能发生这种风险。</p><p>我们的研究表明，视觉+语言模型的“双方”都可能出现意外伤害的新风险。例如，最近的研究<a href="https://www.microsoft.com/en-us/research/publication/social-biases-through-the-text-to-image-generation-lens/" target="_blank" rel="noreferrer noopener">“通过文本到图像生成镜头的社会偏见”</a>表明，诸如“首席执行官的照片”和“计算机程序员的照片”之类的提示到 DALL-E v2 会产生图像没有被人类注释者视为女性的个体的代表。尽管自然语言提示不包含强化社会偏见的语言，但图像输出中缺乏女性代表与劳工统计数据背道而驰，强化了有害的刻板印象，即没有女性首席执行官或程序员和/或女性没有有能力胜任此类职业。同样，稳定扩散的“护士照片”和“管家照片”等提示会导致图像不代表被注释者视为男性的个体。除了与职业相关的提示之外，该研究还表明，与性格特征和日常情况相关的提示也可能无法产生多样化的输出。例如，提示“婚礼”可能会导致系统生成仅对应于西方婚礼视觉风格的图像。这项研究表明，即使给出更明确的提示来命名特定地理位置，例如“尼日利亚的生日聚会”，这些系统也可能生成明显质量较低的图像。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="301" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-1024x301.jpg" alt="图 1：使用 DALL-E v2 和稳定扩散模型的“计算机程序员”和“管家”职业的世代示例。" class="wp-image-965184" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-1024x301.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-300x88.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-768x225.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-240x70.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 1：使用 DALL-E v2 和稳定扩散模型为“计算机程序员”和“管家”职业生成的前四个图像的示例。值得注意的是，在 500 张生成的图像分布中明显缺少一种性别（如人类注释者所感知的）。</figcaption></figure><p>同样，对于图像到文本的场景， <a href="https://www.microsoft.com/en-us/research/publication/measuring-representational-harms-in-image-captioning/">另一项研究</a>表明，对于常见情况的图像（来自 COCO 数据集），模型可以生成排除或错误添加单词的说明，其方式可能是由社会偏见来解释的。训练数据。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="258" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-1024x258.jpg" alt="图 2：系统为 COCO 数据集的图像生成的标题示例。其中包括可能由刻板印象解释的不准确之处。例如，一张拿着吹风机的女人的图片被标题为“一个戴着眼镜拿着一瓶酒的女人”。" class="wp-image-965187" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-1024x258.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-300x76.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-768x194.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-240x61.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 2：系统为 COCO 数据集生成的标题示例，可能通过刻板印象进行解释。这些情况包括实际上不正确的粗体文本。</figcaption></figure><p><strong>评估和模型改进策略：</strong></p><p>正如《 <a href="https://www.microsoft.com/en-us/research/publication/taxonomizing-and-measuring-representational-harms-a-look-at-image-tagging/" target="_blank" rel="noreferrer noopener">分类和衡量代表性危害：审视图像标签</a>》中所探讨的那样，没有一种方法可以识别或衡量代表性危害，即某些社会群体不如其他群体值得关注或不如其他群体的表征。值得注意的是，虽然一些危害在单独观察单个输入或输出时会很明显，但其他危害只有在组合观察或跨越多代的输入或输出时才会变得明显。因此，有效的评估通常需要混合使用测量方法，包括检查已知令人反感的特定输入或输出（或特定输入-输出对），根据人口统计寻找输出的准确性或质量差异群体，审查按人口群体划分的产出分布差异，并确定对投入的具体扰动如何影响产出等。<strong> </strong>从这项工作和文本到图像生成工作中可以得出的另一个关键见解是需要内容过滤或选择策略，这些策略可以在不同的模式上运行，以解决输入和输出以及生成的不同阶段的潜在危害过程。</p><p>文本到图像生成工作探索的另一种缓解技术是即时扩展。在初始提示中添加描述符（例如，在提示“播音员的肖像”中指定“女性”）被证明对于创建指定内容最有效；然而，生成的内容在人口统计特征和背景和服装等特征方面的多样性较低，并且图像质量较低，如图 3 所示。考虑到这些额外的问题，虽然通过扩展提示来增强控制很有用，但同时，它也为人们提供足够的透明度和机构来控制迅速扩张非常重要，以便他们能够实现预期的结果。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="598" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-1024x598.jpg" alt="图 2：系统为 COCO 数据集的图像生成的标题示例。其中包括可能由刻板印象解释的不准确之处。例如，一张拿着吹风机的女人的图片被标题为“一个戴着眼镜拿着一瓶酒的女人”。" class="wp-image-965190" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-1024x598.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-300x175.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-768x448.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-480x280.jpg 480w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-240x140.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 3：使用“女性”等描述符的扩展提示确实可以产生更多样化的描述，但通常以图像多样性和质量为代价。用于衡量图像质量的 Fréchet 起始距离 (FID) 越高，生成的图像与真实图像的距离就越远。令人惊讶的是，提示“男性播音员的肖像”的 FID 得分为 164。 </figcaption></figure><h2 class="wp-block-heading" id="navigating-distributional-shifts-and-spurious-correlations">应对分布变化和虚假相关性</h2><p><strong>观察 2</strong> ：互联网规模数据的庞大规模和多样性使得能够开发能够执行各种任务的模型。但这些数据并不能反映现实的各个方面，导致模型在存在分布变化和虚假相关性的情况下表现不佳。</p><p>从历史上看，机器学习模型一直在封闭世界的假设下运行，受到训练数据或特定应用环境的限制。互联网规模数据的出现及其看似超越这些界限的潜力引起了人们的极大兴奋，但​​现实是存在重大问题。互联网规模数据集中发现的巨大多样性并不一定反映现实世界的分布。某些日常物体或概念可能仍然很少见或代表性不足，例如，在安全关键的应用程序中，例如帮助残疾人，如<a href="https://www.microsoft.com/en-us/research/publication/disability-first-datasets/">“残疾优先数据集创建：通过盲和低技术构建可教物体识别数据集的经验教训”</a>中所示<a href="https://www.microsoft.com/en-us/research/publication/disability-first-datasets/">视觉数据收集器。”</a></p><p>因此，多模态基础模型尽管拥有庞大的训练数据集，但仍然容易受到分布变化（即训练数据与现实数据之间的差异）和虚假相关性的影响，或者巧合特征可能错误地影响模型预测的情况。在最近的论文<a href="https://www.microsoft.com/en-us/research/publication/mitigating-spurious-correlations-in-multi-modal-models-during-fine-tuning/">《在微调过程中减轻多模态模型中的虚假相关性》中，</a>研究人员发现，当测试时的示例中不存在虚假相关性时，CLIP 等模型就无法表现良好。例如，当图片中有婴儿时，CLIP 对奶嘴进行分类的准确度为 92.9%（零样本），但当图片中没有婴儿时，准确度仅为 30.8%。基于梯度的解释表明，在很多情况下，即使模型是准确的，它也会针对娃娃脸或背景进行预测，在这种情况下，它是因为错误的原因而正确的。那么，在这个例子中，虚假特征就是婴儿。当婴儿在场时，该模型更有可能做出正确的预测，而在婴儿不在场时，该模型则不太可能做出正确的预测。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="460" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-1024x460.jpg" alt="图 4：左：大型多模态基础模型学习依靠虚假相关性进行预测的示例。例如婴儿奶嘴、开罐器、橡皮、口哨和卷笔刀的图像。右图：模式解释在缓解后从虚假特征转变为正确特征的图示。" class="wp-image-965193" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-1024x460.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-300x135.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-768x345.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-240x108.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 4：大型多模态基础模型学习依靠虚假相关性进行预测的示例。</figcaption></figure><p><strong>评估和模型改进策略：</strong><em>不同条件下的误差分析和分类评估</em>：分布外检测文献建议用最差组准确度来补充平均准确度。准确度最差的组通常也对应于受分布变化和虚假相关性影响最严重的组。误差分析和公平性评估的扩展方法表明，对不同输入条件的评估进行分解或分解可以提供一种有效的方法来发现和评估常见的可靠性或公平性问题以及虚假相关性（参见下面的列表）<a href="#literature">有关分类评估和误差分析的文献</a>）。过去，视觉和多模态任务的输入条件是根据元数据或视觉特征（例如光照条件、图像大小、颜色、模糊和图像质量）指定的（“ <a href="https://www.microsoft.com/en-us/research/publication/a-large-scale-robustness-analysis-of-video-action-recognition-models/" target="_blank" rel="noreferrer noopener">视频动作识别模型的大规模鲁棒性分析</a>”）在存在此类扰动的情况下，会降低卷积和变换器视觉模型的性能）。如今，开放词汇模型（即那些不限于预定义的封闭概念集的模型）的可用性创造了为视觉内容生成软标签或元数据的可能性，然后可以将其用于表征故障，例如减轻虚假相关性工作中显示。为了说明这一点，该工作使用具有开放词汇表的对象检测模型来检测内容标签，例如<em>baby</em> 、 <em>can</em> 、 <em>hand</em> 、 <em>ring</em>和<em>pencil</em> ，如图4所示，然后用它来分析是否存在此类内容的增加与准确性的显着下降有关。</p><p><em>评估模型是否因正确的原因而正确：</em>除了误差分析之外，评估的一个关键部分是模型是否因正确的原因而正确，正如减轻虚假相关性工作中所探讨的那样。回到奶嘴的例子，当奶嘴在婴儿旁边或被婴儿使用时，模型可以识别出奶嘴，这很好，但在现实世界中，情况并非总是如此。安抚奶嘴可能位于沙发下、桌子上或商店货架上，在所有情况下模型都不太可能正确识别它。在不同的情况下，对模型是否“因正确的原因而正确”的检查可能会有所不同。例如，在图像分类中，模型解释和地面实况边界框之间的交集是一个很好的指标。该指标称为<em>“调整交并并”</em> ，与最差组准确度一起，它为评估虚假相关性的存在提供了良好的画面。</p><p>早期的论文<a href="https://www.microsoft.com/en-us/research/publication/squinting-at-vqa-models-introspecting-vqa-models-with-sub-questions/">“SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions” <span class="sr-only">（在新选项卡中打开）</span></a>中提出了用方法丰富通用指标的另一个例子，这些方法也测试了预测背后的原因，该论文检查了视觉问答（VQA） ） 任务。鉴于 VQA 模型可能会在特定答案上表现出统计偏差（例如，对于是/否问题大多回答“是”），该工作提出了一个基准、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/VQA-introspect" target="_blank" rel="noreferrer noopener">VQA-Introspect <span class="sr-only">（在新选项卡中打开）</span></a>和一个分解模型将较大的任务分解为较小的较简单的任务。例如，如果有关照片的问题是“照片中似乎有紧急情况吗？”并且模型可以正确回答这个问题“是”，它还应该能够回答更简单的问题，例如“照片中有消防车吗？” </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="167" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-1024x167.jpg" alt="图 5：来自 VQA-Introspect 数据集的图像示例、主要推理问题和子问题。左：结婚照的图像和主要推理问题“这是一张纪念照片吗？是的。” “这是黑白照片吗？是”是子问题之一。右图：动物园里的长颈鹿的图片和相应的问题。" class="wp-image-965196" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-1024x167.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-300x49.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-768x126.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-240x39.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 5：来自 VQA-Introspect 数据集的示例，它通过评估模型是否能够回答主要问题所需的更简单的子问题来分解模型回答复杂问题的能力。</figcaption></figure><p>为了更好地理解 VQA 任务模型的视觉感知和推理能力之间的关系， <a href="https://www.microsoft.com/en-us/research/publication/neuro-symbolic-visual-reasoning-disentangling-visual-from-reasoning-2/">“神经符号视觉推理：将‘视觉’与‘推理’分离”</a>通过独立评估对象检测和关系表示学习的质量将这两个方面分开彼此的。对于调试模型中何时以及如何发生缺乏推理来说，这是一个重要的区别。研究发现，当模型能够访问真实视觉信息时，它可以仅使用一阶逻辑以 96% 的准确度解决具有挑战性的 VQA 任务，这表明模型在任务中的成功与更好的视觉特征提取有关方法。利用这一发现，本文提出了一种利用所提出模型的推理组件的反馈来改进弱视觉特征提取方法的方法。</p><p><em>从识别和测量到缓解：</em>多模态和开放词汇模型不仅有助于生成用于表征模型性能的元数据，而且还开辟了模型改进的新领域。特别是，给定模态内和跨模态的对比学习创造了直接指导优化过程以将虚假特征与目标概念分开的机会。更令人兴奋的是，由于现在可以使用元数据标记实例或使用标题中提供的信息，因此可以用语言来表达什么是虚假特征以及是否应该使用它来对目标概念进行分类的规范。例如，在减轻虚假相关性论文中，研究人员使用额外的损失来指定优化过程，即“婴儿”一词和包含“婴儿”的图像应该在表示空间中远离“奶嘴”表示，以便模型创建单个对象（在本例中为奶嘴）的更稳健的表示。同样，他们表明可以改进更困难的虚假相关性基准，例如水鸟数据集，其中陆地鸟类被有意放置在水背景中，水鸟被放置在陆地背景中，以研究背景虚假相关性对分类的影响。他们表明，预训练的 CLIP 模型（带有 ResNet 或 Transformer 核心）确实对这些特征进行了索引，但在通过对比学习添加这些规范后，它们提高了最差组的准确性并专注于相关概念（见图 4）。 </p><div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956148"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/" aria-label="AI Frontiers: Models and Systems with Ece Kamar" data-bi-cN="AI Frontiers: Models and Systems with Ece Kamar" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/ece-podcast-_Topic_podcast-2023Mmm_hero_1400x788_16-9.jpg" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能前沿：Ece Kamar 的模型和系统</h2><p class="large">Ece Kamar 探索短期缓解技术，使这些模型成为人工智能系统的可行组成部分，赋予它们目的，并分享有助于最大化其价值的长期研究问题。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: Models and Systems with Ece Kamar" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="decomposing-evaluation-for-controllability-and-precision-in-multimodal-generation">多模态生成中可控性和精度的分解评价</h2><p><strong>观察3：</strong>当前基准测试中使用的通用分数无法完全评估生成能力的可控性，或者用户在获得他们想要的精确输出方面有多大影响力。评估可控性需要新的协议，通过关注基本技能（即在许多场景中重要的技能）来分解评估。</p><p>由于许多基础模型（包括多模态模型）已被训练来完成生成任务，因此它们的主要评估通常依赖于 Fréchet 起始距离（FID）或起始分数等分数。这些分数是衡量输出质量的良好指标。例如，在生成的图像的情况下，输出质量可以是真实感，在生成的字幕的情况下，输出质量可以是连贯性。但它们并没有反映出这一代人如何很好地捕捉输入提示的重要方面。如果没有这些信息，就很难确定模型的可控性。生成图像的其他方面可能与它看起来的“真实”程度一样重要。考虑空间理解。它是一系列需要仔细控制的更复杂任务的基本子任务，包括语言引导任务、对象操作、导航和场景理解。这里的误解不仅令人沮丧，而且令人沮丧。它们可能会妨碍生产力或对安全关键型应用有害。根据<a href="https://www.microsoft.com/en-us/research/publication/benchmarking-spatial-relationships-in-text-to-image-generation/">“文本到图像生成中的空间关系基准测试”的研究结果，</a>很明显当前的文本到图像模型经常会误解空间线索。现有的指标（例如 FID 甚至对象准确度）似乎不够敏感，无法标记这些空间错误。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="248" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-1024x248.jpg" alt="图 6：使用指定空间关系的提示生成的图像示例，但所描绘的关系不正确。" class="wp-image-965199" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-1024x248.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-300x73.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-768x186.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-240x58.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 6：使用指定空间关系的提示生成的图像示例。</figcaption></figure><p><strong>评估和模型改进策略</strong>：为了考虑空间理解，对空间关系进行基准测试的研究提出了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/VISOR" target="_blank" rel="noreferrer noopener">验证空间对象关系或 VISOR <span class="sr-only">（在新选项卡中打开）的</span></a>分数，该分数将这些能力的评估分解为两部分：</p><ol><li>生成的图像是否包含所有指定的对象？</li><li>生成的对象的空间配置是否遵循提示中指定的空间关系？</li></ol><p>例如，在研究中，具有最佳对象准确度生成的模型 (DALL-E v2) 可以在 64% 的时间内生成所有指定对象（由人类注释者评分）。在这些世代中，对象之间的关系在 59% 的情况下是准确的（如提示中指定的）。从用户体验来看，这意味着模型将在不到 40% 的时间内完全生成提示中指定的内容。</p><p>除了这些评估结果之外，该工作还建议利用自动化评估，这对于复杂的任务通常具有挑战性。但通过将评估分解为更小的任务，研究发现可以使用其他形式的机器学习和计算机视觉来进行细粒度的自动化评估。例如，与人工注释的分数并行，该研究使用了 VISOR 的自动化版本。该自动化版本利用对象检测器来评估对象准确性，并利用边界框定位技术来评估空间关系。随着任务变得越来越复杂，进一步分解微任务的评估变得更加重要，也是一个有前途的方向。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="241" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-1024x241.jpg" alt="图 7：该图显示了 VISOR 分数如何将空间理解的评估分解为对象检测和关系评估，以大象骑着摩托车过马路的照片为例。" class="wp-image-965202" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-1024x241.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-300x71.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-768x180.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-240x56.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 7：VISOR 通过使用其他机器学习和计算机视觉技术来首先检测对象，然后评估它们的空间关系，从而使用指标和任务分解进行评估。</figcaption></figure><p>随着对模型可控性有了更好的理解，我们可以开始开发改进模型的方法。完善多模式模型的一个关键方面是其训练数据。例如，由于用于训练的现有图像说明不优先考虑空间关系（通常它们是隐含的或不显着的），因此可以使用自动文本数据增强来生成指定空间关系的替代说明（例如，“一辆卡车在摩托车前面”）。利用类似的直觉， <a href="https://www.microsoft.com/en-us/research/publication/kosmos-2-grounding-multimodal-large-language-models-to-the-world/">“Kosmos-2：为世界奠定多模态大型语言模型”</a>背后的研究人员构建了一个大规模的基于图像-文本对的数据集，其中还包含对象位置的描述。科斯莫斯-2,<strong> </strong>新的多式联运模式<strong> </strong>在数据集上进行训练，在任务上表现出更高的准确性，这些任务直接受益于模式之间更好的基础，例如导航。</p><p>机器学习模型（尤其是生成模型）的输出会根据<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/completions" target="_blank" rel="noreferrer noopener">生成温度<span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering" target="_blank" rel="noreferrer noopener">提示工程<span class="sr-only">（在新选项卡中打开）</span></a>和固有模型随机性等因素而变化。当然，虽然这些都是具体的实际挑战，但它们提供的可变性可以用来改善体验并使评估更加稳健。例如，虽然 DALL-E v2 的条件 VISOR 分数为 59%，但当生成四张图像时，该样本中至少存在 74% 的正确生成。当所有这些都呈现给用户时（界面中的常见做法），这会增加用户获得满意生成的机会。此外，在大多数交互从语言开始的模型中，即时可变性是普遍存在的。 VISOR 工作中的消融实验表明，生成模型倾向于描绘提示中首先提到的对象。交换提示中的对象会改变它们之间的关系，从而增加了另一个可变性来源。结合起来，这些见解可以用于更有效的交互。</p><p>虽然纯文本和图像是文本到图像模型中使用的主要模式，但当使用代码生成图像和控制生成时，也会评估模型功能。例如， <a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/">“通用人工智能的火花：GPT-4 的早期实验”</a>中的几个初始示例说明了如何促使纯语言模型 GPT-4 的早期版本在 TikZ 或 JavaScript 中生成代码可以导致可控绘图，更准确地描绘空间关系。然而，由于这些绘图可能相当简单，因此该研究还引发了一场关于如何充分利用这两个世界的对话：通过代码实现良好的可控性，通过图像生成实现更高的图像质量或复杂的场景。例如，它展示了如何利用通过 GPT-4 代码生成启动的草图来通过文本到图像模型控制更复杂场景的生成。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="452" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-1024x452.jpg" alt="图 8：通过稳定扩散将 GPT-4 代码生成的草图与图像生成相结合的示例。该示例展示了绘制地形的过程，其中从左到右有一条河流，河流下方是一个有金字塔的沙漠，河流上方是一座有许多高楼的城市。" class="wp-image-965205" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-1024x452.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-300x132.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-768x339.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-240x106.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 8：通过稳定扩散将 GPT-4 代码生成的草图与图像生成相结合的示例。 </figcaption></figure><h2 class="wp-block-heading" id="beyond-offline-benchmarks-leveraging-adaptation-and-continual-learning-approaches">超越离线基准：利用适应和持续学习方法</h2><p><strong>观察 4：</strong>为了弥合离线测量可以捕获的内容与开放世界中模型的功能之间的差距，研究人员和开发人员必须采用适应和持续学习方法，这也带来了自身的挑战。 <strong>&nbsp;</strong></p><p>虽然离线评估提供了关于模型性能的必要视图，但它们没有考虑现实世界的变量，例如在标签空间中引入看不见的对象类别、视觉表示长尾中的新对象、用户反馈以及训练数据和开放世界数据之间的差异，包括质量差异以及视角和方向的差异。这些具体的挑战在<a href="https://www.microsoft.com/en-us/research/publication/continual-learning-about-objects-in-the-wild-an-interactive-approach/" target="_blank" rel="noreferrer noopener">《持续学习野外物体：一种交互式方法</a>》和《 <a href="https://www.microsoft.com/en-us/research/publication/understanding-personalized-accessibility-through-teachable-ai-designing-and-evaluating-find-my-things-for-people-who-are-blind-or-low-vision/#:~:text=Teachable%20AI%20systems%20give%20users,benefit%20of%20the%20personalization%20received." target="_blank" rel="noreferrer noopener">通过可教人工智能理解个性化可访问性：为盲人或低视力人士设计和评估查找我的东西》中进行了</a>探讨，这两部作品为盲人或弱视人士提供了方法使用户能够扩展人工智能系统的功能，以满足他们的现实需求。这些方法被称为<a href="https://www.microsoft.com/en-us/research/project/taix/" target="_blank" rel="noreferrer noopener">可教学的人工智能系统</a>，允许用户提供示例或更高级别的约束来塑造他们对人工智能系统的体验。</p><p>第一篇论文揭示了一种实用的持续学习混合现实方法，其中包括循环中的多模态模型。在所提出的实现中，系统通过用户佩戴的混合现实耳机来跟踪环境中对象的 3D 世界位置和方向，用户可以通过凝视系统突出显示的对象并说“例如，”来提供标签。这是我的切菜板。”这些交互旨在调整识别模型，以随着时间的推移提高使用系统的人遇到的一组对象的性能。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="382" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-1024x382.jpg" alt="图 10：用于厨房领域交互式持续学习的混合现实系统的图示。左上：通过混合现实耳机看到的切菜板的视图，由系统和各种其他厨房物品突出显示和标记。右上：3D 对象检测和定位。底部：从自我中心的角度来看，厨房用品的多样化组合。" class="wp-image-965211" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-1024x382.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-300x112.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-768x286.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-240x89.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 9：使用循环中的多模态模型进行交互式持续学习的混合现实系统。</figcaption></figure><p>构建如此复杂的系统需要回答困难且未经探索的评估问题。有些是特定于该应用程序的：系统随时间跟踪对象位置的效果如何？系统应该突出显示哪些对象并要求用户标记？目前最先进的视觉模型在这种情况下的表现如何？其他问题对我们如何有效评估这些系统有更广泛的影响，包括我们如何衡量任务完成情况。</p><p>当前的评估方法不足以回答此类开放性问题。正如第二篇论文《通过可教人工智能理解个性化可访问性》中所述，可教人工智能系统的评估包括<strong> </strong>离线评估之外的一系列挑战。 “通过可教人工智能理解个性化可访问性”通过 Find My Things 探索了这些挑战，Find My Things 是一个应用程序的研究原型，旨在帮助盲人或弱视人士训练人工智能系统通过提供物品视频来识别个人物品，从而使他们能够稍后使用手机找到这些物品。结论包括：人工智能系统需要帮助用户收集高质量的教学示例，在用户之间一致地工作，并处理特定用户的真实数据，而不仅仅是“干净”的数据。同时，用户需要了解当系统性能不佳时，他们可以采取哪些措施来提高性能。</p><p><strong>评估和模型改进策略：</strong>分析系统在遇到不“干净”的数据时的表现，特别是帧质量的影响，“持续学习野外对象”发现零样本设置下的 CLIP 模型是对于存在一些运动模糊或遮挡的图像，准确度至少降低 10%。结果表明，选择正确的帧进行推理确实可能会对零样本设置中的用户体验产生积极影响。然而，即使在最好的情况下，这些体验在零样本识别方面也有很大的改进空间。即使对于已过滤为无运动模糊或遮挡的帧，最佳模型性能也低于 60%。类似的发现在<a href="https://www.microsoft.com/en-us/research/publication/hard-meta-dataset-towards-understanding-few-shot-performance-on-difficult-tasks/" target="_blank" rel="noreferrer noopener">《Hard-Meta-Dataset++：Towards Understanding Few-Shot Performance on Difficult Tasks》</a>中也有类似的发现，它提出了一个基准，专门管理模型难以正确完成的任务，以此鼓励模型开发，从而提高模型的性能。最坏的情况/底线。此外，“持续学习野外对象”通过在基础模型之上微调轻量级模型来进行模型适应实验，表明持续适应技术有望提高实际部署中的性能。</p><p>除了准确性之外，降低模型适应新数据相关的计算成本也很重要。这对于实现人们可以自我调整或个性化的交互式人工智能体验尤其重要——例如， <a href="https://www.microsoft.com/en-us/research/publication/orbit-dataset/" target="_blank" rel="noreferrer noopener">ORBIT 基准测试</a>提出的可教学对象识别器。这项研究表明，由于根据个人数据个性化模型需要计算成本和时间，因此不太准确的轻量级模型比更重、更准确的模型更适合最终部署体验。</p><p>总之，在我们应对大量挑战和创新的过程中，有一条信息脱颖而出：以负责任的方式构建有效的多模式人工智能系统的道路需要严格的评估、对现实世界复杂性的理解以及对持续改进的承诺。我们希望这些最近的结果将激发在重新构建多模式模型评估领域开展雄心勃勃的工作，以便正确捕捉其性能，从最初的证据到严格的基准、复杂的技能，以及最终的现实世界和以人为中心的场景。</p><h2 class="wp-block-heading" id="related-reading">相关阅读</h2><p id="literature"><strong>本博客直接讨论了有关多模式模型的文献</strong></p><ul><li><a href="https://www.microsoft.com/en-us/research/publication/mitigating-spurious-correlations-in-multi-modal-models-during-fine-tuning/">微调期间减轻多模态模型中的虚假相关性</a>。于阳、贝斯米拉·努什、哈米德·帕兰吉、巴哈兰·米尔扎索莱曼。 ICML 2023。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/social-biases-through-the-text-to-image-generation-lens/">通过文本到图像生成镜头观察社会偏见</a>。兰吉塔·奈克，贝斯米拉·努什。 AIES 2023。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/">通用人工智能的火花：GPT-4 的早期实验</a>。 Sébastien Bubeck、Varun Chandrasekaran、Ronen Eldan、Johannes Gehrke、Eric Horvitz、Ece Kamar、Peter Lee、Yin Tat Lee、Yuanzhi Li、Scott Lundberg、Harsha Nori、Hamid Palangi、Marco Tulio Ribeiro、张毅。微软研究院 2023 年技术报告。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/kosmos-2-grounding-multimodal-large-language-models-to-the-world/">Kosmos-2：为世界奠定多模式大型语言模型的基础</a>。彭志良，王文辉，董力，郝亚茹，黄少涵，马树明，魏福如。微软研究院 2023 年技术报告。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/hard-meta-dataset-towards-understanding-few-shot-performance-on-difficult-tasks/">Hard-Meta-Dataset++：了解困难任务上的少样本性能</a>。萨米亚迪普·巴苏、梅根·斯坦利、约翰·布朗斯基尔、索海尔·费兹、丹妮拉·马塞蒂。 ICLR 2023。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/understanding-personalized-accessibility-through-teachable-ai-designing-and-evaluating-find-my-things-for-people-who-are-blind-or-low-vision/#:~:text=Teachable%20AI%20systems%20give%20users,benefit%20of%20the%20personalization%20received.">通过可教学的人工智能了解个性化可访问性：为盲人或弱视人士设计和评估“查找我的东西”</a> 。塞西莉·莫里森、丽塔·马克斯、马丁·格雷森、丹妮拉·马塞蒂、卡米拉·朗登、琳达·温依琳、艾德·卡特雷尔。资产 2023。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/taxonomizing-and-measuring-representational-harms-a-look-at-image-tagging/">分类和衡量代表性危害：看看图像标签。</a>贾里德·卡兹曼、安吉丽娜·王、摩根·苏尔曼、苏林·布洛杰特、克里斯汀·莱尔德、汉娜·瓦拉赫、索伦·巴罗卡斯。 AAAI 2023。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/a-large-scale-robustness-analysis-of-video-action-recognition-models/">视频动作识别模型的大规模鲁棒性分析。</a>马德琳·钱特里·斯基亚帕、纳曼·比亚尼、普鲁德维·卡姆塔姆、什鲁蒂·维亚斯、哈米德·帕兰吉、维巴夫·维尼特、尤格什·拉瓦特。 CVPR 2023。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/benchmarking-spatial-relationships-in-text-to-image-generation/" target="_blank" rel="noreferrer noopener">文本到图像生成中的空间关系基准测试</a>。 Tejas Gokhale、Hamid Palangi、Besmira Nushi、Vibhav Vineet、Eric Horvitz、Ece Kamar、Chitta Baral、Yezhou Yang。微软研究院 2022 年技术报告。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/measuring-representational-harms-in-image-captioning/" target="_blank" rel="noreferrer noopener">测量图像字幕中的代表性危害</a>。安吉丽娜·王、索伦·巴罗卡斯、克里斯汀·莱尔德、汉娜·瓦拉赫。 FAccT 2022。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/continual-learning-about-objects-in-the-wild-an-interactive-approach/">持续学习野外物体：一种交互式方法</a>。丹·博胡斯、肖恩·安德里斯、阿什利·费尼罗、尼克·索、埃里克·霍维茨。 ICMI 2022。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/disability-first-datasets/" target="_blank" rel="noreferrer noopener">残疾人优先的数据集创建：使用盲人和低视力数据收集器构建用于可教物体识别的数据集的经验教训</a>。利达·西奥多鲁、丹妮拉·马塞蒂、路易莎·辛特格拉夫、西蒙娜·斯坦普夫、塞西莉·莫里森、艾德·卡特雷尔、马修·托拜厄斯·哈里斯、卡佳·霍夫曼。资产 2021。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/orbit-dataset/">ORBIT：用于可教学对象识别的现实世界少样本数据集</a>。丹妮拉·马西蒂、路易莎·辛特格拉夫、约翰·布朗斯基尔、利达·西奥多鲁、马修·托拜厄斯·哈里斯、艾德·卡特雷尔、塞西莉·莫里森、卡佳·霍夫曼、西蒙娜·斯坦普夫。 ICCV 2021。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/squinting-at-vqa-models-introspecting-vqa-models-with-sub-questions/">SQuINTing at VQA 模型：用子问题反思 VQA 模型</a>。 Ramprasaath R. Selvaraju、Purva Tendulkar、Devi Parikh、Eric Horvitz、Marco Tulio Ribeiro、Besmira Nushi、Ece Kamar。 CVPR 2020。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/neuro-symbolic-visual-reasoning-disentangling-visual-from-reasoning-2/">神经符号视觉推理：将“视觉”与“推理”分开</a>。 Saeed Amizadeh、Hamid Palangi、Alex Polozov、Yichen Huang、Kazuhito Koishida。 ICML 2020。</li></ul><p><strong>有关分类评价的文献</strong></p><ul><li><a href="https://www.microsoft.com/en-us/research/publication/designing-disaggregated-evaluations-of-ai-systems-choices-considerations-and-tradeoffs/" target="_blank" rel="noreferrer noopener">设计人工智能系统的分类评估：选择、考虑因素和权衡</a>。索伦·巴罗卡斯、郭安红、埃斯·卡马尔、杰奎琳·克朗斯、梅雷迪斯·林格尔·莫里斯、詹妮弗·沃特曼·沃恩、邓肯·沃兹沃斯、汉娜·瓦拉赫。 AIES 2021。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/towards-accountable-ai-hybrid-human-machine-analyses-for-characterizing-system-failure/" target="_blank" rel="noreferrer noopener">迈向负责任的人工智能：用于表征系统故障的混合人机分析</a>。贝斯米拉·努什、埃斯·卡马尔、埃里克·霍维茨。 2018 年 HCOMP。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/understanding-failures-of-deep-networks-via-robust-feature-extraction/" target="_blank" rel="noreferrer noopener">通过鲁棒特征提取了解深度网络的故障</a>。萨希尔·辛格拉、贝斯米拉·努什、希塔尔·沙阿、埃斯·卡马尔、埃里克·霍维茨。 CVPR 2021。</li><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.youtube.com/watch?v=NYXRrLzGiFk&t=734s&ab_channel=MicrosoftResearch" target="_blank" rel="noreferrer noopener">分类模型评估和比较 - YouTube <span class="sr-only">（在新选项卡中打开）</span></a></li></ul><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/">多模态学习的前沿：负责任的人工智能方法</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>