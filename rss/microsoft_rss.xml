<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 5 月 30 日星期四 17:08:16 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.3</generator><item><title>创新与隐私的十字路口：生成人工智能的私有合成数据</title><link/>https://www.microsoft.com/en-us/research/blog/the-crossroads-of-innovation-and-privacy-private-synthetic-data-for-generative-ai/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 29 May 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1038870 </guid><description><![CDATA[<p>合成数据可能有助于解决人工智能模型开发和训练中的一些隐私问题，但它也有局限性。微软的研究人员正在探索能够生成具有强大隐私保护的更真实数据的技术。</p><p>文章<a href="https://www.microsoft.com/en-us/research/blog/the-crossroads-of-innovation-and-privacy-private-synthetic-data-for-generative-ai/">《创新与隐私的十字路口：生成人工智能的私有合成数据》</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1.jpg" alt="图具有四个连续块的流程图。从数据所有者开始，提供私有数据来训练具有差异隐私的语言模型。随后提示语言模型生成类似于私有数据的新颖的合成数据。该数据可用于下游应用，例如机器学习、反馈分析或统计分析。" class="wp-image-1041408" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/PSD-for-Gen-AI-2024-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h2 class="wp-block-heading" id="introduction">介绍</h2><p>在当今数据驱动的世界中，组织努力利用数据来训练和调整人工智能模型。然而，这种追求往往面临一个重要的挑战：平衡数据的价值与保护个人隐私权的需要，并遵守《 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://gdpr.eu/" target="_blank" rel="noreferrer noopener">通用数据保护条例<span class="sr-only">》（在新选项卡中打开）</span></a> （GDPR）和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence" target="_blank" rel="noreferrer noopener">《欧盟人工智能》</a>等数据隐私法规。 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence" target="_blank" rel="noreferrer noopener">行动<span class="sr-only">（在新选项卡中打开）</span></a> 。</p><p>合成数据已成为应对隐私和合规挑战的强大解决方案。它允许组织创建现实且有用的数据集，针对特定用例量身定制，而不会损害个人隐私。这使组织能够：</p><ul><li><strong>训练和调整人工智能模型</strong>：即使现实世界数据有限或存在隐私问题，合成数据也可用于训练模型并使其适应特定领域和行业。</li><li><strong>遵守法规</strong>：由于合成数据生成不需要用户数据，因此可以帮助组织遵守数据隐私法规。</li><li><strong>解锁新的可能性</strong>：合成数据为创新人工智能应用程序打开了大门，而这些应用程序以前受到数据可用性或隐私限制的限制。</li></ul><p> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/" target="_blank" rel="noreferrer noopener">Microsoft 的 Phi-3 <span class="sr-only">（在新选项卡中打开）</span></a>小语言模型 (SLM) 是一个很好的例子，说明合成数据如何有助于负责任的 AI 开发，从而在不损害隐私的情况下创建强大的语言模型。 Phi-3 结合了“教科书质量”的网络数据和法学硕士生成的合成内容，创建了一种不需要真实个人数据的战略方法。</p><p>然而，合成数据存在局限性。人工生成可预测各种用例和个别场景的真实数据可能很困难。此外，由预先训练的大语言模型 (LLM) 生成的合成数据有时会降低准确性并增加<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2403.04190v1" target="_blank" rel="noreferrer noopener">下游任务的偏差<span class="sr-only">（在新选项卡中打开）</span></a> 。那么，我们如何生成能够准确捕获私人数据的多样性和特殊性的合成数据，同时对数据贡献者保持严格的隐私保护呢？</p><h3 class="wp-block-heading" id="differential-privacy-a-bridge-between-innovation-and-privacy"> 差异化隐私：创新与隐私之间的桥梁</h3><p>差分私有（DP）合成数据生成是一个有前途的解决方案。它允许开发人员在优先考虑隐私的同时追求机器学习的创新。合成数据生成的目标是生成与现实世界数据源在统计上相似的数据。然而，当数据过于相似时，复制源数据的唯一标识细节，保护隐私的承诺就会受到损害。这就是 DP 可以提供帮助的地方。 DP 是一种数学框架，用于保证特定计算对于单个数据贡献者的添加或删除相对不变。 <a href="https://www.microsoft.com/en-us/research/blog/privacy-preserving-machine-learning-maintaining-confidentiality-and-preserving-trust/" target="_blank" rel="noreferrer noopener">使用 DP 技术</a>，研究人员可以生成合成数据集，保留原始数据的统计特性，同时确保有助于识别数据贡献者的信息保持模糊。</p><p>这篇博文探讨了私有合成数据生成的最新进展。我们研究了最近发表的四篇研究论文，这些论文提出了生成具有强大隐私保证的合成数据的创新技术，同时保持其对分析、训练人工智能模型和其他任务的有用性。</p><ul><li> <strong><a href="https://www.microsoft.com/en-us/research/publication/synthetic-text-generation-with-differential-privacy-a-simple-and-practical-recipe/">具有差异隐私的合成文本生成：简单实用的配方<span class="sr-only">（在新选项卡中打开），</span></a></strong>由 Yue<em>等人发表，</em>发表在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2023.aclweb.org/calls/main_conference/" target="_blank" rel="noreferrer noopener">ACL 2023 <span class="sr-only">（在新选项卡中打开）</span></a> ，建议在生成式 LLM 的微调训练过程中使用 DP 。这种方法在训练期间将噪声注入到模型的更新中，确保隐私保证，同时保持模型生成真实文本的能力。</li><li> <strong><a href="https://www.microsoft.com/en-us/research/publication/differentially-private-synthetic-data-via-foundation-model-apis-1-images/">通过基础模型 API 的差分私有合成数据 1：图像<span class="sr-only">（在新选项卡中打开）</span></a></strong>和<strong><a href="https://www.microsoft.com/en-us/research/publication/differentially-private-synthetic-data-via-foundation-model-apis-2-text-2/" target="_blank" rel="noreferrer noopener">通过基础模型 API 的差分私有合成数据 2：文本<span class="sr-only">（在新选项卡中打开），</span></a></strong>由 Lin、Xie<em>等人</em>撰写，出现在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://iclr.cc/Conferences/2024" target="_blank" rel="noreferrer noopener">ICLR 2024 上<span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://icml.cc/" target="_blank" rel="noreferrer noopener">ICML 2024 <span class="sr-only">（在新选项卡中打开）</span></a>分别提出了一种数据合成方法，重点是利用预先训练的基础模型作为黑匣子。该方法利用对模型推理 API 的差异化私有查询来生成数据，提供基于 API 的免训练方法。</li><li> Tang<em>等人</em>在 ICLR 2024 上发表的<a href="https://www.microsoft.com/en-us/research/publication/privacy-preserving-in-context-learning-with-differentially-private-few-shot-generation/" target="_blank" rel="noreferrer noopener"><strong>《Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation》</strong></a> ，探讨了将 DP 应用于少镜头学习任务，其中模型以少量综合生成的演示示例为条件在推理时。当只有私人标记的示例可用时，这种方法非常有用，并且可以利用法学硕士的泛化能力来解决上下文中的任务。</li></ul><p>在本博文的其余部分中，我们将更详细地描述每种方法，并提供实验结果来说明其价值。 </p><h2 class="wp-block-heading" id="technical-deep-dive-differentially-private-synthetic-data-generation">技术深入探讨：差分隐私合成数据生成</h2><h3 class="wp-block-heading" id="synthetic-text-generation-with-differential-privacy-a-simple-and-practical-recipe">具有差异隐私的合成文本生成：简单实用的秘诀</h3><p>生成式法学硕士提供了通过从法学硕士输出中采样来生成合成文本的机会。生成真实合成文本的一种途径是微调<strong> </strong>使用代表性数据的法学硕士。例如，我们可以考虑在科学论文语料库上对预先训练的法学硕士进行微调，使模型能够更容易地生成捕获科学写作中使用的知识和写作风格的文本。然而，假设我们想要基于<em>私有</em>文档语料库生成合成文本。我们可以采取哪些措施来保护文档作者及其文档中的任何敏感信息？例如，我们可能想要生成合成医疗记录或个人电子邮件。法学硕士具有众所周知的记忆训练样本的能力，而具有从训练集中复制样本的潜力的模型可能会带来重大的隐私风险。</p><p>在论文《<em>具有差异隐私的合成文本生成：简单实用的方法》</em>中，微软的研究人员提出了一种利用私有数据语料库进行合成生成的方法，同时又不损害数据主体的隐私。该方法使用<a href="https://www.microsoft.com/en-us/research/publication/differentially-private-fine-tuning-of-language-models/" target="_blank" rel="noreferrer noopener">差分隐私随机梯度下降</a>（DP-SGD）来微调隐私文档上的 LLM，并提供强大的隐私保证。 <a href="https://www.microsoft.com/en-us/research/publication/differentially-private-fine-tuning-of-language-models/" target="_blank" rel="noreferrer noopener">差分私有模型训练</a>提供了数学保证，训练后的模型参数以及任何<strong> </strong>随后的模型输出相对不受任何单个用户训练示例的添加或删除的影响。</p><p>这项工作中描述的合成生成方法通过对具有不同隐私保护级别的餐厅评论进行训练，然后促使模型生成新颖的评论进行了验证。然后，这些评论被用于下游分类任务，例如情绪预测和餐厅类型分类，结果如表 1 所示，与原始私人数据的训练相比，准确性损失很小。这种方法开启了一种强大的方式，可以在不损害隐私或机密性的情况下从私人数据生成真实的合成数据。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1400" height="529" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure1_Synthetic-Data-Generation.jpg" alt="具有四个连续块的流程图。从数据所有者开始，提供私有数据来训练具有差异隐私的语言模型。随后提示语言模型生成类似于私有数据的新颖的合成数据。该数据可用于下游应用，例如机器学习、反馈分析或统计分析。" class="wp-image-1039950" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure1_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure1_Synthetic-Data-Generation-300x113.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure1_Synthetic-Data-Generation-1024x387.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure1_Synthetic-Data-Generation-768x290.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure1_Synthetic-Data-Generation-240x91.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 1：通过对具有差异隐私的 LLM 进行微调，该模型可用于生成类似于私有语料库的合成示例</figcaption></figure><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1400" height="700" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table1_Synthetic-Data-Generation.jpg" alt="具有四列和四行的结果表。这些列指示数据类型、数据生成器、epsilon、评级和类别。  第一行表示“原始”数据类型，并且没有数据生成器或 epsilon 的条目。评级为 0.733，类别为 0.775。  以下三行均表示数据类型为 Synthetic，以及数据生成器为 GPT2、GPT2-Medium 和 GPT2-Large。每行进一步分为两行，分别对应 epsilon = 4 和 epsilon = 无穷大。在所有情况下，评级和类别分数都比原始标记的行低几个百分点。与 epsilon = 4 对应的行比标记 epsilon=无穷大的对应行低 1-2 个百分点。一般来说，epsilon = 4 行对于较大的 GPT2 模型得分有所增加，而 epsilon = 无穷大行则相对平坦。" class="wp-image-1039956" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table1_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table1_Synthetic-Data-Generation-300x150.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table1_Synthetic-Data-Generation-1024x512.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table1_Synthetic-Data-Generation-768x384.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table1_Synthetic-Data-Generation-240x120.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">表 1：不同版本的 GPT-2 在有（ε = 4）和没有（ε = ∞）隐私保证的餐厅评论上进行训练。这些模型用于生成综合训练集，用于训练评论评级和餐厅类别的分类模型，并随后评估私人保留集的准确性。结果表明，在合成数据上训练的模型可以达到与没有隐私保证的情况下训练的模型相媲美的准确性。 </figcaption></figure><h3 class="wp-block-heading" id="differentially-private-synthetic-data-via-foundation-model-apis">通过基础模型 API 实现差异化私有合成数据</h3><p>虽然 ACL 论文展示了一种强大的合成数据生成方法，但对大型模型进行微调可能不切实际。模型训练需要大量的计算能力，并且一些最强大的可用模型是专有的，无法用于 DP 训练。认识到这一挑战，微软的研究人员探索了是否可以<strong>仅使用对模型的推理 API 访问来</strong>直接生成合成数据，即使在使用由第三方控制的不受信任的模型时也是如此。至关重要的是，合成数据应该类似于目标私有语料库，并产生与之前基于模型训练的工作中所满足的类似的 DP 保证。在两篇独立的论文中，作者展示了一种解决该问题的方法，使用称为私有进化（PE）的差分私有采样方法。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1138" height="676" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Synthetic-Data-Generation-NEW-Fig2.png" alt="两个独立的流程图。首先，将私有数据应用于使用 DP-SGD 的预训练模型。微调模型用于生成差分隐私合成数据。  在第二张图中，通过 API 提示预训练模型生成通用数据。私有数据用于通知生成数据的选择，具有强大的隐私保证，产生差异私有的合成数据。" class="wp-image-1040847" style="width:718px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Synthetic-Data-Generation-NEW-Fig2.png 1138w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Synthetic-Data-Generation-NEW-Fig2-300x178.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Synthetic-Data-Generation-NEW-Fig2-1024x608.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Synthetic-Data-Generation-NEW-Fig2-768x456.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Synthetic-Data-Generation-NEW-Fig2-240x143.png 240w" sizes="(max-width: 1138px) 100vw, 1138px" /><figcaption class="wp-element-caption">图 2：Private Evolution (PE) 不需要使用 DP-SGD 微调预训练模型（上图），而是只需要访问模型的推理 API（下图）。因此，PE 很容易与难以进行 DP 微调（例如，因为它们太大）或无法微调（例如，它们只能通过推理 API 访问）的基础模型兼容。</figcaption></figure><p><strong>使用基础模型 API 生成合成图像：</strong>在<em>通过基础模型 API 进行差异化私有合成数据 1：图像</em>中，作者介绍了私有进化 (PE)，这是一种仅通过生成模型的推理 API 即可实现 DP 图像合成的方法。 PE 通过从预先训练的扩散模型（例如稳定扩散）中采样来进行操作，该模型不了解私有语料库。然后，PE 迭代地将这些样本与私有语料库进行比较，保留与私有语料库最相似的样本，并使用预训练的模型生成更多此类样本。至关重要的是，与私有语料库的比较是在 DP 保证下完成的，因此任何有关私有语料库的信息都受到严格限制。此外，对基础模型 API 的所有查询都满足相同的 DP 保证，以便我们可以安全地使用（不受信任的）第三方提供的 API。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="818" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation.jpg" alt="PE概述。我们使用两个私有图像和合成图像进行说明。第 1 步（RANDOM_API）：我们使用模型 API 生成随机图像。步骤 2：我们迭代执行步骤 2.1-2.3，将合成图像细化为私有图像。步骤 2.1：每个私有图像投票选出嵌入空间中最接近的合成图像。在此示例中，我们假设鸟图像获得两票，而汽车图像获得零票。然后我们在投票中添加高斯噪声以确保 DP。这为我们提供了 DP 最近邻直方图 (DP_NN_HISTOGRAM)。步骤2.2：我们对生成的图像与直方图成比例进行重新采样。我们假设只剩下鸟图像。步骤2.3（VARIATION_API）：我们使用模型API生成与鸟图像相似的新图像，这是下一次迭代中的初始合成图像。 " class="wp-image-1039968" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation-300x175.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation-1024x598.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation-768x449.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation-480x280.jpg 480w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure3_Synthetic-Data-Generation-240x140.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 3：PE 概述。我们使用两个私有图像和合成图像进行说明。第 1 步（RANDOM_API）：我们使用模型 API 生成随机图像。步骤 2：我们迭代执行步骤 2.1-2.3，将合成图像细化为私有图像。步骤 2.1：每个私有图像投票选出嵌入空间中最接近的合成图像。在此示例中，我们假设鸟图像获得两票，而汽车图像获得零票。然后我们在投票中添加高斯噪声以确保 DP。这为我们提供了 DP 最近邻直方图 (DP_NN_HISTOGRAM)。步骤2.2：我们对生成的图像与直方图成比例进行重新采样。我们假设只剩下鸟图像。步骤2.3（VARIATION_API）：我们使用模型API生成与鸟图像相似的新图像，这是下一次迭代中的初始合成图像。</figcaption></figure><p>即使不进行任何模型训练，PE 也可以在某些数据集上显着提高最先进的结果。例如，在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noreferrer noopener">CIFAR10 数据集<span class="sr-only">（在新选项卡中打开）</span></a>上，我们实现了 FID 分数（图像质量度量，越小越好）≤ 7.9，DP 隐私成本 ϵ = 0.67，显着提高了之前的 SOTA，从 ϵ = 32 开始。在论文中，我们还表明，与 DP 微调相比，PE 需要更少的计算资源（GPU 小时）来实现这样的结果。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1400" height="1011" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure4_Synthetic-Data-Generation.jpg" alt="具有六条线系列的 2D 折线图，包括私有进化和 DP-MEPF 方法以及 DP-GAN 和 DP-Diffusion 的条件和无条件变化。 x 轴表示从 0 到 32 的 epsilon 值。y 轴表示从 0 到 80 的图像质量度量 FID 的值，其中值更好。  所有六个系列均显示 FID 值随着 epsilon 值的增加而减小。与私有进化相对应的两个系列都显示出明显较低的 FID 值，范围从大约 epsilon = 0.1 到 epsilon = 2。" class="wp-image-1039971" style="width:531px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure4_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure4_Synthetic-Data-Generation-300x217.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure4_Synthetic-Data-Generation-1024x739.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure4_Synthetic-Data-Generation-768x555.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure4_Synthetic-Data-Generation-240x173.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 4：CIFAR10 上的 FID（图像质量衡量标准，越低越好）与 DP 隐私成本 ϵ (δ = 10 <sup>−5</sup> )。 (Un)cond 表示(un)条件生成。与之前基于训练的方法相比，我们的方法实现了最佳的隐私质量权衡。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="1400" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation.jpg" alt="十行缩略图的数组，每行描绘生成的合成图像的十个实例。这些行包括鸟类、汽车、猫、狗和其他动物、飞机、船只和卡车。  大多数图像看起来都很真实，但有些图像表现出不寻常的伪影。" class="wp-image-1039974" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation-300x300.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation-1024x1024.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation-768x768.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation-180x180.jpg 180w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure5_Synthetic-Data-Generation-360x360.jpg 360w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 5：使用 CIFAR-10 作为私有语料库的 Private Evolution 生成的样本（ε =0.67，δ =10 <sup>-5</sup> ）。每一行对应一个对象类。</figcaption></figure><p><strong>使用基础模型 API 的合成文本生成：</strong>上述 PE 方法非常适合图像，因为它很容易产生有前景图像的附近扰动。在<em>通过基础模型 API 实现差异化私有合成数据 2：文本</em>中，微软研究人员探索了是否可以将类似的方法应用于文本。他们的方法称为增强私人进化（Aug-PE），其操作与基本 PE 方法类似，但利用预先训练的法学硕士的力量来产生输入文本的变化和重新措辞。 Aug-PE还提出了一些可能有利于PE未来发展的基本算法改进。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1400" height="813" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation.jpg" alt="用于合成文本生成的增强私人进化算法的概述。步骤 1 调用语言模型来生成随机文本。步骤 2.1 使用私有数据和差分私有对步骤 1 中的最佳候选者进行投票，步骤 2.2 从该差分私有直方图中采样以生成选定的代集。步骤2.3提示语言模型产生所选代的变体，并且重复步骤2.1至2.3。" class="wp-image-1039977" style="width:804px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation-300x174.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation-1024x595.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation-768x446.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation-480x280.jpg 480w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure6_Synthetic-Data-Generation-240x139.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 6：增强私人进化 (Aug-PE) 利用基础法学硕士来合成文本，并以保护隐私的方式与私人语料库进行比较。与图像的 PE 类似，在 Aug-PE 中，更接近私人数据的样本被保留和细化，以生成具有强大隐私保证的新合成文本。下图显示了我们如何在给定两个私人样本的情况下为餐厅生成 DP 综合评论。</figcaption></figure><p>结果表明，Aug-PE 是 DP 文本合成中 DP 微调的一个有前途的替代方案。使用相同的基础模型，PE 在文本质量和隐私之间的权衡方面可以匹配甚至击败 DP 微调。此外，由于Aug-PE只需要推理API，Aug-PE可以轻松地与最先进的LLM（例如GPT-3.5、LLaMA和Mixtral）配合使用，以进一步提高文本质量。在计算成本（GPU 小时）方面，与 DP 微调方法相比，PE 可以实现高达 65.7 倍的加速。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1400" height="682" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table2_Synthetic-Data-Generation.jpg" alt="各种模型的面积和评级分类精度的结果表，以及 PE 与 DP 合成的比较。该表包含这样的评论：相同模型的 PE 在文本质量与隐私方面匹配或击败 DP 微调，并且 PE 与可能具有挑战性或不可能微调的高级 LLM 配合良好。比较的模型包括三种尺寸的GPT-2、几种主要的开源模型以及GPT-3.5。 Mixtral 模型上的 PE 显示出最强的区域分类准确度，为 43.6，而 GPT-3.5 上的 PE 显示出最强的评级分类准确度，为 43.1。" class="wp-image-1039980" style="width:698px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table2_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table2_Synthetic-Data-Generation-300x146.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table2_Synthetic-Data-Generation-1024x499.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table2_Synthetic-Data-Generation-768x374.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table2_Synthetic-Data-Generation-240x117.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">表 2：ICLR 2023 论文评审结果 (ϵ = 1)。我们使用每种方法来生成 DP 合成论文评论，并通过训练下游论文领域或评级分类器来测试数据的实用性，并评估它们在真实保留数据上的准确性（越高越好）。在相同的基础模型（GPT-2族）下，PE通过DP微调取得了有竞争力的结果。 PE 还支持高级 LLM，由于模型尺寸较大或黑匣子访问，这些高级 LLM 可能难以与 DP 微调一起使用。 </figcaption></figure><h3 class="wp-block-heading" id="privacy-preserving-in-context-learning-with-differentially-private-few-shot-generation">具有差分隐私少样本生成的隐私保护情境学习</h3><p>情境学习是一种通过法学硕士执行任务的技术，方法是在向法学硕士呈现特定任务之前，在法学硕士的提示中提供演示示例的样本。例如，我们可能会展示一些电影情节及其类型，并要求法学硕士为感兴趣的特定情节建议类型。上下文学习利用了法学硕士强大的泛化能力，但它需要在推理时提供带标签的演示示例样本。当唯一可用的标记示例是私有的时，我们如何进行上下文学习？一个简单的解决方案可能是使用私有示例，但对用户隐藏演示提示。然而， <a href="https://www.microsoft.com/en-us/security/blog/2024/04/11/how-microsoft-discovers-and-mitigates-evolving-attacks-against-ai-guardrails/" target="_blank" rel="noreferrer noopener">越狱攻击</a>带来的威胁使这些示例面临暴露给恶意用户的风险。</p><p>在<em>《使用差异化私有少样本生成的隐私保护情境学习》</em>中，微软研究人员探索了如何从具有隐私保证的私有语料库中合成演示示例。该方法通过从私有示例定义的令牌分布中增量抽取样本来运行，但在分布中添加了噪声。噪声经过校准，以确保每个样本的隐私损失受到限制。研究表明，上下文学习可以超越零样本学习（在没有任何演示示例的情况下查询模型），并且接近于没有隐私缓解措施的情况下的相同水平，如表 3 所示。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="328" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure7_Synthetic-Data-Generation.jpg" alt="差分隐私小样本生成的概述。  一轮代币生成分为四个步骤。给定到目前为止生成的令牌，步骤 1 选择相关的私有数据。步骤 2 获取私有数据的 M × N 样本，生成 M 批 N 个样本。步骤 3 将 M 个 LLM 提示与任务说明和附加的 N 个示例组合在一起。第 4 步将 M 提示提供给 LLM，并对 LLM 的输出概率执行噪声聚合以选择下一个生成的标记。" class="wp-image-1039983" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure7_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure7_Synthetic-Data-Generation-300x70.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure7_Synthetic-Data-Generation-1024x240.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure7_Synthetic-Data-Generation-768x180.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/figure7_Synthetic-Data-Generation-240x56.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 7：DP 几次生成的图示。该示例显示了为主题学校生成的一个又一个代币的综合演示，具有差异化的私人担保。当对新令牌进行采样时，私有示例会告知每个后续令牌的采样概率，并注入噪声以保护隐私。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="395" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table3_Synthetic-Data-Generation.jpg" alt="私人上下文学习任务的结果表，包括三个数据集（AGNews、DBPedia 和 TREC）上的文本分类以及两个数据集（MIT-G 和 MIT-D）上的信息提取。  比较了 epsilon = 0（零次和四次）的两种情况以及 epsilon 值为 1、2、4、8 和无穷大的精度。一般来说，精度随着 epsilon 的增加而提高，但 epsilon = 8 通常优于 epsilon = 无穷大。" class="wp-image-1039986" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table3_Synthetic-Data-Generation.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table3_Synthetic-Data-Generation-300x85.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table3_Synthetic-Data-Generation-1024x289.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table3_Synthetic-Data-Generation-768x217.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/table3_Synthetic-Data-Generation-240x68.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">表 3：对于分类和信息提取任务，DP 上下文学习实现了与非私有 ICL 类似的准确率 (ϵ =∞)</figcaption></figure><h2 class="wp-block-heading" id="conclusion">结论</h2><p>合成数据生成为开发人工智能系统提供了巨大的机会，同时又不损害最终用户的隐私。在这篇博文中，我们探索了具有强大隐私保证的合成数据生成方面的最新创新。这些方法可以使从业者能够从私人实体生成合成数据，同时降低私人信息可能被泄露的风险。虽然这些方法非常有前途，但它们确实有局限性。例如，我们目前仅限于生成相对较短的文本段落。未来的工作将继续探索这些方法带来的机会，旨在产生具有强大隐私保证的越来越真实的数据。</p><p><strong>致谢：</strong>作者感谢本博文中评论的论文合著者的贡献：Xiang Yue、Xuechen Li、Girish Kumar、Julia McAnallen、Hoda Shajari、Huan Sun、David Levitan、Chulin Xie、Arturs Backurs、 Sivakanth Gopi、Da Yu、Harsha Nori、Haotian Jiang、Huishuai Chang、Yin Tat Lee、Bo Li、Janardhan Kulkarni、Xinyu Tang、Richard Shin、Andre Manoel 和 Niloofar Mireshghallah。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>文章<a href="https://www.microsoft.com/en-us/research/blog/the-crossroads-of-innovation-and-privacy-private-synthetic-data-for-generative-ai/">《创新与隐私的十字路口：生成人工智能的私有合成数据》</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 5 月 27 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-27-2024/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 29 May 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-27-2024/ </guid><description><![CDATA[<p>生成式人工智能工具如何代表不常见的身份和叙述；法学硕士能否帮助玩家参与游戏叙事？利用法学硕士改善地理空间人口数据；用于以查询为中心的摘要的图 RAG 方法；和更多。</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-27-2024/">研究焦点：2024 年 5 月 27 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-1024x576.png" alt="研究重点：2024 年 5 月 27 日" class="wp-image-1039827" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF42-BlogHeroFeature-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-488855ca12d875c96a91ecc4bc3a24f6" id="new-research">事件</h3><h2 class="wp-block-heading" id="title">立即报名参加 6 月 4 日的研究论坛</h2><p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_RF42_ep3_2024" target="_blank" rel="noreferrer noopener">加入我们的研究论坛<span class="sr-only">（在新选项卡中打开）</span></a> ，这是一个系列活动，探讨通用人工智能时代的最新研究进展、大胆的新想法以及与全球研究界的重要讨论。</p><p>在第 3 集中，微软的研究人员强调了全球公平人工智能的重要性，并将分享新颖的用例、从工业到材料设计的变革性应用程序，并提供 AutoGen 和 MatterGen 的更新。</p><p>您的注册包括在活动当天访问我们与研究人员的实时聊天。</p><p>第 3 集将于太平洋时间 6 月 4 日星期二上午 9:00 播出。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_RF42_ep3_2024">现在注册</a></div></div><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="title">生成式人工智能和可见性政治</h2><p>生成式人工智能工具具有非凡的能力，只需用户的简单指导即可生成复杂而冗长的文本。人工智能的支持者声称他们可以帮助作家，提供创造性的建议，完成写了一半的句子或故事片段，并发明人物背景故事。但这引发了关于可见性政治的问题：这些工具往往会产生什么样的故事，它们通常会遗漏什么？这些工具是否充分代表多样化或边缘化人群和非规范社区？</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/generative-ai-and-the-politics-of-visibility/">生成式人工智能和可见性政治</a>中，微软的一位研究人员测试了三种广泛使用的生成式人工智能工具（Bing Chat、ChatGPT 和谷歌的 Bard，现在是 Gemini），并通过旨在揭示其规范假设的提示来提示这些工具次来跟踪同一查询的输出的多样性。他的研究表明，至少按照目前的设计和训练，生成式人工智能工具倾向于重现规范的身份和叙述，除非有特别提示，否则很少代表不常见的安排和观点。当它们确实产生多样性时，它通常是狭窄的，在尚不存在的地方维持更深层次的规范性假设。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/generative-ai-and-the-politics-of-visibility/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1002645"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：人工智能驱动的体验</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo" aria-label="Microsoft research copilot experience" data-bi-cN="Microsoft research copilot experience" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MSR-Chat-Promo.png" alt="" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究院副驾驶经历</h2><p class="large">通过我们的人工智能体验，了解有关 Microsoft 研究的更多信息</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Microsoft research copilot experience" data-bi-cN="Microsoft research copilot experience" target="_blank">现在开始</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="title">ACM MMSys 2024 实时通信带宽估计挑战赛</h2><p>视频会议已成为从全球业务运营到无障碍教育的一切不可或缺的一部分，改变了人们跨越物理障碍和地理鸿沟的沟通方式。视频会议系统提供的体验质量 (QoE) 部分取决于随时间推移正确估计发送方和接收方之间瓶颈链路的容量。实时通信 (RTC) 的带宽估计仍然是一个重大挑战，这主要是由于异构网络架构和技术的不断发展。从 Microsoft 在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2021.acmmmsys.org/rtc_challenge.php" target="_blank" rel="noreferrer noopener">ACM MMSys 2021</a>举办的首届带宽估计挑战赛中，研究人员了解到，由于模拟与真实的差距，在模拟中使用强化学习 (RL) 进行训练以最大化基于网络的奖励函数的带宽估计模型可能不是最佳的以及将基于网络的奖励与用户感知的 QoE 结合起来的困难。在今年的<a href="https://www.microsoft.com/en-us/research/publication/acm-mmsys-2024-bandwidth-estimation-in-real-time-communications-challenge/" target="_blank" rel="noreferrer noopener">ACM MMSys 2024 实时通信带宽估算挑战赛中</a>，微软的研究人员旨在使用离线 RL 和 Microsoft Teams 发布的真实数据集，将奖励最大化与用户感知的 QoE 优化结合起来。此次挑战赛得到了学术界和工业界的热情参与。提交给大挑战的所有模型都经过了初步评估，顶级模型在地理分布的测试台上进行了进一步评估。挑战结果表明，通过利用真实世界的数据并整合客观的音频/视频质量分数作为奖励，离线强化学习可以促进 RTC 竞争性带宽估计器的开发。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/acm-mmsys-2024-bandwidth-estimation-in-real-time-communications-challenge/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="title">LLM 驱动的游戏叙事中玩家驱动的出现</h2><p>游戏创作是一个劳动密集型过程，与对话和叙事结构相关的非图形游戏元素的自动化程度有限。这些元素通常是手工编码的并且具有严格的确定性，向玩家提供的选项很少。大型语言模型（LLM）开始显示出创建更丰富、更广阔的叙事空间的潜力。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/player-driven-emergence-in-llm-driven-game-narrative/">LLM 驱动的游戏叙事中玩家驱动的出现（Player-Driven Emergence in LLM-Driven Game Narrative）</a> （被接受在 IEEE 游戏会议 2024 上发表）中，来自 Microsoft 的研究人员与 Xbox 组织的成员合作，探讨了与 LLM 的交互如何使玩家能够参与到游戏中。游戏叙事的演变。作为测试平台，他们创建了一款文本冒险游戏，玩家试图在固定的叙事前提下解开谜团，但可以与最先进的法学硕士 GPT-4 生成的非玩家角色自由互动。他们招募了 28 名玩家来玩游戏，并使用 GPT-4 自动将游戏日志转换为代表玩家游戏中的叙述的节点图。通过与法学硕士的非确定性行为的互动，玩家能够发现有趣的新出现的节点，这些节点不是原始叙述的一部分，但有可能变得有趣和引人入胜。创建最新兴节点的玩家往往是那些经常喜欢促进发现、探索和实验的游戏的玩家。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/player-driven-emergence-in-llm-driven-game-narrative/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="title">使用大语言模型进行细分：美国社区的新类型</h2><p>美国人口普查局的美国社区调查 (ACS) 是该国社会和经济数据的主要来源。但大部分数据质量较低，尤其是最高级别的地理细节（块组）。当人们在地图上放大地理时，社会和经济数据的分辨率就会降低，这是违反直觉的。通常，放大会生成更多细节，而不是更少。美国统计系统最近的变化放大了这种地理-人口分辨率的权衡。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/segmentation-using-large-language-models-a-new-typology-of-american-neighborhoods/">使用大语言模型的分割：美国社区的新类型学中</a>，微软的研究人员提出了一个解决方案，即使用 ACS 的小区域估计，以基于人工智能的开放且可重复的地理人口统计分类系统的形式解决这个问题。他们对一系列社会经济、人口和建筑环境变量采用分区聚类算法。使用开源软件管道可确保对未来数据更新的适应性。一项关键创新是集成 GPT-4，以生成直观的集群描述和名称。这代表了自然语言处理在地理人口统计研究中的一种新颖应用，并展示了地理空间领域内人类与人工智能协作的潜力。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-5 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/segmentation-using-large-language-models-a-new-typology-of-american-neighborhoods/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="title">从局部到全局：以查询为中心的摘要的图 RAG 方法</h2><p>使用检索增强生成（RAG）从外部知识源检索相关信息使法学硕士能够回答有关私人和/或以前未见过的文档集合的问题。然而，RAG 在针对整个文本语料库的全局问题上失败了，例如：“数据集中的主题是什么？”，因为这本质上是一个以查询为中心的摘要 (QFS) 任务，而不是一个显式检索任务。先前的 QFS 方法无法扩展到典型 RAG 系统索引的文本数量。</p><p>在最近的预印本： <a href="https://www.microsoft.com/en-us/research/publication/from-local-to-global-a-graph-rag-approach-to-query-focused-summarization/">从本地到全局：以查询为中心的摘要的图 RAG 方法中</a>，微软的研究人员建议通过图 RAG 方法结合这些对比方法的优势，在私有文本语料库上进行问答，该方法可扩展的通用性用户问题和要索引的源文本数量。该方法使用 LLM 分两个阶段构建基于图的文本索引：首先从源文档导出实体知识图，然后为所有密切相关实体组预先生成社区摘要。给定一个问题，每个社区摘要都用于生成部分响应，然后所有部分响应再次汇总为对用户的最终响应。对于 100 万个 token 范围内的数据集的一类全局意义构建问题，Graph RAG 在生成答案的全面性和多样性方面比朴素的 RAG 基线有了显着的改进。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-6 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/from-local-to-global-a-graph-rag-approach-to-query-focused-summarization/">阅读论文</a></div></div><div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section"><div class="container"><div class="wp-block-msr-immersive-section__inner"><div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-the-news"><div class="msr-cards__inner"><div class="heading-wrapper"><h2 class="mb-5 ">微软研究院新闻报道</h2></div><div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3"><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Microsoft Announces New Foundation Model For Digital Pathology, Diving Deeper Into Clinical Medicine " href="https://www.forbes.com/sites/saibala/2024/05/22/microsoft-announces-new-foundation-model-for-digital-pathology-diving-deeper-into-clinical-medicine/?sh=7a2956033828"><span>微软宣布推出新的数字病理学基础模型，深入研究临床医学</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>福布斯 | 2024 年 5 月 22 日</p><p>微软与普罗维登斯卫生系统和华盛顿大学合作，利用其在生成人工智能方面的重要工作推出了 GigaPath，这是第一个经过真实世界数据预先训练的数字病理学整体幻灯片基础模型。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Spanish mini-satellites bring the internet to isolated areas (en español) " href="https://www.larazon.es/emergente/mini-satelites-espanoles-que-llevan-internet-zonas-aisladas_20240517664715438e8c66000184230c.html"><span>西班牙迷你卫星将互联网带到偏远地区 (en español)</span> <span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>拉拉松 | 2024 年 5 月 17 日</p><p>西班牙公司 Fossa 在微软研究院的帮助下，成功测试了一颗重量不到一公斤的小型卫星，该卫星改善了覆盖很少或根本没有覆盖的地方的连接性，这对物联网 (IoT) 具有潜在的推动作用。</p></div></div></div></div><div class="justify-content-center text-center mb-4"> <a href="https://www.microsoft.com/en-us/research/news-and-awards/" class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta" data-bi-cN="View more news and awards" data-bi-type="button">查看更多新闻和奖项</a></div></div></div></div></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-27-2024/">研究焦点：2024 年 5 月 27 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>