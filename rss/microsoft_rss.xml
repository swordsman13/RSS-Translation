<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 8 月 14 日星期三 18:25:18 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.6.1</generator><item><title>研究重点：2024 年 8 月 12 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-12-2024/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 14 Aug 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=106540​​5 </guid><description><![CDATA[<p>本期：研究论坛 Ep。 4 探索多模式人工智能。注册现已开放；调查开发者的人工智能需求； SuperBench提高了云AI基础设施的可靠性；虚拟声音：探索影响虚拟会议参与的因素。</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-12-2024/">研究焦点：2024 年 8 月 12 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p>欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。 </p></blockquote></figure><figure class="wp-block-image aligncenter size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1.jpg" alt="研究重点：2024 年 8 月 5 日" class="wp-image-1065426" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/RF47-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-b60fbfa117bcce78e07885aa24d19fc7" id="new-research">事件</h2><h2 class="wp-block-heading" id="heading">立即报名参加 9 月 3 日的研究论坛</h2><p>在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_ep4_RF47_rfhome_2024">Microsoft 研究论坛<span class="sr-only">（在新选项卡中打开）</span></a>中了解 AI 世界的未来，这是一个探索最新研究进展、大胆新想法以及与全球研究界的重要讨论的活动系列。</p><p>在第 4 集中，您将了解最新的多模态 AI 模型、AI 评估和模型自我改进的高级基准，以及用于 AI 推理和硬优化的全新计算机。了解这些研究突破及其他研究如何帮助推进从天气预报到材料设计的一切。</p><p>您的一次性注册包括在活动当天访问我们与研究人员的实时聊天以及深入研究的其他资源。</p><p>第 4 集将于太平洋时间 9 月 3 日星期二上午 9:00 播出。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--c8417a502fb0881854fbf7797a0dae2f"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://register.researchforum.microsoft.com/?OCID=msr_researchforum_ep4_RF47_register_2024" target="_blank" rel="noreferrer noopener">立即注册</a></div></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="999693"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：活动系列</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum" data-bi-cN="Microsoft Research Forum" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png" alt="浅蓝色背景上的各种抽象 3D 形状" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究论坛</h2><p class="large">加入我们，持续交流有关通用人工智能时代研究的想法。点播观看前三集。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Register for series" data-bi-cN="Microsoft Research Forum" target="_blank">注册系列</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">为开发者提供有效的人工智能支持：愿望和担忧的调查</h2><p>与客户交谈可以让我们深入了解他们面临的挑战以及他们的喜好。这有助于确定解决问题的创新和创造性方法（无需创建新问题），并防止破坏客户真正喜欢的工作流程。然而，目前许多人工智能相关的开发工具都是在没有咨询开发人员的情况下构建的。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/towards-effective-ai-support-for-developers-a-survey-of-desires-and-concerns/">为开发人员提供有效的人工智能支持：愿望和担忧的调查中</a>，微软的研究人员探讨了开发人员对工作流程中人工智能集成的看法。这项研究揭示了开发人员对人工智能帮助的最大愿望以及他们的主要担忧。这项针对 791 名 Microsoft 开发人员的全面调查结果帮助研究人员确定人工智能可以提高生产力的关键领域以及如何解决开发人员的担忧。研究结果为产品团队和领导者提供了可操作的见解，以创建真正支持开发人员需求的人工智能工具。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--a5ff7fafbe09f9bf2262f5f0b82d60df"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/towards-effective-ai-support-for-developers-a-survey-of-desires-and-concerns/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">SuperBench：通过主动验证提高云人工智能基础设施的可靠性</h2><p>多年来，云服务提供商一直在硬件中使用地理冗余来确保其云基础设施的可用性。然而，对于人工智能工作负载来说，这些冗余可能会无意中导致隐藏的性能下降，也称为“灰色故障”。这可能会降低端到端性能并隐藏性能问题，从而使故障和回归的根本原因分析变得复杂。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/superbench/">SuperBench：通过主动验证提高云 AI 基础设施可靠性<span class="sr-only">（在新选项卡中打开）中</span></a>，Microsoft 研究人员和 Azure 云工程师介绍了专门针对 AI 基础设施的主动验证系统，该系统可减轻由硬件冗余引起的隐藏性能下降<s> </s>。该论文获得了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.usenix.org/conference/atc24" target="_blank" rel="noreferrer noopener"><strong><em>USENIX ATC</em></strong> <span class="sr-only">（在新选项卡中打开）</span></a>的“最佳论文”奖，概述了 SuperBench 的综合基准测试套件，该套件能够评估单个硬件组件并代表最真实的人工智能工作负载。它包括一个验证器，它学习基准标准以清楚地查明有缺陷的组件，以及一个选择器，它平衡验证时间和与问题相关的惩罚，从而通过定制的基准子集实现验证执行的最佳时机。测试台评估和模拟表明 SuperBench 可以将事件之间的平均时间延长多达 22.61 倍。 SuperBench 已成功部署在 Azure 生产中，在过去两年中验证了数十万个 GPU。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--05c72106642e59efc87498659bddbe2a"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/superbench/">阅读论文</a></div><div class="wp-block-button is-style-outline is-style-outline--a9bb4b8e2ddb13a58551549df33cec46"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/superbenchmark/" target="_blank" rel="noreferrer noopener">查看 GitHub</a> </div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"><h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">新研究</h2><h2 class="wp-block-heading" id="heading">虚拟声音：探索书面和口头参与会议的个体差异</h2><p>团队绩效的一个关键组成部分是团队成员的参与。工作场所会议为这种参与提供了一个共同的舞台。但随着远程工作的转变，许多会议都是虚拟进行的。在此类会议中，聊天提供了另一种参与途径，与会者可以通过写作同步参与对话。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/virtual-voices-exploring-individual-differences-in-written-and-verbal-participation-in-meetings/">虚拟声音：探索会议中书面和口头参与的个体差异<span class="sr-only">（在新选项卡中打开）中</span></a>，来自 Microsoft 的研究人员和外部同事利用个体差异（状态特征理论）、心理因素，探讨了影响虚拟会议参与的因素。安全观念和团体沟通。该论文的结果发表在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.sciencedirect.com/science/article/abs/pii/S0001879124000563" target="_blank" rel="noreferrer noopener">《职业行为杂志<span class="sr-only">》（在新选项卡中打开）</span></a>上，揭示了性别（自我认同）和工作级别的细微差别。根据会议遥测测量，女性更多地参与聊天，而男性更频繁地口头参与。此外，职位级别最高的男性在虚拟会议中口头贡献最多，而职位级别最高的女性使用聊天的频率最高。关于发送的聊天类型，女性比男性更频繁地使用表情符号反应，男性比女性发送更多附件。此外，结果显示，心理安全感调节了工作级别与整体聊天参与度之间的关系，因此工作级别低、心理安全感高的员工比同事发送了更多的聊天内容。这项研究提供了关于沟通模式以及心理安全对参与技术介导空间的影响的见解。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline is-style-outline--acd10b286c3bea4ae62e49034e4073b7"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/virtual-voices-exploring-individual-differences-in-written-and-verbal-participation-in-meetings/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-12-2024/">研究焦点：2024 年 8 月 12 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>大规模病理学基础模型在各种癌症相关任务中显示出前景</title><link/>https://www.microsoft.com/en-us/research/blog/large-scale-pathology-foundation-models-show-promise-on-a-variety-of-cancer-lated-tasks/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 08 Aug 2024 19:13:34 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>微软研究人员合作发布了新的病理学基础模型。他们的报告显示，模型受益于多样化的数据、增加的模型大小和专门的算法，以提高癌症诊断和治疗的准确性和适用性。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/large-scale-pathology-foundation-models-show-promise-on-a-variety-of-cancer-related-tasks/">大规模病理学基础模型在各种癌症相关任务中显示出前景，该</a>帖子首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1.jpg" alt="男医生在医院办公桌前使用电脑" class="wp-image-1068084" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>想象一下，如果病理学家拥有可以通过分析癌症组织图像来帮助预测治疗反应的工具。这一愿景有一天可能会通过计算病理学的革命性领域成为现实。通过利用人工智能和机器学习，研究人员现在能够以前所未有的准确性和规模分析数字化组织样本，这有可能改变我们理解和治疗癌症的方式。</p><p>当怀疑患者患有癌症时，有时会取出组织样本，进行染色，将其固定在载玻片上，然后由病理学家使用显微镜进行分析。病理学家在该组织上执行多项任务，例如检测癌细胞和确定癌症亚型。这些微小的组织样本越来越多地被数字化成巨大的完整幻灯片图像，其细节足以比手机上存储的典型照片大 50,000 倍。机器学习模型最近的成功，加上这些图像的可用性不断增加，点燃了计算病理学领域，该领域专注于组织分析机器学习模型的创建和应用，旨在揭示抗击癌症的新见解。</p><p>直到最近，计算病理学模型的潜在适用性和影响还受到限制，因为这些模型是诊断特异性的，并且通常在狭窄的样本上进行训练。因此，它们往往缺乏足够的性能来满足现实世界的临床实践，在现实世界的临床实践中，患者样本代表了广泛的疾病特征和实验室准备工作。此外，罕见和不常见癌症的应用很难收集足够的样本量，这进一步限制了计算病理学的范围。</p><p>基础模型的兴起正在引入计算病理学的新范式。这些大型神经网络在不需要标记的庞大且多样化的数据集上进行训练，使它们能够泛化到许多任务。他们为从大型、未标记的整个幻灯片图像中学习创造了新的可能性。然而，基础模型的成功关键取决于数据集和模型本身的大小。 </p><h2 class="wp-block-heading" id="advancing-pathology-foundation-models-with-data-scale-model-scale-and-algorithmic-innovation">通过数据规模、模型规模和算法创新推进病理学基础模型</h2><p>Microsoft Research 与癌症临床 AI 应用领域的全球领导者<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://paige.ai/" target="_blank" rel="noreferrer noopener">Paige <span class="sr-only">（在新选项卡中打开）</span></a>合作，正在推进计算基础模型的最先进技术。此次合作的第一个贡献是一个名为 Virchow 的模型，我们对此的研究最近发表在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41591-024-03141-0" target="_blank" rel="noreferrer noopener">《自然医学<span class="sr-only">》（在新选项卡中打开）</span></a>上。 Virchow 是病理学基础模型的重要证明点，因为它证明了单个模型如何可用于检测常见和罕见的癌症，从而实现了可推广表示的承诺。继这一成功之后，我们开发了两个第二代计算病理学基础模型，称为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.businesswire.com/news/home/20240808348827/en/Unlocking-the-Complexities-of-Cancer-Paige-Launches-Worlds-Largest-AI-Models-to-Revolutionize-Cancer-Diagnosis-with-Second-Generation-of-Virchow">Virchow2 和 Virchow2G <span class="sr-only">（在新选项卡中打开）</span> ，</a>它们受益于数据集和模型大小的前所未有的扩展，如图 1 所示。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="2100" height="571" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1.jpg" alt="与模型参数数量（左侧）和训练整个幻灯片图像数量（右侧）相比的性能缩放图（y 轴）。中间面板描述了 Virchow 2 除了引入病理学特定训练之外还如何增加数据集大小和多样性。 Virchow 2G 进一步增加了模型尺寸。" class="wp-image-1067133" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1.jpg 2100w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-300x82.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-1024x278.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-768x209.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-1536x418.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-2048x557.jpg 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-240x65.jpg 240w" sizes="(max-width: 2100px) 100vw, 2100px" /><figcaption class="wp-element-caption">图 1. Virchow2G 通过利用庞大的数据集和模型大小，在病理学任务上实现了最先进的性能。</figcaption></figure><p>除了访问大型数据集和强大的计算能力之外，我们的团队还展示了如何根据病理数据的独特方面定制用于训练基础模型的算法也可以提高性能，从而展示了进一步的创新。 <a href="https://www.microsoft.com/en-us/research/publication/virchow-2-scaling-self-supervised-mixed-magnification-models-in-pathology/" target="_blank" rel="noreferrer noopener">最近的一份技术报告</a>描述了这三大支柱——数据规模、模型规模和算法创新。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1045002"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：活动</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/event/cvpr-2024/" aria-label="Microsoft at CVPR 2024" data-bi-cN="Microsoft at CVPR 2024" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CVPR_WebBanner_1920x720.png" alt="青色背景三角形图案" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软在 CVPR 2024</h2><p class="large"> Microsoft 是<a href="https://cvpr2023.thecvf.com/Conferences/2024" target="_blank" rel="noreferrer noopener">CVPR 2024</a>的赞助商和积极参与者，该会议重点关注计算机视觉和模式识别领域的进步。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/event/cvpr-2024/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Learn more" data-bi-cN="Microsoft at CVPR 2024" target="_blank">了解更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="virchow-foundation-models-and-their-performance">Virchow基础模型及其性能</h2><p>Virchow2 和 2G 模型使用来自超过 310 万张完整幻灯片图像（2.4PB 数据）的数据，这些图像对应于 45 个国家 225,000 名患者的 40 多个组织，并在最大的已知数字病理数据集上进行训练。 Virchow2 与第一代 Virchow 的模型大小相当，有 6.32 亿个参数，而 Virchow2G 将模型大小扩展到 18.5 亿个参数，使其成为最大的病理模型。</p><p>在报告中，我们评估了这些基础模型在 12 项任务上的性能，旨在了解计算病理学应用领域的广度。早期结果表明 Virchow2 和 Virchow2G 更擅长识别细胞形状和结构中的微小细节，如图 2 所示。它们在检测细胞分裂和预测基因活性等任务中表现良好。这些任务可能受益于细微特征的量化，例如细胞核的形状和方向。我们目前正在努力扩大评估任务的数量，以包含更多功能。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="3648" height="591" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled.png" alt="从左到右：H&amp;E 染色的结直肠组织图像、带有细胞类型专家注释的同一图像以及由 Virchow 确定的具有最突出特征的同一图像。接下来是 H&amp;E 染色的结直肠组织的第二张图像，该图像带有细胞类型的专家注释，以及由 Virchow 确定的具有最突出特征的同一图像。在这两种情况下，魏尔啸都强调了癌细胞。" class="wp-image-1068066" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled.png 3648w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-300x49.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-1024x166.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-768x124.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-1536x249.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-2048x332.png 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-240x39.png 240w" sizes="(max-width: 3648px) 100vw, 3648px" /><figcaption class="wp-element-caption">图 2. Virchow 学习了如何理清病理图像中的不同内容。该图显示了染色结直肠组织样本的三种可视化：组织样本本身 (A)、专家注释 (B) 和模型表示 (C)。当选择图像中最突出的内容时，癌细胞（B，红色）会突出显示（C）。</figcaption></figure><h2 class="wp-block-heading" id="looking-forward">期待</h2><p>医疗保健和生命科学领域的基础模型有潜力显着造福社会。我们在 Virchow 模型上的合作已经奠定了基础，我们的目标是继续研究这些模型，为它们提供更多功能。在<a href="https://www.microsoft.com/en-us/research/lab/microsoft-health-futures" target="_blank" rel="noreferrer noopener">微软健康未来研究院</a>，我们相信进一步的研究和开发可能会带来常规成像的新应用，例如生物标志物预测，目标是更有效、更及时的癌症治疗。</p><p> Paige 在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/paige-ai/Virchow-2">Hugging Face <span class="sr-only">（在新选项卡中打开）</span></a>上发布了 Virchow2，我们邀请研究界探索计算病理学模型可以揭示的新见解。请注意，Virchow2 和 Virchow2G 是研究模型，并不用于做出诊断或治疗决策。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/large-scale-pathology-foundation-models-show-promise-on-a-variety-of-cancer-related-tasks/">大规模病理学基础模型在各种癌症相关任务中显示出前景，该</a>帖子首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>