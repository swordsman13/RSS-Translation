<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 8 月 8 日星期四 21:48:39 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.5</generator><item><title>大规模病理学基础模型在各种癌症相关任务中显示出前景</title><link/>https://www.microsoft.com/en-us/research/blog/large-scale-pathology-foundation-models-show-promise-on-a-variety-of-cancer-lated-tasks/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 08 Aug 2024 19:13:34 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>微软研究人员合作发布了新的病理学基础模型。他们的报告显示，模型受益于多样化的数据、增加的模型大小和专门的算法，以提高癌症诊断和治疗的准确性和适用性。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/large-scale-pathology-foundation-models-show-promise-on-a-variety-of-cancer-related-tasks/">大规模病理学基础模型在各种癌症相关任务中显示出前景，该</a>帖子首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1.jpg" alt="男医生在医院办公桌前使用电脑" class="wp-image-1068084" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Verchow-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>想象一下，如果病理学家拥有可以通过分析癌症组织图像来帮助预测治疗反应的工具。这一愿景有一天可能会通过计算病理学的革命性领域成为现实。通过利用人工智能和机器学习，研究人员现在能够以前所未有的准确性和规模分析数字化组织样本，这有可能改变我们理解和治疗癌症的方式。</p><p>当怀疑患者患有癌症时，有时会取出组织样本，进行染色，将其固定在载玻片上，然后由病理学家使用显微镜进行分析。病理学家在该组织上执行多项任务，例如检测癌细胞和确定癌症亚型。这些微小的组织样本越来越多地被数字化成巨大的完整幻灯片图像，其细节足以比手机上存储的典型照片大 50,000 倍。机器学习模型最近的成功，加上这些图像的可用性不断增加，点燃了计算病理学领域，该领域专注于用于组织分析的机器学习模型的创建和应用，旨在揭示抗击癌症的新见解。</p><p>直到最近，计算病理学模型的潜在适用性和影响仍然有限，因为这些模型是诊断特异性的，并且通常在狭窄的样本上进行训练。因此，它们往往缺乏足够的性能来满足现实世界的临床实践，在现实世界的临床实践中，患者样本代表了广泛的疾病特征和实验室准备工作。此外，罕见和不常见癌症的应用很难收集足够的样本量，这进一步限制了计算病理学的范围。</p><p>基础模型的兴起正在引入计算病理学的新范式。这些大型神经网络在不需要标记的庞大且多样化的数据集上进行训练，使它们能够泛化到许多任务。他们为从大型、未标记的整个幻灯片图像中学习创造了新的可能性。然而，基础模型的成功关键取决于数据集和模型本身的大小。 </p><h2 class="wp-block-heading" id="advancing-pathology-foundation-models-with-data-scale-model-scale-and-algorithmic-innovation">通过数据规模、模型规模和算法创新推进病理学基础模型</h2><p>Microsoft Research 与癌症临床 AI 应用领域的全球领导者<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://paige.ai/" target="_blank" rel="noreferrer noopener">Paige <span class="sr-only">（在新选项卡中打开）</span></a>合作，正在推进计算基础模型的最先进技术。此次合作的第一个贡献是一个名为 Virchow 的模型，我们对此的研究最近发表在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41591-024-03141-0" target="_blank" rel="noreferrer noopener">《自然医学<span class="sr-only">》（在新选项卡中打开）</span></a>上。 Virchow 是病理学基础模型的重要证明点，因为它证明了单个模型如何可用于检测常见和罕见的癌症，从而实现了可推广表示的承诺。继这一成功之后，我们开发了两个第二代计算病理学基础模型，称为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.businesswire.com/news/home/20240808348827/en/Unlocking-the-Complexities-of-Cancer-Paige-Launches-Worlds-Largest-AI-Models-to-Revolutionize-Cancer-Diagnosis-with-Second-Generation-of-Virchow">Virchow2 和 Virchow2G <span class="sr-only">（在新选项卡中打开）</span> ，</a>它们受益于数据集和模型大小的前所未有的扩展，如图 1 所示。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="2100" height="571" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1.jpg" alt="与模型参数数量（左侧）和训练整个幻灯片图像数量（右侧）相比的性能缩放图（y 轴）。中间面板描述了 Virchow 2 除了引入病理学特定训练之外还如何增加数据集大小和多样性。 Virchow 2G 进一步增加了模型尺寸。" class="wp-image-1067133" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1.jpg 2100w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-300x82.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-1024x278.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-768x209.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-1536x418.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-2048x557.jpg 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/Fig_scaling_teaser-1-240x65.jpg 240w" sizes="(max-width: 2100px) 100vw, 2100px" /><figcaption class="wp-element-caption">图 1. Virchow2G 通过利用庞大的数据集和模型大小，在病理学任务上实现了最先进的性能。</figcaption></figure><p>除了访问大型数据集和强大的计算能力之外，我们的团队还展示了如何根据病理数据的独特方面定制用于训练基础模型的算法也可以提高性能，从而展示了进一步的创新。 <a href="https://www.microsoft.com/en-us/research/publication/virchow-2-scaling-self-supervised-mixed-magnification-models-in-pathology/" target="_blank" rel="noreferrer noopener">最近的一份技术报告</a>描述了这三大支柱——数据规模、模型规模和算法创新。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="电脑屏幕截图 一名男子的屏幕截图" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 解释者：基础模型和 AI 的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多数据以及情境学习如何帮助推动人工智能从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">观看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="virchow-foundation-models-and-their-performance">Virchow基础模型及其性能</h2><p>Virchow2 和 2G 模型使用来自超过 310 万张完整幻灯片图像（2.4PB 数据）的数据，这些图像对应于 45 个国家 225,000 名患者的 40 多个组织，并在最大的已知数字病理数据集上进行训练。 Virchow2 与第一代 Virchow 的模型大小相当，有 6.32 亿个参数，而 Virchow2G 将模型大小扩展到 18.5 亿个参数，使其成为最大的病理模型。</p><p>在报告中，我们评估了这些基础模型在 12 项任务上的性能，旨在了解计算病理学应用领域的广度。早期结果表明 Virchow2 和 Virchow2G 更擅长识别细胞形状和结构中的微小细节，如图 2 所示。它们在检测细胞分裂和预测基因活性等任务中表现良好。这些任务可能受益于细微特征的量化，例如细胞核的形状和方向。我们目前正在努力扩大评估任务的数量，以包含更多功能。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="3648" height="591" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled.png" alt="从左到右：H&amp;E 染色的结直肠组织图像、带有细胞类型专家注释的同一图像以及由 Virchow 确定的具有最突出特征的同一图像。接下来是 H&amp;E 染色的结直肠组织的第二张图像，该图像带有细胞类型的专家注释，以及由 Virchow 确定的具有最突出特征的同一图像。在这两种情况下，魏尔啸都强调了癌细胞。" class="wp-image-1068066" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled.png 3648w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-300x49.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-1024x166.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-768x124.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-1536x249.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-2048x332.png 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/08/blog_fig2_v2_labeled-240x39.png 240w" sizes="(max-width: 3648px) 100vw, 3648px" /><figcaption class="wp-element-caption">图 2. Virchow 学习了如何理清病理图像中的不同内容。该图显示了染色结直肠组织样本的三种可视化：组织样本本身 (A)、专家注释 (B) 和模型表示 (C)。当选择图像中最突出的内容时，癌细胞（B，红色）会突出显示（C）。</figcaption></figure><h2 class="wp-block-heading" id="looking-forward">期待</h2><p>医疗保健和生命科学领域的基础模型有潜力显着造福社会。我们在 Virchow 模型上的合作已经奠定了基础，我们的目标是继续研究这些模型，为它们提供更多功能。在<a href="https://www.microsoft.com/en-us/research/lab/microsoft-health-futures" target="_blank" rel="noreferrer noopener">微软健康未来研究院</a>，我们相信进一步的研究和开发可能会带来常规成像的新应用，例如生物标志物预测，目标是更有效、更及时的癌症治疗。</p><p> Paige 在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/paige-ai/Virchow-2">Hugging Face <span class="sr-only">（在新选项卡中打开）</span></a>上发布了 Virchow2，我们邀请研究界探索计算病理学模型可以揭示的新见解。请注意，Virchow2 和 Virchow2G 是研究模型，并不用于做出诊断或治疗决策。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/large-scale-pathology-foundation-models-show-promise-on-a-variety-of-cancer-related-tasks/">大规模病理学基础模型在各种癌症相关任务中显示出前景，该</a>帖子首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> GENEVA 使用大语言模型进行互动游戏叙事设计</title><link/>https://www.microsoft.com/en-us/research/blog/geneva-uses-large-language-models-for-interactive-game-narrative-design/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Mon, 05 Aug 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/geneva-uses-large-language-models-for-interactive-game-narrative-design/ </guid><description><![CDATA[<p> GENEVA 专为游戏中的交互式故事讲述而设计，可让用户探索叙事路径并使故事适应不同的背景。它使用法学硕士从高级描述中生成和可视化分支叙述，并将它们表示为图表。</p><p>后<a href="https://www.microsoft.com/en-us/research/blog/geneva-uses-large-language-models-for-interactive-game-narrative-design/">GENEVA使用大型语言模型进行交互式游戏叙事设计</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-center"><strong><em>本文在</em></strong><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2024.ieee-cog.org/" target="_blank" rel="noreferrer noopener"><strong><em>IEEE 2024 年游戏会议</em></strong><span class="sr-only">（在新选项卡中打开）</span></a> <strong><em>(IEEE CoG 2024) 上发表，该会议是关于游戏创新的领先论坛。</em></strong> </p><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1.png" alt="IEEE 2024 游戏大会回顾博客" class="wp-image-1057038" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-Conference-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>掌握讲故事的艺术是电影、小说、游戏等领域中一项非常有价值的技能，需要创造具有引人入胜的情节和角色的丰富叙事。近年来，人工智能的兴起引发了人们对大型语言模型（LLM）是否能够有效生成和维持吸引观众的详细、连贯的故事情节的疑问。因此，研究人员一直在积极探索人工智能支持视频游戏开发创意过程的潜力，其中叙事设计不断增长的需求往往超出了传统工具的能力。这项调查的重点是人工智能在讲故事方面的创新能力以及推动此类进步所需的人类互动。</p><p>在这种背景下，我们介绍了在 IEEE CoG 2024 上提出的“ <a href="https://www.microsoft.com/en-us/research/publication/geneva-generating-and-visualizing-branching-narratives-using-llms/" target="_blank" rel="noreferrer noopener">GENEVA：使用 LLM 生成和可视化分支叙述<span class="sr-only">（在新选项卡中打开）</span></a> ”。这种基于图形的叙述生成和可视化工具需要高级叙述描述和约束，例如比如不同的开始、结局和故事情节的数量，以及叙事的背景。 GENEVA 使用 GPT-4 的生成功能来创建具有分支故事情节的叙事，并将其以图形格式呈现，允许用户通过其<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://narrative.msr-emergence.com/" target="_blank" rel="noreferrer noopener">Web 界面<span class="sr-only">（在新选项卡中打开）</span></a>交互式探索不同的叙事路径。</p><h2 class="wp-block-heading" id="visualizing-narratives-using-graphs">使用图表可视化叙述</h2><p>叙事图本身是一个有向无环图 (DAG)，其中每个节点代表一个<em>叙事节拍</em>（推动情节向前发展的事件），并用有向边（箭头）标记故事事件的进展。这些节拍是叙事结构的基本单位，代表着行动和反应的交换。从起始节点到结束节点的单一路径概述了独特的故事情节，并且该图说明了基于相同总体叙述的各种潜在故事情节。</p><p>这些叙述图的生成和可视化是使用 GPT-4 分两步完成的。首先，模型根据给定的描述和约束生成分支故事情节。其次，它生成代码以视觉上可理解的图形格式呈现这些叙述。</p><p>我们在<a href="https://www.microsoft.com/en-us/research/publication/geneva-generating-and-visualizing-branching-narratives-using-llms/" target="_blank" rel="noreferrer noopener">论文</a>中通过案例研究详细介绍了这种方法，其中我们使用日内瓦为四个著名故事（ <em>《德古拉》</em> 、 <em>《弗兰肯斯坦》</em> 、 <em>《杰克与魔豆</em>》和<em>《小红帽》）</em>构建了叙事图表。每个游戏都以四个不同的世界之一为背景：《我的世界》游戏、 <sup>21</sup>世纪、古罗马和量子领域。图1显示了以<sup>21</sup>世纪为背景的弗兰肯斯坦的叙事图，图2显示了为这个故事生成的故事情节。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1200" height="959" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-demo.png" alt="图 1. GENEVA 在线界面截图。屏幕截图的标题是“可视化生成的叙述”。标题下方有四个下拉菜单，每个菜单都包含故事、开始数量、结束数量、情节数量和上下文。为各个选项选择的值是弗兰肯斯坦故事，有 1 个开头、2 个结局、4 个情节，背景设定在 21 世纪。除此之外，还有两个按钮，一个显示“显示图表”，另一个显示“显示详细信息”。这些菜单选项下方是一个带有节点和边的大图。左侧的一个橙色节点被注释为起始节点，右侧的两个橙色节点被注释为结束节点。其余节点为蓝色，每个节点都注释有大约 3 到 4 个单词的短语。" class="wp-image-1057032" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-demo.png 1200w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-demo-300x240.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-demo-1024x818.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-demo-768x614.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-demo-225x180.png 225w" sizes="(max-width: 1200px) 100vw, 1200px" /><figcaption class="wp-element-caption">图 1：21 世纪小说《弗兰肯斯坦》的叙事图。图表上的其他约束包括一个开始、两个结局和四个故事情节。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1280" height="879" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details.png" alt="图 2. GENEVA 在线界面截图。屏幕截图的标题是“可视化生成的叙述”。标题下方有四个下拉菜单，每个菜单都包含故事、开始数量、结束数量、情节数量和上下文。为各个选项选择的值是弗兰肯斯坦故事，有 1 个开头、2 个结局、4 个情节，背景设定在 21 世纪。除此之外，还有两个按钮，一个显示“显示图表”，另一个显示“隐藏详细信息”。这些菜单选项下方是一个包含三个故事情节的大文本区域。每个故事情节都由一系列节拍组成。每个节拍都有一个唯一的编号和描述该节拍的句子。" class="wp-image-1057029" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details-300x206.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details-1024x703.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details-768x527.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details-800x550.png 800w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/IEEE-conference-blog_frankenstien-details-240x165.png 240w" sizes="(max-width: 1280px) 100vw, 1280px" /><figcaption class="wp-element-caption">图 2：图 1 叙述图中四个不同故事情节的详细视图。 </figcaption></figure><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1045008"><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/" aria-label="GigaPath: Whole-Slide Foundation Model for Digital Pathology" data-bi-cN="GigaPath: Whole-Slide Foundation Model for Digital Pathology" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/GigaPath-TW_FB_LI.png" alt="数字病理学有助于解码肿瘤微环境以进行精准免疫治疗。 GigaPath 是一种新颖的视觉转换器，可以通过适应数字病理学的扩展注意力来扩展到十亿像素的全幻灯片图像。在与普罗维登斯大学和华盛顿大学的合作中，我们正在共享 Prov-GigaPath，这是第一个基于大规模真实数据进行预训练的全幻灯片病理学基础模型，用于推进临床研究和发现。" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> GigaPath：数字病理学的全幻灯片基础模型</h2><p class="large">数字病理学有助于解码肿瘤微环境以进行精准免疫治疗。我们与普罗维登斯大学和华盛顿大学合作，共享 Prov-GigaPath，这是第一个全玻片病理学基础模型，用于推进临床研究。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Read more" data-bi-cN="GigaPath: Whole-Slide Foundation Model for Digital Pathology" target="_blank">阅读更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="assessing-geneva-s-narrative-adaptations">评估《日内瓦》的叙事改编</h2><p>在我们的评估中，我们发现《日内瓦》在特定的叙事背景下表现更好。例如，在改编自 21 世纪<em>的《弗兰肯斯坦》</em>中，故事情节包括利用 DNA 片段和基因工程创造生命等主题，在保持相关性的同时保留了原始故事的精髓。然而，经过仔细检查，我们发现了需要改进的地方，例如需要更多的多样性和更好的叙事基础。一般来说，更广为人知、记录更详尽的故事往往会产生更丰富、更多样化的改编。</p><h2 class="wp-block-heading" id="implications-and-looking-forward">影响和展望</h2><p>GENEVA 仍然是一个原型，作为探索法学硕士叙事能力的工具。随着这些模型的发展，我们预计它们的叙事生成能力也会相应进步。游戏设计的最终目标是让玩家获得引人入胜的互动体验。凭借经验丰富的游戏设计师的熟练输入，像 GENEVA 这样的工具可以通过迭代完善叙事路径来越来越有助于创造引人入胜的游戏体验。</p><p>我们<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://developer.microsoft.com/en-us/games/articles/2023/11/xbox-and-inworld-ai-partnership-announcement/" target="_blank" rel="noreferrer noopener">与 Xbox 和 Inworld AI <span class="sr-only">（在新选项卡中打开）</span>的合作</a>继续推进 AI 在游戏开发中的使用，将这些开发成果融入到创作者的实用工具中。通过观看<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.youtube.com/watch?v=RjoRW6yyEsA" target="_blank" rel="noreferrer noopener">此视频<span class="sr-only">（在新选项卡中打开）</span></a>了解有关这一变革性技术的更多信息。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>后<a href="https://www.microsoft.com/en-us/research/blog/geneva-uses-large-language-models-for-interactive-game-narrative-design/">GENEVA使用大型语言模型进行交互式游戏叙事设计</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>