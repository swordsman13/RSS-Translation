<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 4 月 5 日星期五 21:02:44 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.3</generator><item><title>研究重点：2024 年 4 月 1 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-1-2024/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 03 Apr 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-1-2024/ </guid><description><![CDATA[<p>本期：新研究帮助 COMET 拥抱非洲语言； FeatUp 改进了深层特征，是计算机视觉研究的基石； Imaginarium 的法学硕士：通过模拟试错进行工具学习；跨语言等对法学硕士进行基准测试。</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-1-2024/">研究焦点：2024 年 4 月 1 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1.png" alt="研究重点 2024 年 4 月 1 日" class="wp-image-1021371" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF38-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-73123c9697b9c6db2728fb2f179fa924" id="new-research-2">新研究</h3><h2 class="wp-block-heading" id="llms-in-the-imaginarium-tool-learning-through-simulated-trial-and-error"> Imaginarium 中的法学硕士：通过模拟试错来学习工具</h2><p>就像工具可以帮助人们完成超出其先天能力的任务一样，工具对于大型语言模型 (LLM) 获取最新信息并在外部环境中采取相应行动至关重要。工具增强法学硕士的现有工作主要侧重于工具的广泛覆盖范围和添加新工具的灵活性。然而，一个令人惊讶的未被充分研究的问题是，法学硕士如何准确地使用其接受过培训的工具。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/llms-in-the-imaginarium-tool-learning-through-simulated-trial-and-error/">Imaginarium 中的 LLM：通过模拟试错进行工具学习 中</a>，微软的研究人员发现现有的 LLM，包括 GPT-4 和专门针对工具使用进行微调的开源 LLM，正确率仅达到 30 %到60%，这对于实际使用来说太不可靠了。他们提出了一种受生物学启发的工具增强法学硕士方法——模拟试错（STE）——协调三个关键机制：试错、想象力和记忆。 STE 模拟使用工具的合理场景，然后法学硕士与该工具交互以从其执行反馈中学习。短期记忆和长期记忆都被用来提高探索的深度和广度。 ToolBench 上的实验表明，STE 在上下文学习和微调设置下显着改善了法学硕士的工具学习。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/llms-in-the-imaginarium-tool-learning-through-simulated-trial-and-error/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1002645"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：人工智能驱动的体验</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo" aria-label="Microsoft research copilot experience" data-bi-cN="Microsoft research copilot experience" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MSR-Chat-Promo.png" alt="" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究院副驾驶经历</h2><p class="large">通过我们的人工智能体验，了解有关 Microsoft 研究的更多信息</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Microsoft research copilot experience" data-bi-cN="Microsoft research copilot experience" target="_blank">现在开始</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-ad50996f2914bc16d805d061e6456589" id="new-research-4">新研究</h3><h2 class="wp-block-heading" id="benchmarking-large-language-models-across-languages-modalities-models-and-tasks">跨语言、模式、模型和任务对大型语言模型进行基准测试</h2><p>最新的法学硕士在多项任务和基准测试中的表现已经超越了旧语言模型，有时接近甚至超过了人类的表现。然而，并不总是清楚这是否是由于这些模型的功能增强，还是其他影响，例如数据集中的伪影、测试数据集污染以及缺乏衡量这些模型真实功能的数据集。</p><p>因此，了解 LLM 能力和局限性的研究最近激增。然而，大部分研究仅限于英语，因此非英语语言的法学硕士建设和评估相对未经探索。最近推出了几个新的法学硕士，需要对非英语语言进行评估。在最近的一篇论文：MEGAVERSE： <a href="https://www.microsoft.com/en-us/research/publication/benchmarking-large-language-models-across-languages-modalities-models-and-tasks/">跨语言、模态、模型和任务的大型语言模型基准测试中</a>，微软的研究人员旨在对最先进的法学硕士的非英语能力进行全面评估（GPT-3.5-Turbo） 、GPT-4、PaLM2、Mistral、Gemini、Gemma 和 Llama2），在同一组多语言数据集上进行比较。他们的基准包括 22 个数据集，涵盖 81 种语言，其中包括几种资源匮乏的非洲语言。他们还在基准测试中包含两个多模式数据集，并比较 LLaVA-v1.5 和 GPT-4-Vision 的性能。实验表明，GPT-4 和 PaLM2 在各种任务上都优于 Llama 和 Mistral 模型，特别是在低资源语言上，GPT-4 在更多数据集上优于 PaLM2。然而，必须解决数据污染等问题，才能准确评估非英语语言的法学硕士表现。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/benchmarking-large-language-models-across-languages-modalities-models-and-tasks/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-0663ba4d11b1a8df4b8ebb08832c118e" id="new-research-3">新研究</h3><h2 class="wp-block-heading" id="training-audio-captioning-models-without-audio">在没有音频的情况下训练音频字幕模型</h2><p>自动音频字幕 (AAC) 是一个为录音创建文本描述的过程。与转录语音的隐藏式字幕不同，AAC 旨在描述音频中的所有声音（例如：人们在背景中说话时发出低沉的隆隆声，同时远处警报器鸣响）。典型的 AAC 系统需要昂贵的音频-文本对精选数据，这通常会导致缺乏合适的数据，从而阻碍模型训练。</p><p>在这篇论文《 <a href="https://www.microsoft.com/en-us/research/publication/training-audio-captioning-models-without-audio/">没有音频的情况下训练音频字幕模型》</a>中，来自微软和卡内基梅隆大学的研究人员提出了一种训练 AAC 系统的新范例，仅使用文本描述，从而消除了配对音频和文本描述的要求。他们的方法利用了 CLAP，这是一种对比学习模型，使用音频和文本编码器在音频和文本之间创建共享向量表示。例如，文本“警笛鸣响”及其相应的录音将共享相同的向量。该模型根据文本字幕进行训练：GPT 语言解码器根据预训练的 CLAP 文本编码器和映射网络生成字幕。在推理过程中，首先使用预训练的 CLAP<em>音频</em>编码器将音频输入转换为其向量，然后生成文本标题。</p><p>研究人员发现，所提出的纯文本框架与在文本和音频上训练的顶级模型具有很好的竞争性，证明高效的文本到音频转换是可能的。他们还展示了融合各种写作风格的能力，例如幽默，有利于根据特定领域定制字幕生成。最后，他们强调，利用法学硕士生成的文本丰富训练可以提高性能，并有可能增加词汇多样性。这是一个将微软人工智能原理付诸实践的研究项目。如果系统的使用方式被滥用或非法或侵犯您或其他人的权利，您可以在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://mcas-proxyweb.mcas.ms/certificate-checker?login=false&originalUrl=https%3A%2F%2Fmsrc.microsoft.com.mcas.ms%2Freport%2Fabuse%3FMcasTsid%3D20892&McasCSRF=00149341d131a8e83b03829abe906f4d53486a783e05d1c655422c338fd004b0" target="_blank" rel="noreferrer noopener">举报滥用门户<span class="sr-only">（在新选项卡中打开）</span></a>中举报。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/training-audio-captioning-models-without-audio/">阅读论文</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-1-2024/">研究焦点：2024 年 4 月 1 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>从与 Microsoft Copilot 的交互中学习（网络）</title><link/> https://www.microsoft.com/en-us/research/blog/learning-from-interaction-with-microsoft-copilot-web/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 27 Mar 2024 22:22:24 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>微软研究人员正在采取全面、动态的方法来帮助 Copilot（网络）不断从交互和反馈中学习，改进人工智能系统并使其对消费者越来越有用。了解更多。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/learning-from-interaction-with-microsoft-copilot-web/">从与 Microsoft Copilot 的交互中学习（网络）</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1.jpg" alt="显示人工智能如何从用户交互中学习的流程图" class="wp-image-1017312" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Learning-from-User-Interactions-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>像 Bing 和 Microsoft Copilot（网络）这样的人工智能系统之所以出色，是因为它们不断从人们的互动中学习和改进。自 2000 年代初以来，用户对搜索结果页面的点击推动了搜索引擎的不断改进。最近，基于人类反馈的强化学习 (RLHF) 为生成式 AI 模型的响应质量带来了阶跃函数改进。 Bing 在通过学习用户交互来改进其人工智能产品方面拥有丰富的成功历史。例如，Bing 率先提出了使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://dl.acm.org/doi/abs/10.1145/1148170.1148177" target="_blank" rel="noreferrer noopener">短期和长期用户行为<span class="sr-only">数据</span></a><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://dl.acm.org/doi/abs/10.1145/1148170.1148177" target="_blank" rel="noreferrer noopener"><span class="sr-only">（在新选项卡中打开）提高搜索排名（在新</span></a><a href="https://www.microsoft.com/en-us/research/publication/personalizing-search-via-automated-analysis-of-interests-and-activities/" target="_blank" rel="noreferrer noopener"><span class="sr-only">选项卡中打开）和个性化搜索（</span></a>在新选项卡中打开）的想法。</p><p>随着 Microsoft Copilot（Web）的推出，人们与 AI 系统交互的方式发生了根本性的变化，从搜索到对话，从简单的操作到复杂的工作流程。今天，我们很高兴与大家分享三份技术报告，介绍我们如何<em>开始</em>利用新型用户交互来了解和改进消费者客户的 Copilot（网络）。 <a id="_ftnref1" href="#_ftn1">[1]</a></p><h2 class="wp-block-heading" id="how-are-people-using-copilot-web">人们如何使用 Copilot（网络）？</h2><p>关于用户与 Copilot（网络）的交互，我们提出的第一个问题是“人们如何使用 Copilot（网络）？”生成式人工智能可以执行许多过去不可能完成的任务，了解人们的期望和需求非常重要，这样我们才能以最能帮助用户的方式不断改进 Copilot（网络）。</p><p>大规模理解用户任务的一个关键挑战是将非结构化交互数据（例如 Copilot 日志）转换为<a href="https://www.microsoft.com/en-us/research/publication/using-large-language-models-to-generate-validate-and-apply-user-intent-taxonomies/" target="_blank" rel="noreferrer noopener">有意义的任务分类</a>。现有方法严重依赖人工，这在生成人工智能等新颖且未指定的领域中无法扩展。为了应对这一挑战，我们引入了<a href="https://www.microsoft.com/en-us/research/publication/tnt-llm-text-mining-at-scale-with-large-language-models/" target="_blank" rel="noreferrer noopener">TnT-LLM（ <strong>Taxonomy</strong> Generation <strong>and T</strong> ext Prediction with <strong>LLM</strong> ）</a> ，这是一个由 LLM 驱动的两阶段框架，可以在最少的人工参与下端到端地生成和预测任务标签（图 1） 。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="738" height="375" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig1.png" alt="该图展示了三种文本数据处理框架的比较。第一个是劳动密集型的人机交互框架，涉及在开发分类器之前手动推导标签分类和注释。第二种是传统的无监督文本聚类框架，首先对数据进行聚类，然后生成标签分类法。第三个是TnT-LLM框架，将LLM集成到标签分类法的推导和注释中。散点图显示，人机交互具有高度可解释性，但可扩展性较差，文本聚类框架具有高度可扩展性，但可解释性较差，TnT-LLM 框架在这两方面均表现出色。" class="wp-image-1017252" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig1.png 738w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig1-300x152.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig1-240x122.png 240w" sizes="(max-width: 738px) 100vw, 738px" /><figcaption class="wp-element-caption">图 1. 将我们的 TnT-LLM 框架与现有方法在可解释性和可扩展性方面进行比较。</figcaption></figure><p>我们进行了广泛的人工评估，以了解 TnT-LLM 的表现。在从 Copilot（网络）对话中发现用户意图和领域时，TnT-LLM 生成的分类法比现有基线更加准确（图 2）。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="858" height="294" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig2.png" alt="该图比较了不同人工智能方法在生成用户意图分类法方面的准确性。并排呈现两个条形图，标有“准确性（意图）”和“准确性（域）”。比较的方法有“GPT-4 (TnT-LLM)”、“GPT-3.5-turbo (TnT-LLM)”、“ada2 + GPT-4”、“ada2 + GPT-3.5-turbo”、“Instructor-XL” + GPT-4”和“Instructor-XL + GPT-3.5-turbo”。底部标有“GPT-4 评估”标签。在此图中，“GPT-4 (TnT-LLM)”似乎优于其他方法。" class="wp-image-1017255" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig2.png 858w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig2-300x103.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig2-768x263.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig2-240x82.png 240w" sizes="(max-width: 858px) 100vw, 858px" /><figcaption class="wp-element-caption">图 2. 评估 TnT-LLM 在用户意图分类生成方面的性能。误差线表示 95% 置信区间。</figcaption></figure><p>我们将 TnT-LLM 应用于大量完全去识别化的 Copilot（网络）对话和传统的 Bing 搜索会话。 <a href="https://www.microsoft.com/en-us/research/publication/the-use-of-generative-search-engines-for-knowledge-work-and-complex-tasks/">结果</a>（图 3）表明人们使用 Copilot（Web）来执行写作和编辑、数据分析、编程、科学和商业等领域的知识工作任务。此外，与传统搜索引擎中完成的任务相比，在 Copilot（Web）中完成的任务通常具有更高的复杂性和更多的知识工作导向。生成式人工智能的新兴功能已经发展了机器可以执行的任务，包括一些传统上人类必须在没有帮助的情况下完成的任务。结果表明，人们经常在知识工作的背景下执行更复杂的任务，并表明此类工作正在由 Copilot（网络）提供新的协助。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="726" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig3.png" alt="该图比较了 Bing Copilot 对话与 Bing Search 会话的本质复杂程度以及面向知识工作的程度。并排显示两个散点图，Bing Copilot 和 Bing Search 各一个。 x 轴标记为“分类为复杂的每个域 Copilot 聊天的百分比”和“分类为复杂的每个域搜索会话的百分比”。对于 Bing Copilot，y 轴标记为“分类为知识工作的每个域 Copilot 聊天的百分比”；对于 Bing 搜索，标记为“分类为知识工作的每个域搜索会话的百分比”。散点图中的点是任务域，例如“编程和脚本”和“游戏和娱乐”。散点图中的数据点显示，对于 Bing 搜索，大多数搜索会话的复杂性和知识工作相关性都较低，而对于 Bing Copilot，许多数据点的复杂性和知识工作相关性都很高。" class="wp-image-1017294" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig3.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig3-300x156.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig3-1024x531.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig3-768x398.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig3-240x124.png 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 3. 比较 Bing 搜索（左）和 Copilot（Web）（右）之间的主题域分布和任务复杂性。 </figcaption></figure><h2 class="wp-block-heading" id="estimating-and-interpreting-user-satisfaction">估计和解释用户满意度</h2><p>为了有效地从用户交互中学习，对用户满意度进行分类并了解人们在尝试完成给定任务时感到满意或不满意的原因同样重要。最重要的是，这将使系统开发人员能够确定需要改进的领域，并为更广泛的用户群体扩大和建议成功的用例。</p><p>人们在与人工智能系统交互时会给出显式和隐式的反馈。过去，用户反馈的形式是点击、评分或逐字调查。对于 Copilot（Web）等对话系统，人们还会在对话期间发送的消息中提供反馈（图 4）。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="802" height="571" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig4.png" alt="该图展示了AI助手的持续改进过程。该过程从用户和人工智能助手之间的示例对话开始。示例中的用户对 AI 助手的响应不满意。改进过程将不满意的示例作为输入，并在同一对话中输出更好的响应。改进后，用户对响应感到满意。" class="wp-image-1017258" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig4.png 802w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig4-300x214.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig4-768x547.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig4-240x171.png 240w" sizes="(max-width: 802px) 100vw, 802px" /><figcaption class="wp-element-caption">图 4. 说明人们如何在消息中向聊天机器人提供反馈。</figcaption></figure><p>为了捕捉这一新类别的反馈信号，我们提出了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2403.12388" target="_blank" rel="noreferrer noopener">用户满意度监督提示（SPUR） <span class="sr-only">（在新选项卡中打开）</span></a>框架（图 5）。这是一个用于评估用户对法学硕士满意度的三阶段提示框架：</p><ol><li><strong>受监督的提取提示</strong>从与 Copilot（网络）交互的用户中提取各种<em>现场</em>文本反馈。</li><li><strong>总结量规提示</strong>可识别突出的文本反馈模式，并将其总结为评估用户满意度的量规。</li><li>根据总结的评分标准，最终的<strong>评分提示</strong>会进行用户和人工智能代理之间的对话，并评估用户的满意度。 </li></ol><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="975" height="480" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig5.png" alt="该图显示了用户满意度评分标准的监督提示框架。第一步表明法学硕士根据用户的话语解释用户的满意度或不满意。然后，LLM在第二步中将满意或不满意的原因总结为SAT和DSAT评分标准。最后，LLM 使用 SAT 和 DSAT 评分标准来确定用户是否对第三步中 AI 代理的响应感到满意。" class="wp-image-1017261" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig5.png 975w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig5-300x148.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig5-768x378.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig5-240x118.png 240w" sizes="(max-width: 975px) 100vw, 975px" /><figcaption class="wp-element-caption">图 5. 用户满意度评分标准的监督提示框架。</figcaption></figure><p>我们在 Copilot（网络）中通过完全去识别化的对话以及明确的用户竖起大拇指/向下的拇指来评估我们的框架（表 1）。我们发现 SPUR 优于其他基于 LLM 和基于嵌入的方法，特别是仅提供有限的用户满意度人工注释。用于 RLHF 的开源奖励模型不能代表用户满意度，因为奖励模型通常是使用辅助人类反馈进行训练的，这些反馈可能与参与与 AI 代理对话的用户的反馈不同。</p><figure class="wp-block-table"><table><thead><tr><th>方法</th><th>加权 F1 分数</th></tr></thead><tbody><tr><td>奖励（RLHF）</td><td> 17.8</td></tr><tr><td> ASAP（嵌入的 SOTA）</td><td> 57.0</td></tr><tr><td>零射击 (GPT4)</td><td> 74.1</td></tr><tr><td> SESRP (GPT4)</td><td> <strong>77.4</strong><strong></strong></td></tr></tbody></table><figcaption class="wp-element-caption"><center>表 1. 用户满意度评估模型之间的性能比较。</center></figcaption></figure><p> SPUR 的另一个重要特征是它的可解释性。它显示了人们如何表达满意或不满意（图 6）。例如，我们看到用户经常通过明确赞扬 Copilot（网络）的响应来给出明确的积极反馈。相反，当副驾驶（网络）的响应出现错误时，他们会表达明显的挫败感或转换话题。这提供了在用户满意和不满意的关键时刻提供定制用户体验的机会，例如切换主题后的上下文和记忆重置。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="624" height="241" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig6_v2.png" alt="该图显示了两个直方图。左侧直方图显示了 10 项 SAT 评分标准的分布，右侧直方图显示了 Bing Copilot 中 10 项 DSAT 评分标准的分布。左侧直方图的 y 轴显示十种汇总模式，表示用户对 Bing Copilot 的响应的满意度，x 轴显示 Bing Copilot 中出现的每种模式的百分比。同样，右侧直方图的 y 轴显示了 10 个汇总模式，表示用户对 Bing Copilot 的响应如何不满意，x 轴显示了 Bing Copilot 中每种模式发生的百分比。" class="wp-image-1017852" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig6_v2.png 624w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig6_v2-300x116.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Fig6_v2-240x93.png 240w" sizes="(max-width: 624px) 100vw, 624px" /><figcaption class="wp-element-caption">图 6. SPUR 揭示了具有明确用户赞成或反对票的对话中满意度和不满意模式的分布。</figcaption></figure><p>在前面讨论的用户任务分类中，我们知道人们正在使用 Copilot（Web）进行知识工作和更复杂的任务。当我们进一步应用 SPUR 进行用户满意度评估时，我们发现人们在完成或部分完成认知复杂任务时也会更加满意。具体来说，当根据 SPUR 得出的汇总用户满意度分数回归任务复杂性时，我们发现，当使用最低级别的任务复杂性（即“记住”）作为基线时，任务复杂性级别的增加系数通常会增加，前提是任务至少部分完成（见表2）。例如，部分完成创建级任务（任务复杂性的最高级别）会导致用户满意度的提高，其提高程度是部分完成理解级任务时的两倍以上。完全完成创建级任务可以最大程度地提高用户满意度。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="605" height="436" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Table2.png" alt="该表显示了回归分析的结果，包括预测变量及其各自在回归中的系数。在此回归中，三个预测变量根据用户满意度作为结果变量进行回归。三个预测变量是任务复杂性、任务完成度和用户消息数量。此外，还包括任务复杂性和任务完成之间以及用户消息数量和任务完成之间的交互的交互术语。结果表明，当用户完成更复杂的任务时，他们的用户满意度会增加。" class="wp-image-1017267" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Table2.png 605w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Table2-300x216.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/Copilot_Table2-240x173.png 240w" sizes="(max-width: 605px) 100vw, 605px" /><figcaption class="wp-element-caption">表 2. 回归结果，其中因变量是用户满意度。一般来说，任务越复杂，用户就越满意，无论是部分完成还是全部完成。</figcaption></figure><p>这三份报告提出了一种全面、多方面的方法，可以从 Copilot（Web）中的对话日志中大规模动态学习。随着人工智能生成能力的增强，用户正在寻找新的方法来使用该系统来帮助他们做更多的事情，并从传统的点击反应转向更细致、持续的以对话为导向的反馈。为了驾驭不断变化的用户-人工智能交互格局，从既定的任务框架和相关性评估转向更动态、自下而上的任务识别和用户满意度评估方法至关重要。</p><h5 class="wp-block-heading" id="key-contributors">主要贡献者</h5><p><a href="https://www.microsoft.com/en-us/research/people/reidan/">里德·安德森</a>、乔治·布舍尔、<a href="https://www.microsoft.com/en-us/research/people/counts/">斯科特·康茨</a>、迪帕克<a href="https://www.microsoft.com/en-us/research/people/brhecht/">·古普塔、布伦特·赫克特</a>、德鲁夫·乔希、<a href="https://www.microsoft.com/en-us/research/people/sjauhar/">苏杰·库马尔·乔哈</a>、林迎春、萨蒂什·马尼瓦南、<a href="https://www.microsoft.com/en-us/research/people/jenneville/">詹妮弗·内维尔</a>、纳古·兰甘、奇拉格·沙阿、多莉·索巴尼、<a href="https://www.microsoft.com/en-us/research/people/suri/">悉达思·苏瑞</a>、<a href="https://www.microsoft.com/en-us/research/people/tarasafavi/">塔拉·萨法维</a>、<a href="https://www.microsoft.com/en-us/research/people/teevan/">杰米·蒂万</a>、 <a href="https://www.microsoft.com/en-us/research/people/satiwary/">Saurabh Tiwary</a> 、 <a href="https://www.microsoft.com/en-us/research/people/mengtwan/">Mengting Wan</a> 、 <a href="https://www.microsoft.com/en-us/research/people/ryenw/">Ryen W. White</a> 、 <a href="https://www.microsoft.com/en-us/research/people/xiaso/">Xia Song</a> 、Jack W. Stokes、Xiaofeng Xu 和<a href="https://www.microsoft.com/en-us/research/people/loy/">Longqi Yang</a> 。</p><hr class="wp-block-separator has-alpha-channel-opacity"/><p> <a id="_ftn1" href="#_ftnref1">[1]</a><em>该研究仅针对来自 Copilot（网络）消费者的完全去识别化的交互数据进行。根据我们对企业客户的承诺，没有使用任何企业数据。我们采取了谨慎的措施来保护用户隐私，并遵守严格的道德和负责任的人工智能标准。在将对话用于研究之前，所有个人、私人或敏感信息都被清除和屏蔽。数据集的访问严格限于经过批准的研究人员。该研究得到了我们的机构审查委员会 (IRB) 的审查和批准。</em></p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/learning-from-interaction-with-microsoft-copilot-web/">从与 Microsoft Copilot 的交互中学习（网络）</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>