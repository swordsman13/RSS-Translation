<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 6 月 20 日星期二 16:20:08 +0000</lastbuilddate><language>英文</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1个</sy:updatefrequency><generator>https://wordpress.org/?v=6.2.2</generator><item><title>微软参加 CVPR 2023：突破计算机视觉的界限</title><link/>https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2023-pushing-the-boundaries-of-computer-vision/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 20 Jun 2023 16:19:50 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>在广阔的人工智能领域，很少有领域能像计算机视觉那样吸引我们的想象力并突破可能性的界限。这一研究和创新领域的核心在于雄心壮志，旨在为现实世界中基于视觉的系统提供技术支持，使机器能够以无与伦比的 […]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2023-pushing-the-boundaries-of-computer-vision/">Microsoft 在 CVPR 2023 上的帖子：推动计算机视觉的边界</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1400" height="264" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/BlogBanner-1400x264_AH.jpg" alt="CVPR 2023 会议的标志显示了不列颠哥伦比亚省温哥华市的天际线，会议日期为 2023 年 6 月 18 日至 23 日。背景是阳光明媚的日子里，温哥华市的褪色照片。" class="wp-image-948327" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/BlogBanner-1400x264_AH.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/BlogBanner-1400x264_AH-300x57.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/BlogBanner-1400x264_AH-1024x193.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/BlogBanner-1400x264_AH-768x145.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/BlogBanner-1400x264_AH-240x45.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>在广阔的人工智能领域，很少有领域能像<a href="https://www.microsoft.com/en-us/research/research-area/computer-vision/?">计算机视觉</a>那样吸引我们的想象力并突破可能性的界限。这一研究和创新领域的核心在于为现实世界中基于视觉的系统提供技术支持的雄心，使机器能够以无与伦比的精度和复杂性接收和响应视觉刺激。通过人工智能、深度学习和海量数据的结合，计算机视觉近年来取得了长足的进步，使我们进入了一个看似不可能的时代。</p><p><a href="https://cvpr2023.thecvf.com/" target="_blank" rel="noreferrer noopener">计算机视觉和模式识别</a>(CVPR) 2023 于 6 月 10 日至 6 月 22 日举行，是一项广泛认可的活动，汇集了计算机视觉领域的领先专家。它作为展示该领域一些最引人注目和创新工作的平台。</p><p>微软研究人员及其合作者在今年的 CVPR 上所做的贡献涵盖了广泛的研究领域。从生成模型和网络预训练到手语理解和神经视频编解码器，这些前沿进步强调了系统不断发展的分析视觉数据并从中提取有价值见解的能力。</p><p>以下是一些要点（已发表论文及其作者的列表见下文）：</p><h2 class="wp-block-heading" id="uniting-vision-language-and-multi-modal-encoding">结合视觉、语言和多模态编码</h2><p>论文“ <a href="https://www.microsoft.com/en-us/research/publication/image-as-a-foreign-language-beit-pretraining-for-vision-and-vision-language-tasks/">Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks</a> ”位于视觉、语言和多模态预训练的交叉点。为了从这些不同形式的数据中学习，我们提出了一个将图像视为“外语”的通用基础模型。来自不同模态的数据使用 Multiway Transformers 进行编码，Multiway Transformers 是一种模块化架构，可实现特定于模态的编码和深度融合。该模型以一种将掩码语言建模方法推广到不同模态的方式对图像、文本和图像-文本对进行预训练。通过大幅扩展模型和数据，我们发现基础架构和预训练方面的这些进步在各种视觉和视觉语言任务中带来了出色的迁移性能，包括对象检测、语义分割、图像分类、视觉推理、视觉问答、图像字幕和跨模态图像检索。</p><h2 class="wp-block-heading" id="scaling-training-data-for-large-vision-models">扩展大型视觉模型的训练数据</h2><p>大型语言模型的优势在于它们能够大规模利用未标记的训练数据。通过使用这些数据，这些模型获得了对语言的广泛理解，增强了它们的泛化能力，并提高了它们在广泛的与语言相关的任务中的表现。受这一成就的启发，我们的研究重点是为大型视觉模型扩展训练数据的可能性。在论文“ <a href="https://www.microsoft.com/en-us/research/publication/on-data-scaling-in-masked-image-modeling/">关于蒙版图像建模中的数据缩放</a>”中，我们探讨了数据缩放对通过蒙版图像建模预训练的大型视觉模型的影响。通过广泛的调查，我们发现大型视觉模型中的蒙版图像建模需要大规模数据才能进行有效的预训练。然而，与大型语言模型不同，大型视觉模型无法在非过度拟合场景中从更多数据中获益。这些发现加深了我们对蒙版图像建模的理解，并可能为未来大规模视觉模型的发展铺平道路。</p><h2 class="wp-block-heading" id="creating-3d-avatars-with-a-diffusion-network">使用扩散网络创建 3D 头像</h2><p>在图像生成领域，在将文本描述转化为令人惊叹的视觉效果方面取得了令人难以置信的进步。 DALL-E 和扩散模型的兴起将这些尖端工具带到了日常用户的手中。在论文“ <a href="https://www.microsoft.com/en-us/research/publication/rodin-a-generative-model-for-sculpting-3d-digital-avatars-using-diffusion/">RODIN：使用扩散雕刻 3D 数字化身的生成模型</a>”中，我们通过将扩散的力量引入 3D 化身生成来扩展这项创新。为此，有必要将扩散从 2D 转移到 3D。然而，将扩散从 2D 转移到 3D 是一项重大挑战，因为在 3D 中生成具有丰富细节的高质量结果的内存和处理成本过高。我们通过提出展开扩散网络 (RODIN) 来克服这个问题，该网络将 3D 神经辐射场展开到单个 2D 特征平面并在其上执行 3D 感知扩散。在其他技术贡献的支持下，包括促进全局一致性的潜在调节和进一步增强细节的层次合成，RODIN 显着加快了原本乏味的 3D 建模过程，并为 3D 艺术家开辟了新的机会。 </p><div style="height:15px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="874872"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：点播活动</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/event/microsoft-research-summit-2022/?OCID=msr-researchsummit_Blog_PromoMod" aria-label="Microsoft Research Summit 2022" data-bi-cN="Microsoft Research Summit 2022" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2022/09/WebsiteHero_1400x788_B.jpg" alt="蓝色、紫色和橙色瓷砖向上移动的抽象图像" /></a></div><div class="msr-promo__content py-3 col-12 col-md"><h2 class="h4"> 2022 年微软研究院峰会</h2><p class="large"><strong>一经请求</strong><br>立即观看以了解我们的研究社区面临的一些最紧迫的问题，并收听与 120 多名研究人员就如何确保新技术为人类带来尽可能广泛的利益的对话。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/event/microsoft-research-summit-2022/?OCID=msr-researchsummit_Blog_PromoMod" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Read more" data-bi-cN="Microsoft Research Summit 2022" target="_blank">探索会议</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--></div><!--/.msr-promo--><p>微软在 CVPR 2023 上发表的论文及其作者：</p><ol type="1"><li> <a href="https://www.microsoft.com/en-us/research/publication/3d-human-mesh-estimation-from-virtual-markers/">来自虚拟标记的 3D 人体网格估计</a><br>Xiaoxuan Ma，<em>北京大学</em>；苏家军，<em>北京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/chnuwa/">王春雨</a>，<em>微软研究院</em>；朱文涛，<em>北京大学</em>； Yizhou Wang，<em>北京大学</em><em>视觉技术国家工程研究中心</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/limap-global-mapper-3d-line-mapping-revisited/">重新审视 3D 线映射</a><br>刘少辉，<em>苏黎世联邦理工学院</em>； Yifan Yu，<em>苏黎世联邦理工学院</em>； Rémi Pautrat，<em>苏黎世联邦理工学院</em>； <a href="https://www.microsoft.com/en-us/research/people/mapoll/">Marc Pollefeys</a> ，<em>苏黎世联邦理工学院和微软研究院</em>； Viktor Larsson，<em>隆德大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/blendfields-few-shot-example-driven-facial-modeling/">BlendFields：Few-Shot 示例驱动的面部建模</a><br>Kacper Kania，<em>华沙理工大学</em>； Stephan J. Garbin，<em>微软研究院</em>； Andrea Tagliasacchi、 <em>Simon Fraser 和 University 以及 Google Brain</em> ； Virginia Estellers，<em>微软研究院</em>； Kwang Moo Yi，<em>不列颠哥伦比亚大学</em>；朱利安·瓦伦丁，<em>微软研究院</em>； Tomasz Trzciński，<em>雅盖隆大学</em>； Marek Kowalski，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/cico-domain-aware-sign-language-retrieval-via-cross-lingual-contrastive-learning/">CiCo：通过跨语言对比学习进行域感知手语检索<br></a>Yiting Cheng，<em>复旦大学</em>；<a href="https://www.microsoft.com/en-us/research/people/fawe/">魏方云</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/jianbao/">鲍建民</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/doch/">陈东</a>，<em>微软研究院</em>；张文强，<em>复旦大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/deep-frequency-filtering-for-domain-generalization/">域泛化的深度频率过滤</a><br>林诗琪，<em>中国科学技术大学</em>； <a href="https://www.microsoft.com/en-us/research/people/zhizzhang/">Zhizheng Zhang</a> ，<em>微软研究院</em>；黄志鹏，<em>中国科学技术大学</em>； <a href="https://www.microsoft.com/en-us/research/people/yanlu/">Yan Lu</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/culan/">蓝翠玲</a>，<em>微软研究院</em>；彭楚，<em>微软</em>；尤泉增，<em>微软</em>；王江，<em>微软</em>；<a href="https://www.microsoft.com/en-us/research/people/zliu/">刘子成</a>，<em>微软研究院</em>； Amey Parulkar，<em>微软</em>； Viraj Navkal，<em>微软</em>；陈志波，<em>中国科学技术大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/deeplsd-line-segment-detection-and-refinement-with-deep-image-gradients/">DeepLSD：使用深度图像梯度进行线段检测和细化</a><br>Rémi Pautrat，<em>苏黎世联邦理工学院</em>； Daniel Barath，<em>苏黎世联邦理工学院</em>；<em>隆德大学的 Viktor Larsson；</em> Martin R. Oswald，<em>阿姆斯特丹大学</em>； <a href="https://www.microsoft.com/en-us/research/people/mapoll/">Marc Pollefeys</a> ,<em>苏黎世联邦理工学院和微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/detrs-with-hybrid-matching/">具有混合匹配的 DETR<br></a>丁佳，<em>北京大学</em>； Yuhui Yuan，<em>微软研究院</em>；何浩迪，<em>斯坦福大学</em>；吴晓培，<em>浙江大学</em>；于浩军，<em>北京大学</em>；林卫红，<em>微软研究院</em>；孙磊，<em>微软研究院</em>；张超，<em>北京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>,<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/efficientvit-memory-efficient-vision-transformer-with-cascaded-group-attention/">EfficientViT：具有级联组注意力的高效内存视觉转换器<br></a>刘新宇，<em>香港中文大学</em>；<a href="https://www.microsoft.com/en-us/research/people/hopeng/">彭厚文</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/nizhen/">Ningxin Zheng</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/yuqyang/">Yuqing Yang</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>，<em>微软研究院</em>； Yixuan Yuan，<em>香港中文大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/four-view-geometry-with-unknown-radial-distortion/">具有未知径向畸变的四视图几何</a><br>Petr Hruby、Viktor Korotynskiy、Timothy Duff、Luke Oeding、 <a href="https://www.microsoft.com/en-us/research/people/mapoll/">Marc Pollefeys</a> 、<em>苏黎世联邦理工学院和微软研究院</em>； Tomas Pajdla、Viktor Larsson，<em>隆德大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/high-fidelity-and-freely-controllable-talking-head-video-generation/">高保真和可自由控制的会说话的头部视频生成</a><br><a href="https://www.microsoft.com/en-us/research/people/yuegao/">高跃</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/zhouyuan/">袁州</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/jinglwa/">Jinglu Wang</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/xili11/">李晓</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/xiangming/">向明</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/yanlu/">严璐</a><em>，微软研究院</em></li><li> <a href="https://www.microsoft.com/en-us/research/publication/human-pose-as-compositional-tokens/">作为组合标记的人体姿势</a><br>Zigang Geng，<em>中国科学技术大学</em>和<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/chnuwa/">王春雨</a>，<em>微软研究院</em>； Yixuan Wei，<em>清华大学</em><em>和</em><em>微软研究院</em>；刘泽，<em>中国科学技术大学和</em><em>微软研究院</em>；李厚强，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>,<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/iclip-bridging-image-classification-and-contrastive-language-image-pre-training-for-visual-recognition/">iCLIP：桥接图像分类和对比语言图像预训练以进行视觉识别</a><br>Yixuan Wei，<em>清华大学和微软研究院</em>； Yue Cao，<em>微软研究院</em>； Zheng Zhang，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hopeng/">彭厚文</a>，<em>微软研究院</em>； Zhuliang Yao，<em>清华大学和微软研究院</em>； Zhenda Xie，<em>清华大学和微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/bainguo/">郭百宁</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/image-as-a-foreign-language-beit-pretraining-for-all-vision-and-vision-language-tasks/">图像作为外语：针对所有视觉和视觉语言任务的 BEiT 预训练<br></a>王文辉，<em>微软；</em>航博宝，<em>微软；</em><a href="https://www.microsoft.com/en-us/research/people/lidong1/">董力</a>，<em>微软研究院；</em>约翰·比约克，<em>微软；</em>彭志良，<em>微软；</em>刘强，<em>微软；</em> <a href="https://www.microsoft.com/en-us/research/people/kragga/">Kriti Aggarwal</a> ，<em>微软研究院；</em> Owais Khan Mohammed，<em>微软；</em> <a href="https://www.microsoft.com/en-us/research/people/saksingh/">Saksham Singhal</a> ，<em>微软研究院；</em><em>微软的 Subhojit Som；</em><a href="https://www.microsoft.com/en-us/research/people/fuwei/">魏付如</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/iterative-proposal-refinement-for-weakly-supervised-video-grounding/">弱监督视频接地的迭代提议细化</a><br>曹萌，<em>北京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/fawe/">魏方云</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/caxu/">徐灿</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/xigeng/">耿秀波</a>，<em>微软研究院</em>；陈龙，<em>香港科技大学</em>；张灿，<em>北京大学；</em>邹月贤，<em>北京大学；</em>沉涛，<em>微软</em>；<a href="https://www.microsoft.com/en-us/research/people/djiang/">姜大新</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/layoutformer-conditional-graphic-layout-generation-via-constraint-serialization-and-decoding-space-restriction/">LayoutFormer++：通过约束序列化和解码空间限制生成条件图形布局</a><br>蒋兆云，<em>西安交通大学</em>；郭佳琪，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/shizsu/">孙世钊</a>，<em>微软研究院</em>；邓华宇，<em>上海交通大学</em>；北京航空<em>航天大学</em>吴仲凯；<em>微软的</em>Vuksan Mijovic； Zijiang James Yang，<em>西安交通大学</em>；<a href="https://www.microsoft.com/en-us/research/people/jlou/">楼建光</a>，<em>微软研究院</em>；<em>微软研究院</em><a href="https://www.microsoft.com/en-us/research/people/dongmeiz/">张冬梅</a></li><li><a href="https://www.microsoft.com/en-us/research/publication/learning-to-exploit-temporal-structure-for-biomedical-vision-language-processing/">学习利用时间结构进行生物医学视觉语言处理</a><br><a href="https://www.microsoft.com/en-us/research/people/shbannur/">Shruthi Bannur</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/sthyland/">斯蒂芬妮·海兰 (Stephanie Hyland)</a> ，<em>微软研究院</em>； Qianchu Liu， <a href="https://www.microsoft.com/en-us/research/people/fperezgarcia/">Fernando Pérez García</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/maxilse/">Maximilian Ilse</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/dacoelh/">Daniel C. Castro</a> ，<em>微软研究院</em>； Benedikt Boecking， <a href="https://www.microsoft.com/en-us/research/people/harssharma/">Harshita Sharma</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/t-kbouzid/">Kenza Bouzid</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/anthie/">Anja Thieme</a> ，<em>微软研究院</em>；<em>微软研究院</em><a href="https://www.microsoft.com/en-us/research/people/antonsc/">安东施瓦格霍夫</a>； Maria Wetscherek、Matthew P. Lungren、 <a href="https://www.microsoft.com/en-us/research/people/adityan/">Aditya Nori，</a><em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/jaalvare/">Javier Alvarez-Valle</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/ozoktay/">Ozan Oktay</a><em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/look-before-you-match-instance-understanding-matters-in-video-object-segmentation/">匹配前先看：实例理解在视频对象分割中很重要</a><br>王俊科，<em>上海市智能视觉计算协同创新中心</em>；<a href="https://www.microsoft.com/en-us/research/people/dochen/">陈冬冬</a>，<em>微软研究院</em>； Zuxuan Wu，<em>上海市智能视觉计算协同创新中心；</em><a href="https://www.microsoft.com/en-us/research/people/cluo/">罗冲</a>，<em>微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/chutan/">唐传新</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/xidai/">Xiyang Dai</a> ，<em>微软研究院</em>；赵玉成，<em>微软研究院</em>； Yujia Xie，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/luyuan/">卢源</a>，<em>微软研究院</em>； Yu-Gang Jiang，<em>上海智能视觉计算协同创新中心</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/maskclip-masked-self-distillation-advances-contrastive-language-image-pretraining/">MaskCLIP：Masked 自蒸馏推进对比语言图像预训练</a><br>Xiaoyi Dong，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/jianbao/">鲍建民</a>，<em>微软研究院</em>； Yinglin Zheng，<em>厦门大学</em>；<a href="https://www.microsoft.com/en-us/research/people/tinzhan/">张婷</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/dochen/">陈冬冬</a>，<em>微软研究院</em>；杨浩，<em>微软研究院</em>；曾铭，<em>厦门大学</em>；张伟明，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/luyuan/">卢源</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/doch/">陈东</a>，<em>微软研究院</em>；方文，<em>微软研究院</em>；于能海，<em>中国科学技术大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/metaportrait-identity-preserving-talking-head-generation-with-fast-personalized-adaptation/">MetaPortrait：具有快速个性化适应的身份保持谈话头像生成<br></a>张博文，<em>中国科学技术大学</em>； Chenyang Qi，<em>香港科技大学</em>；张攀，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/zhanbo/">张博</a>，<em>微软研究院</em>；吴向涛，<em>微软</em>；<em>香港科技大学</em>陈东；陈启峰，<em>香港科技大学</em>；王勇，<em>中国科学技术大学</em>；方文，<em>微软</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/mm-diffusion-learning-multi-modal-diffusion-models-for-joint-audio-and-video-generation/">MM-Diffusion：学习用于联合音频和视频生成的多模态扩散模型</a><br><em>中国人民大学</em>阮鲁丹；马一阳，<em>北京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/huayan/">杨欢</a>，<em>微软研究院</em>；何惠国，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/libei/">刘北</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/jianf/">付建龙</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/nicholasyuan/">Nicholas Jing Yuan</a> ，<em>微软研究院</em>；秦进，<em>中国人民大学</em>；<a href="https://www.microsoft.com/en-us/research/people/bainguo/">郭百宁</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/motion-information-propagation-for-neural-video-compression/">神经视频压缩的运动信息传播</a><br>Linfeng Qi，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/jiahali/">李家豪</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/libin/">李斌</a>，<em>微软研究院</em>；李厚强，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/yanlu/">严璐</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/natural-language-assisted-sign-language-recognition/">自然语言辅助手语识别<br></a>左荣来，<em>香港科技大学</em>；<a href="https://www.microsoft.com/en-us/research/people/fawe/">魏方云</a>，<em>微软研究院</em>；<em>香港科技大学</em>Brian Mak</li><li> <a href="https://www.microsoft.com/en-us/research/publication/neural-video-compression-with-diverse-contexts/">具有不同上下文的神经视频压缩<br></a><a href="https://www.microsoft.com/en-us/research/people/jiahali/">李家豪</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/libin/">李斌</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/yanlu/">严璐</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/on-data-scaling-in-masked-image-modeling/">蒙版图像建模中的数据缩放</a><br>Zhenda Xie，<em>清华大学和微软研究院</em>； Zheng Zhang，<em>微软研究院</em>； Yue Cao，<em>微软研究院</em>； Yutong Lin，<em>西安交通大学和微软研究院</em>； Yixuan Wei，<em>清华大学和微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/qid/">戴奇</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>,<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/paint-by-example-exemplar-based-image-editing-with-diffusion-models/">Paint by Example：使用扩散模型进行基于范例的图像编辑<br></a>杨斌新，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/shuyanggu/">谷舒阳</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/zhanbo/">张博</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/tinzhan/">张婷</a>，<em>微软研究院</em>；陈学金，<em>中国科学技术大学</em>； Xiaoyan Sun，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/doch/">陈东</a>，<em>微软研究院</em>；方文，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/reco-region-controlled-text-to-image-generation/">ReCo：区域控制的文本到图像生成</a><br><a href="https://zyang-ur.github.io/">杨正元</a>，<em>微软研究院；</em>王建峰，<em>微软；</em>甘哲，<em>微软；</em><a href="https://www.microsoft.com/en-us/research/people/linjli/">李林杰</a>，<em>微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/keli/">凯文·林</a>，<em>微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/chewu/">吴晨飞</a>，<em>微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/nanduan/">南段</a>，<em>微软；</em><a href="https://www.microsoft.com/en-us/research/people/zliu/">刘子成</a>，<em>微软研究院；</em>刘策，<em>微软；</em> <a href="https://www.microsoft.com/en-us/research/people/nzeng/">Michael Zeng</a> ，<em>微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/lijuanw/">王丽娟</a><em>，微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/resformer-scaling-vits-with-multi-resolution-training/">ResFormer：通过多分辨率训练扩展 ViT<br></a>田蕊，<em>复旦大学与上海市智能视觉计算协同创新中心</em>； Zuxuan Wu，<em>复旦大学与上海市智能视觉计算协同创新中心</em>；<a href="https://www.microsoft.com/en-us/research/people/qid/">戴奇</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>，<em>微软研究院</em>； Yu Qiao，<em>上海人工智能实验室</em>； Yu-Gang Jiang，<em>复旦大学上海智能视觉计算协同创新中心</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/revealing-the-dark-secrets-of-masked-image-modeling/">揭示蒙版图像建模的黑暗秘密<br></a>Zhenda Xie，<em>清华大学和微软研究院</em>； Zigang Geng，<em>中国科学技术大学和微软研究院</em>； Jingcheng Hu，<em>清华大学和微软研究院</em>； Zheng Zhang，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>，<em>微软研究院</em>； Yue Cao，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/rodin-a-generative-model-for-sculpting-3d-digital-avatars-using-diffusion/">RODIN：使用扩散雕刻 3D 数字化身的生成模型</a><br>王腾飞，<em>香港科技大学</em>；<a href="https://www.microsoft.com/en-us/research/people/zhanbo/">张博</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/tinzhan/">张婷</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/shuyanggu/">谷舒阳</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/jianbao/">鲍建民</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/tabaltru/">Tadas Baltrusaitis</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/jinshen/">沉晶晶</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/doch/">陈东</a>，<em>微软研究院</em>；方文，<em>微软研究院</em>；陈启峰，<em>香港科技大学；</em><a href="https://www.microsoft.com/en-us/research/people/bainguo/">郭百宁</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/seqtrack-sequence-to-sequence-learning-for-visual-object-tracking/">SeqTrack：用于视觉对象跟踪的序列到序列学习<br></a>Xin Chen，<em>大连理工大学</em>；<a href="https://www.microsoft.com/en-us/research/people/hopeng/">彭厚文</a>，<em>微软研究院</em>；王东，<em>大连理工大学</em>； Huchuan Lu，<em>大连理工大学和程鹏实验室</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>,<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/side-adapter-network-for-open-vocabulary-semantic-segmentation/">用于开放词汇语义分割的侧适配器网络</a><br>Mengde Xu，<em>华中科技大学和微软研究院</em>； Zheng Zhang，<em>华中科技大学和微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/fawe/">魏方云</a>，<em>微软研究院；</em><a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>，<em>微软研究院；</em>向白；<em>华中科技大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/streaming-video-model/">流媒体视频模型<br></a>赵玉成，<em>中国科学技术大学</em>；<a href="https://www.microsoft.com/en-us/research/people/cluo/">罗冲</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/chutan/">唐传新</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/dochen/">陈冬冬，</a><em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/ncodella/">Noel Codella</a> ，<em>微软研究院</em>； Zheng-Jun Zha，<em>中国科学技术大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/structural-multiplane-image-bridging-neural-view-synthesis-and-3d-reconstruction/">结构多平面图像：桥接神经视图合成和 3D 重建<br></a>Mingfang Zhang，<em>东京大学和微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/jinglwa/">Jinglu Wang</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/xili11/">李晓</a>，<em>微软研究院</em>； Yifei Huang，<em>东京大学</em>； Yoichi Sato，<em>东京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/yanlu/">严璐</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/svformer-semi-supervised-video-transformer-for-action-recognition/">SVFormer：用于动作识别的半监督视频转换器<br></a>邢振，<em>复旦大学与上海市智能视觉计算协同创新中心</em>；<a href="https://www.microsoft.com/en-us/research/people/qid/">戴奇</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>，<em>微软研究院</em>； Jingjing Chen，<em>复旦大学与上海市智能视觉计算协同创新中心；</em> Zuxuan Wu，<em>复旦大学与上海市智能视觉计算协同创新中心；</em> Yu-Gang Jiang，<em>复旦大学上海智能视觉计算协同创新中心</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/tinymim-an-empirical-study-of-distilling-mim-pre-trained-models/">TinyMIM：蒸馏 MIM 预训练模型的实证研究</a><br>任苏成，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/fawe/">魏方云</a>，<em>微软研究院</em>； Zheng Zhang，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/hanhu/">韩虎</a>,<em>微软研究院</em></li><li> <a href="https://www.microsoft.com/en-us/research/publication/two-shot-video-object-segmentation/">两次视频对象分割</a><br>颜坤，<em>北京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/xili11/">李晓</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/fawe/">魏方云</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/jinglwa/">Jinglu Wang</a> ，<em>微软研究院</em>；张晨斌，<em>北京大学</em>；王平，<em>北京大学</em>；<a href="https://www.microsoft.com/en-us/research/people/yanlu/">严璐</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/unifying-layout-generation-with-a-decoupled-diffusion-model/">使用解耦扩散模型统一布局生成</a><br>穆德辉，<em>西安交通大学</em>； <a href="https://www.microsoft.com/en-us/research/people/zhizzhang/">Zhizheng Zhang</a> ，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/xiaoyizhang/">Xiaoyi Zhang</a> ，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/wenxie/">谢文轩</a>，<em>微软研究院</em>； Yuwang Wang，<em>清华大学</em>；<a href="https://www.microsoft.com/en-us/research/people/yanlu/">严璐</a>，<em>微软研究院</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/videotrack-learning-to-track-objects-via-video-transformer/">VideoTrack：通过视频转换器学习跟踪对象</a><br>谢飞，<em>上海交通大学</em>；<a href="https://www.microsoft.com/en-us/research/people/leichu/">雷楚</a>，<em>微软研究院</em>；<a href="https://www.microsoft.com/en-us/research/people/jiahali/">李家豪</a>，<em>微软研究院</em>； <a href="https://www.microsoft.com/en-us/research/people/yanlu/">Yan Lu</a> ，<em>微软研究院</em>； Chao Ma，<em>上海交通大学</em></li><li><a href="https://www.microsoft.com/en-us/research/publication/volrecon-volume-rendering-of-signed-ray-distance-functions-for-generalizable-multi-view-reconstruction/">VolRecon：用于通用多视图重建的符号射线距离函数的体积绘制</a><br>任宇凡， <em>EPFL</em> ； Fangjinhua Wang<em>苏黎世联邦理工学院</em>；张彤， <em>EPFL；</em> <a href="https://www.microsoft.com/en-us/research/people/mapoll/">Marc Pollefeys</a> ，<em>苏黎世联邦理工学院和微软研究院；</em> Sabine Süsstrunk, <em>EPFL</em></li><li> <a href="https://www.microsoft.com/en-us/research/publication/x-avatar-expressive-human-avatars/">X-Avatar：富有表现力的人类化身</a><br>Kaiyue Shen，<em>苏黎世联邦理工学院</em>；陈果，<em>苏黎世联邦理工学院</em>；曼努埃尔·考夫曼，<em>苏黎世联邦理工学院</em>； Juan Jose Zarate，<em>苏黎世联邦理工学院</em>；朱利安·瓦伦丁，<em>微软研究院</em>；宋杰，<em>苏黎世联邦理工学院</em>； Otmar Hilliges，<em>苏黎世联邦理工学院</em></li></ol><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2023-pushing-the-boundaries-of-computer-vision/">Microsoft 在 CVPR 2023 上的帖子：推动计算机视觉的边界</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>通过机器学习改进次季节预测</title><link/>https://www.microsoft.com/en-us/research/blog/improving-subseasonal-forecasting-with-machine-learning/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Fri, 16 Jun 2023 20:30:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=948789 </guid><description><![CDATA[<p>此内容之前由 Nature Portfolio 和 Springer Nature Communities 在 Nature Portfolio Earth and Environment Community 上发表。提高我们预报天气和气候的能力对所有经济部门以及从地方到国家一级的政府机构都有兴趣。提前零到十天的天气预报和[...]</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/improving-subseasonal-forecasting-with-machine-learning/">使用机器学习改进次季节预测一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p><em>此内容之前由<a href="https://communities.nature.com/" target="_blank" rel="noreferrer noopener">Nature Portfolio 和 Springer Nature Communities</a>在 Nature Portfolio Earth and Environment Community 上发表</em><em><a href="https://earthenvironmentcommunity.nature.com/posts/improving-subseasonal-forecasting-with-machine-learning" target="_blank" rel="noreferrer noopener">。</a></em></p><p>提高我们预报天气和气候的能力对所有经济部门以及从地方到国家一级的政府机构都有兴趣。未来零到十天的天气预报和未来几十年的气候预报目前在决策制定中得到实际应用，这些预报的准确性和可靠性在最近几十年中不断提高（Troccoli，2010 年）。然而，许多关键应用——包括水资源分配、野火管理以及干旱和洪水缓解——需要提前期介于这两个极端之间的次季节预报（Merryfield 等人，2020 年；White 等人，2017 年）。</p><p>虽然短期预测的准确性主要由基于物理的动力学模型维持，但这些确定性方法由于混沌而限制了次季节的准确性（Lorenz，1963 年）。事实上，由于对当地天气和全球气候变量的复杂依赖，次季节预报长期以来一直被认为是<em>“可预测性沙漠”</em> （Vitart 等人，2012 年）。然而， <a href="https://nap.nationalacademies.org/catalog/21873/next-generation-earth-system-prediction-strategies-for-subseasonal-to-seasonal" target="_blank" rel="noreferrer noopener">最近的研究</a>强调了次季节时间尺度可预测性的重要来源，最近几项大规模研究工作的重点是提高基于物理的操作模型的次季节能力（Vitart 等人，2017 年；Pegion 等人., 2019 年；Lang 等人，2020 年）。我们的团队同时开展了一项工作，以证明机器学习方法在改善次季节预测方面的价值。</p><h2 class="wp-block-heading" id="the-subseasonal-climate-forecast-rodeo">次季节气候预报圈地</h2><p>为了提高次季节预报的准确性，美国垦务局 (USBR) 和美国国家海洋和大气管理局 (NOAA) 发起了次<a href="https://www.challenge.gov/challenge/sub-seasonal-climate-forecast-rodeo/" target="_blank" rel="noreferrer noopener">季节气候预报圈地比赛</a>，这是一项为期一年的实时预报挑战赛，参赛者旨在熟练地预测温度和降水量在美国西部提前两到四个星期和四到六周。我们的团队为 Rodeo 和<a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IHBANG" target="_blank" rel="noreferrer noopener">SubseasonalRodeo 数据集</a>开发了一种机器学习方法，用于训练和评估次季节预报系统。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="1390" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast.jpg" alt="2018 年 2 月 5 日第 3-4 周的温度预报和观测。左上角：我们的 Rodeo 提交。右上：实现的温度异常。左下：美国业务动态模型预测，气候预测系统 v2。右下：用作 Rodeo 基线的标准气象预报方法。" class="wp-image-948849" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast-300x298.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast-1024x1017.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast-768x763.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast-180x180.jpg 180w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/week-3-4-forecast-181x180.jpg 181w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"> <em>2018 年 2 月 5 日第 3-4 周的温度预报和观测。左上角：我们的</em><a href="https://www.challenge.gov/challenge/sub-seasonal-climate-forecast-rodeo/" target="_blank" rel="noreferrer noopener"><em>Rodeo</em></a><em>提交。右上：实现的温度异常。左下：美国业务动态模型的预测，气候预测系统 v2。右下：用作 Rodeo 基线的标准气象预报方法</em>。 </figcaption></figure><div style="height:15px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="一个人的电脑屏幕截图" /></a></div><div class="msr-promo__content py-3 col-12 col-md"><h2 class="h4"> AI Explainer：基础模型和人工智能的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多的数据以及情境学习如何帮助推动 AI 从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--></div><!--/.msr-promo--><p>我们最终的 Rodeo 解决方案是两个非线性回归模型的集合。第一个集成了气象测量和动态模型预测的多样化集合，并使用定制的多任务模型选择程序修剪不相关的预测因子。第二种方法仅使用目标变量（温度或降水量）的历史测量值，并将多任务最近邻特征引入加权局部线性回归。每个模型单独优于去偏操作美国气候预报系统版本 2 (CFSv2)，并且在 2011-2018 年期间，我们的回归模型和去偏 CFSv2 的集合将去偏 CFSv2 温度技能提高了 40%-50%，在温度方面提高了 129%-169 % 降水。有关更多详细信息，请参阅我们的文章<a href="https://www.microsoft.com/en-us/research/publication/improving-subseasonal-forecasting-in-the-western-u-s-with-machine-learning/">“使用机器学习改进美国西部的次季节预测”</a> 。虽然这项工作展示了机器学习模型在次季节预测中的前景，但它也强调了基于物理和基于学习的方法的互补优势以及结合这些优势以提高预测技能的机会。</p><h2 class="wp-block-heading" id="adaptive-bias-correction-abc">自适应偏差校正 (ABC)</h2><p>为了利用基于物理和基于学习的模型的互补优势，我们接下来开发了一个混合动态学习框架来改进次季节预测。特别是，我们学会了自适应地纠正动力学模型的偏差，并应用我们新颖的<em>自适应偏差校正</em>(ABC) 来提高次季节温度和降水预报的技能。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="1322" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/subseasonal-lead-times.jpg" alt="在第 3-4 周和第 5-6 周的次季节提前期，ABC 将美国 (CFSv2) 和欧洲 (ECMWF) 领先运营动态模型的预测技能提高了一倍或三倍。" class="wp-image-948867" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/subseasonal-lead-times.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/subseasonal-lead-times-300x283.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/subseasonal-lead-times-1024x967.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/subseasonal-lead-times-768x725.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/subseasonal-lead-times-191x180.jpg 191w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><em>在第 3-4 周和第 5-6 周的次季节提前期，ABC 将美国 (CFSv2) 和欧洲 (ECMWF) 领先的运营动态模型的预测技能提高了一倍或三倍。</em></figcaption></figure><p> ABC 是三种新的低成本、高精度机器学习模型的集合：Dynamical++、Climatology++ 和 Persistence++。每个模型仅根据过去的温度、降水量和预测数据进行训练，并为针对地点、目标日期和动态模型量身定制的未来预测输出修正。 Dynamical++ 和 Climatology++ 通过在自适应选择的训练期间最小化预测误差来学习特定于站点和日期的动态和气候预测偏移。 Persistence++ 还通过结合滞后观测、动态预测和气候学来考虑最近的天气趋势，以最大限度地减少每个站点的历史预测误差。</p><p> ABC 可以在操作上作为任何动态模型预测的计算成本低廉的增强应用，我们使用此属性大幅减少八个操作动态模型的预测误差，包括最先进的 ECMWF 模型。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="1400" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts.jpg" alt="ABC 可以作为对任何动态模型预测的计算成本低廉的增强在操作上应用。" class="wp-image-948870" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts-300x300.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts-1024x1024.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts-768x768.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts-180x180.jpg 180w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/temperature-forecasts-360x360.jpg 360w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"> <em>ABC 可以作为对任何动态模型预测的计算成本低廉的增强在操作上应用。</em></figcaption></figure><p>这些改进对下游决策者的实际意义是扩大了可操作技能的地理范围，此处将其定义为高于给定充分性阈值的空间技能。例如，我们将第 5-6 周的充分性阈值从 0 变为 0.6，发现 ABC 持续增加具有可操作技能的语言环境的数量，而不是原始的和操作去偏的 CFSv2 和 ECMWF。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="1257" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ABC-forecasting-accuracy.jpg" alt="ABC 不断增加预测准确度超过给定技能阈值的地点数量，这是水资源分配、野火管理以及干旱和洪水缓解方面的运营决策的重要属性。" class="wp-image-948873" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ABC-forecasting-accuracy.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ABC-forecasting-accuracy-300x269.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ABC-forecasting-accuracy-1024x919.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ABC-forecasting-accuracy-768x690.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ABC-forecasting-accuracy-200x180.jpg 200w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"> <em>ABC 不断增加预测准确度超过给定技能阈值的地点数量，这是水资源分配、野火管理以及干旱和洪水缓解方面的运营决策的重要属性。</em></figcaption></figure><p>我们将这些性能改进与实际工作流程相结合，以使用 Cohort Shapley（Mase 等人，2019 年）解释 ABC 技能提升，并根据相关气候变量确定更高技能的机会窗口（Mariotti 等人，2020 年）。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="1002" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/forecast-of-opportunity-workflow.jpg" alt="a.) hgt_500_pc1 对 ABC 技能提升的影响 b.) hgt_500_pc1 影响最大的预测" class="wp-image-948876" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/forecast-of-opportunity-workflow.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/forecast-of-opportunity-workflow-300x215.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/forecast-of-opportunity-workflow-1024x733.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/forecast-of-opportunity-workflow-768x550.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/forecast-of-opportunity-workflow-240x172.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><em>我们的“机会预测”工作流程根据预测时可观察到的相关气候变量来解释 ABC 技能的提高。</em></figcaption></figure><p>为了方便未来的部署和开发，我们还通过<a href="http://github.com/microsoft/subseasonal_toolkit" target="_blank" rel="noreferrer noopener">subseasonal_toolkit</a> Python 包发布了我们的模型和工作流代码。</p><h3 class="wp-block-heading" id="the-subseasonalclimateusa-dataset"> SubseasonalClimateUSA 数据集</h3><p>为了训练和评估我们连续的美国模型，我们开发了一个<a href="https://github.com/microsoft/subseasonal_data" target="_blank" rel="noreferrer noopener">SubseasonalClimateUSA 数据集</a>，其中包含与次季节时间尺度相关的各种地面实况测量和模型预测集合。 SubseasonalClimateUSA 数据集定期更新并可通过<a href="https://github.com/microsoft/subseasonal_data" target="_blank" rel="noreferrer noopener">subseasonal_data</a>包公开访问。在<a href="https://github.com/microsoft/subseasonal_data" target="_blank" rel="noreferrer noopener">SubseasonalClimateUSA：用于次季节预测和基准测试的数据集</a>，我们使用该数据集将 ABC 与操作动态模型和文献中的七种最先进的深度学习和机器学习方法进行基准测试。对于每个次季节预报任务，ABC 及其组件模型提供了最佳性能。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="958" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/percentage-accuracy-improvement.jpg" alt="与操作去偏动态 CFSv2 预测相比，准确性提高了百分比。 ABC 始终优于标准气象基线（持久性和气候学）以及文献中的 7 种最先进的机器学习和深度学习方法。" class="wp-image-948879" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/percentage-accuracy-improvement.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/percentage-accuracy-improvement-300x205.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/percentage-accuracy-improvement-1024x701.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/percentage-accuracy-improvement-768x526.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/percentage-accuracy-improvement-240x164.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><em>与操作去偏动态 CFSv2 预测相比，准确性提高了百分比。 ABC 始终优于标准气象基线（持久性和气候学）以及文献中的 7 种最先进的机器学习和深度学习方法。</em></figcaption></figure><h2 class="wp-block-heading" id="online-learning-with-optimism-and-delay">乐观和延迟的在线学习</h2><p>为了在实时气候和天气预报的操作环境中提供更灵活和自适应的模型集成，我们开发了三种新的乐观在线学习算法——AdaHedgeD、DORM 和 DORM+——它们不需要参数调整，并且在延迟反馈下具有最佳后悔保证. </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="595" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/cumulative-regret.jpg" alt="在线学习后悔情节" class="wp-image-948882" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/cumulative-regret.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/cumulative-regret-300x128.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/cumulative-regret-1024x435.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/cumulative-regret-768x326.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/06/cumulative-regret-240x102.jpg 240w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><em>每年，</em> <a href="https://github.com/geflaspohler/poold" target="_blank" rel="noreferrer noopener"><em>PoolD</em></a><em>在线学习算法都会产生整体预测，尽管每年仅观察 26 次观测，​​但其准确度可与事后最好的个体模型相媲美。</em></figcaption></figure><p>我们的开源 Python 实现可通过<a href="https://github.com/geflaspohler/poold" target="_blank" rel="noreferrer noopener">PoolD</a>库获得，它提供了简单的策略来组合不同的次季节预测模型的预测，根据实时性能调整每个模型的权重。有关更多详细信息，请参阅我们的文章<a href="https://www.microsoft.com/en-us/research/publication/online-learning-with-optimism-and-delay/">《乐观和延迟在线学习》</a> 。</p><h2 class="wp-block-heading" id="looking-forward">期待</h2><p>我们很高兴继续探索应用于全球范围内的次季节预测的机器学习，我们希望我们的开源包将促进未来的次季节发展和基准测试。如果您对模型或数据集开发有想法，请贡献我们的<a href="https://www.microsoft.com/en-us/research/project/subseasonal-climate-forecasting/downloads/">开源 Python 代码</a>或联系我们！</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/improving-subseasonal-forecasting-with-machine-learning/">使用机器学习改进次季节预测一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>