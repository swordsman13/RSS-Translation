<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 2 月 13 日星期二 16:50:07 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.3</generator><item><title> GraphRAG：解锁叙事私人数据的法学硕士发现</title><link/>https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 13 Feb 2024 20:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1005408 </guid><description><![CDATA[<p>也许法学硕士最大的挑战和机遇是扩展他们强大的能力，以解决他们所接受过的数据之外的问题，并利用法学硕士从未见过的数据获得可比较的结果。这为数据调查开辟了新的可能性，例如通过上下文识别主题和语义概念[...]</p><p> <a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">GraphRAG：解锁叙事私人数据上的 LLM 发现</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1.png" alt="Project Ire - GraphRag 背景：蓝绿色渐变" class="wp-image-1005555" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>也许法学硕士最大的挑战和机遇是扩展他们强大的能力，以解决他们所接受过的数据之外的问题，并利用法学硕士从未见过的数据获得可比较的结果。这为数据调查开辟了新的可能性，例如根据上下文和数据集识别主题和语义概念。在这篇文章中，我们将介绍由 Microsoft Research 创建的 GraphRAG，它是增强法学硕士能力的重大进步。 </p><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--right"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">出版物</span><a href="https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine" data-bi-aN="margin-callout" data-bi-cN="Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine">通才基础模型能否胜过专用调整？医学案例研究<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span></a></li></ul></div><p>检索增强生成（RAG）是一种基于用户查询搜索信息并提供结果作为生成人工智能答案的参考的技术。该技术是大多数基于 LLM 的工具的重要组成部分，并且大多数 RAG 方法都使用向量相似性作为搜索技术。 GraphRAG 使用 LLM 生成的知识图在对复杂信息进行文档分析时显着提高问答性能。这是建立在我们最近的<a href="https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/" target="_blank" rel="noreferrer noopener">研究的</a>基础上的，该研究指出了在<em>私人数据集</em>上执行发现时即时增强的力量。在这里，我们将<em>私有数据集</em>定义为法学硕士未受过培训且以前从未见过的数据，例如企业的专有研究、商业文档或通信。创建<em>基线 RAG</em> <sup><a href="#baseline-RAG">1</a></sup>是为了帮助解决此问题，但我们观察到基线 RAG 性能非常差的情况。例如：</p><ul><li> Baseline RAG 很难将这些点联系起来。当回答问题需要通过共享属性遍历不同的信息以提供新的综合见解时，就会发生这种情况。</li><li>当要求基线 RAG 全面理解大型数据集合甚至单个大型文档的概括语义概念时，基线 RAG 表现不佳。</li></ul><p>为了解决这个问题，技术社区正在努力开发扩展和增强 RAG 的方法（例如<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.llamaindex.ai/" target="_blank" rel="noreferrer noopener">LlamaIndex <span class="sr-only">（在新选项卡中打开）</span></a> ）。微软研究院的新方法GraphRAG使用LLM基于私有数据集创建知识图。然后将该图与图机器学习一起使用，以在查询时执行提示增强。 GraphRAG 在回答上述两类问题方面显示出显着的进步，展示了优于之前应用于私有数据集的其他方法的智能或掌握能力。</p><h2 class="wp-block-heading" id="applying-rag-to-private-datasets">将 RAG 应用于私有数据集</h2><p>为了证明 GraphRAG 的有效性，我们首先使用新闻文章中的暴力事件信息 (VIINA) <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/zhukovyuri/VIINA" target="_blank" rel="noreferrer noopener">数据集<span class="sr-only">（在新选项卡中打开）</span></a>进行调查。选择该数据集是因为其复杂性以及存在不同意见和部分信息。这是一个混乱的现实世界测试用例，由于最近才出现，因此未包含在 LLM 基础模型的训练中。</p><p>在这项研究中，我们使用了 2023 年 6 月来自俄罗斯和乌克兰新闻来源的数千篇新闻文章（翻译成英文）来创建一个私人数据集，我们将在该数据集上执行基于 LLM 的检索。数据集太大，无法放入 LLM 上下文窗口，因此需要 RAG 方法。</p><p>我们从一个探索性查询开始，我们向基线 RAG 系统和我们的新方法 GraphRAG 提出该查询：</p><p>问题： <em>“Novorossiya 是什么？”</em></p><figure class="wp-block-table"><table class="has-fixed-layout"><tbody><tr><td><strong>基线RAG</strong></td><td><strong>图RAG</strong></td></tr><tr><td>所提供的上下文中未提及“Novorossiya”一词。不过，为了提供一些信息，Novorossiya（新俄罗斯）是一个历史术语，指的是乌克兰南部的一个地区，该地区在 18 世纪被俄罗斯帝国征服。近年来，俄罗斯支持的乌克兰东部分离主义者重新使用了这个词来指称他们声称拥有主权的领土，但国际机构并未正式承认它是一个独立的实体。</td><td>新俄罗斯，又称新俄罗斯，是一个具有历史和当代意义的术语。历史上，它指的是俄罗斯帝国南部的一个地区，现在是乌克兰的一部分。在当代背景下，它被亲俄罗斯分离主义者用来指代乌克兰的某些地区[数据：实体（6494, 912, 6493）]。<br><br> “Novorossiya”一词在乌克兰的政治运动中被使用，特别是俄罗斯民族主义者。这一运动与破坏乌克兰稳定和创建所谓的“Novorossiya”的努力有关[数据：实体（912）；关系（15211、15206）]。该术语还被用来表示乌克兰的一个分离主义国家，称为新俄罗斯联邦共和国 (FRN) [数据：实体 (7690)]。</td></tr></tbody></table></figure><p>在这些结果中，我们可以看到两个系统都表现良好 - 突出显示基线 RAG 表现良好的一类查询。让我们尝试一个需要连接点的查询：</p><p>询问： <em>“新俄罗斯做了什么？”</em></p><figure class="wp-block-table"><table class="has-fixed-layout"><tbody><tr><td><strong>基线RAG</strong></td><td><strong>图RAG</strong></td></tr><tr><td>该文本没有提供有关 Novorossiya 所做工作的具体信息。</td><td>乌克兰的政治运动 Novorossiya 参与了一系列破坏性活动，特别是针对乌克兰的各种实体 [实体 (6494, 912)]。该运动与摧毁多个乌克兰实体财产的计划有关，包括罗森、敖德萨罐头厂、敖德萨地区广播电视传输中心和乌克兰国家电视公司[关系（15207、15208、15209、15210）] 。除此之外，Novorossiya 还参与了摧毁 Roshen、敖德萨音乐学院工厂、敖德萨地区广播电视传输中心和乌克兰国家电信公司财产的计划 [关系 (8329、8330、8331、8332)] 。此外，Novorossiya 还参与了炸毁乌克兰最大国有银行 PrivatBank ATM 机的计划 [Relationships (8335, 8335)]。<br><br>乌克兰总检察长办公室报告了 Novorossiya 的成立，表明政府对该运动的活动的认识和潜在关注 [关系 (8264, 8264)]。新俄罗斯的破坏活动对目标实体产生了重大影响，并可能加剧了该地区持续的紧张局势和冲突。<br>总之，“新俄罗斯”参与了一系列针对乌克兰境内各个实体的破坏性活动。这些活动对目标实体产生了重大影响，并可能加剧了该地区持续的紧张局势和冲突。乌克兰政府通过总检察长办公室承认了新俄罗斯组织的存在和活动，表明对该运动的行为表示一定程度的关注。</td></tr></tbody></table></figure><p>基线 RAG 无法回答这个问题。查看插入到上下文窗口中的源文档（图 1），没有任何文本段讨论 Novorossiya，导致此失败。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="600" height="452" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure1.png" alt="图 1：LangChain 问答检索上下文 标题为“相关源文档块”的表，包含从 VIINA 数据集提取的 10 行文本片段。每个文本片段都提到乌克兰和俄罗斯发生的新闻事件。没有一个包含“Novorossiya”一词。" class="wp-image-1005432" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure1.png 600w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure1-300x226.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure1-80x60.png 80w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure1-240x180.png 240w" sizes="(max-width: 600px) 100vw, 600px" /><figcaption class="wp-element-caption">图 1：基线 RAG 检索上下文</figcaption></figure><p>相比之下，GraphRAG 方法在查询中发现了一个实体 Novorossiya。这使得法学硕士能够在图表中扎根，并产生一个优秀的答案，其中包含通过原始支持文本链接的出处。例如，下面的图 2 显示了法学硕士用于生成的声明“Novorossiya 涉嫌炸毁 ATM 机的计划”的确切内容。我们看到原始源文件（英文翻译后）中的片段，法学硕士用来通过图中两个实体之间存在的关系来支持特定银行是 Novorossiya 目标的断言。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="600" height="414" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure2.png" alt="图 2：GraphRAG 来源 GraphRAG 系统的图像显示了用于建立 Novorossiya 和 PrivatBank 之间连接的 VIINA 源文本表格。该表包含三列：源、日期和文本。显示单行内容。该行显示来源来自“interfaxua”，发布日期为 2023 年 6 月 8 日，文本框包含摘自源文档的段落。总之，文本描述了新俄罗斯组织的成立，其目的是针对私人银行、地区广播电视广播中心和其他目标实施恐怖主义行为。它描述了敖德萨居民的招募。文本框中突出显示的是两个单独的文本字符串。第一个是“Novorossiya”一词，第二个是“罪犯炸毁了军事委员会和自动取款机的建筑物”。" class="wp-image-1005435" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure2.png 600w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure2-300x207.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag_Figure2-240x166.png 240w" sizes="(max-width: 600px) 100vw, 600px" /><figcaption class="wp-element-caption">图 2：GraphRAG 来源</figcaption></figure><p>通过使用 LLM 生成的知识图，GraphRAG 极大地改进了 RAG 的“检索”部分，用更高相关性的内容填充上下文窗口，从而获得更好的答案并捕获证据来源。</p><p>能够信任和验证法学硕士生成的结果始终很重要。我们关心结果是否事实正确、连贯并准确地代表源材料中的内容。 GraphRAG 在生成每个响应时提供出处或来源接地信息。它表明答案是基于数据集的。随时可用每个断言的引用来源还使人类用户能够直接根据原始来源材料快速准确地审核法学硕士的输出。</p><p>然而，这并不是使用 GraphRAG 所能实现的全部。</p><h2 class="wp-block-heading" id="whole-dataset-reasoning">整个数据集推理</h2><p>Baseline RAG 很难处理需要聚合整个数据集中的信息才能得出答案的查询。诸如“数据中排名前 5 位的主题是什么？”之类的查询表现很差，因为基线 RAG 依赖于数据集中语义相似文本内容的矢量搜索。查询中没有任何内容可以将其定向到正确的信息。</p><p>然而，通过 GraphRAG，我们<em>可以</em>回答这些问题，因为 LLM 生成的知识图的结构告诉我们整个数据集的结构（以及主题）。这允许将私有数据集组织成预先汇总的有意义的语义集群。法学硕士在响应用户查询时使用这些集群来总结这些主题。</p><p>我们通过向两个系统提出以下问题来说明整个数据集的推理能力：</p><p>查询：“<em>数据中排名前 5 的主题是什么？</em> “</p><figure class="wp-block-table"><table class="has-fixed-layout"><tbody><tr><td><strong>基线RAG</strong></td><td><strong>图RAG</strong></td></tr><tr><td> 1. 提高城市生活质量和城市发展。<br> 2. 弗拉基米尔·普京与阿拉伯联合酋长国总统穆罕默德·本·扎耶德·阿勒纳哈扬的会晤。<br> 3.俄罗斯各地区投资环境国家评级。<br> 4.俄罗斯经济状况和国内品牌的成长。<br> 5. 关于生命意义和科学在理解生命中的作用的讨论。</td><td>数据呈现了广泛的主题，但最流行的五个主题可以确定如下：<br><br> 1.<strong>冲突和军事活动</strong>：很大一部分数据围绕乌克兰持续的冲突，有大量报告详细介绍了各种实体的军事活动、占领和袭击。该主题包括乌克兰军队、俄罗斯军队以及其他各种军事单位和实体的行动[数据：报告（513、241、151、493、343，+更多）]。<br><br> 2.<strong>政治和政府实体</strong>：许多报告关注政治人物和政府实体，强调他们在当前形势下的角色、关系和行动。这包括克里姆林宫、乌克兰总统、美国国务院和各个地区行政机构等实体[数据：报告（98、493、265、129、196，+更多）]。<br><br> 3.<strong>基础设施和环境问题</strong>：一些报告强调了潜在的环境影响和基础设施威胁。其中包括工业活动造成的潜在环境破坏、洪水危机以及军事冲突造成的基础设施威胁[数据：报告（308、154、201、348、216，+更多）]。<br><br> 4.<strong>社区分析和威胁评估</strong>：一些报告提供了对特定社区的详细分析，通常以特定位置或实体为中心。这些分析通常讨论社区内的关键实体、它们的关系以及任何相关的威胁。许多报告还包括对与他们讨论的实体或情况相关的潜在威胁的评估[数据：报告（323、596、518、583、179，+更多）]。<br><br> 5.<strong>健康、人道主义关切和紧急情况</strong>：一些报告重点关注健康和人道主义问题，例如谢列舍夫斯基-特纳综合症社区和敖德萨地区肠道疾病的潜在风险。该数据还涵盖紧急情况，包括自然灾害、事故和袭击[数据：报告（204、149、372、154、532，+更多）]。<br>这些主题全面概述了当前形势，突出了当前问题的复杂性和相互关联性。</td></tr></tbody></table></figure><p>从基线 RAG 的结果来看，我们发现列出的主题都与两国之间的战争没有太大关系。正如预期的那样，向量搜索检索到了不相关的文本，并将其插入到法学硕士的上下文窗口中。包含的结果很可能以“主题”一词为关键，导致对数据集中发生的情况的评估不太有用。</p><p>观察 GraphRAG 的结果，我们可以清楚地看到结果与整个数据集中发生的情况更加一致。答案提供了五个主要主题以及数据集中观察到的支持细节。引用的报告由法学硕士为 GraphRAG 中的每个语义集群预先生成，并反过来提供原始源材料的出处。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="电脑屏幕截图 一名男子的屏幕截图" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 解释者：基础模型和 AI 的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多数据以及情境学习如何帮助推动人工智能从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="creating-llm-generated-knowledge-graphs">创建 LLM 生成的知识图</h2><p>我们注意到支撑 GraphRAG 的基本流程，它建立在我们之前使用图机器学习<a href="https://www.microsoft.com/en-us/worklab/patterns-hidden-inside-the-org-chart" target="_blank" rel="noreferrer noopener">的研究<span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/graspologic" target="_blank" rel="noreferrer noopener">存储库<span class="sr-only">（在新选项卡中打开）的</span></a>基础上：</p><ul><li> LLM 处理整个私有数据集，创建对源数据中所有实体和关系的引用，然后用于创建 LLM 生成的知识图。</li><li>然后，该图用于创建自下而上的聚类，将数据按层次结构组织成语义聚类（在下面的图 3 中使用颜色表示）。这种划分允许对语义概念和主题进行预先总结，这有助于对数据集的整体理解。</li><li>在查询时，这两个结构都用于在回答问题时为 LLM 上下文窗口提供材料。</li></ul><p>图 3 显示了该图的可视化示例。每个圆圈都是一个实体（例如，人、地点或组织），实体大小表示该实体具有的关系数量，颜色表示相似实体的分组。颜色分区是一种建立在图结构之上的自下而上的聚类方法，它使我们能够回答不同抽象级别的问题。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="600" height="611" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-Figure3.jpg" alt="图 3：使用 GPT-4 Turbo 从私有数据集构建的 LLM 生成的知识图。知识图可视化，由 3D 空间中的集合投影到不同大小和颜色的圆圈的 2D 图像上表示。这些圆圈按颜色在空间中分组在一起，并且在每个颜色区域内，较大的圆圈被许多较小的圆圈包围。每个圆圈代表知识图中的一个实体。" class="wp-image-1005441" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-Figure3.jpg 600w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-Figure3-295x300.jpg 295w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/GraphRag-Figure3-177x180.jpg 177w" sizes="(max-width: 600px) 100vw, 600px" /><figcaption class="wp-element-caption">图 3：使用 GPT-4 Turbo 从私有数据集构建的 LLM 生成的知识图。</figcaption></figure><h2 class="wp-block-heading" id="result-metrics">结果指标</h2><p>上面的示例代表了 GraphRAG 在不同主题领域的多个数据集上的一致改进。我们通过使用 LLM 评分器进行评估来评估这一改进，以确定 GraphRAG 和基线 RAG 之间的配对获胜者。我们使用一组定性指标，包括全面性（问题隐含背景框架内的完整性）、人类选举权（提供支持源材料或其他背景信息）和多样性（提供关于问题的不同观点或角度）摆）。初步结果表明，GraphRAG 在这些指标上<em>始终优于</em>基线 RAG。</p><p>除了相对比较之外，我们还使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/pdf/2303.08896.pdf" target="_blank" rel="noreferrer noopener">SelfCheckGPT <span class="sr-only">（在新选项卡中打开）</span></a>执行绝对的忠实度测量，以帮助确保基于源材料的事实、连贯的结果。结果表明 GraphRAG 达到了与基线 RAG 相似的忠实度。我们目前正在开发一个评估框架来衡量上述类别问题的表现。这将包括用于生成问答测试集的更强大的机制以及其他指标，例如准确性和上下文相关性。</p><h2 class="wp-block-heading" id="next-steps">下一步</h2><p id="baseline-RAG">通过将 LLM 生成的知识图和图机器学习相结合，GraphRAG 使我们能够回答仅使用基线 RAG 无法尝试的重要问题类别。将这项技术应用于各种场景后，包括社交媒体、新闻文章、工作场所生产力和化学，我们看到了可喜的结果。展望未来，我们计划在各种新领域与客户密切合作，继续应用这项技术，同时致力于指标和稳健评估。随着我们研究的继续，我们期待分享更多。</p><hr class="wp-block-separator has-alpha-channel-opacity"/><p id="baseline-RAG"> <sup>1</sup>作为本次比较中的<em>基线 RAG</em> ，我们使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://python.langchain.com/docs/use_cases/question_answering/" target="_blank" rel="noreferrer noopener">LangChain 的问答<span class="sr-only">（在新选项卡中打开）</span></a> ，这是当今广泛使用的此类 RAG 工具的著名代表示例。</p><div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">GraphRAG：解锁叙事私人数据上的 LLM 发现</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> AI 控制器接口：具有轻量级、LLM 集成 VM 的生成式 AI</title><link/> https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 07 Feb 2024 22:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1004529 </guid><description><![CDATA[<p>大型语言模型 (LLM) 的出现彻底改变了人们创建文本和与计算交互的方式。然而，这些模型在确保其生成的内容的准确性以及严格遵守特定格式（例如 JSON 和其他计算机编程语言）方面受到限制。此外，法学硕士处理来自多个来源的信息[…]</p><p>后<a href="https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/">人工智能控制器接口：具有轻量级、LLM 集成 VM 的生成人工智能</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg" alt="该图显示了约束解码期间 AI 控制器和 LLM 之间的流程和交互。该图从步骤 0 开始，如有必要，将所需的 AI 控制器上传到 LLM 服务。步骤 1 向服务器发送 LLM 请求。第 2 步是令牌生成，在每次令牌生成之前、期间和之后调用 AI 控制器来控制 LLM 的行为。对于 LLM 生成的每个令牌，重复步骤 2。步骤 3 返回生成的文本结果。" class="wp-image-1005213" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>大型语言模型 (LLM) 的出现彻底改变了人们创建文本和与计算交互的方式。然而，这些模型在确保其生成的内容的准确性以及严格遵守特定格式（例如 JSON 和其他计算机编程语言）方面受到限制。此外，处理来自多个来源的信息的法学硕士在保护机密性和安全性方面面临着显着的挑战。在医疗保健、金融和科学等信息保密性和可靠性至关重要的领域，法学硕士的成功在很大程度上依赖于满足严格的隐私和准确性标准。当前解决这些问题的策略（例如约束解码和基于代理的方法）提出了实际挑战，包括巨大的性能成本或需要直接模型集成，而这很困难。</p><h2 class="wp-block-heading" id="the-ai-controller-interface-and-program"> AI控制器接口和程序</h2><p>为了使这些方法更加可行，我们创建了人工智能控制器接口（AICI）。 AICI 超越了基于云的工具的标准“文本输入/文本输出”API，具有“提示即程序”界面。它旨在允许用户级代码与云中的 LLM 输出生成无缝集成。它还提供对现有安全框架、特定于应用程序的功能、快速实验以及用于提高准确性、隐私性和对特定格式的遵守的各种策略的支持。通过提供对生成式 AI 基础设施的粒度级访问，AICI 允许对 LLM 处理进行定制控制，无论它是在本地运行还是在云中运行。</p><p>轻量级虚拟机 (VM)、AI 控制器位于此界面之上。 AICI隐藏了LLM处理引擎的具体实现，提供了正确的机制，使开发人员和研究人员能够敏捷、高效地与LLM合作，让他们更轻松地进行开发和实验。借助允许调整决策过程、高效内存使用、一次处理多个请求以及同时协调任务的功能，用户可以微调输出，逐步控制它。</p><p>个人用户、租户或平台可以使用专为特定应用程序或提示完成任务设计的可定制界面来开发 AI 控制器程序。 AICI 专为 AI 控制器而设计，可在 CPU 上与 GPU 上的模型处理并行运行，从而实现对 LLM 行为的高级控制，而不影响其性能。此外，多个人工智能控制器可以同时运行。图 1 展示了 AI 控制器架构。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="519" height="520" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1.jpg" alt="该图显示了 AI 控制器接口系统的架构堆栈。在堆栈的顶部，副驾驶或应用程序独立运行并调用堆栈中低一级的 AI 控制器。 AI 控制器可以是 DeclCtrl、PyCtrl、JSCtrl 或自定义控制器。 AI 控制器位于 AI 控制器接口之上，它直接与 LLM 服务引擎集成，例如 rLLM、llama.cpp 或其他 LLM 服务引擎。" class="wp-image-1004823" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1.jpg 519w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-300x300.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-180x180.jpg 180w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-360x360.jpg 360w" sizes="(max-width: 519px) 100vw, 519px" /><figcaption class="wp-element-caption">图 1. 应用程序向 AI 控制器发送指令，该控制器提供高级 API。 AICI 允许控制器在云中与模型推理并行高效执行。</figcaption></figure><p> AI 控制器作为 WebAssembly VM 实现，最容易编写为 Rust 程序。但是，它们也可以用任何可以编译为或解释为 WebAssembly 的语言编写。我们已经开发了几个示例 AI 控制器，可以<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/aici/" target="_blank" rel="noreferrer noopener">开源<span class="sr-only">（在新选项卡中打开）</span></a> 。这些功能提供了用于受控文本创建的内置工具，允许即时更改初始指令和结果文本。它们还可以有效管理涉及多个阶段或批处理的任务。</p><h2 class="wp-block-heading" id="high-level-execution-flow">高层执行流程</h2><p>让我们举个例子来说明人工智能控制器如何影响法学硕士的输出。假设用户请求完成一项任务，例如求解数学方程，并期望收到数字答案。以下程序确保法学硕士的响应是数字。<em> </em>该过程展开如下：</p><p> 1.<strong>设置。</strong>用户或平台所有者首先设置支持 AICI 的 LLM 引擎，然后通过 REST API 将提供的 AI 控制器<code>DeclCtrl</code>部署到云。</p><p> 2.<strong>请求。</strong>用户使用指定 AI 控制器 ( <code>DeclCtrl</code> ) 的 REST 请求和 JSON 格式的声明性程序来启动 LLM 推理，如下例所示。</p><pre class="wp-block-code"> <code>{&quot;steps&quot;: [<br>    {&quot;Fixed&quot;:{&quot;text&quot;:&quot;Please tell me what is 122.3*140.4?&quot;}},<br>    {&quot;Gen&quot;: {&quot;rx&quot;:&quot; ^(([1-9][0-9]*)|(([0-9]*)\.([0-9]*)))$&quot;}}<br> ]}</code></pre><p>一旦服务器收到此请求，它就会创建所请求的<code>DeclCtrl</code> AI 控制器的实例，并将声明性程序传递到其中。 AI 控制器解析其输入，初始化其内部状态，然后 LLM 推理开始。</p><p> 3.<strong>代币生成。</strong>服务器按顺序生成令牌，AICI 在每次令牌生成之前、期间和之后调用<code>DeclCtrl</code> AI 控制器。</p><ul><li> <code>pre_process()</code>在令牌生成之前调用。此时，AI控制器可以停止生成（例如，如果它已完成）、分叉并行生成、暂停或继续。</li><li> <code>mid_process()</code>在令牌生成期间被调用，是 AI 控制器中计算的主要入口点。在此调用期间，AI 控制器可以返回 logit 偏差来约束生成、在生成中回溯或通过一组固定或零熵令牌快进。 <code>mid_process()</code>函数与 GPU 上的模型推理并行运行，并且其计算（例如，logit 偏差）被合并到 GPU 上的模型令牌采样中。</li><li>一旦模型生成了下一个标记，就会调用<code>post_process()</code> 。例如，在这里，AI 控制器可以执行简单的簿记，根据采样的令牌更新其状态。</li></ul><p>在这些调用期间， <code>DeclCtrl</code> AI 控制器执行必要的逻辑，以确保 LLM 生成符合用户提供的声明性程序。这确保了法学硕士的答案是数学问题的数值解。</p><p> 4.<strong>回应。</strong>一旦<code>DeclCtrl</code>完成其程序，它就会组装结果，其中可能包括中间输出、调试信息和计算变量。这些可以作为最终响应返回或流式传输以显示进度。最后，AI 控制器被释放。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg" alt="该图显示了约束解码期间 AI 控制器和 LLM 之间的流程和交互。该图从步骤 0 开始，如有必要，将所需的 AI 控制器上传到 LLM 服务。步骤 1 向服务器发送 LLM 请求。第 2 步是令牌生成，在每次令牌生成之前、期间和之后调用 AI 控制器来控制 LLM 的行为。对于 LLM 生成的每个令牌，重复步骤 2。步骤 3 返回生成的文本结果。" class="wp-image-1005216" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 2. AI 控制器在逐个令牌解码过程中纳入自定义逻辑，与 LLM 并行工作以支持快速、灵活且安全的受控生成。</figcaption></figure><h2 class="wp-block-heading" id="use-cases">用例</h2><p><strong>高效受限解码</strong></p><p>对于基于 Rust 的 AI 控制器，我们开发了一种有效的方法来在<code>aici_abi</code>库中创建文本期间检查和强制执行格式规则（约束）。此方法涉及使用一种特殊类型的搜索树（称为特里树）并根据模式（正则表达式）或规则（上下文无关语法）进行检查，以确保每段文本都遵循指定的约束。这种效率确保了快速的合规性检查，使程序能够与 GPU 的进程无缝集成，而不影响性能。</p><p>虽然 AI 控制器目前支持强制格式要求，例如分配负无穷大值以禁止无效令牌，但我们预计未来版本将支持更灵活的指导。</p><p><strong>信息流限制</strong></p><p>此外，AI控制器VM使用户能够控制提示、后台数据和中间文本创建影响后续输出的时间和方式。这是通过回溯、编辑和提示处理来实现的。</p><p>此功能在许多场景中都很有用。例如，它允许用户有选择地影响结构化思维过程的一部分，但不能影响另一部分。它还可以应用于预处理背景数据，以在开始 LLM 分析之前删除不相关或潜在敏感的细节。目前，实现这种控制级别需要对法学硕士进行多次独立调用。</p><p><strong>展望未来</strong></p><p>我们与 AICI 的合作成功实现了参考 LLM 服务引擎 (rLLM) 以及与 LLaMa.cpp 的集成。目前，我们正在努力为 Guidance 等流行库提供一小组标准 AI 控制器。在不久的将来，我们计划与各种 LLM 基础设施合作，我们很高兴能够使用 LLM 服务引擎的开源生态系统来集成 AICI，为 AI 控制器提供跨环境的可移植性。</p><p><strong>资源</strong></p><p>代码、AICI 的详细描述和教程可在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/aici/" target="_blank" rel="noreferrer noopener">GitHub <span class="sr-only">（在新选项卡中打开）</span></a>上找到。我们鼓励开发人员和研究人员创建并分享他们自己的定制人工智能控制器。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>后<a href="https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/">人工智能控制器接口：具有轻量级、LLM 集成 VM 的生成人工智能</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>