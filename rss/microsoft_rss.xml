<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 5 月 22 日星期三 16:01:34 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.5.3</generator><item><title> GigaPath：数字病理学的全幻灯片基础模型</title><link/>https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 22 May 2024 15:08:11 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>数字病理学有助于解码肿瘤微环境以进行精准免疫治疗。我们与普罗维登斯大学和华盛顿大学合作，共享 Prov-GigaPath，这是第一个全玻片病理学基础模型，用于推进临床研究。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/">GigaPath：数字病理学的整体幻灯片基础模型</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero.png" alt="数字病理学有助于解码肿瘤微环境以进行精准免疫治疗。 GigaPath 是一种新颖的视觉转换器，可以通过适应数字病理学的扩展注意力来扩展到十亿像素的全幻灯片图像。在与普罗维登斯大学和华盛顿大学的合作中，我们正在共享 Prov-GigaPath，这是第一个基于大规模真实数据进行预训练的全幻灯片病理学基础模型，用于推进临床研究和发现。" class="wp-image-1038840" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><em>图片：Ella Maru Studio</em></figcaption></figure><p>生物医学数字化转型与当前的生成式人工智能革命的融合，为大幅加速精准健康的进步创造了前所未有的机遇。数字病理学是这一令人兴奋的前沿领域的象征。在癌症护理中，全载玻片成像已成为常规技术，可将肿瘤组织的显微镜载玻片转换为高分辨率数字图像。这种全幻灯片图像包含破译肿瘤微环境的关键信息，这对于精准免疫治疗至关重要（例如根据淋巴细胞浸润区分热肿瘤和冷肿瘤）。数字病理学还可以与多模态生成人工智能中的其他多模态、纵向患者信息相结合，以扩展人群水平、真实世界的证据生成。</p><p>这是一个激动人心的时刻，但数字病理学带来了独特的计算挑战，因为标准的十亿像素幻灯片在宽度和长度上可能比典型的自然图像大数千倍。传统的视觉变换器很难应对如此巨大的尺寸，因为自注意力的计算随着输入长度的增加而急剧增长。因此，数字病理学的先前工作经常忽略每张幻灯片中图像图块之间复杂的相互依赖性，从而错过了关键应用（例如肿瘤微环境建模）的重要幻灯片级上下文。</p><p>在这篇博文中，我们介绍了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41586-024-07441-w">GigaPath <span class="sr-only">（在新选项卡中打开）</span></a> ，这是一种新颖的视觉转换器，它通过利用扩张的自注意力来保持计算的易处理性，从而实现整个幻灯片建模。我们与普罗维登斯卫生系统和华盛顿大学合作开发了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://aka.ms/prov-gigapath" target="_blank" rel="noreferrer noopener">Prov-GigaPath <span class="sr-only">（在新选项卡中打开）</span></a> ，这是一种开放访问的全幻灯片病理学基础模型，在超过 10 亿张 256 X 256 病理图像图块上进行了预训练。来自普罗维登斯真实世界数据的超过 170,000 张完整幻灯片。所有计算均在普罗维登斯的私人租户内进行，并得到普罗维登斯机构审查委员会 (IRB) 的批准。</p><p>据我们所知，这是第一个针对数字病理学的全幻灯片基础模型，对真实世界数据进行了大规模预训练。 Prov-GigaPath 在标准癌症分类和病理学任务以及视觉语言任务上实现了最先进的性能。这证明了对大规模真实世界数据进行全幻灯片建模的重要性，并为推进患者护理和加速临床发现开辟了新的可能性。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956160"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/" aria-label="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" data-bi-cN="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/collaboratorsEP2_hero_1400x788.jpg" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Bichlien Nguyen 和 David Kwabi 的可再生能源存储</h2><p class="large">Bichlien Nguyen 博士和 David Kwabi 博士探索了他们在液流电池方面的工作，以及机器学习如何帮助更有效地搜索广阔的有机化学空间，以识别具有适合储存水力和其他可再生能源的特性的化合物。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="adapting-dilated-attention-and-longnet-to-digital-pathology">将扩张注意力和 LongNet 应用于数字病理学</h2><figure class="wp-block-image size-full"><img decoding="async" width="1532" height="1404" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust.jpg" alt="图 1：GigaPath 概述。 a，Prov-GigaPath 模型架构的流程图。 Prov-GigaPath 首先将每个输入 WSI 按行主序序列化为 256 × 256 个图像图块的序列，并使用图像图块级编码器将每个图像图块转换为视觉嵌入。然后，Prov-GigaPath 应用基于 LongNet 架构的滑动级编码器来生成上下文嵌入，这可以作为各种下游应用的基础。 b，使用 DINOv2 进行图像图块级预训练。 c，使用掩码自动编码器通过 LongNet 进行滑动级预训练。" class="wp-image-1038756" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-300x275.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-1024x938.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-768x704.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-196x180.jpg 196w" sizes="(max-width: 1532px) 100vw, 1532px" /><figcaption class="wp-element-caption">图 1：GigaPath 概述。 a，Prov-GigaPath 模型架构的流程图。 Prov-GigaPath 首先将每个输入 WSI 按行主序序列化为 256 × 256 图像图块序列，并使用图像图块级编码器将每个图像图块转换为视觉嵌入。然后，Prov-GigaPath 应用基于 LongNet 架构的滑动级编码器来生成上下文嵌入，这可以作为各种下游应用的基础。 b，使用 DINOv2 进行图像图块级预训练。 c，使用掩码自动编码器通过 LongNet 进行滑动级预训练。</figcaption></figure><p> GigaPath 采用两阶段课程学习，包括使用 DINOv2 的图块级预训练和使用带有<a href="https://www.microsoft.com/en-us/research/publication/longnet-scaling-transformers-to-1000000000-tokens/" target="_blank" rel="noreferrer noopener">LongNet</a>的掩码自动编码器的滑动级预训练（见图 1）。 DINOv2 是一种标准的自监督方法，在训练教师和学生视觉变换器时结合了对比损失和掩模重建损失。然而，由于自注意力的计算挑战，其应用仅限于小图像，例如 256 × 256 瓦片。对于幻灯片级建模，我们将扩张注意力从<a href="https://www.microsoft.com/en-us/research/publication/longnet-scaling-transformers-to-1000000000-tokens/" target="_blank" rel="noreferrer noopener">LongNet</a>调整到数字病理学（见图 2）。为了处理整张幻灯片的长图像图块序列，我们引入了一系列递增的尺寸，用于将图块序列细分为给定尺寸的片段。对于较大的片段，我们引入稀疏注意力，稀疏性与片段长度成正比，从而抵消二次增长。最大的部分将覆盖整个幻灯片，尽管具有稀疏的子采样自注意力。这使我们能够以系统的方式捕获远程依赖关系，同时保持计算的易处理性（上下文长度呈线性）。 </p><figure class="wp-block-image size-full"><img decoding="async" width="2042" height="1786" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust.jpg" alt="图 2：注意力扩张的图示。扩张注意力引入了一系列不断增加的尺寸，用于将图块序列细分为给定尺寸的片段。对于较大的片段，我们引入稀疏注意力，稀疏性与片段长度成正比，从而抵消二次增长。这使我们能够以系统的方式捕获远程依赖关系，同时保持计算的易处理性（上下文长度呈线性）。" class="wp-image-1038762" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust.jpg 2042w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-300x262.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-1024x896.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-768x672.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-1536x1343.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-206x180.jpg 206w" sizes="(max-width: 2042px) 100vw, 2042px" /><figcaption class="wp-element-caption">图 2：注意力扩张的图示。扩张注意力引入了一系列不断增加的尺寸，用于将图块序列细分为给定尺寸的片段。对于较大的片段，我们引入稀疏注意力，稀疏性与片段长度成正比，从而抵消二次增长。这使我们能够以系统的方式捕获远程依赖关系，同时保持计算的易处理性（上下文长度呈线性）。 </figcaption></figure><h2 class="wp-block-heading" id="gigapath-on-cancer-classification-and-pathomics-tasks"> GigaPath 癌症分类和病理组学任务</h2><p>我们使用普罗维登斯和 TCGA 数据构建了一个数字病理学基准，包括 9 项癌症亚型任务和 17 项病理组学任务。通过大规模预训练和全幻灯片建模，Prov-GigaPath 在 26 项任务中的 25 项上实现了最先进的性能，在 18 项任务上比第二最佳模型有了显着改进。 </p><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1532" height="1149" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust.jpg" alt="图 3：癌症亚型比较。条形图比较了九种癌症类型的 AUROC (a,c,e) 和平衡准确度 (b,d,f) 方面的癌症亚型分型表现。数据为平均值±s.e.m。 n = 10 个独立实验。列出的 P 值表明 Prov-GigaPath 优于单侧 Wilcoxon 测试的最佳比较方法的显着性。 BACC，平衡精度。 BRCA，乳腺浸润性癌； CNS，中枢神经系统； COADREAD，结直肠腺癌； DIFG，弥漫性内在脑桥神经胶质瘤； EGC，早期胃癌； HB，肝胆； NSCLC，非小细胞肺癌； OVT，卵巢肿瘤； RCC，肾细胞癌。" class="wp-image-1038771" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-300x225.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-1024x768.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-768x576.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-80x60.jpg 80w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-240x180.jpg 240w" sizes="(max-width: 1532px) 100vw, 1532px" /><figcaption class="wp-element-caption">图 3：癌症亚型比较。条形图比较了九种癌症类型的 AUROC (a,c,e) 和平衡准确度 (b,d,f) 方面的癌症亚型分型表现。数据为 n = 10 次独立实验的平均值 ± sem。列出的 P 值表明 Prov-GigaPath 优于单侧 Wilcoxon 测试的最佳比较方法的显着性。 BACC，平衡精度。 BRCA，乳腺浸润性癌； CNS，中枢神经系统； COADREAD，结直肠腺癌； DIFG，弥漫性内在脑桥神经胶质瘤； EGC，早期胃癌； HB，肝胆； NSCLC，非小细胞肺癌； OVT，卵巢肿瘤； RCC，肾细胞癌。</figcaption></figure><p>在癌症亚型划分方面，目标是根据病理切片对细粒度亚型进行分类。例如，对于卵巢癌，模型需要区分六种亚型：透明细胞卵巢癌、子宫内膜样卵巢癌、高级别浆液性卵巢癌、低级别浆液性卵巢癌、粘液性卵巢癌和卵巢癌肉瘤。 Prov-GigaPath 在所有九项任务中都取得了最先进的性能，在九项任务中的六项中比第二名有了显着的改进（见图 3）。对于六种癌症（乳腺癌、肾癌、肝癌、脑癌、卵巢癌、中枢神经系统癌），Prov-GigaPath 的 AUROC 达到 90% 或更高。这对于癌症诊断和预后等精准健康领域的下游应用来说是个好兆头。 </p><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1532" height="1616" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust.jpg" alt="图4：基因突变预测比较。 a−j，比较 Prov-GigaPath 和竞争方法对泛癌 18 生物标志物的 AUROC 和 AUPRC 评分的条形图 (a,f)、LUAD 特异性 5-基因突变预测 (b,g)、泛癌 5 -基因突变预测（c，h），TCGA上的LUAD特异性5基因突变预测（d，i）和泛癌TMB预测（e，j）。 k，条形图显示 TCGA 上 LUAD 特异性五基因突变预测中每个基因的 AUROC。 a−k，数据为平均值±s.e.m。 n = 10 个独立实验。列出的 P 值表明 Prov-GigaPath 优于单侧 Wilcoxon 测试的最佳比较方法的显着性。 l，泛癌18生物标志物预测中各个生物标志物的AUROC评分比较。" class="wp-image-1038780" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-284x300.jpg 284w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-971x1024.jpg 971w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-768x810.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-1456x1536.jpg 1456w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-171x180.jpg 171w" sizes="(max-width: 1532px) 100vw, 1532px" /><figcaption class="wp-element-caption">图4：基因突变预测比较。 a−j，比较 Prov-GigaPath 和竞争方法对泛癌 18 生物标志物的 AUROC 和 AUPRC 评分的条形图 (a,f)、LUAD 特异性 5-基因突变预测 (b,g)、泛癌 5 -基因突变预测（c，h），TCGA上的LUAD特异性5基因突变预测（d，i）和泛癌TMB预测（e，j）。 k，条形图显示 TCGA 上 LUAD 特异性五基因突变预测中每个基因的 AUROC。 a−k，数据是 n = 10 个独立实验的平均值±sem。列出的 P 值表明 Prov-GigaPath 优于单侧 Wilcoxon 测试的最佳比较方法的显着性。 l，泛癌18生物标志物预测中各个生物标志物的AUROC评分比较。</figcaption></figure><p>在病理组学任务中，目标是仅根据幻灯片图像对肿瘤是否表现出特定的临床相关基因突变进行分类。这可能会揭示组织形态和遗传途径之间的有意义的联系，这些联系太微妙而无法被人类观察发现。除了一些众所周知的特定癌症类型和基因突变对之外，尚不清楚仅从载玻片中存在多少信号。此外，在一些实验中，我们考虑了泛癌场景，我们试图在所有癌症类型和非常多样化的肿瘤形态中识别基因突变的通用信号。在如此具有挑战性的场景中，Prov-GigaPath 在 18 项任务中的 17 项中再次达到了最先进的性能，在 18 项任务中的 12 项中显着优于第二名（见图 4）。例如，在泛癌 5 基因分析中，Prov-GigaPath 在 AUROC 中比最佳竞争方法高出 6.5%，在 AUPRC 中比最佳竞争方法高出 18.7%。我们还对 TCGA 数据进行了头对头比较，以评估 Prov-GigaPath 的通用性，发现 Prov-GigaPath 同样优于所有竞争方法。考虑到竞争方法都是在 TCGA 上进行预训练的，这一点就更加引人注目了。 Prov-Gigapath 可以在整个幻灯片水平上提取遗传相关的泛癌和亚型特异性形态特征，突出了基础学习嵌入的生物学相关性，并为使用真实世界数据围绕复杂的未来研究方向打开了大门肿瘤微环境的生物学。</p><h2 class="wp-block-heading" id="gigapath-on-vision-language-tasks"> GigaPath 处理视觉语言任务</h2><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1532" height="1447" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust.jpg" alt="图 5：视觉语言任务比较。 a，流程图显示使用病理报告对 Prov-GigaPath 进行微调。使用 OpenAI 的 GPT-3.5 处理真实世界的病理报告，以删除与癌症诊断无关的信息。我们进行了基于 CLIP 的对比学习，以协调 Prov-GigaPath 和 PubMedBERT。 b，经过微调的 Prov[1]GigaPath 可用于执行零样本癌症亚型分析和突变预测。 Prov-GigaPath 的输入是从 WSI 分段的图块序列，文本编码器 PubMedBERT 的输入是手动设计的代表癌症类型和突变的提示。根据 Prov-GigaPath 和 PubMedBERT 的输出，我们可以计算输入 WSI 被分类为特定癌症亚型和突变的概率。 c，比较 NSCLC 和 COADREAD 在 BACC、精度和 f 1 方面的零样本亚型分型性能的条形图。d，比较使用六个基因的微调模型进行突变预测的性能的条形图。 c，d，数据为平均值±s.e.m。跨 n = 50 个实验。列出的 P 值表明 Prov-GigaPath 优于单侧 Wilcoxon 测试的最佳比较方法的显着性。 e，散点图比较 Prov-GigaPath 和 MI-Zero 在 BACC 零样本癌症亚型分型方面的性能。每个点表示使用一组特定文本查询公式的一次试验。" class="wp-image-1038786" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-300x283.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-1024x967.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-768x725.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-191x180.jpg 191w" sizes="(max-width: 1532px) 100vw, 1532px" /><figcaption class="wp-element-caption">图 5：视觉语言任务比较。 a，流程图显示使用病理报告对 Prov-GigaPath 进行微调。使用 OpenAI 的 GPT-3.5 处理真实世界的病理报告，以删除与癌症诊断无关的信息。我们进行了基于 CLIP 的对比学习，以协调 Prov-GigaPath 和 PubMedBERT。 b，经过微调的 Prov-GigaPath 可用于执行零样本癌症亚型分析和突变预测。 Prov-GigaPath 的输入是从 WSI 分段的图块序列，文本编码器 PubMedBERT 的输入是手动设计的代表癌症类型和突变的提示。根据 Prov-GigaPath 和 PubMedBERT 的输出，我们可以计算输入 WSI 被分类为特定癌症亚型和突变的概率。 c，比较 NSCLC 和 COADREAD 在 BACC、精度和 f 1 方面的零样本亚型分型性能的条形图。d，比较使用六个基因的微调模型进行突变预测的性能的条形图。 c、d，数据为 n = 50 次实验的平均值 ± sem。列出的 P 值表明 Prov-GigaPath 优于单侧 Wilcoxon 测试的最佳比较方法的显着性。 e，散点图比较 Prov-GigaPath 和 MI-Zero 在 BACC 零样本癌症亚型分型方面的性能。每个点表示使用一组特定文本查询公式的一次试验。</figcaption></figure><p>我们通过合并病理报告进一步证明了 GigaPath 在视觉语言任务上的潜力。先前关于病理视觉语言预训练的工作往往集中在图块级别的小图像上。相反，我们探索幻灯片级别的视觉语言预训练。通过继续对幻灯片报告对进行预训练，我们可以利用报告语义来对齐病理幻灯片表示，这可以用于下游预测任务，而无需监督微调（例如，零样本子类型）。具体来说，我们使用 Prov-GigaPath 作为整个幻灯片图像编码器，使用 PubMedBERT 作为文本编码器，并使用幻灯片报告对进行对比学习。这比传统的视觉语言预训练更具挑战性，因为我们没有单个图像图块和文本片段之间的细粒度对齐信息。 Prov-GigaPath 在标准视觉语言任务中显着优于三种最先进的病理学视觉语言模型，例如零样本癌症亚型分型和基因突变预测，展示了 Prov-GigaPath 在全幻灯片视觉中的潜力。语言建模（见图 5）。 </p><h2 class="wp-block-heading" id="gigapath-is-a-promising-step-toward-multimodal-generative-ai-for-precision-health"> GigaPath 是迈向精准健康多模态生成人工智能的充满希望的一步</h2><p>我们进行了彻底的消融研究，以建立全幻灯片预训练和视觉语言建模的最佳实践。我们还观察到数字病理学中缩放定律的早期迹象，其中更大规模的预训练通常会提高下游性能，尽管我们的实验由于计算限制仍然受到限制。</p><p>展望未来，还有很多进步的机会。与之前的最佳模型相比，Prov-GigaPath 获得了最先进的性能，但在许多下游任务中仍然存在巨大的增长空间。虽然我们已经对病理视觉语言预训练进行了初步探索，但要发挥多模态会话助手的潜力还有很长的路要走，特别是通过结合<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/llava-med" target="_blank" rel="noreferrer noopener">LLaVA-Med <span class="sr-only">（在新选项卡中打开）</span></a>等先进的多模态框架。最重要的是，我们尚未探索 GigaPath 和全玻片预训练在许多关键的精准健康任务中的影响，例如肿瘤微环境建模和预测治疗反应。</p><p> GigaPath 与普罗维登斯卫生系统和华盛顿大学 Paul G. Allen 计算机科学与工程学院合作，并带来了 Microsoft* 内多个团队的协作。它反映了微软对推进多模式生成人工智能以实现精准健康的更大承诺，并在其他数字病理学研究合作方面取得了令人兴奋的进展，例如<a href="https://www.microsoft.com/en-us/research/blog/scaling-early-detection-of-esophageal-cancer-with-ai/" target="_blank" rel="noreferrer noopener">Cyted <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.businesswire.com/news/home/20240326651392/en/Volastra-Therapeutics-Announces-New-and-Expanded-Partnerships-with-AI-and-Precision-Medicine-Leaders-to-Broaden-Potential-of-KIF18A-Inhibitors-Across-Cancer" target="_blank" rel="noreferrer noopener">Volastra <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://paige.ai/paige-announces-collaboration-with-microsoft-to-build-the-worlds-largest-image-based-ai-model-to-fight-cancer/" target="_blank" rel="noreferrer noopener">Paige <span class="sr-only">（在新选项卡中打开）</span></a>以及其他技术进步，例如<a href="https://www.microsoft.com/en-us/research/publication/large-scale-domain-specific-pretraining-for-biomedical-vision-language-processing/" target="_blank" rel="noreferrer noopener">BiomedCLIP <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2403.08002" target="_blank" rel="noreferrer noopener">LLaVA-Rad <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2310.10765" target="_blank" rel="noreferrer noopener">BiomedJourney <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/biomedparse-paper" target="_blank" rel="noreferrer noopener">BiomedParse <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a href="https://www.microsoft.com/en-us/research/project/project-maira/" target="_blank" rel="noreferrer noopener">MAIRA <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a href="https://www.microsoft.com/en-us/research/publication/rad-dino-exploring-scalable-medical-image-encoders-beyond-text-supervision/" target="_blank" rel="noreferrer noopener">Rad -DINO <span class="sr-only">（在新选项卡中打开）</span></a> ， <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/pdf/2309.07778v5" target="_blank" rel="noreferrer noopener">Virchow <span class="sr-only">（在新选项卡中打开）</span></a> 。</p><hr class="wp-block-separator has-alpha-channel-opacity"/><p> （致谢脚注）*：在 Microsoft 内部，这是 Health Futures、MSRA、MSR Deep Learning 和 Nuance 之间的精彩合作。<br><br>论文共同作者：Hanwen Xu、Naoto Usuyama、Jaspreet Bagga、Sheng Zhang、Rajesh Rao、Tristan Naumann、Cliff Wong、Zelalem Gero、Javier Gonz ́alez、Yu Gu、Yanbo Xu、Mu Wei、Wenhui Wang、Shuming Ma、Furu Wei 、Jianwei Yang、Chunyuan Li、Jianfeng Taka、Jaylen Rosemon、Tucker Bower、Soohee Lee、Roshanthi Weerasinghe、Bill J. Wright、Ari Robicsek、Brian Piening、Carlo Bifulco、Sheng Wang、Hoifung Poon。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/">GigaPath：数字病理学的整体幻灯片基础模型</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 5 月 13 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-13-2024/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 15 May 2024 18:12:21 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1032900 </guid><description><![CDATA[<p>欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、事件、代码/数据集、新员工和其他里程碑。大型语言模型 (LLM) 在生成与人类创建的文本相似的文本方面表现出了卓越的性能，被证明是跨各种应用程序的宝贵资产。然而，适应[...]</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-13-2024/">研究焦点：2024 年 5 月 13 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、事件、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1024x576.png" alt="研究重点：2024 年 5 月 13 日" class="wp-image-1033017" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning">通过监督微调将新知识注入大型语言模型</h2><p>大型语言模型 (LLM) 在生成与人类创建的文本相似的文本方面表现出了卓越的性能，被证明是跨各种应用程序的宝贵资产。然而，调整这些模型以纳入新的领域外知识仍然是一个挑战，特别是对于模型训练知识截止日期之后发生的事实和事件。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning/" target="_blank" rel="noreferrer noopener">通过监督微调将新知识注入大型语言模型中</a>，微软的研究人员研究了监督微调（SFT）作为法学硕士知识注入方法的有效性，特别关注最近的体育赛事。他们比较不同的数据集生成策略（基于令牌和基于事实的扩展），以创建帮助模型学习新信息的训练数据。他们在 GPT-4 上的实验表明，虽然基于令牌的扩展可以提高问答准确性，但它可能无法提供新知识的统一覆盖。另一方面，基于事实的扩展提供了一种更系统的方法来确保均匀覆盖所有事实。研究人员提出了一种新颖的数据集生成过程，可以通过 SFT 更有效地获取知识，结果表明与域外知识相关的问答任务的性能得到了显着提高。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="hh">人工智能时代人类笔记本体验的反思</h2><p>计算笔记本提供了一种处理数据的交互式方式。它们已被数据专业人员广泛使用，以在一个文档中编写代码、探索数据和生成可视化效果。之前的研究揭示了计算笔记本中用户体验的独特痛点。然而，随着ChatGPT或Copilot等AI工具的出现，目前尚不清楚这些痛点是否减少或改变，或者是否出现了新的痛点。由于人工智能技术的快速进步，大多数新人工智能工具的开发主要由技术驱动，而不是由用户体验驱动。</p><p>在最近的一篇论文<a href="https://www.microsoft.com/en-us/research/publication/a-reflection-on-human-notebook-experiences-in-the-era-of-ai/" target="_blank" rel="noreferrer noopener">《人工智能时代人类笔记本体验的反思》</a>中，微软的研究人员总结了有关新人工智能技术如何影响人类笔记本交互和人机交互 (HCI) 范式、新挑战和用户行为的文献。使用人工智能助手，以及计算笔记本场景中人工智能助手的最新研究。他们概述了现有文献中的差距，并建议未来重点改善整个用户工作流程中的宏观人类笔记本体验，衡量和量化人工智能系统的价值，并为人工智能工具建立一套标准和最佳实践。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/a-reflection-on-human-notebook-experiences-in-the-era-of-ai/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="电脑屏幕截图 一名男子的屏幕截图" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 解释者：基础模型和 AI 的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多数据以及情境学习如何帮助推动人工智能从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="hh">Jacdac：基于服务的嵌入式系统原型设计</h2><p>嵌入式系统编程的传统方法是单片式的：微控制器上的固件包含应用程序代码以及使用 I2C、SPI 和 RS232 等低级协议与传感器和执行器通信所需的驱动程序。相比之下，云软件开发已转向基于服务的开发和操作范例：服务提供离散的功能单元，可以由应用程序或其他服务远程访问，但可以独立管理和更新。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/jacdac-pldi2024/" target="_blank" rel="noreferrer noopener">Jacdac：嵌入式系统的基于服务的原型设计<span class="sr-only">（在新选项卡中打开）</span></a>中，微软的研究人员提出、设计、实现和评估了一种基于服务的嵌入式系统原型设计方法，称为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/jacdac" target="_blank" rel="noreferrer noopener">Jacdac <span class="sr-only">（在新选项卡中打开）</span></a> 。 Jacdac 定义了一种专门为嵌入式系统设计的服务规范语言，以及针对各种传感器和执行器的大量规范。借助 Jacdac，系统中的每个传感器/执行器都与低成本微控制器配对，该微控制器通过高效且低成本的单线总线协议宣传代表底层硬件功能的服务。一个单独的微控制器执行用户的应用程序，它是总线上 Jacdac 服务的客户端。</p><p>第三方制造商生产了三个 Jacdac 套件，包含二十多个模块： <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.kittenbot.cc/" target="_blank" rel="noreferrer noopener">KittenBot <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://forwardedu.com/">Forward Education <span class="sr-only">（在新选项卡中打开）</span></a> 。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/jacdac-pldi2024/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="hh">PARIKSHA：用于评估印度大语言模型的可扩展、民主、透明的评估平台</h2><p>由于多种因素，多语言法学硕士的评估具有挑战性——缺乏具有足够语言多样性的基准、法学硕士预训练数据中流行基准的污染以及翻译基准中缺乏当地文化的细微差别。因此，很难在多语言环境中广泛评估法学硕士，导致模型之间缺乏公平的比较，并且难以复制某些模型使用的评估设置。最近，创建了几个印度语（印度语言）法学硕士，以帮助建立更多与本地和文化相关的法学硕士。</p><p>在最近的一篇论文<a href="https://www.microsoft.com/en-us/research/publication/pariksha-a-scalable-democratic-transparent-evaluation-platform-for-assessing-indic-large-language-models/" target="_blank" rel="noreferrer noopener">《PARIKSHA：用于评估印度大型语言模型的可扩展、民主、透明的评估平台》</a>中，微软的研究人员提出了一个评估框架，这是第一个结合人工评估和基于法学硕士评估的印度法学硕士综合评估。研究人员对 29 个模型进行了总共 90,000 次人类评估和 50,000 次基于 LLM 的评估，以呈现 10 种印度语言的排行榜。 Pariksha 通过吸引代表印度庞大且多元化劳动力的工人社区来提供包容性评估，同时也作为改进评估过程的研究平台。为了过程的透明度，评估工件将被发布。研究人员定期进行 Pariksha，旨在通过评估中的见解和工件使模型能够随着时间的推移而改进。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/pariksha-a-scalable-democratic-transparent-evaluation-platform-for-assessing-indic-large-language-models/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="hh">修补、定制、配置、定制：定制人工智能公平性检查表的衔接工作</h2><p>许多负责任的人工智能资源，例如工具包、手册和清单，都是为了支持人工智能从业者识别、衡量和减轻潜在的与公平相关的危害而开发的。这些资源通常被设计为通用目的，以便解决各种用例、领域和部署环境。然而，这可能会导致脱离语境，因为这些资源缺乏使用它们所需的相关性或特异性。</p><p>为了了解 AI 从业者如何将此类资源（即 AI 公平性检查表）用于其特定用例、领域和部署环境，微软的研究人员对来自 7 个组织的 13 名 AI 从业者进行了回顾性背景调查。在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/tinker-tailor-configure-customize-the-articulation-work-of-customizing-ai-fairness-checklists/" target="_blank" rel="noreferrer noopener">修补、定制、配置、定制：定制人工智能公平性清单的衔接工作中</a>，他们确定了该清单的情境化如何为人工智能从业者和其他利益相关者引入新的工作形式，同时为人工智能公平性的谈判和争论开辟新的场所。人工智能中的价值观。研究人员还确定了情境化过程如何帮助人工智能从业者围绕人工智能公平开发一种共享语言。他们还确定了与这一过程的所有权相关的动态，这表明负责任的人工智能工作中存在更大的责任问题。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-5 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/tinker-tailor-configure-customize-the-articulation-work-of-customizing-ai-fairness-checklists/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="hh">MS MARCO Web 搜索：包含数百万个真实点击标签的大规模信息丰富的 Web 数据集</h2><p>法学硕士正在成为许多创意和信息相关任务不可或缺的工具，但它们仍然存在局限性，包括捏造内容的倾向。最先进的算法将法学硕士与外部动态更新的知识库配对，为法学硕士的答案提供基础并提供最新信息。然而，这些技术需要大量以前未公开的相关、标记的训练数据。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/ms-marco-web-search-a-large-scale-information-rich-web-dataset-with-millions-of-real-click-labels/" target="_blank" rel="noreferrer noopener">MS MARCO Web 搜索：在 2024 年 ACM Web 会议上发表的具有数百万个真实点击标签的大规模信息丰富的 Web 数据集中</a>，来自 Microsoft 的研究人员介绍了一种紧密模仿现实世界 Web 文档和查询的新颖数据集分配。 MS MARCO Web 搜索包含 93 种语言的 1000 万个唯一查询，以及数百万个相关标记的查询-文档对。它以ClueWeb22的100亿个高质量网页作为文档语料库，为各类下游任务提供丰富的信息。</p><p>该数据集解锁了以前的数据集无法很好支持的几个新研究方向，包括通用端到端神经索引器模型、通用嵌入模型和具有法学硕士的下一代信息访问系统。 MS MARCO Web 搜索提供了包含三个 Web 规模检索挑战任务的检索基准，每个任务都具有自动评估和排行榜。这些任务需要机器学习和信息检索系统的创新。研究人员希望 MS MARCO Web 搜索为人工智能和系统研究的未来发展奠定基础。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-6 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-fill-github"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/MS-MARCO-Web-Search">查看数据集</a></div><div class="wp-block-button is-style-outline"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/ms-marco-web-search-a-large-scale-information-rich-web-dataset-with-millions-of-real-click-labels/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-56323e1c55299b34125129c842d8b7cd" id="new-research">视频</h3><h2 class="wp-block-heading" id="ai-case-studies-for-natural-science-research-with-bonnie-kruft">邦妮·克鲁夫特 (Bonnie Kruft) 的自然科学研究人工智能案例研究</h2><p>在人工智能带来的惊人变化和颠覆中，最重要的变化和颠覆之一是对科学发现的影响。微软 AI 科学研究院合作伙伴副主任 Bonnie Kruft 在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://event.technologyreview.com/emtech-digital-us-2024/home" target="_blank" rel="noreferrer noopener">EmTech Digital 2024 <span class="sr-only">（在新选项卡中打开）</span></a>上的演讲中概述了生成式 AI 如何在自然科学研究中实现突破性研究的一些示例。人工智能助力的最新突破包括治疗传染病的小分子抑制剂、新能源存储材料的发现以及新药开发。</p><p>观看<a href="https://www.microsoft.com/en-us/research/video/ai-case-studies-for-natural-science-research-with-bonnie-kruft/" target="_blank" rel="noreferrer noopener">演示文稿的重播</a>，包括与观众的后续问答，并了解研究人员如何将发现时间从几年缩短到几个月。讨论探讨了安全和负责任的人工智能实践、大型语言模型如何与基于科学的模型协同工作，以及人工智能在科学领域的前景。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-7 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/video/ai-case-studies-for-natural-science-research-with-bonnie-kruft/">观看视频</a></div></div><div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section"><div class="container"><div class="wp-block-msr-immersive-section__inner"><div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-the-news"><div class="msr-cards__inner"><div class="heading-wrapper"><h2 class="mb-5 ">微软研究院新闻报道</h2></div><div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3"><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="The tiny glass blocks that can preserve your data for centuries" href="https://www.thetimes.co.uk/article/the-tiny-glass-blocks-that-can-preserve-your-data-for-centuries-7vwxn2sk3"><span>微小的玻璃块可以保存您的数据几个世纪</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>英国泰晤士报 | 2024 年 4 月 27 日</p><p>微软的<a href="https://www.thetimes.co.uk/article/the-tiny-glass-blocks-that-can-preserve-your-data-for-centuries-7vwxn2sk3" target="_blank" rel="noreferrer noopener">Project Silica</a>是一种创新的长期存储形式，可能会彻底改变为子孙后代保存重要数据的方式。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="These Recyclable Circuit Boards Could Stem E-Waste" href="https://spectrum.ieee.org/electronic-waste-recycling-2668106144"><span>这些可回收​​电路板可以阻止电子垃圾</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p> IEEE 频谱 | 2024 年 5 月 2 日</p><p>华盛顿大学和微软的新研究表明，基于 vitrimer 的 PCB 可以<a href="https://spectrum.ieee.org/electronic-waste-recycling-2668106144" target="_blank" rel="noreferrer noopener">分解成凝胶</a>以重复使用。该研究源于<a href="https://www.microsoft.com/en-us/research/collaboration/microsoft-climate-research-initiative/" target="_blank" rel="noreferrer noopener">微软研究气候计划</a>。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Today’s AI models are impressive. Teams of them will be formidable" href="https://www.economist.com/science-and-technology/2024/05/13/todays-ai-models-are-impressive-teams-of-them-will-be-formidable"><span>今天的人工智能模型令人印象深刻。他们的团队将是强大的</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>经济学人 | 2024 年 5 月 13 日</p><p>华盛顿雷德蒙德微软研究院首席研究员 Chi Wang 表示，法学硕士团队比单独的代理人更有能力、更聪明，因为一项工作可以分解为许多更小、更专业的任务。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="You Only Cache Once: Decoder-Decoder Architectures for Language Models" href="https://www.linkedin.com/posts/microsoftresearch_yoco-is-a-novel-decoder-decoder-architecture-activity-7194772456170037248-L2bf/?utm_source=li_share&utm_content=feedcontent&utm_medium=g_dt_web&utm_campaign=copy"><span>您只需缓存一次：语言模型的解码器-解码器架构</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>微软研究院 LinkedIn | 2024 年 5 月 11 日</p><p>YOCO 是一种新颖的 LLM 解码器-解码器架构，通过仅缓存一次键值对来提高内存效率。它大幅削减了 KV 缓存和预填充时间，并使 1M 长度的 LLM 变得实用。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="Peter Lee discusses new technologies that will drive the future of drug discovery" href="https://www.aaps.org/aaps/news/media/closing-plenary-nbc"><span>Peter Lee 讨论将推动药物发现未来的新技术</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p> AAPS | 2024 年 5 月 10 日</p><p>微软研究院院长在 5 月 16 日星期四举行的 AAPS 国家生物技术会议 (NBC) 闭幕全体会议上探讨了人工智能和机器学习等技术的新进展如何改变生物技术。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="PKSHA develops advanced LLMs in collaboration with Microsoft Japan" href="https://www.businesswire.com/news/home/20240418370582/en/PKSHA-develops-advanced-Large-Language-Models-in-collaboration-with-Microsoft-Japan?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark"><span>PKSHA 与微软日本合作开发高级法学硕士</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>美国商业资讯 | 2024 年 4 月 29 日</p><p>PKSHA Technology 与 Microsoft Japan 合作开发了首批日英法学硕士之一。这一发展主要侧重于提高联络中心和企业服务台的生产力。 </p></div></div></div><div class="msr-cards__card msr-cards__card--default col"><div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group"><div class="card-body bg-white p-4 pt-3"><h3 class="h5"> <a class="text-decoration-none text-black" data-bi-cN="BRAID fellowships include three collaborations with Microsoft Research" href="https://braiduk.org/projects-fellowships"><span>BRAID 奖学金包括与微软研究院的三项合作</span><span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span></a></h3><p>弥合负责任的人工智能鸿沟 | 2024年5月</p><p>BRAID 奖学金支持个人研究人员与公共和私人组织合作，应对负责任的人工智能领域的挑战。最新的奖学金项目中有三项是由微软研究院支持的。</p></div></div></div></div><div class="justify-content-center text-center mb-4"> <a href="https://www.microsoft.com/en-us/research/news-and-awards/" class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta" data-bi-cN="View more news and awards" data-bi-type="button">查看更多新闻和奖项</a></div></div></div></div></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-13-2024/">研究焦点：2024 年 5 月 13 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>