<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 2 月 7 日，星期三 20:29:53 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.3</generator><item><title> AI 控制器接口：具有轻量级、LLM 集成 VM 的生成式 AI</title><link/> https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 07 Feb 2024 22:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1004529 </guid><description><![CDATA[<p>大型语言模型 (LLM) 的出现彻底改变了人们创建文本和与计算交互的方式。然而，这些模型在确保其生成的内容的准确性以及严格遵守特定格式（例如 JSON 和其他计算机编程语言）方面受到限制。此外，法学硕士处理来自多个来源的信息[…]</p><p>后<a href="https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/">人工智能控制器接口：具有轻量级、LLM 集成 VM 的生成人工智能</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg" alt="该图显示了约束解码期间 AI 控制器和 LLM 之间的流程和交互。该图从步骤 0 开始，如有必要，将所需的 AI 控制器上传到 LLM 服务。步骤 1 向服务器发送 LLM 请求。第 2 步是令牌生成，在每次令牌生成之前、期间和之后调用 AI 控制器来控制 LLM 的行为。对于 LLM 生成的每个令牌，重复步骤 2。步骤 3 返回生成的文本结果。" class="wp-image-1005213" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>大型语言模型 (LLM) 的出现彻底改变了人们创建文本和与计算交互的方式。然而，这些模型在确保其生成的内容的准确性以及严格遵守特定格式（例如 JSON 和其他计算机编程语言）方面受到限制。此外，处理来自多个来源的信息的法学硕士在保护机密性和安全性方面面临着显着的挑战。在医疗保健、金融和科学等信息保密性和可靠性至关重要的领域，法学硕士的成功在很大程度上依赖于满足严格的隐私和准确性标准。当前解决这些问题的策略（例如约束解码和基于代理的方法）提出了实际挑战，包括巨大的性能成本或需要直接模型集成，而这很困难。</p><h2 class="wp-block-heading" id="the-ai-controller-interface-and-program"> AI控制器接口和程序</h2><p>为了使这些方法更加可行，我们创建了人工智能控制器接口（AICI）。 AICI 超越了基于云的工具的标准“文本输入/文本输出”API，具有“提示即程序”界面。它旨在允许用户级代码与云中的 LLM 输出生成无缝集成。它还提供对现有安全框架、特定于应用程序的功能、快速实验以及用于提高准确性、隐私性和对特定格式的遵守的各种策略的支持。通过提供对生成式 AI 基础设施的粒度级访问，AICI 允许对 LLM 处理进行定制控制，无论它是在本地运行还是在云中运行。</p><p>轻量级虚拟机 (VM)、AI 控制器位于此界面之上。 AICI隐藏了LLM处理引擎的具体实现，提供了正确的机制，使开发人员和研究人员能够敏捷、高效地与LLM合作，让他们更轻松地进行开发和实验。借助允许调整决策过程、高效内存使用、一次处理多个请求以及同时协调任务的功能，用户可以微调输出，逐步控制它。</p><p>个人用户、租户或平台可以使用专为特定应用程序或提示完成任务设计的可定制界面来开发 AI 控制器程序。 AICI 专为 AI 控制器而设计，可在 CPU 上与 GPU 上的模型处理并行运行，从而实现对 LLM 行为的高级控制，而不影响其性能。此外，多个人工智能控制器可以同时运行。图 1 展示了 AI 控制器架构。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="519" height="520" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1.jpg" alt="该图显示了 AI 控制器接口系统的架构堆栈。在堆栈的顶部，副驾驶或应用程序独立运行并调用堆栈中低一级的 AI 控制器。 AI 控制器可以是 DeclCtrl、PyCtrl、JSCtrl 或自定义控制器。 AI 控制器位于 AI 控制器接口之上，它直接与 LLM 服务引擎集成，例如 rLLM、llama.cpp 或其他 LLM 服务引擎。" class="wp-image-1004823" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1.jpg 519w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-300x300.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-180x180.jpg 180w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICIFIG1-360x360.jpg 360w" sizes="(max-width: 519px) 100vw, 519px" /><figcaption class="wp-element-caption">图 1. 应用程序向 AI 控制器发送指令，该控制器提供高级 API。 AICI 允许控制器在云中与模型推理并行高效执行。</figcaption></figure><p> AI 控制器作为 WebAssembly VM 实现，最容易编写为 Rust 程序。但是，它们也可以用任何可以编译为或解释为 WebAssembly 的语言编写。我们已经开发了几个示例 AI 控制器，可以<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/aici/" target="_blank" rel="noreferrer noopener">开源<span class="sr-only">（在新选项卡中打开）</span></a> 。这些功能提供了用于受控文本创建的内置工具，允许即时更改初始指令和结果文本。它们还可以有效管理涉及多个阶段或批处理的任务。</p><h2 class="wp-block-heading" id="high-level-execution-flow">高层执行流程</h2><p>让我们举个例子来说明人工智能控制器如何影响法学硕士的输出。假设用户请求完成一项任务，例如求解数学方程，并期望收到数字答案。以下程序确保法学硕士的响应是数字。<em> </em>该过程展开如下：</p><p> 1.<strong>设置。</strong>用户或平台所有者首先设置支持 AICI 的 LLM 引擎，然后通过 REST API 将提供的 AI 控制器<code>DeclCtrl</code>部署到云。</p><p> 2.<strong>请求。</strong>用户使用指定 AI 控制器 ( <code>DeclCtrl</code> ) 的 REST 请求和 JSON 格式的声明性程序来启动 LLM 推理，如下例所示。</p><pre class="wp-block-code"> <code>{&quot;steps&quot;: [<br>    {&quot;Fixed&quot;:{&quot;text&quot;:&quot;Please tell me what is 122.3*140.4?&quot;}},<br>    {&quot;Gen&quot;: {&quot;rx&quot;:&quot; ^(([1-9][0-9]*)|(([0-9]*)\.([0-9]*)))$&quot;}}<br> ]}</code></pre><p>一旦服务器收到此请求，它就会创建所请求的<code>DeclCtrl</code> AI 控制器的实例，并将声明性程序传递到其中。 AI 控制器解析其输入，初始化其内部状态，然后 LLM 推理开始。</p><p> 3.<strong>代币生成。</strong>服务器按顺序生成令牌，AICI 在每次令牌生成之前、期间和之后调用<code>DeclCtrl</code> AI 控制器。</p><ul><li> <code>pre_process()</code>在令牌生成之前调用。此时，AI控制器可以停止生成（例如，如果它已完成）、分叉并行生成、暂停或继续。</li><li> <code>mid_process()</code>在令牌生成期间被调用，是 AI 控制器中计算的主要入口点。在此调用期间，AI 控制器可以返回 logit 偏差来约束生成、在生成中回溯或通过一组固定或零熵令牌快进。 <code>mid_process()</code>函数与 GPU 上的模型推理并行运行，并且其计算（例如，logit 偏差）被合并到 GPU 上的模型令牌采样中。</li><li>一旦模型生成了下一个标记，就会调用<code>post_process()</code> 。例如，在这里，AI 控制器可以执行简单的簿记，根据采样的令牌更新其状态。</li></ul><p>在这些调用期间， <code>DeclCtrl</code> AI 控制器执行必要的逻辑，以确保 LLM 生成符合用户提供的声明性程序。这确保了法学硕士的答案是数学问题的数值解。</p><p> 4.<strong>回应。</strong>一旦<code>DeclCtrl</code>完成其程序，它就会组装结果，其中可能包括中间输出、调试信息和计算变量。这些可以作为最终响应返回或流式传输以显示进度。最后，AI 控制器被释放。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg" alt="该图显示了约束解码期间 AI 控制器和 LLM 之间的流程和交互。该图从步骤 0 开始，如有必要，将所需的 AI 控制器上传到 LLM 服务。步骤 1 向服务器发送 LLM 请求。第 2 步是令牌生成，在每次令牌生成之前、期间和之后调用 AI 控制器来控制 LLM 的行为。对于 LLM 生成的每个令牌，重复步骤 2。步骤 3 返回生成的文本结果。" class="wp-image-1005216" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWAICI-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 2.AI 控制器在逐个令牌解码过程中纳入自定义逻辑，与 LLM 并行工作以支持快速、灵活且安全的受控生成。</figcaption></figure><h2 class="wp-block-heading" id="use-cases">用例</h2><p><strong>高效受限解码</strong></p><p>对于基于 Rust 的 AI 控制器，我们开发了一种有效的方法来在<code>aici_abi</code>库中创建文本期间检查和强制执行格式规则（约束）。此方法涉及使用一种特殊类型的搜索树（称为特里树）并根据模式（正则表达式）或规则（上下文无关语法）进行检查，以确保每段文本都遵循指定的约束。这种效率确保了快速的合规性检查，使程序能够与 GPU 的进程无缝集成，而不影响性能。</p><p>虽然 AI 控制器目前支持强制格式要求，例如分配负无穷大值以禁止无效令牌，但我们预计未来版本将支持更灵活的指导。</p><p><strong>信息流限制</strong></p><p>此外，AI控制器VM使用户能够控制提示、后台数据和中间文本创建影响后续输出的时间和方式。这是通过回溯、编辑和提示处理来实现的。</p><p>此功能在许多场景中都很有用。例如，它允许用户有选择地影响结构化思维过程的一部分，但不能影响另一部分。它还可以应用于预处理背景数据，以在开始 LLM 分析之前删除不相关或潜在敏感的细节。目前，实现这种控制级别需要对法学硕士进行多次独立调用。</p><p><strong>展望未来</strong></p><p>我们与 AICI 的合作成功实现了参考 LLM 服务引擎 (rLLM) 以及与 LLaMa.cpp 的集成。目前，我们正在努力为 Guidance 等流行库提供一小组标准 AI 控制器。在不久的将来，我们计划与各种 LLM 基础设施合作，我们很高兴能够使用 LLM 服务引擎的开源生态系统来集成 AICI，为 AI 控制器提供跨环境的可移植性。</p><p><strong>资源</strong></p><p>代码、AICI 的详细描述和教程可在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/aici/" target="_blank" rel="noreferrer noopener">GitHub <span class="sr-only">（在新选项卡中打开）</span></a>上找到。我们鼓励开发人员和研究人员创建并分享他们自己的定制人工智能控制器。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>后<a href="https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/">人工智能控制器接口：具有轻量级、LLM 集成 VM 的生成人工智能</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 2 月 5 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-february-5-2024/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 07 Feb 2024 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1004556 </guid><description><![CDATA[<p>研究焦点：新研究论坛系列探讨人工智能时代的大胆想法； LASER 改进了语言模型的推理；高基数大型数据集上的高速缓存高效 Top-k 聚合；六名 Microsoft 研究人员被评为 2023 年 ACM 院士。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-february-5-2024/">《研究焦点：2024 年 2 月 5 日一周》一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1.png" alt="2024 年 2 月 5 日研究焦点周" class="wp-image-1004565" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-fbe88093d062c629283ec625f92315a8" id="event-recap">活动回顾</h3><h2 class="wp-block-heading" id="microsoft-research-forum-series-kicks-off-with-focus-on-the-promise-and-challenges-of-ai">微软研究论坛系列拉开帷幕，重点关注人工智能的前景和挑战</h2><p>首届微软研究论坛回顾了 2023 年发生的令人难以置信的变化，展望了未来的切实进展，探讨了通用人工智能时代的大胆新想法和重要问题。微软研究院的领导者，包括<a href="https://www.microsoft.com/en-us/research/lab/ai-frontiers/">AI Frontiers</a>团队和<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/">AI4Science 实验室</a>，讨论了开放和协作对于实现成功和负责任的 AI 研究的重要性。</p><p>微软研究院和孵化器首席副总裁<a href="https://www.microsoft.com/en-us/research/people/petelee/">Peter Lee</a>主持了此次讨论，随后小组讨论了一些最大的潜在人工智能突破以及需要克服的挑战。这包括：</p><ul><li>构建成为物理世界助手的人工智能系统</li><li>揭示人类推理的基石</li><li>使人工智能技术更小、成本更低，以提高性能和可用性</li><li>帮助人工智能向使用它的人学习，而不是简单地回答问题</li></ul><p>在“闪电轮”中，微软研究人员探索了当前的工作，以改进预训练的大型语言模型、理解和评估基础模型、促进分子科学的突破、增强人类决策以及改进视觉叙事。</p><p>要了解更多信息，请查看<a href="https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-new-series-explores-bold-ideas-in-technology-research-in-the-era-of-ai/">此回顾<span class="sr-only">（在新选项卡中打开）</span></a>并浏览<a href="https://www.microsoft.com/en-us/research/quarterly-brief/jan-2024-brief/?OCID=msr_researchforum_MCR_Blog_Promo">点播会话重播<span class="sr-only">（在新选项卡中打开）</span></a> 。请务必<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://researchforum.microsoft.com/?OCID=msr_researchforum_MSR_Research_Focus" target="_blank" rel="noreferrer noopener">注册即将播出的剧集<span class="sr-only">（在新选项卡中打开）</span></a> 。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="970287"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-future-of-scale-with-ahmed-awadallah-and-ashley-llorens/" aria-label="AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens" data-bi-cN="AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Ahmed_AI_Frontiers_TW_LI_FB_1200x627_With_Name.png" alt="MSR 播客 |人工智能前沿 |艾哈迈德·阿瓦达拉" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能前沿：艾哈迈德·阿瓦达拉 (Ahmed Awadallah) 和阿什利·洛伦斯 (Ashley Llorens) 的规模化未来</h2><p class="large">本集的主角是高级首席研究经理<a href="https://www.microsoft.com/en-us/research/people/hassanam/" target="_blank" rel="noreferrer noopener">Ahmed H. Awadallah</a> ，他致力于提高大规模人工智能模型的效率，并努力帮助推动该领域从研究到实践的进步<strong> </strong>使他处于人工智能新时代的前沿。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-future-of-scale-with-ahmed-awadallah-and-ashley-llorens/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="the-truth-is-in-there-improving-reasoning-in-language-models-with-layer-selective-rank-reduction">真相就在那里：通过层选择性降级改进语言模型的推理</h2><p>基于 Transformer 的大型语言模型 (LLM) 已成为机器学习的固定装置。相应地，大量资源被分配用于进一步推进这项技术的研究，通常会导致模型规模不断增大，并根据越来越多的数据进行训练。</p><p>在最近的一篇论文<a href="https://www.microsoft.com/en-us/research/publication/the-truth-is-in-there-improving-reasoning-in-language-models-with-layer-selective-rank-reduction/">《真相就在那里：通过层选择性降级改进语言模型中的推理》中</a>，微软的研究人员展示了一个令人惊讶的结果：通过选择性地删除其组成部分的高阶组件，可以显着提高 LLM 的性能权重矩阵。正如<a href="https://www.microsoft.com/en-us/research/quarterly-brief/jan-2024-brief/articles/improving-reasoning-in-language-models-with-laser-layer-selective-rank-reduction/">Microsoft 研究论坛闪电演讲</a>中所介绍的，这种简单的干预措施——层选择性降级 (LASER)——可以在训练完成后在模型上完成，并且不需要额外的参数或数据。在广泛的实验中，研究人员证明了这一发现在语言模型和数据集中的普遍性。他们提供深入的分析，深入了解激光何时有效及其运作机制。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-1 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/the-truth-is-in-there-improving-reasoning-in-language-models-with-layer-selective-rank-reduction/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-21d8108ee594aad478409a8aa618b2ee" id="new-research-1">新研究</h3><h2 class="wp-block-heading" id="cache-efficient-top-k-aggregation-over-high-cardinality-large-datasets">高基数大型数据集上的高速缓存高效 Top-k 聚合</h2><p>商业智能工具可以轻松分析大量数据。在这些工具中，top-k 聚合查询用于汇总和识别重要的数据组。通常通过计算所有组的精确聚合，然后选择具有前 k 个聚合值的组来处理这些查询。然而，这对于高基数大型数据集来说可能效率低下，其中中间结果可能不适合多核处理器的本地缓存，从而导致过多的数据移动。</p><p>微软的研究人员在他们最近的论文： <a href="https://www.microsoft.com/en-us/research/publication/cache-efficient-top-k-aggregation-over-high-cardinality-large-datasets/">高基数大型数据集上的缓存高效 Top-k 聚合中</a>，引入了一种新的缓存感知算法来解决这个问题。该算法可以有效地计算精确的前 k 个聚合，而无需完全处理所有组。大型数据集的聚合需要多次数据分区和重新分区，从而为减少 top-k 聚合查询的分区开销提供了重要的机会。该算法利用数据分布的偏度来选择一小组候选组进行早期聚合。这有助于通过高效的分区技术和粗粒度统计来消除许多非<s>候选</s>组分区，而无需计算精确的聚合。使用真实数据集和合成数据集进行的实证评估表明，与现有的缓存感知聚合方法相比，该算法在标准 k 值范围内，单调聚合函数的中值加速超过 3 倍，非单调函数的中值加速超过 1.4 倍（1 到 100）。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/cache-efficient-top-k-aggregation-over-high-cardinality-large-datasets/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-d0c45191bd84884375870a119b31f3d8" id="awards">奖项</h3><h2 class="wp-block-heading" id="six-microsoft-researchers-named-2023-acm-fellows">六名 Microsoft 研究人员被评为 2023 年 ACM 院士</h2><p>计算机协会 (ACM) 的年度研究员奖旨在表彰为计算科学和技术做出变革性贡献的人们。该全球组织在 2023 年的 68 名获奖者中提名了 6 名来自微软的研究人员。</p><p><a href="https://www.microsoft.com/en-us/research/people/jfgao/">高剑锋</a>– 副总裁兼杰出科学家<br><em>对网络搜索、自然语言处理和对话系统机器学习的贡献</em></p><p><a href="https://www.microsoft.com/en-us/research/people/sumitg/">Sumit Gulwani</a> – 合作伙伴研究经理<br><em>为开发人员、数据科学家、最终用户和学生的人工智能辅助编程做出贡献</em></p><p><a href="https://www.microsoft.com/en-us/research/people/nicimm/">Nicole Immorlica</a> – 高级首席研究员<br><em>对经济学和计算的贡献，包括市场设计、拍卖和社交网络</em></p><p><a href="https://www.microsoft.com/en-us/research/people/ssaroiu/">Stefan Saroiu</a> – 高级首席研究员<br><em>对内存安全和可信计算的贡献</em></p><p><a href="https://www.microsoft.com/en-us/research/people/manik/">Manik Varma</a> – 副总裁兼杰出科学家<br><em>对机器学习及其应用的贡献</em></p><p><a href="https://www.microsoft.com/en-us/research/people/xingx/">谢星</a>– 高级首席研究经理<br><em>对空间数据挖掘和推荐系统的贡献</em></p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.acm.org/media-center/2024/january/fellows-2023" target="_blank" rel="noreferrer noopener">2023 ACM 研究员</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-february-5-2024/">《研究焦点：2024 年 2 月 5 日一周》一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>