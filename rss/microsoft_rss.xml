<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 12 月 12 日，星期二 00:22:44 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.2</generator><item><title> Phi-2：小语言模型的惊人力量</title><link/>https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 12 Dec 2023 14:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=991293 </guid><description><![CDATA[<p>现在可以在 Azure 模型目录中访问 Phi-2。其紧凑的尺寸以及模型扩展和训练数据管理方面的新创新使其成为探索机械可解释性、安全性改进和各种任务的微调实验的理想选择。</p><p>后<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2：小语言模型的惊人力量</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<h3 class="wp-block-heading" id="contributors">贡献者</h3><p><a href="https://www.microsoft.com/en-us/research/people/maabdin/">玛拉·阿布丁</a>、<a href="https://www.microsoft.com/en-us/research/people/jyotianeja/">乔蒂·</a><a href="https://www.microsoft.com/en-us/research/people/sebubeck/">阿内贾、塞巴斯蒂安</a>·布贝克、卡约·塞萨尔·特奥多罗·门德斯、陈伟<a href="https://www.microsoft.com/en-us/research/people/wzchen/">柱</a>、<a href="https://www.microsoft.com/en-us/research/people/roneneldan/">艾莉·德尔·乔诺、罗南·埃尔丹</a>、 <a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a> 、 <a href="https://www.microsoft.com/en-us/research/people/suriyag/">Suriya Gunasekar</a> 、 <a href="https://www.microsoft.com/en-us/research/people/mojavaheripi/">Mojan Javaheripi</a> 、 <a href="https://www.microsoft.com/en-us/research/people/pkauffmann/">Piero Kauffmann</a> 、 <a href="https://www.microsoft.com/en-us/research/people/yintatlee/">Yin Tat Lee</a> 、李远志、 <a href="https://www.microsoft.com/en-us/research/people/anhnguyen/">Anh Nguyen</a> 、 <a href="https://www.microsoft.com/en-us/research/people/gderosa/">Gustavo de Rosa</a> 、 <a href="https://www.microsoft.com/en-us/research/people/olsaarik/">Olli Saarikivi</a> 、 <a href="https://www.microsoft.com/en-us/research/people/adilsalim/">Adil Salim</a> 、 <a href="https://www.microsoft.com/en-us/research/people/shitals/">Shital Shah</a> 、Michael Santacroce、Anh Harkirat Singh Behl、 <a href="https://www.microsoft.com/en-us/research/blog/tag/adam-kalai/">Adam Taumann Kalai</a> 、 <a href="https://www.microsoft.com/en-us/research/people/wanxin/">Xin Wang</a> 、 <a href="https://www.microsoft.com/en-us/research/people/rachelward/">Rachel Ward</a> 、 <a href="https://www.microsoft.com/en-us/research/people/pwitte/">Philipp Witte</a> 、 <a href="https://www.microsoft.com/en-us/research/people/cyrilzhang/">Cyril 张</a>、Yi 张</p><figure class="wp-block-image aligncenter size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg" alt="Satya Nadella 在 Microsoft Ignite 2023 的舞台上宣布 Phi-2。" class="wp-image-991311" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><strong>图 1.Satya</strong> Nadella 在 Microsoft Ignite 2023 上宣布 Phi-2。</figcaption></figure><p>在过去的几个月里，我们微软研究院的机器学习基础团队发布了一套名为“Phi”的小型语言模型 (SLM)，它们在各种基准测试中取得了卓越的性能。我们的第一个模型，13 亿个参数<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/microsoft/phi-1" target="_blank" rel="noreferrer noopener"><strong>Phi-1</strong> <span class="sr-only">（在新选项卡中打开）</span></a> ，在现有 SLM 中的 Python 编码方面实现了最先进的性能（特别是在 HumanEval 和 MBPP 基准测试上）。然后，我们将重点扩展到常识推理和语言理解，并创建了一个新的 13 亿参数模型，名为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noreferrer noopener"><strong>Phi-1.5</strong> <span class="sr-only">（在新选项卡中打开）</span></a> ，其性能可与 5 倍大的模型相媲美。</p><p>我们现在发布<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong> <span class="sr-only">（在新选项卡中打开）</span></a> ，这是一个 27 亿参数的语言模型，展示了出色的推理和语言理解能力，展示了参数少于 130 亿的基础语言模型中最先进的性能。在复杂的基准测试中，得益于模型扩展和训练数据管理方面的新创新，Phi-2 的性能可与大 25 倍的模型相匹配或优于。</p><p>凭借其紧凑的尺寸，Phi-2 成为研究人员的理想游乐场，包括探索机械可解释性、安全性改进或对各种任务的微调实验。我们已经制作了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong> <span class="sr-only">（在新选项卡中打开）</span></a><strong> </strong>可在 Azure 模型目录中找到，以促进语言模型的研究和开发。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="670821"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：微软研究通讯</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2019/09/Newsletter_Banner_08_2019_v1_1920x1080.png" alt="" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">微软研究院通讯</h2><p class="large">与 Microsoft 研究社区保持联系。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button is-style-fill-chevron"> <a href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank">立即订阅</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="key-insights-behind-phi-2">Phi-2 背后的关键见解</h2><p>语言模型的规模大幅增加到数千亿个参数，释放了许多新兴功能，重新定义了自然语言处理的格局。一个问题仍然是，是否可以使用训练策略选择（例如数据选择）在较小的规模上实现这种新兴能力。</p><p>我们对 Phi 模型的研究旨在通过训练 SLM 来回答这个问题，这些 SLM 的性能可与更大规模的模型相媲美（但距离前沿模型还很远）。我们对使用 Phi-2 打破传统语言模型缩放定律的主要见解有两个：</p><p>首先，训练数据质量对模型性能起着至关重要的作用。几十年来，人们已经知道这一点，但我们继我们之前的工作“<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">教科书就是你所需要的</a>”之后，通过关注“教科书质量”的数据，将这一见解发挥到了极致。我们的训练数据混合物包含专门创建的合成数据集，用于教授模型常识推理和常识，包括科学、日常活动和心理理论等。我们通过精心挑选的网络数据进一步扩充我们的训练语料库，这些数据根据教育价值和内容质量进行过滤。其次，我们使用创新技术进行扩展，从我们的 13 亿参数模型 Phi-1.5 开始，并将其知识嵌入到 27 亿参数 Phi-2 中。这种规模化的知识转移不仅加速了训练收敛，而且显着提高了 Phi-2 基准分数。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="25377" height="5876" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png" alt="条形图比较 Phi-2（具有 2.7B 参数）和 Phi-1.5（具有 1.3B 参数）在常识推理、语言理解、数学、编码和 Bigbench-hard 基准测试方面的性能。 Phi-2 在所有类别中均优于 Phi1.5。常识推理任务有 PIQA、WinoGrande、ARC easy 和challenge 以及 SIQA。语言理解任务有 HellaSwag、OpenBookQA、MMLU、SQuADv2 和 BoolQ。数学任务是 GSM8k，编码包括 HumanEval 和 MBPP 基准测试。" class="wp-image-991359" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png 25377w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-300x69.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1024x237.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-768x178.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1536x356.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-240x56.png 240w" sizes="(max-width: 25377px) 100vw, 25377px" /><figcaption class="wp-element-caption"><strong>图 2.</strong> Phi-2 (2.7B) 和 Phi-1.5 (1.3B) 模型之间的比较。除了 BBH 和 MMLU 分别使用 3-shot CoT 和 5-shot 之外，所有任务均以 0-shot 进行评估。</figcaption></figure><h2 class="wp-block-heading" id="training-details">培训详情</h2><p>Phi-2 是一个基于 Transformer 的模型，具有下一个单词预测目标，在用于 NLP 和编码的合成数据集和 Web 数据集的混合上多次传递的 1.4T 标记上进行训练。 Phi-2 的训练在 96 个 A100 GPU 上花费了 14 天。 Phi-2 是一个基础模型，没有通过人类反馈强化学习 (RLHF) 进行对齐，也没有进行指令微调。尽管如此，与经过调整的现有开源模型相比，我们观察到在毒性和偏差方面有更好的行为（见图 3）。由于我们定制的数据管理技术，这与我们在 Phi-1.5 中看到的情况一致，有关更多详细信息，请参阅我们<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need-ii-phi-1-5-technical-report/">之前的技术报告<span class="sr-only">（在新选项卡中打开）</span></a> 。有关 Phi-2 模型的更多信息，请访问<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener">Azure AI |机器学习工作室<span class="sr-only">（在新选项卡中打开）</span></a> 。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="16803" height="8165" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png" alt="条形图比较 Phi-1.5、Phi-2 和 Llama-7B 模型在 ToxiGen 基准的 13 个类别上的安全评分。 Phi-1.5 在所有类别中获得最高分，Phi-2 在所有类别中获得第二高分，Llama-7B 在所有类别中获得最低分。" class="wp-image-991365" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png 16803w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-300x146.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1024x498.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-768x373.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1536x746.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-2048x995.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-240x117.png 240w" sizes="(max-width: 16803px) 100vw, 16803px" /><figcaption class="wp-element-caption"><strong>图 3.</strong>根据 ToxiGen 的 13 个人口统计数据计算的安全评分。选择 6541 个句子的子集，并根据困惑度和句子毒性进行 0 到 1 之间的评分。较高的分数表明与良性句子相比，模型产生有毒句子的可能性较小。</figcaption></figure><h2 class="wp-block-heading" id="phi-2-evaluation"> Phi-2 评估</h2><p>下面，我们总结了 Phi-2 在学术基准上的表现与流行语言模型的比较。我们的基准测试涵盖多个类别，即 Big Bench Hard (BBH)（3 shot with CoT）、常识推理（PIQA、WinoGrande、ARC easy 和 Challenge、SIQA）、语言理解（HellaSwag、OpenBookQA、MMLU（5-shot）、 SQuADv2（2 个镜头）、BoolQ）、数学（GSM8k（8 个镜头））和编码（HumanEval、MBPP（3 个镜头））。</p><p> Phi-2 仅拥有 27 亿个参数，在各种聚合基准上的 7B 和 13B 参数上超越了 Mistral 和 Llama-2 模型的性能。值得注意的是，与大 25 倍的 Llama-2-70B 模型相比，它在多步推理任务（即编码和数学）上实现了更好的性能。此外，尽管尺寸较小，但 Phi-2 的性能可与最近发布的 Google Gemini Nano 2 相媲美或优于其。</p><p>当然，我们承认当前模型评估面临的挑战，并且许多公共基准可能会泄漏到训练数据中。对于我们的第一个模型 Phi-1，我们进行了广泛的净化研究以排除这种可能性，这可以在我们的第一份报告“<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">教科书就是你所需要的</a>”中找到。最终，我们相信判断语言模型的最佳方法是在具体用例上对其进行测试。遵循这种精神，我们还使用多个 Microsoft 内部专有数据集和任务评估了 Phi-2，并再次将其与 Mistral 和 Llama-2 进行比较。我们观察到类似的趋势，即平均而言，Phi-2 优于 Mistral-7B，后者优于 Llama-2 模型（7B、13B 和 70B）。</p><figure class="wp-block-table"><table><thead><tr><th>模型</th><th>尺寸</th><th>BBH</th><th>常识<br>推理</th><th>语言<br>理解</th><th>数学</th><th>编码</th></tr></thead><tbody><tr><td rowspan="3">羊驼-2</td><td> 7B</td><td> 40.0</td><td> 62.2</td><td> 56.7</td><td> 16.5</td><td> 21.0</td></tr><tr><td> 13B</td><td> 47.8</td><td> 65.0</td><td> 61.9</td><td> 34.2</td><td> 25.4</td></tr><tr><td> 70B</td><td> 66.5</td><td> 69.2</td><td> 67.6</td><td> 64.1</td><td> 38.3</td></tr><tr><td>米斯特拉尔</td><td>7B</td><td> 57.2</td><td> 66.4</td><td> 63.7</td><td> 46.4</td><td> 39.4</td></tr><tr><td> Φ2</td><td> 2.7B</td><td> 59.2</td><td> 68.8</td><td> 62.0</td><td> 61.1</td><td> 53.7</td></tr></tbody></table><figcaption class="wp-element-caption"><center><strong>表 1.</strong>与流行的开源 SLM 相比，分组基准的平均性能。</center></figcaption></figure><figure class="wp-block-table"><table><thead><tr><th>模型</th><th>尺寸</th><th>BBH</th><th>布尔Q</th><th> MBPP</th><th> MMLU</th></tr></thead><tbody><tr><td>双子座纳米2</td><td> 3.2B</td><td> 42.4</td><td> 79.3</td><td> 27.2</td><td> 55.8</td></tr><tr><td> Φ2</td><td> 2.7B</td><td> 59.3</td><td> 83.3</td><td> 59.1</td><td> 56.7</td></tr></tbody></table><figcaption class="wp-element-caption"><center><strong>表 2.</strong> Phi-2 和 Gemini Nano 2 模型在 Gemini 报告的基准上的比较。</center></figcaption></figure><p>除了这些基准之外，我们还对研究社区的常用提示进行了广泛的测试。我们观察到的行为与我们给出的基准结果的预期一致。例如，我们测试了一个用于探测模型解决物理问题的能力的提示，最近用于评估 Gemini Ultra 模型的能力，并取得了以下结果： </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1347" height="758" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png" alt="Phi-2 给出了一个示例提示，其中显示“滑雪者沿着高 40m、长 80m 的无摩擦斜坡滑下。滑雪者在底部的速度是多少？”。然后，Phi-2 通过解释势能到动能的转换并提供计算每一项的公式来回答提示。然后它继续使用能量公式计算正确的速度。" class="wp-image-991326" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png 1347w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1280x720.png 1280w" sizes="(max-width: 1347px) 100vw, 1347px" /><figcaption class="wp-element-caption"><strong>图 4.</strong> Phi-2 在一个简单物理问题上的输出，其中包括近似正确的平方根计算。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1600" height="710" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png" alt="然后向模型提供学生对滑雪物理问题的错误答案，并询问它是否可以纠正学生的错误。 Phi-2 回答了学生的错误，即使用了错误的势能公式，并提供了正确的公式。" class="wp-image-991332" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png 1600w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-300x133.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1024x454.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-768x341.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1536x682.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-240x107.png 240w" sizes="(max-width: 1600px) 100vw, 1600px" /><figcaption class="wp-element-caption"><strong>图 5.</strong>与 Gemini 的测试类似，我们还进一步向 Phi-2 询问学生的错误答案，看看 Phi-2 是否能够识别出错误所在（它确实如此，尽管 Phi-2 没有针对聊天或指令遵循进行微调） ）。然而，我们注意到，这并不完全是与 Gemini 报告中描述的 Gemini Ultra 输出的同类比较，特别是在后一种情况下，学生的答案是作为带有手写文本的图像给出的，而不是在我们的例子中为原始文本。</figcaption></figure><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>后<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2：小语言模型的惊人力量</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> NeurIPS 2023 凸显了微软机器学习创新的广度</title><link/>https://www.microsoft.com/en-us/research/blog/neurips-2023-highlights-breadth-of-microsofts-machine-learning-innovation/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Mon, 11 Dec 2023 15:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=989523 </guid><description><![CDATA[<p>我们很自豪能在 NeurIPS 2023 上收到 100 多篇论文，并举办 18 场研讨会。一些提交的作品被选为口头报告和重点海报，反映了突破性的概念、方法或应用。以下是这些提交内容的概述。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/neurips-2023-highlights-breadth-of-microsofts-machine-learning-innovation/">NeurIPS 2023 强调了微软机器学习创新的广度，该文章</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1.png" alt="研究重点：NeurIPS 2023 年 12 月 11 日" class="wp-image-990225" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/RFNeurIPS-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p> Microsoft 很荣幸能够赞助<a href="https://www.microsoft.com/en-us/research/event/neurips-2023/" target="_blank" rel="noreferrer noopener">第 37 届神经信息处理系统会议</a>(NeurIPS 2023)。这个跨学科论坛汇集了机器学习、神经科学、统计学、优化、计算机视觉、自然语言处理、生命科学、自然科学、社会科学和其他相邻领域的专家。我们很高兴地告诉大家，Microsoft 已接受 100 多篇论文，并在 NeurIPS 2023 上举办了 18 个研讨会。</p><p>今年的会议包括来自 Microsoft 的三篇论文，这些论文被选为口头演讲，其特点是突破性的概念、方法或应用程序，解决了该领域的紧迫问题。此外，我们的重点海报（也在下面突出显示）是由会议组织者精心策划的，展示了新颖性、技术严谨性以及对机器学习领域产生重大影响的潜力。这篇博文庆祝了这些成就。</p><h2 class="wp-block-heading" id="oral-presentations">口头报告</h2><h3 class="wp-block-heading" id="bridging-discrete-and-backpropagation-straight-through-and-beyond"><a href="https://www.microsoft.com/en-us/research/publication/bridging-discrete-and-backpropagation-straight-through-and-beyond/" target="_blank" rel="noreferrer noopener">连接离散和反向传播：直通和超越</a></h3><p>梯度计算对于深度学习的成功至关重要，但它们主要依赖于反向传播，这是一种仅限于连续变量的技术。论文<a href="https://www.microsoft.com/en-us/research/publication/bridging-discrete-and-backpropagation-straight-through-and-beyond/" target="_blank" rel="noreferrer noopener">《桥接离散和反向传播：直通及超越》</a>解决了这一限制。它引入了 ReinMax，扩展了反向传播的能力来估计包含离散变量采样的模型的梯度。在本研究的大量实验中，ReinMax 表现出了比现有技术一致且显着的性能提升。该论文不仅仅是一个实用的解决方案，还阐明了现有的深度学习实践。它阐明了“直通”方法曾经被认为仅仅是一种启发式技巧，实际上是一般多项式情况的可行的一阶近似。相应地，ReinMax 在这种情况下实现了二阶精度，而没有二阶导数的复杂性，因此计算开销可以忽略不计。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="874872"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播活动</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/event/microsoft-research-summit-2022/?OCID=msr-researchsummit_Blog_PromoMod" aria-label="Microsoft Research Summit 2022" data-bi-cN="Microsoft Research Summit 2022" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2022/09/WebsiteHero_1400x788_B.jpg" alt="具有向上移动的蓝色、紫色和橙色瓷砖的抽象图像" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> 2022 年微软研究院峰会</h2><p class="large"><strong>一经请求</strong><br>立即观看，了解我们研究界面临的一些最紧迫的问题，并聆听与 120 多名研究人员围绕如何确保新技术为人类带来最广泛利益的对话。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/event/microsoft-research-summit-2022/?OCID=msr-researchsummit_Blog_PromoMod" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Read more" data-bi-cN="Microsoft Research Summit 2022" target="_blank">探索会议</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading" id="the-minerl-basalt-competition-on-learning-from-human-feedback"> <a href="https://www.microsoft.com/en-us/research/publication/the-minerl-basalt-competition-on-learning-from-human-feedback/" target="_blank" rel="noreferrer noopener">MineRL BASALT 竞赛：从人类反馈中学习</a></h3><p>深度学习研究的发展，包括将其融入商业产品，带来了一个新的挑战：在缺乏清晰、明确定义的规范的情况下，我们如何构建能够解决任务的人工智能系统？为了鼓励对这一类重要技术的研究，微软的研究人员领导了<a href="https://www.microsoft.com/en-us/research/publication/the-minerl-basalt-competition-on-learning-from-human-feedback/" target="_blank" rel="noreferrer noopener">MineRL BASALT 人类反馈学习竞赛<span class="sr-only">（在新选项卡中打开）</span></a> ，这是该大学研究人员<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://proceedings.mlr.press/v176/shah22a/shah22a.pdf" target="_blank" rel="noreferrer noopener">于 2021 年首次发起的竞赛<span class="sr-only">（在新选项卡中打开）</span></a>的更新加州大学伯克利分校和其他地方。本次比赛的挑战是仅根据英语语言描述完成模糊任务，重点是鼓励从人类反馈中学习的不同方式作为传统奖励信号的替代方案。</p><p>研究人员在《我的世界》中设计了一套包含四个任务的套件，为这些任务编写硬编码的奖励函数会很困难。这些任务由自然语言定义：例如，“创建一个瀑布并为其拍摄一张风景照片”，并附有额外的澄清细节。参与者必须为每项任务训练一个单独的代理。然后，由阅读了任务描述的人员对代理进行评估。</p><p>该竞赛旨在鼓励人工智能系统的开发，即使其意图无法轻易形式化，也能实现设计者的意图。除了让人工智能能够解决更多任务之外，这还可以更有效地监管人工智能系统，并在价值调整问题上取得进展，在这些问题中，人工智能代理的具体目标与其用户的目标不同。</p><h4 class="wp-block-heading" id="related">有关的</h4><div class="annotations " data-bi-aN="citation"><ul class="annotations__list card depth-16 bg-body p-4 "><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">出版物《</span> <a href="https://www.microsoft.com/en-us/research/publication/towards-solving-fuzzy-tasks-with-human-feedback-a-retrospective-of-the-minerl-basalt-2022-competition/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Towards Solving Fuzzy Tasks with Human Feedback: A Retrospective of the MineRL BASALT 2022 Competition" data-bi-aN="citation" data-bi-cN="Towards Solving Fuzzy Tasks with Human Feedback: A Retrospective of the MineRL BASALT 2022 Competition">利用人类反馈解决模糊任务：MineRL BASALT 2022 竞赛回顾》<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span></a> </li></ul></div><div style="height:15px" aria-hidden="true" class="wp-block-spacer"></div><h3 class="wp-block-heading" id="decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models"> <a href="https://www.microsoft.com/en-us/research/publication/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/">DecodingTrust：GPT 模型可信度的综合评估</a></h3><p>这个综合评估平台旨在回答以下问题：生成式预训练 Transformer (GPT) 模型的可信度如何？在<a href="https://www.microsoft.com/en-us/research/publication/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/" target="_blank" rel="noreferrer noopener">DecodingTrust：GPT 模型可信度的综合评估中</a>，研究人员特别关注 GPT-4、GPT-3.5 和一系列开放式法学硕士。他们考虑了不同的观点，包括<em>毒性、刻板印象偏见、对抗鲁棒性、分布外鲁棒性、对抗性演示的鲁棒性、隐私、机器道德和公平性。</em></p><p>研究人员的评估发现了之前未发布的与可信度相关的漏洞。该团队与 Microsoft 产品组合作，确认所发现的潜在漏洞不会影响当前面向客户的服务。这在一定程度上是正确的，因为成品人工智能应用程序应用了一系列缓解方法来解决技术模型级别可能发生的潜在危害。他们还与 GPT 的开发商 OpenAI 分享了他们的发现，后者注意到了相关模型的系统卡中的潜在漏洞。</p><p>这项研究旨在鼓励研究界的其他人利用这项工作并以此为基础，从而可能先发制人，利用漏洞造成伤害。为了促进协作，基准测试代码非常可扩展且易于使用：单个命令足以在新模型上运行完整的评估。</p><h2 class="wp-block-heading" id="spotlight-posters">聚光灯海报</h2><h3 class="wp-block-heading" id="differentially-private-approximate-near-neighbor-counting-in-high-dimensions"> <a href="https://www.microsoft.com/en-us/research/publication/differentially-private-approximate-near-neighbor-counting-in-high-dimensions/" target="_blank" rel="noreferrer noopener">高维差分隐私近似近邻计数</a></h3><p>差分隐私（DP）是一种广泛使用的工具，用于保护敏感个人信息的隐私。它允许数据结构为其所保存的数据的查询提供近似答案，同时确保删除或添加单个数据库条目不会显着影响任何分析的结果。</p><p>差分隐私下的范围计数（计算落入给定查询球的数据点的数量）已被广泛研究。然而，当前解决该问题的算法面临着挑战。一类算法会遭受加性误差，该误差是点数的固定多项式。另一类算法允许多对数加性误差，但误差在维度上呈指数增长。为了实现后者，问题被放宽以允许范围边界的“模糊”定义，例如，对于某些 c >; 1，半径为 r 的球中的点的计数也可能包括半径为 cr 的球中的点。</p><p>在<a href="https://www.microsoft.com/en-us/research/publication/differentially-private-approximate-near-neighbor-counting-in-high-dimensions/" target="_blank" rel="noreferrer noopener">《高维差分隐私近似近邻计数》</a>中，研究人员提出了一种有效的算法，可以在这两个类别之间提供最佳平衡点。该算法具有一个加性误差，该误差是数据集大小的任意小幂，具体取决于范围边界的模糊程度，以及一个小的 (1 + o(1)) 乘性误差。至关重要的是，添加的噪声量与尺寸无关。这种新算法引入了局部敏感哈希的变体，以一种新颖的方式利用它。</p><h3 class="wp-block-heading" id="exposing-attention-glitches-with-flip-flop-language-modeling"> <a href="https://www.microsoft.com/en-us/research/publication/exposing-attention-glitches-with-flip-flop-language-modeling/" target="_blank" rel="noreferrer noopener">通过触发器语言模型揭示注意力缺陷</a></h3><p>为什么大型语言模型有时会输出不准确的事实并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，似乎是为其连贯地综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。</p><p>为了帮助理解这个根本上未解决的问题， <a href="https://www.microsoft.com/en-us/research/publication/exposing-attention-glitches-with-flip-flop-language-modeling/" target="_blank" rel="noreferrer noopener">使用触发器语言模型暴露注意力故障</a>识别并分析了注意力故障现象，其中 Transformer 架构的归纳偏差间歇性地无法捕获稳健的推理。为了解决这个问题，研究人员引入了触发器语言模型（FFLM），这是一个参数化的综合基准系列，旨在探测神经语言模型的外推行为。这个简单的生成任务需要一个模型来复制远程依赖关系上的二进制符号，忽略之间的标记。这项研究展示了 Transformer FFLM 如何遭受长尾的零星推理错误，其中一些错误可以使用各种正则化技术来消除。初步的机制分析表明为什么剩余的错误可能很难诊断和解决。研究人员推测，注意力缺陷是自然法学硕士中发生的一些闭域错误的原因。</p><h3 class="wp-block-heading" id="in-context-learning-unlocked-for-diffusion-models"> <a href="https://www.microsoft.com/en-us/research/publication/in-context-learning-unlocked-for-diffusion-models/" target="_blank" rel="noreferrer noopener">为扩散模型解锁情境学习</a></h3><p>大型语言模型（LLM）的一个新兴行为是从上下文中学习或<em>上下文中学习的能力。</em>通过正确设计的提示结构和情境学习，法学硕士可以结合多种语言任务的预训练，并很好地推广到以前未见过的任务。虽然上下文学习在自然语言处理（NLP）领域得到了广泛的研究，但其在计算机视觉领域的应用仍然有限。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/in-context-learning-unlocked-for-diffusion-models/" target="_blank" rel="noreferrer noopener">为扩散模型解锁的上下文学习</a>提出了 Prompt Diffusion，这是一个在基于扩散的生成模型中实现上下文学习的框架。给定一对特定于任务的示例图像和文本指导，该模型可以理解底层任务，并按照文本指导对新的查询图像执行相同的任务。为了实现这一目标，研究人员提出了一种可以模拟各种视觉语言任务的视觉语言提示，以及一种将其作为输入的扩散模型。使用这些提示对六个不同任务联合训练扩散模型。由此产生的即时扩散模型是第一个能够进行上下文学习的基于扩散的视觉语言基础模型。它展示了在训练任务上的高质量上下文生成，并推广到新的、未见过的视觉任务及其各自的提示。该模型还显示了引人注目的文本引导图像编辑结果。</p><h3 class="wp-block-heading" id="optimizing-prompts-for-text-to-image-generation"> <a href="https://www.microsoft.com/en-us/research/publication/optimizing-prompts-for-text-to-image-generation/" target="_blank" rel="noreferrer noopener">优化文本到图像生成的提示</a></h3><p>可以提示生成基础模型遵循用户指令，包括语言模型和文本到图像模型。精心设计的提示可以指导文本到图像模型生成令人惊叹的图像。然而，性能提示通常是特定于模型的并且与用户输入不一致。 <a href="https://www.microsoft.com/en-us/research/publication/optimizing-prompts-for-text-to-image-generation/" target="_blank" rel="noreferrer noopener">优化文本到图像生成的提示</a>提出了提示适应，而不是费力的人类工程，这是一个通用框架，可以自动使原始用户输入适应模型首选的提示。</p><p>研究人员使用强化学习来探索更好的语言模型提示。他们定义了一个奖励函数，鼓励策略网络（即语言模型）生成更美观的图像，同时保留原始的用户意图。 Stable Diffusion 的实验结果表明，该方法在自动指标和人类偏好评级方面均优于手动提示工程。强化学习进一步提高了性能，尤其是在域外提示下。 </p><h3 class="wp-block-heading" id="pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck"> <a href="https://www.microsoft.com/en-us/research/publication/pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck/" target="_blank" rel="noreferrer noopener">神经特征学习中的帕累托前沿：数据、计算、宽度和运气</a></h3><p>深度学习中的算法设计看起来更像是“黑客攻击”，而不是工程实践。有许多架构选择和训练启发式方法，它们通常可以以不可预测和复杂的方式调节模型性能和资源成本。因此，在训练大规模神经网络（例如最先进的语言模型）时，算法决策和资源分配首先是经验驱动的，涉及<em>缩放定律</em>的测量和外推。对这一过程的精确数学理解是难以捉摸的，并且不能通过孤立的统计或优化来解释。</p><p>在<a href="https://www.microsoft.com/en-us/research/publication/pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck/" target="_blank" rel="noreferrer noopener">《神经特征学习的帕累托前沿：数据、计算、宽度和运气》一书中，</a>来自微软、哈佛大学和宾夕法尼亚大学的研究人员通过单个合成任务的视角探索了这些算法的复杂性和权衡：有限样本稀疏奇偶校验学习问题。在这种情况下，上述复杂性不仅是显而易见的，而且是可证明的：直观上，由于任务的计算难度，神经网络需要足够的资源<em>组合</em>（“数据×模型大小×训练时间×运气”）才能成功。这项研究表明，深度学习中的标准算法选择会产生<em>帕累托前沿</em>，其中成功的学习是通过这些资源的可互换组合“购买”的。他们表明，对这个玩具问题的算法改进可以转移到现实世界，从而提高神经网络在小型表格数据集上的数据效率。 </p><h3 class="wp-block-heading" id="pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers"> <a href="https://www.microsoft.com/en-us/research/publication/pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers/" target="_blank" rel="noreferrer noopener">PDE-Refiner：使用神经 PDE 求解器实现精确的长推出</a></h3><p>瞬态偏微分方程 (PDE) 在科学和工程中无处不在。传统求解技术的高计算成本激发了人们对基于深度神经网络的偏微分方程代理的兴趣。这种神经偏微分方程求解器的实用性取决于它们在长时间范围内提供准确、稳定的预测的能力，这是一个众所周知的难题。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers/" target="_blank" rel="noreferrer noopener">PDE-Refiner：使用神经 PDE 求解器实现准确的长时间推出</a>，对常见的时间推出策略进行了大规模分析，确定了对非主导空间频率信息（通常与 PDE 解决方案中的高频相关）的忽视，这是限制稳定的主要缺陷，准确的推出性能。受扩散模型最新进展的推动，研究人员开发了 PDE-Refiner，这是一种新颖的模型类，可以通过多步细化过程对所有频率分量进行更准确的建模。他们在复杂流体动力学的挑战性基准上验证了 PDE-Refiner，展示了稳定且准确的推出，始终优于最先进的模型，包括神经、数值和混合神经数值架构。他们还证明，PDE-Refiner 极大地提高了数据效率，因为去噪目标隐式地引入了一种新形式的光谱数据增强。最后，PDE-Refiner 与扩散模型的连接能够准确有效地评估模型的预测不确定性，使研究人员能够估计替代变量何时变得不准确。 </p><h3 class="wp-block-heading" id="should-i-stop-or-should-i-go-early-stopping-with-heterogeneous-populations"> <a href="https://www.microsoft.com/en-us/research/publication/should-i-stop-or-should-i-go-early-stopping-with-heterogeneous-populations/" target="_blank" rel="noreferrer noopener">我应该停止还是应该离开：异质人群的早期停止</a></h3><p>随机实验是确定因果效应的黄金标准方法，无论是在评估医学治疗的临床试验中还是在评估在线产品的 A/B 测试中。但是，当治疗或测试引起意外的有害影响时，随机实验通常需要提前停止。确定何时提前停止实验的现有方法通常应用于汇总数据，并且不考虑治疗效果异质性。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/should-i-stop-or-should-i-go-early-stopping-with-heterogeneous-populations/" target="_blank" rel="noreferrer noopener">我应该停止还是应该离开：异质群体的早期停止</a>研究了早期停止实验对异质群体的伤害。该论文表明，当治疗伤害少数参与者时，当前的方法通常无法阻止实验。研究人员使用因果机器学习开发了异构停止因果潜在分析（CLASH），这是第一个广泛适用的异构早期停止方法。他们展示了 CLASH 在模拟和真实数据上的性能，并表明它可以为临床试验和 A/B 测试提供有效的早期停止。</p><h3 class="wp-block-heading" id="survival-instinct-in-offline-reinforcement-learning"> <a href="https://www.microsoft.com/en-us/research/publication/survival-instinct-in-offline-reinforcement-learning-2/" target="_blank" rel="noreferrer noopener">离线强化学习中的生存本能</a></h3><p>在离线强化学习（RL）中，代理在给定离线数据集的情况下优化其性能。 <a href="https://www.microsoft.com/en-us/research/publication/survival-instinct-in-offline-reinforcement-learning-2/" target="_blank" rel="noreferrer noopener">离线强化学习中的生存本能</a>提出了一个新颖的观察结果：在许多基准数据集上，离线强化学习可以产生性能良好且安全的策略，即使使用“错误”的奖励标签进行训练，例如那些处处为零或真实奖励为负数的标签。这种现象无法简单地用离线强化学习的回报最大化目标来解释。此外，它还为离线强化学习提供了一定程度的鲁棒性，这与在线强化学习相对应的特征不同，众所周知，在线强化学习对奖励设计很敏感。</p><p>这项研究表明，这种令人惊讶的鲁棒性属性可归因于离线强化学习算法中的悲观主义概念与常见数据收集实践中隐含的某种偏见之间的相互作用。这项工作表明，这种悲观主义赋予了智能体一种“生存本能”，即长期留在数据支持范围内的激励，而有限且有偏见的数据覆盖范围进一步限制了生存策略的设定。研究人员认为，在解释现有离线 RL 基准的结果以及创建未来的基准时，应考虑生存本能。 </p><h3 class="wp-block-heading" id="timewarp-transferable-acceleration-of-molecular-dynamics-by-learning-time-coarsened-dynamics"> <a href="https://www.microsoft.com/en-us/research/publication/timewarp-transferable-acceleration-of-molecular-dynamics-by-learning-time-coarsened-dynamics/" target="_blank" rel="noreferrer noopener">时间扭曲：通过学习时间粗化动力学实现分子动力学的可转移加速</a></h3><p>分子动力学 (MD) 是一种成熟的原子级物理系统模拟技术。当准确执行时，它可以提供对分子运动详细力学的无与伦比的洞察力，而无需进行湿实验室实验。 MD 通常用于计算平衡属性，这需要从平衡分布中采样，例如<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://en.wikipedia.org/wiki/Boltzmann_distribution" target="_blank" rel="noreferrer noopener">玻尔兹曼分布<span class="sr-only">（在新选项卡中打开）</span></a> 。然而，许多重要的过程，例如结合和折叠，发生的时间尺度为毫秒或更长，并且无法使用传统 MD 进行有效采样。此外，需要对每个研究的分子系统从头开始进行新的分子动力学模拟。</p><p> <a href="https://www.microsoft.com/en-us/research/publication/timewarp-transferable-acceleration-of-molecular-dynamics-by-learning-time-coarsened-dynamics/" target="_blank" rel="noreferrer noopener">时间扭曲：通过学习时间粗化动力学实现分子动力学的可转移加速</a>提出了一种增强采样方法，该方法使用归一化流作为针对玻尔兹曼分布的马尔可夫链蒙特卡罗方法中的建议分布。该流程在 MD 轨迹上进行离线训练，并学习及时迈出大步，模拟 10^5−10^6fs 的分子动力学。至关重要的是，Timewarp 可以在分子系统之间转移：研究人员表明，经过训练，Timewarp 可以推广到看不见的小肽（2-4 个氨基酸），探索它们的亚稳态，并在采样时与标准 MD 相比提供挂钟加速。这种新方法是开发通用的、可转移的加速 MD 算法的重要一步。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/neurips-2023-highlights-breadth-of-microsofts-machine-learning-innovation/">NeurIPS 2023 强调了微软机器学习创新的广度，该文章</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>