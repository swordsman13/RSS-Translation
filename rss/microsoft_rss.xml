<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 12 月 16 日星期六 00:20:52 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.2</generator><item><title>前沿指导：扩大提示的力量</title><link/>https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 12 Dec 2023 14:40:31 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=991758 </guid><description><![CDATA[<p>我们看到前沿基础模型令人兴奋的功能，包括跨众多知识和专业领域的抽象、泛化和组合的有趣能力。即使是经验丰富的人工智能研究人员也对通过简单的零样本提示来引导模型的能力印象深刻。除了基本的、开箱即用的提示之外，我们一直在探索新的提示策略，并在我们的 Medprompt 工作中展示，以 [...]</p><p> <a href="https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/">前沿引导：扩展提示的力量一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1.jpg" alt="蓝色、紫色和粉色渐变背景上的三个对话气泡" class="wp-image-991947" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Steeering-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>我们看到前沿基础模型令人兴奋的功能，包括跨众多知识和专业领域的抽象、泛化和组合的有趣能力。即使是经验丰富的人工智能研究人员也对通过简单的零样本提示来引导模型的能力印象深刻。除了基本的、开箱即用的提示之外，我们一直在探索新的提示策略（在我们的<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">Medprompt</a>工作中展示），以激发专家的力量。</p><p>今天，我们在<em><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/promptbase" target="_blank" rel="noreferrer noopener">Promptbase <span class="sr-only">（在新选项卡中打开）（</span></a></em> GitHub 上的资源集合）中分享有关 Medprompt 和其他引导前沿模型的方法的信息。我们的目标是为工程师和客户提供信息和工具，以激发基础模型的最佳性能。我们将首先包含一些脚本，这些脚本可以使用我们在此介绍的提示策略来复制我们的结果。我们将在未来几周内添加更复杂的通用工具和信息。</p><p>为了说明前沿模型的功能以及通过指导 GPT-4 来利用和扩展最近的努力以达到最先进 (SoTA) 结果的机会，我们将根据 Google 选择的基准审查 SoTA 结果用于评估 Gemini Ultra。我们的端到端探索、快速设计和性能计算只花了几天时间。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956160"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/" aria-label="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" data-bi-cN="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/collaboratorsEP2_hero_1400x788.jpg" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Bichlien Nguyen 和 David Kwabi 的可再生能源存储</h2><p class="large">Bichlien Nguyen 博士和 David Kwabi 博士探索了他们在液流电池方面的工作，以及机器学习如何帮助更有效地搜索广阔的有机化学空间，以识别具有适合储存水力和其他可再生能源的特性的化合物。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>让我们重点关注著名的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2009.03300" target="_blank" rel="noreferrer noopener">MMLU <span class="sr-only">（在新选项卡中打开）</span></a> （测量大规模多任务语言理解）挑战，该挑战是为了测试大型语言模型的常识和推理能力而设立的。完整的 MMLU 基准包含数以万计的不同形式的挑战问题，涉及从基础数学到美国历史、法律、计算机科学、工程、医学等 57 个领域。</p><p>在我们的<a href="https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/">Medprompt 研究</a>中，我们专注于医疗挑战问题，但发现即时策略可以具有更通用的应用，并在几个域外基准上检查其性能——尽管其工作根源在于医疗挑战。今天，我们报告使用 Medprompt 的修改版本引导 GPT-4 取得<em>了完整 MMLU 上有史以来的最高分。</em> </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1215" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt.jpg" alt="该图显示了 MMLU 基准上基线多个模型和方法的报告性能。从左到右，Palm 2-L（5 次）实现了 78.4% 的准确率，Claude 2（5 次 CoT）实现了 78.5% 的准确度，Inflection-2（5 次）实现了 79.6% 的准确度，Google Pro（CoT） @8) 实现了 79.13% 的准确度，Gemini Ultra (CoT@32) 实现了 90.04% 的准确度，GPT-4-1106 (5-Shot) 实现了 86.4% 的准确度，GPT-4-1106 (Medprompt @ 5) 实现了 89.1% 的准确度， GPT-4-1106 (Medprompt @ 20) 的准确率达到 89.56%，GPT-4-1106 (Medprompt @ 31) 的准确率达到 90.10%。" class="wp-image-991926" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt.jpg 1215w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-300x142.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-1024x485.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-768x364.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/gemini_medprompt-240x114.jpg 240w" sizes="(max-width: 1215px) 100vw, 1215px" /><figcaption class="wp-element-caption">图1。报告了多种模型和方法在 MMLU 基准上的性能。</figcaption></figure><p>在我们的探索中，我们初步发现将原始的 Medprompt 应用到 GPT-4 在综合 MMLU 上取得了 89.1% 的分数。通过将 Medprompt 中的集成调用数量从 5 个增加到 20 个，GPT-4 在 MMLU 上的性能进一步提高到 89.56%。为了在 MMLU 上实现新的 SoTA，我们将 Medprompt 扩展为 Medprompt+，添加了更简单的提示方法，并制定了一个策略，通过集成基本 Medprompt 策略和简单提示的输出来得出最终答案。最终答案的合成由 GPT-4 控制的控制策略和候选答案的推断置信度指导。 Promptbase 存储库中提供了有关 Medprompt+ 的更多详细信息。 Google Gemini 团队利用了一种耦合复杂和简单查询的相关方法。使用修改后的 Medprompt+ 引导的 GPT-4 达到了 90.10% 的创纪录分数。我们注意到 Medprompt+ 依赖于从 GPT-4 获取置信度分数 (logprobs)。这些功能尚未通过当前 API 公开提供，但将在不久的将来向所有人开放。</p><p>虽然系统的提示工程可以产生最大的性能，但我们继续探索具有简单提示的前沿模型的开箱即用性能。重要的是要密切关注 GPT-4 的原生功能以及我们如何通过零或几次提示策略来引导模型。如表 1 所示，从简单的提示开始有助于在采用更复杂和更昂贵的方法之前建立基准性能。</p><figure class="wp-block-table"><table><thead><tr><th>基准</th><th>GPT-4 提示</th><th>GPT-4 结果</th><th>双子座超结果</th></tr></thead><tbody><tr><td>MMLU</td><td>医疗提示+</td><td> <strong>90.10%</strong></td><td> 90.04%</td></tr><tr><td> GSM8K</td><td>零射击</td><td><strong>95.27%</strong></td><td> 94.4%</td></tr><tr><td>数学</td><td>零射击</td><td><strong>68.42%</strong></td><td> 53.2%</td></tr><tr><td>人类评估</td><td>零射击</td><td><strong>87.8</strong> %</td><td> 74.4%</td></tr><tr><td>大板凳硬</td><td>少量射击 + CoT*</td><td> <strong>89.0%</strong></td><td> 83.6%</td></tr><tr><td>降低</td><td>零射击+CoT</td><td> <strong>83.7%</strong></td><td> 82.4%</td></tr><tr><td>海拉斯瓦格</td><td>10 发**</td><td> <strong>95.3%**</strong></td><td> 87.8%</td></tr></tbody></table><figcaption class="wp-element-caption"><center> <sup>* 遵循评估规范并使用数据集创建者提供的标准少数样本示例<br>** 来源：谷歌</sup><br>表 1：模型、策略和结果</center></figcaption></figure><p>我们鼓励您查看 GitHub 上的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/promptbase" target="_blank" rel="noreferrer noopener">promptbase 存储库<span class="sr-only">（在新选项卡中打开），</span></a>了解有关提示技术和工具的更多详细信息。这一工作领域正在不断发展，有很多值得学习和分享的地方。我们对未来的方向和可能性感到兴奋。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/">前沿引导：扩展提示的力量一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> Phi-2：小语言模型的惊人力量</title><link/>https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 12 Dec 2023 14:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=991293 </guid><description><![CDATA[<p>现在可以在 Azure 模型目录中访问 Phi-2。其紧凑的尺寸以及模型扩展和训练数据管理方面的新创新使其成为探索机械可解释性、安全性改进和各种任务的微调实验的理想选择。</p><p>后<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2：小语言模型的惊人力量</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<h3 class="wp-block-heading" id="contributors">贡献者</h3><p><a href="https://www.microsoft.com/en-us/research/people/maabdin/">玛拉·阿布丁</a>、<a href="https://www.microsoft.com/en-us/research/people/jyotianeja/">乔蒂·</a><a href="https://www.microsoft.com/en-us/research/people/sebubeck/">阿内贾、塞巴斯蒂安</a>·布贝克、卡约·塞萨尔·特奥多罗·门德斯、陈伟<a href="https://www.microsoft.com/en-us/research/people/wzchen/">柱</a>、<a href="https://www.microsoft.com/en-us/research/people/roneneldan/">艾莉·德尔·乔诺、罗南·埃尔丹</a>、 <a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a> 、 <a href="https://www.microsoft.com/en-us/research/people/suriyag/">Suriya Gunasekar</a> 、 <a href="https://www.microsoft.com/en-us/research/people/mojavaheripi/">Mojan Javaheripi</a> 、 <a href="https://www.microsoft.com/en-us/research/people/pkauffmann/">Piero Kauffmann</a> 、 <a href="https://www.microsoft.com/en-us/research/people/yintatlee/">Yin Tat Lee</a> 、李远志、 <a href="https://www.microsoft.com/en-us/research/people/anhnguyen/">Anh Nguyen</a> 、 <a href="https://www.microsoft.com/en-us/research/people/gderosa/">Gustavo de Rosa</a> 、 <a href="https://www.microsoft.com/en-us/research/people/olsaarik/">Olli Saarikivi</a> 、 <a href="https://www.microsoft.com/en-us/research/people/adilsalim/">Adil Salim</a> 、 <a href="https://www.microsoft.com/en-us/research/people/shitals/">Shital Shah</a> 、Michael Santacroce、Harkirat Singh Behl、 <a href="https://www.microsoft.com/en-us/research/blog/tag/adam-kalai/">Adam Taumann Kalai</a> 、 <a href="https://www.microsoft.com/en-us/research/people/wanxin/">Xin Wang</a> 、 <a href="https://www.microsoft.com/en-us/research/people/rachelward/">Rachel Ward</a> 、 <a href="https://www.microsoft.com/en-us/research/people/pwitte/">Philipp Witte</a> 、 <a href="https://www.microsoft.com/en-us/research/people/cyrilzhang/">Cyril 张</a>、Yi 张</p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg" alt="Satya Nadella 在 Microsoft Ignite 2023 的舞台上宣布 Phi-2。" class="wp-image-991311" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption"><strong>图 1.Satya</strong> Nadella 在 Microsoft Ignite 2023 上宣布 Phi-2。</figcaption></figure><p>在过去的几个月里，我们微软研究院的机器学习基础团队发布了一套名为“Phi”的小型语言模型 (SLM)，它们在各种基准测试中取得了卓越的性能。我们的第一个模型，13 亿个参数<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/microsoft/phi-1" target="_blank" rel="noreferrer noopener"><strong>Phi-1</strong> <span class="sr-only">（在新选项卡中打开）</span></a> ，在现有 SLM 中的 Python 编码方面实现了最先进的性能（特别是在 HumanEval 和 MBPP 基准测试上）。然后，我们将重点扩展到常识推理和语言理解，并创建了一个新的 13 亿参数模型，名为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noreferrer noopener"><strong>Phi-1.5</strong> <span class="sr-only">（在新选项卡中打开）</span></a> ，其性能可与 5 倍大的模型相媲美。</p><p>我们现在发布<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ai.azure.com/explore/models/microsoft-phi-2/version/4/registry/azureml-msr" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong> <span class="sr-only">（在新选项卡中打开）</span></a> ，这是一个 27 亿参数的语言模型，展示了出色的推理和语言理解能力，展示了参数少于 130 亿的基础语言模型中最先进的性能。在复杂的基准测试中，得益于模型扩展和训练数据管理方面的新创新，Phi-2 的性能可与大 25 倍的模型相匹配或优于。</p><p>凭借其紧凑的尺寸，Phi-2 成为研究人员的理想游乐场，包括探索机械可解释性、安全性改进或对各种任务的微调实验。我们已经制作了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ai.azure.com/explore/models/microsoft-phi-2/version/4/registry/azureml-msr" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong> <span class="sr-only">（在新选项卡中打开）</span></a><strong> </strong>可在 Azure AI Studio 模型目录中找到，以促进语言模型的研究和开发。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="980709"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-madeleine-daepp-with-jennifer-scurrell-and-alejandro-cuevas/" aria-label="Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas" data-bi-cN="Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Madeline_Insights_Hero_Feature_No_Text_1400x788-651ecfa4ebcf8.png" alt="MSR：播客实习生见解" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">实习生见解：Madeleine Daepp 博士、Jennifer Scurrell 和 Alejandro Cuevas</h2><p class="large">在本集中，博士生<a href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcss.ethz.ch%2Fen%2Fcenter%2Fpeople%2Fjennifer-victoria-scurrell.html&data=05%7C01%7Cv-amelfi%40microsoft.com%7Cdeb2b53d3b8d4c3a3ccf08dbbdec0d9e%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638312593774254107%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=s8N98lzOV4kJIp2nzGFTx74SU%2BZQCxgXvyXGoIxk6S0%3D&reserved=0" target="_blank" rel="noreferrer noopener">Jennifer Scurrell</a>和<a href="https://www.alejandrocuevas.me/" target="_blank" rel="noreferrer noopener">Alejandro Cuevas</a>与高级研究员<a href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fpeople%2Fmdaepp%2F&data=05%7C01%7Cv-amelfi%40microsoft.com%7Cdeb2b53d3b8d4c3a3ccf08dbbdec0d9e%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638312593774410340%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=PRbEab7C9R6Lv%2BwVQqz2Md1rE4WVmcPirGHNq9aqzYQ%3D&reserved=0" target="_blank" rel="noreferrer noopener">Madeleine Daepp 博士</a>进行了交谈。他们讨论了微软研究院的实习文化，从与研究人员联系的机会到他们所说的帮助他们取得成功的团队合作，以及他们希望对工作产生的影响。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-madeleine-daepp-with-jennifer-scurrell-and-alejandro-cuevas/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="key-insights-behind-phi-2">Phi-2 背后的关键见解</h2><p>语言模型的规模大幅增加到数千亿个参数，释放了许多新兴功能，重新定义了自然语言处理的格局。一个问题仍然是，是否可以使用训练策略选择（例如数据选择）在较小的规模上实现这种新兴能力。</p><p>我们对 Phi 模型的研究旨在通过训练 SLM 来回答这个问题，这些 SLM 的性能可与更大规模的模型相媲美（但距离前沿模型还很远）。我们对使用 Phi-2 打破传统语言模型缩放定律的主要见解有两个：</p><p>首先，训练数据质量对模型性能起着至关重要的作用。几十年来，人们已经知道这一点，但我们继我们之前的工作“<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">教科书就是你所需要的</a>”之后，通过关注“教科书质量”的数据，将这一见解发挥到了极致。我们的训练数据混合物包含专门创建的合成数据集，用于教授模型常识推理和常识，包括科学、日常活动和心理理论等。我们通过精心挑选的网络数据进一步扩充我们的训练语料库，这些数据是根据教育价值和内容质量进行过滤的。其次，我们使用创新技术进行扩展，从我们的 13 亿参数模型 Phi-1.5 开始，并将其知识嵌入到 27 亿参数 Phi-2 中。这种规模化的知识转移不仅加速了训练收敛，而且显着提高了 Phi-2 基准分数。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="25377" height="5876" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png" alt="条形图比较 Phi-2（具有 2.7B 参数）和 Phi-1.5（具有 1.3B 参数）在常识推理、语言理解、数学、编码和 Bigbench-hard 基准测试方面的性能。 Phi-2 在所有类别中均优于 Phi1.5。常识推理任务有 PIQA、WinoGrande、ARC easy 和challenge 以及 SIQA。语言理解任务有 HellaSwag、OpenBookQA、MMLU、SQuADv2 和 BoolQ。数学任务是 GSM8k，编码包括 HumanEval 和 MBPP 基准测试。" class="wp-image-991359" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png 25377w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-300x69.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1024x237.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-768x178.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1536x356.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-240x56.png 240w" sizes="(max-width: 25377px) 100vw, 25377px" /><figcaption class="wp-element-caption"><strong>图 2.</strong> Phi-2 (2.7B) 和 Phi-1.5 (1.3B) 模型之间的比较。除了 BBH 和 MMLU 分别使用 3-shot CoT 和 5-shot 之外，所有任务均以 0-shot 进行评估。</figcaption></figure><h2 class="wp-block-heading" id="training-details">培训详情</h2><p>Phi-2 是一个基于 Transformer 的模型，具有下一个单词预测目标，在用于 NLP 和编码的合成数据集和 Web 数据集的混合上多次传递的 1.4T 标记上进行训练。 Phi-2 的训练在 96 个 A100 GPU 上花费了 14 天。 Phi-2 是一个基础模型，没有通过人类反馈强化学习 (RLHF) 进行对齐，也没有进行指令微调。尽管如此，与经过调整的现有开源模型相比，我们观察到在毒性和偏差方面有更好的行为（见图 3）。由于我们定制的数据管理技术，这与我们在 Phi-1.5 中看到的情况一致，有关更多详细信息，请参阅我们<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need-ii-phi-1-5-technical-report/">之前的技术报告<span class="sr-only">（在新选项卡中打开）</span></a> 。有关 Phi-2 模型的更多信息，请访问<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ai.azure.com/explore/models/microsoft-phi-2/version/4/registry/azureml-msr" target="_blank" rel="noreferrer noopener">Azure AI |机器学习工作室<span class="sr-only">（在新选项卡中打开）</span></a> 。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="16803" height="8165" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png" alt="条形图比较 Phi-1.5、Phi-2 和 Llama-7B 模型在 ToxiGen 基准的 13 个类别上的安全评分。 Phi-1.5 在所有类别中获得最高分，Phi-2 在所有类别中获得第二高分，Llama-7B 在所有类别中获得最低分。" class="wp-image-991365" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png 16803w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-300x146.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1024x498.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-768x373.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1536x746.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-2048x995.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-240x117.png 240w" sizes="(max-width: 16803px) 100vw, 16803px" /><figcaption class="wp-element-caption"><strong>图 3.</strong>根据 ToxiGen 的 13 个人口统计数据计算的安全评分。选择 6541 个句子的子集，并根据困惑度和句子毒性进行 0 到 1 之间的评分。较高的分数表明与良性句子相比，模型产生有毒句子的可能性较小。</figcaption></figure><h2 class="wp-block-heading" id="phi-2-evaluation"> Phi-2 评估</h2><p>下面，我们总结了 Phi-2 在学术基准上的表现与流行语言模型的比较。我们的基准测试涵盖多个类别，即 Big Bench Hard (BBH)（3 shot with CoT）、常识推理（PIQA、WinoGrande、ARC easy 和 Challenge、SIQA）、语言理解（HellaSwag、OpenBookQA、MMLU（5-shot）、 SQuADv2（2 个镜头）、BoolQ）、数学（GSM8k（8 个镜头））和编码（HumanEval、MBPP（3 个镜头））。</p><p> Phi-2 仅拥有 27 亿个参数，在各种聚合基准上的 7B 和 13B 参数上超越了 Mistral 和 Llama-2 模型的性能。值得注意的是，与大 25 倍的 Llama-2-70B 模型相比，它在多步推理任务（即编码和数学）上实现了更好的性能。此外，尽管尺寸较小，但 Phi-2 的性能可与最近发布的 Google Gemini Nano 2 相媲美或优于其。</p><p>当然，我们承认当前模型评估面临的挑战，并且许多公共基准可能会泄漏到训练数据中。对于我们的第一个模型 Phi-1，我们进行了广泛的净化研究以排除这种可能性，这可以在我们的第一份报告“<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">教科书就是你所需要的</a>”中找到。最终，我们相信判断语言模型的最佳方法是在具体用例上对其进行测试。遵循这种精神，我们还使用多个 Microsoft 内部专有数据集和任务评估了 Phi-2，并再次将其与 Mistral 和 Llama-2 进行比较。我们观察到类似的趋势，即平均而言，Phi-2 优于 Mistral-7B，后者优于 Llama-2 模型（7B、13B 和 70B）。</p><figure class="wp-block-table"><table><thead><tr><th>模型</th><th>尺寸</th><th>BBH</th><th>常识<br>推理</th><th>语言<br>理解</th><th>数学</th><th>编码</th></tr></thead><tbody><tr><td rowspan="3">羊驼-2</td><td> 7B</td><td> 40.0</td><td> 62.2</td><td> 56.7</td><td> 16.5</td><td> 21.0</td></tr><tr><td> 13B</td><td> 47.8</td><td> 65.0</td><td> 61.9</td><td> 34.2</td><td> 25.4</td></tr><tr><td> 70B</td><td> 66.5</td><td> 69.2</td><td> 67.6</td><td> 64.1</td><td> 38.3</td></tr><tr><td>米斯特拉尔</td><td>7B</td><td> 57.2</td><td> 66.4</td><td> 63.7</td><td> 46.4</td><td> 39.4</td></tr><tr><td> Φ2</td><td> 2.7B</td><td> 59.2</td><td> 68.8</td><td> 62.0</td><td> 61.1</td><td> 53.7</td></tr></tbody></table><figcaption class="wp-element-caption"><center><strong>表 1.</strong>与流行的开源 SLM 相比，分组基准的平均性能。</center></figcaption></figure><figure class="wp-block-table"><table><thead><tr><th>模型</th><th>尺寸</th><th>BBH</th><th>布尔Q</th><th> MBPP</th><th> MMLU</th></tr></thead><tbody><tr><td>双子座纳米2</td><td> 3.2B</td><td> 42.4</td><td> 79.3</td><td> 27.2</td><td> 55.8</td></tr><tr><td> Φ2</td><td> 2.7B</td><td> 59.3</td><td> 83.3</td><td> 59.1</td><td> 56.7</td></tr></tbody></table><figcaption class="wp-element-caption"><center><strong>表 2.</strong> Phi-2 和 Gemini Nano 2 模型在 Gemini 报告的基准上的比较。</center></figcaption></figure><p>除了这些基准之外，我们还对研究社区的常用提示进行了广泛的测试。我们观察到的行为与我们给出的基准结果的预期一致。例如，我们测试了一个用于探测模型解决物理问题的能力的提示，最近用于评估 Gemini Ultra 模型的能力，并取得了以下结果： </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1347" height="758" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png" alt="Phi-2 给出了一个示例提示，其中显示“滑雪者沿着高 40m、长 80m 的无摩擦斜坡滑下。滑雪者在底部的速度是多少？”。然后，Phi-2 通过解释势能到动能的转换并提供计算每一个势能的公式来回答提示。然后，它继续使用能量公式计算正确的速度。" class="wp-image-991326" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png 1347w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1280x720.png 1280w" sizes="(max-width: 1347px) 100vw, 1347px" /><figcaption class="wp-element-caption"><strong>图 4.</strong> Phi-2 在一个简单物理问题上的输出，其中包括近似正确的平方根计算。 </figcaption></figure><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1600" height="710" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png" alt="然后向模型提供学生对滑雪物理问题的错误答案，并询问它是否可以纠正学生的错误。 Phi-2 回答了学生的错误，即使用了错误的势能公式，并提供了正确的公式。" class="wp-image-991332" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png 1600w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-300x133.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1024x454.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-768x341.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1536x682.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-240x107.png 240w" sizes="(max-width: 1600px) 100vw, 1600px" /><figcaption class="wp-element-caption"><strong>图 5.</strong>与 Gemini 的测试类似，我们还进一步向 Phi-2 询问学生的错误答案，看看 Phi-2 是否能够识别出错误所在（它确实如此，尽管 Phi-2 没有针对聊天或指令遵循进行微调） ）。然而，我们注意到，这并不完全是与 Gemini 报告中描述的 Gemini Ultra 输出的同类比较，特别是在后一种情况下，学生的答案是作为带有手写文本的图像给出的，而不是在我们的例子中为原始文本。</figcaption></figure><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>后<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2：小语言模型的惊人力量</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>