<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 8 月 29 日星期二 16:01:18 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.2.2</generator><item><title>打造人工智能编译器“重金属四重奏”</title><link/> https://www.microsoft.com/en-us/research/blog/building-a-heavy-metal-quartet-of-ai-compilers/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 30 Aug 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=963594 </guid><description><![CDATA[<p>全新的 AI 编译器四重奏：Rammer、Roller、Welder 和 Grinder，基于相同的图块抽象解决了一系列编译器优化挑战，提供了将 AI 模型与硬件加速器连接起来的全面解决方案。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/building-a-heavy-metal-quartet-of-ai-compilers/">构建人工智能编译器的“重金属四重奏”</a>一文首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<p>作者：MSR 编辑</p><p>编译是程序开发中的一个重要过程，其中称为编译器的程序将用编程语言编写的源代码翻译成计算机硬件上可执行的机器代码。随着人工智能技术和大规模人工智能模型在数字世界中变得越来越普遍，其独特的特性给编译器带来了新的挑战。</p><p>随着人工智能模型从循环神经网络 (RNN) 和卷积神经网络 (CNN) 等早期版本发展到 Transformer 等最新版本，其基本架构也在不断发展。与此同时，底层硬件加速器，例如图形处理单元（GPU）和神经处理单元（NPU）也在快速迭代，一些设计颠覆了以前的架构。因此，人工智能编译器在帮助新的人工智能模型在新硬件上高效运行方面发挥着至关重要的作用。</p><p>对此，微软研究院的研究人员与学术界同事合作，进行了一系列研究，并发布了人工智能编译器的“重金属四重奏”： <a href="https://www.microsoft.com/en-us/research/publication/rammer-enabling-holistic-deep-learning-compiler-optimizations-with-rtasks/"><em>Rammer</em></a> <em>、</em> <a href="https://www.microsoft.com/en-us/research/publication/roller-fast-and-efficient-tensor-compilation-for-deep-learning/"><em>Roller</em></a> <em>、</em> <a href="https://www.microsoft.com/en-us/research/publication/welder-scheduling-deep-learning-memory-access-via-tile-graph/"><em>Welder</em></a><em>和</em><em> </em><a href="https://www.microsoft.com/en-us/research/publication/cocktailer-analyzing-and-optimizing-dynamic-control-flow-in-deep-learning/"><em>磨床</em></a><sup><a id="_ftnref1" href="#_ftn1">[1]</a></sup> .该四方为当前主流的人工智能模型和硬件编译提供了系统的、创新的解决方案。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="978" height="367" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-1.png" alt="左图显示了以基于瓦片的中间表示（IR）为核心的统一编译器抽象。右图展示了AI编译的四大核心技术。" class="wp-image-963609" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-1.png 978w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-1-300x113.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-1-768x288.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-1-240x90.png 240w" sizes="(max-width: 978px) 100vw, 978px" /><figcaption class="wp-element-caption">图1：基于统一瓦片抽象的四大核心AI编译技术</figcaption></figure><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="电脑屏幕截图 一名男子的屏幕截图" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 解释者：基础模型和 AI 的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多数据以及情境学习如何帮助推动人工智能从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="ai-compilation-rammer-improves-hardware-parallel-utilization"> AI编译“Rammer”提高硬件并行利用率</h2><p>深度神经网络（DNN）广泛应用于图像分类、自然语言处理和许多其他智能任务。由于其重要性，许多计算设备（例如 CPU、GPU 和专门设计的 DNN 加速器）都被用来执行 DNN 计算。 DNN 计算效率的一个关键变量是调度，它决定了计算任务在硬件上执行的顺序。传统的 AI 编译器通常将 DNN 计算视为数据流图，其中每个节点代表一个 DNN 运算符。这些运算符作为不透明的库函数实现，并计划在加速器上单独运行。同时，这个过程还依赖于另一层调度程序（通常在硬件中实现），以利用运算符中可用的并行性。这种两级方法会产生大量的调度开销，并且通常不能充分利用硬件资源。</p><p>为了解决这个问题，研究人员提出了<em>一种新的 DNN 编译器 Rammer，它可以优化大规模并行加速器单元上 DNN 工作负载的执行。</em> Rammer 将 AI 编译的调度空间想象为一个二维平面，其中计算任务是可以分为不同形状和大小的“砖块”。 Rammer 中调度的目的是将这些砖块紧密地排列在二维平面的计算单元上（就像建造一堵墙一样）。安排不应留下任何间隙，否则会损害硬件利用率，从而降低执行速度。 Rammer 在这个二维空间中的工作方式就像一个压缩器：当 DNN 程序被翻译成砖块时，Rammer 可以将它们放置在加速器的不同计算单元上来压缩它们。 </p><figure class="wp-block-image aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-2-763x1024.png" alt="Rammer技术框架示意图。 Rammer 的输入是一个数据流图，其中节点是 rOperator。然后，Rammer 引入了 rTask 感知的 DFG 编译器来在一处管理运算符间和运算符内的调度。 rTask感知的DFG编译器将为运行时执行生成静态执行计划。 Rammer 将硬件加速器抽象为虚拟化并行设备（vDevice），其中包括多个虚拟化执行单元（vEU）。 vDevice提供了rTask级别的调度和同步能力，使得rProgram可以在编译时映射到相应的vEU。 vEU 与 vDevice 一起将在运行时映射到硬件。" class="wp-image-963612" width="427" height="573" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-2-763x1024.png 763w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-2-223x300.png 223w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-2-768x1031.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-2-134x180.png 134w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-2.png 1053w" sizes="(max-width: 427px) 100vw, 427px" /><figcaption class="wp-element-caption">图2：Rammer的技术框架</figcaption></figure><p>换句话说，Rammer 提前（在编译期间）为 DNN 生成高效的静态时空调度，从而最大限度地减少运行时调度开销。同时，通过新的独立于硬件的计算任务抽象和硬件加速器，Rammer 暴露了更大的调度空间，并提供了一种实现操作员内和操作员间协作调度的新颖方法。这使得Rammer能够找到更高效的调度，从而大大提高硬件利用率。</p><p>研究人员在多种设备上对 Rammer 进行了评估，包括 NVIDIA GPU、AMD GPU 和 Graphcore 智能处理单元 (IPU)。实验表明，Rammer 在 NVIDIA 和 AMD GPU 上的性能明显优于最先进的编译器，例如 XLA 和 TVM，实现了高达 20.1 倍的加速。与 NVIDIA 专有的 DNN 推理库 TensorRT 相比，Rammer 实现了高达 3.1 倍的加速。</p><h2 class="wp-block-heading" id="ai-compilation-roller-improves-compilation-efficiency"> AI编译“滚轮”提升编译效率</h2><p>加速器配备有并行计算单元和多层存储器层次结构。数据在计算之前需要从底层内存层逐层向上传递。在每一层，数据都被分成更小的块。最终，这些较小的砖块被交给顶层处理器进行计算。挑战在于如何对数据进行分区，并用大砖填充内存空间，从而更好地利用可用内存并提高效率。当前的方法涉及使用机器学习来确定更好的策略来划分这些砖块。然而，这通常需要数千个搜索步骤，每个搜索步骤都在加速器上进行评估，以便找到满意的解决方案。因此，编译完整的人工智能模型的过程可能需要几天甚至几周的时间。</p><p>考虑到每个存储层的计算逻辑和规范，提供了软件和硬件信息的整体视图，就可以制定划分块的最佳策略以及最佳的块尺寸。这使得编译速度更快，计算效率更高。这是<em>Roller</em>背后的关键思想。<em>就像压路机一样，系统将高维张量数据放置到二维存储器上，就像铺地板一样，根据存储器特性找到最佳的瓷砖尺寸。同时，它封装了符合底层加速器硬件特性的张量形状，通过限制形状的选择来实现高效编译。</em> <strong></strong></p><figure class="wp-block-image aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3-1024x740.png" alt="Roller的技术框架示意图。 Roller 采用一个被描述为张量表达式的运算符。 Roller 从张量表达式中提取张量形状，并利用硬件规范来构造 rTiles。 Roller基于rTiles，提出了一种先扩展后扩展的递归构造算法，以生成描述数据处理管道的高效张量程序（名为rProgram）。在生成 rProgram 时，构造算法通过微性能模型评估构造的 rProgram 的性能来识别良好的 rTile 配置。它构建在通过硬件抽象层描述的设备之上，仅公开与 rTile 相关的接口：加载、计算和存储。构造好的rProgram最终通过代码生成器实现，发出对应特定设备的最终内核代码。" class="wp-image-963615" width="530" height="383" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3-1024x740.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3-300x217.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3-768x555.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3-1536x1110.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3-240x173.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-3.png 1888w" sizes="(max-width: 530px) 100vw, 530px" /><figcaption class="wp-element-caption">图3：Roller的技术框架</figcaption></figure><p>对六种主流 DNN 模型和 119 个流行的 DNN 算子的评估表明，Roller 可以在几秒钟内生成高度优化的内核，特别是对于大型且昂贵的定制算子。与现有编译器相比，Roller 的编译时间缩短了三个数量级。 Roller 生成的内核的性能可与最先进的张量编译器（包括 DNN 库）相媲美，某些运算符的性能甚至更好。 Roller在内部也被用于定制DNN内核，这已经证明了其在开发敏捷性方面的真正提升。 </p><h2 class="wp-block-heading" id="ai-compilation-welder-optimizes-memory-access-and-improves-computing-efficiency"> AI编译“Welder”优化内存访问，提高计算效率</h2><p>随着处理更高保真度数据的需求不断增长，以及在更新的硬件加速器中使用更快的计算核心，现代 DNN 模型的内存消耗量越来越大。在各种流行的 DNN 模型中观察到未充分利用的计算核心和饱和内存带宽之间的差异。</p><p>例如，对最先进的 DNN 基准的分析显示，内存带宽利用率高达 96.7%，而计算核心的平均利用率仅为 51.6%。更严重的是，硬件和 DNN 模型的不断演进继续拉大了这一差距。现代人工智能模型倾向于处理高保真数据，例如更大的图像、更长的句子和更高分辨率的图形。此类数据在计算过程中需要更高的内存带宽。此外，更高效的专用计算核心（例如 NVIDIA Tensor Core 或 AMD Matrix Core）的引入进一步增加了内存压力。</p><p>为了解决这个问题，研究人员提出了<em>Welder深度学习编译器，它全面优化了端到端DNN模型的内存访问效率。</em>端到端 DNN 计算表示为数据流图，涉及多个阶段，其中输入数据被分为流经不同运算符的块。这些块被传输到处理器核心进行计算，然后传输回内存。由于跨内存层的数据移动，这会导致显着的开销。由于它包含多个阶段，所以整个过程可以想象为“工人”一层一层向上搬砖的场景。第一个工人拿起砖块，对其进行处理，然后将它们放回原来的位置。第二个工人再次把它们抬起来，雕刻它们，然后再次把它们放回去。这个过程继续进行，第三个工人、第四个工人等等，重复地移动砖块。然而，这会导致巨大的开销。是否可以让第一个worker完成部分子任务，然后直接交给最顶层的下一个worker？然后可以将这些任务“焊接”在一起，实现更高效率的流水线操作。焊机就起到了这样的焊接工具的作用。通过连接（焊接）不同的算子，以流水线的方式处理数据块，大大减少了底层内存层的内存访问流量。近年来，随着AI模型对内存效率的要求越来越高，Welder有助于显着提高计算效率。 </p><figure class="wp-block-image aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-1024x776.png" alt="Welder 技术框架示意图。 Welder 将完整的 DNN 模型作为输入，并将其转换为基于图块的计算任务的数据流图，称为图块图。然后，提出了一种两步调度算法，即图连接和子图调度，以递归地决定多个存储层的有效瓦片图执行计划，称为分层瓦片图。最后，使用硬件层中定义的四个抽象计算接口将该计划映射到特定硬件加速器的可执行代码。" class="wp-image-963621" width="768" height="582" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-1024x776.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-300x227.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-768x582.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-1536x1164.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-80x60.png 80w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4-238x180.png 238w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-4.png 2022w" sizes="(max-width: 768px) 100vw, 768px" /><figcaption class="wp-element-caption">图4：Welder的技术框架</figcaption></figure><p>对10种主流DNN模型（包括视觉、自然语言处理、3D图形等各种任务的经典和最新的AI模型结构）的评估表明，Welder在两个方面都显着超过现有主流框架和编译器的性能NVIDIA 和 AMD GPU。例如，它的性能比 PyTorch、ONNXRuntime 和 Ansor 分别高出 21.4 倍、8.7 倍和 2.8 倍。 Welder 的自动优化甚至超越了 TensorRT 和 Faster Transformer（手工制作的库），分别实现了高达 3.0 倍和 1.7 倍的加速。此外，当在具有更快计算核心（例如 TensorCore）的硬件上运行这些模型时，性能会进一步提高，凸显了内存优化对于未来 AI 加速器的重要性。 </p><h2 class="wp-block-heading" id="ai-compilation-grinder-allows-efficient-control-flow-execution-on-accelerators"> AI编译“Grinder”允许在加速器上高效执行控制流</h2><p>在AI计算中，数据块的移动有时需要更复杂的控制逻辑，即控制流代码。例如，程序可以迭代地遍历句子中的每个单词，或者根据输入动态确定要执行程序的哪一部分。目前，大多数AI编译器侧重于解决数据流执行效率问题，并未对控制流提供有效支持。因此，控制流程较复杂的模型无法有效利用加速器性能。研究人员意识到，控制流和数据流可以被分段和重组，以便更有效地执行。他们的解决方案是<em>Grinder</em> ，它的作用就像便携式研磨和切割机。将数据流切割成不同大小的并行计算块后，再将控制流整合（研磨）到数据流中，使控制流也能在加速器上高效执行。 </p><figure class="wp-block-image aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-1024x774.png" alt="Grinder 技术框架示意图。示例循环结构被调度为映射到 3 级加速器上的 uProgram。 uProgram由4个loop-uTasks组成，分别对应4个L1-Unit，每个loop-uTask都映射到一个L1-Unit来执行。数据流运算符和循环都被调度到loop-uTasks中。" class="wp-image-963624" width="598" height="452" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-1024x774.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-300x227.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-768x580.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-1536x1161.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-80x60.png 80w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5-238x180.png 238w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/ai-compilor-5.png 1712w" sizes="(max-width: 598px) 100vw, 598px" /><figcaption class="wp-element-caption">图5：Grinder的技术框架</figcaption></figure><p>Grinder可以通过uTask这种新的抽象，联合优化控制流和数据流在硬件加速器上的执行，并统一AI模型的表示，包括控制流和数据流。这允许 Grinder 公开整体调度空间，以便将控制流重新调度到较低级别的硬件并行性。 Grinder使用启发式策略来寻找有效的调度方案，并可以自动将控制流移动到设备内核中，从而实现跨控制流边界的优化。实验表明，Grinder 可以在控制流密集型 DNN 模型上实现高达 8.2 倍的加速，使其成为控制流 DNN 框架和编译器中最快的。</p><p>这四种AI编译器基于通用的编译器抽象和统一的中间表示（IR），<em>解决了</em><em>当前AI编译器中的多个基本问题，包括并行性、编译效率、内存和控制流。它们共同构成了一套全面的编译解决方案。</em>并在微软研究院新人工智能模型的定制和优化中发挥了重要作用。</p><p> MSR Asia 首席研究员薛继龙这样总结该项目：</p><blockquote class="wp-block-quote is-style-spectrum"><p> “一方面，人工智能编译器必须执行极端优化，例如针对硬件资源量身定制的运算符融合和内核专业化。另一方面，还必须为新的大规模硬件架构提供系统的编译支持，例如具有片上网络互连（NoC）或混合内存架构的AI芯片，甚至使用白盒编译技术指导硬件设计。我们开发的AI编译器在AI编译效率方面取得了显着提升，从而方便了AI模型的训练和部署。同时，大规模模型的演进也为下一代AI编译器带来了机遇。未来，这些大型模型本身可能本质上有助于实现优化和编译。”</p></blockquote><p>以下研究人员对此项目做出了贡献：</p><p> <em>（按字母顺序排列）</em><a href="https://www.microsoft.com/en-us/research/people/weicu/">崔伟</a>、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://yuxiaoguo.github.io/" target="_blank" rel="noreferrer noopener">郭雨晓</a>、<a href="https://www.microsoft.com/en-us/research/people/wenxh/">胡文祥</a>、<a href="https://www.microsoft.com/en-us/research/people/lingm/">马凌晓</a>、<a href="https://www.microsoft.com/en-us/research/people/yomia/">苗友山</a>、<a href="https://www.microsoft.com/en-us/research/people/zimiao/">苗子明</a>、<a href="https://www.microsoft.com/en-us/research/people/yuqxia/">夏雨晴</a>、<a href="https://www.microsoft.com/en-us/research/people/jxue/">薛继龙</a>、杨<a href="https://www.microsoft.com/en-us/research/people/fanyang/">范</a>、杨<a href="https://www.microsoft.com/en-us/research/people/maoyang/">毛</a>、<a href="https://www.microsoft.com/en-us/research/people/lidongz/">周立东</a></p><hr class="wp-block-separator has-alpha-channel-opacity"/><p><a id="_ftn1" href="#_ftnref1">[1]</a> Grinder是研究项目名称。然而，该系统在论文中被称为 Cocktailer。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/building-a-heavy-metal-quartet-of-ai-compilers/">构建人工智能编译器的“重金属四重奏”</a>一文首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item><item><title>研究重点：2023 年 8 月 28 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-28-2023/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 30 Aug 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=963642 </guid><description><![CDATA[<p>本期：科学结果可预测性的错觉； Kathleen Sullivan 被列入 Insider 的 30 岁以下 40 岁医疗保健名单；图：带有过滤器增强的简单高效的无监督节点表示。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-28-2023/">《研究焦点：2023 年 8 月 28 日一周》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1400" height="264" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-banner-1400x264-1.png" alt="微软研究焦点 23 | 2023 年 8 月 28 日当周" class="wp-image-963663" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-banner-1400x264-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-banner-1400x264-1-300x57.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-banner-1400x264-1-1024x193.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-banner-1400x264-1-768x145.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-banner-1400x264-1-240x45.png 240w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><aside id=accordion-a042bbc7-357c-4147-8506-94e47ebccc24 class="msr-table-of-contents-block accordion mb-5 pb-0" data-bi-aN="table-of-contents"> <button class="btn btn-collapse bg-gray-100 mb-0 display-flex justify-content-between" type="button" data-mount="collapse" data-target="#accordion-collapse-a042bbc7-357c-4147-8506-94e47ebccc24" aria-expanded="true" aria-controls="accordion-collapse-a042bbc7-357c-4147-8506-94e47ebccc24"><span class="msr-table-of-contents-block__label subtitle">在本文中</span><span class="msr-table-of-contents-block__current mr-4 text-gray-600 font-weight-normal" aria-hidden="true"></span></button> <div id="accordion-collapse-a042bbc7-357c-4147-8506-94e47ebccc24" class="msr-table-of-contents-block__collapse-wrapper collapse show" data-parent="#accordion-a042bbc7-357c-4147-8506-94e47ebccc24"><div class="accordion-body bg-gray-100 border-top pt-4"><ol class="msr-table-of-contents-block__list"><li class="msr-table-of-contents-block__list-item"> <a href="#an-illusion-of-predictability-in-scientific-results-even-experts-confuse-inferential-uncertainty-and-outcome-variability" class="msr-table-of-contents-block__list-item-link">科学结果可预测性的错觉：即使是专家也会混淆推论的不确定性和结果的可变性</a></li><li class="msr-table-of-contents-block__list-item"><a href="#figure-simple-and-efficient-unsupervised-node-representations-with-filter-augmentations" class="msr-table-of-contents-block__list-item-link">图：带有过滤器增强的简单高效的无监督节点表示</a></li><li class="msr-table-of-contents-block__list-item"><a href="#kathleen-sullivan-named-to-insiders-30-under-40-in-healthcare-list" class="msr-table-of-contents-block__list-item-link">凯瑟琳·沙利文 (Kathleen Sullivan) 入选 Insider 30 岁以下 40 岁医疗保健名单</a></li></ul></div></div><span class="msr-table-of-contents-block__progress-bar"></span></aside><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research">新研究</h3><h2 class="wp-block-heading" id="an-illusion-of-predictability-in-scientific-results-even-experts-confuse-inferential-uncertainty-and-outcome-variability">科学结果可预测性的错觉：即使是专家也会混淆推论的不确定性和结果的可变性</h2><p>在许多领域，从业者专注于推理（精确估计未知量，例如人口平均值）而不是预测（预测个体结果）。在一篇<a href="https://www.microsoft.com/en-us/research/publication/an-illusion-of-predictability-in-scientific-results-even-experts-confuse-inferential-uncertainty-and-outcome-variability/">新发表的文章</a>中，微软的研究人员证明，这种对推理而非预测的关注可能会误导读者，让他们认为科学研究的结果比实际结果更明确。</p><p>通过一系列随机实验，研究人员证明，这种混乱是呈现统计结果的最基本方式之一，甚至影响到那些工作涉及生成和解释此类结果的专家，包括医学专业人员、数据科学家和终身教授。 。相比之下，该论文表明，同时交流推理和预测信息提供了一种简单而有效的替代方案，从而对科学结果进行校准解释。</p><p>这篇文章发表在《美国国家科学院院刊》（PNAS）上。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/an-illusion-of-predictability-in-scientific-results-even-experts-confuse-inferential-uncertainty-and-outcome-variability/" target="_blank" rel="noreferrer noopener">阅读文章</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/jhofman/illusion-of-predictability" target="_blank" rel="noreferrer noopener">数据和代码</a></div></div><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956154"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" aria-label="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/collaborators_hero_1400x788.jpg" alt="GitHub 产品经理 Kasia Sitkiewicz 和协议实验室研究科学家 Petar Maymounkov 在 Microsoft Research 播客上讨论了他们在 Gov4git 上的合作" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Gov4git、Petar Maymounkov 和 Kasia Sitkiewicz</h2><p class="large"> Gov4git 是一种用于去中心化、开源合作的治理工具，有助于为未来奠定基础，让每个人都可以更高效、透明、轻松地进行协作，并以满足各自社区独特愿望和需求的方式进行协作。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research-1">新研究</h3><h2 class="wp-block-heading" id="figure-simple-and-efficient-unsupervised-node-representations-with-filter-augmentations">图：带有过滤器增强的简单高效的无监督节点表示</h2><p>对比学习是无监督图表示学习的一种强大方法。它通常部署在<em>同质</em>任务上，其中任务标签与图的结构密切相关。然而，这些表示在处理<em>异嗜性</em>任务时会遇到困难，其中边倾向于连接具有不同标签的节点。</p><p>有几篇论文通过利用低频和高频分量的信息来解决异质性问题。然而，这些方法在半监督环境中运行，这些想法在无监督学习中的扩展仍然需要探索。</p><p>在一篇新论文： <a href="https://www.microsoft.com/en-us/research/publication/figure-simple-and-efficient-unsupervised-node-representations-with-filter-augmentations/">FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations</a>中，微软的研究人员建议使用滤波器组来学习可以满足异性和同性任务的表示。他们通过在这些不同的滤波器视图之间共享编码器，并通过学习使用随机傅里叶特征投影到高维度的低维表示来解决相关的计算和存储负担。与最先进的无监督模型相比，FiGURe 在所有考虑的数据集（无论是同质数据集还是异质数据集）上实现了高达 4.4% 的增益。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/figure-simple-and-efficient-unsupervised-node-representations-with-filter-augmentations/">阅读论文</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/figure" target="_blank" rel="noreferrer noopener">查看代码</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="award">奖</h3><h2 class="wp-block-heading" id="kathleen-sullivan-named-to-insider-s-30-under-40-in-healthcare-list">凯瑟琳·沙利文 (Kathleen Sullivan) 入选 Insider 30 岁以下 40 岁医疗保健名单</h2><p>Microsoft Research 祝贺<a href="https://www.microsoft.com/en-us/research/people/kasull/">凯瑟琳·沙利文 (Kathleen Sullivan <span class="sr-only">)（在新选项卡中打开）</span></a>入选 Insider 的<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.businessinsider.com/30-leaders-under-40-changing-healthcare-2023" target="_blank" rel="noreferrer noopener">30 岁以下 40 岁以下杰出人物名单，在医疗保健领域开创新的未来<span class="sr-only">（在新选项卡中打开）</span></a> 。经过竞争性提名和面试后，凯瑟琳被选入这份鼓舞人心的“正在改变医疗保健行业的企业家、科学家、医生和商业领袖”名单。</p><p>作为微软研究院健康与生命科学部门的战略和运营高级总监，沙利文帮助引导公司在人工智能方面的投资。她帮助设计了 Microsoft 与 Nuance Technologies 的合作，这是 Microsoft 在 2021 年收购 Nuance 的前身。2018 年，Sullivan 帮助确保了 Microsoft 与 Adaptive Biotechnologies 的合作伙伴关系，以<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.businesswire.com/news/home/20180104005464/en/Adaptive-Biotechnologies-Announces-Partnership-with-Microsoft-to-Decode-the-Human-Immune-System-to-Improve-the-Diagnosis-of-Disease" target="_blank" rel="noreferrer noopener">绘制人类免疫系统图谱<span class="sr-only">（在新选项卡中打开）</span></a> 。</p><p class="has-text-align-center"> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.businessinsider.com/30-leaders-under-40-changing-healthcare-2023" target="_blank" rel="noreferrer noopener">阅读内幕文章<span class="sr-only">（在新选项卡中打开）</span></a><br> （需要订阅）</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-28-2023/">《研究焦点：2023 年 8 月 28 日一周》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>