<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 1 月 9 日星期二 04:39:23 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.2</generator><item><title> Splitwise 通过分割 LLM 推理阶段来提高 GPU 使用率</title><link/>https://www.microsoft.com/en-us/research/blog/splitwise-improves-gpu-usage-by-splitting-llm-inference-phases/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 04 Jan 2024 17:02:45 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=995736 </guid><description><![CDATA[<p> LLM 使用范围的扩大对云 GPU 容量提出了新的要求。 Splitwise 提出了一种高效的解决方案，将 LLM 推理的两个基本阶段分开，在有限的功率预算内实现更高的吞吐量。</p><p>这篇文章<a href="https://www.microsoft.com/en-us/research/blog/splitwise-improves-gpu-usage-by-splitting-llm-inference-phases/">Splitwise 通过分割 LLM 推理阶段来提高 GPU 使用率</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>最近大型语言模型 (LLM) 使用量的激增给云提供商带来了重大挑战，要求他们以前所未有的速度部署更多 GPU。然而，提供运行这些 GPU 所需的功率的能力是有限的，并且随着计算需求超过供应，用户查询被拒绝的情况并不少见。因此，任何提高现有基础设施效率的方法（使其能够在相同的功率预算下更快地服务更多查询）都可以为云提供商和用户带来非常切实的好处。</p><p>目前限制资源有效利用的 LLM 推理的一方面是它有两个具有不同特征的不同阶段：提示阶段和令牌生成阶段。在提示阶段，法学硕士并行处理所有用户输入或提示，有效利用 GPU 计算。然而，在令牌生成阶段，LLM 按顺序生成每个输出令牌，并受到 GPU 内存带宽的限制。即使采用最先进的批处理机制，这两个阶段之间的差异也会导致整体硬件利用率较低，从而导致向用户提供法学硕士时的成本更高。图 1 说明了这两个阶段之间的差异。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1.jpg" alt="生成式 LLM 推理过程以及与之相关的两个阶段的示例。最初的提示是“披萨和汉堡哪个更好？”它生成了“Pizza”这个词。令牌生成阶段生成单词/令牌：“is”、“better”和“.”。提示阶段具有以下属性：(1) 并行处理所有输入令牌以生成第一个输出令牌，(2) 计算密集型，(3) 是端到端延迟的一小部分。令牌阶段是：(1) 序列化，(2) 内存密集型，(3) 往往是端到端延迟的大部分。" class="wp-image-996810" style="width:600px" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/NEWSplitwise-Jan-24-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 1. 生成式 LLM 推理过程以及与之相关的两个阶段的示例。提示阶段是计算密集型的，而令牌阶段是内存密集型的。</figcaption></figure><h2 class="wp-block-heading" id="splitting-the-phases-with-splitwise">使用 Splitwise 分割相</h2><p>在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/azrs">Azure 研究系统</a>中，我们通过创建 Splitwise 来解决这个问题，这是一种旨在通过将即时计算和令牌生成阶段分离到不同机器上来优化利用可用硬件的技术。这种方法的基础是这样的见解：即时处理和令牌生成在计算、内存和功率要求方面是不同的。通过分离这两个阶段，我们可以提高两个阶段的硬件利用率。我们的论文“ <a href="https://www.microsoft.com/en-us/research/publication/splitwise-efficient-generative-llm-inference-using-phase-splitting/" target="_blank" rel="noreferrer noopener">Splitwise：使用相分裂的高效生成 LLM 推理</a>”详细介绍了我们开发和测试该技术的方法，包括探索不同类型的 GPU 在每个阶段的性能。</p><p>为了创建可持续的 GPU 配置方法，我们使用 Splitwise 来设计 GPU 集群，其主要目标有三个：最大化吞吐量、最小化成本和降低功耗。除了将两个 LLM 推理阶段分成两个不同的机器池之外，我们还包括第三个机器池，用于跨提示和令牌阶段进行混合批处理，并根据实时计算需求动态调整大小。最后，我们通过 InfiniBand 将状态上下文（即 LLM 转换器注意层中的 KV 缓存）从提示传输到令牌机，而不会对用户产生任何可感知的延迟影响。这种高级系统架构如图 2 所示。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2.jpg" alt="Splitwise 架构的高级图表。不同池中维护的机器专用于相应的阶段。混合池根据运行时需求增长和减少。 KV 缓存包含提示阶段之后的查询状态，通过 InfiniBand 以非常低的延迟从提示机传输到令牌机。" class="wp-image-997953" style="width:600px" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/SplitwiseFIG2-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">图 2.Splitwise 架构的高级图表。不同池中维护的机器专用于两个不同的 LLM 推理阶段。混合池根据运行时需求增长和减少。 KV 缓存包含提示阶段之后的查询状态，通过 InfiniBand 以非常低的延迟从提示机传输到令牌机。 </figcaption></figure><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956154"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" aria-label="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/collaborators_hero_1400x788.jpg" alt="GitHub 产品经理 Kasia Sitkiewicz 和协议实验室研究科学家 Petar Maymounkov 在 Microsoft Research 播客上讨论了他们在 Gov4git 上的合作" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Gov4git、Petar Maymounkov 和 Kasia Sitkiewicz</h2><p class="large"> Gov4git 是一种用于去中心化、开源合作的治理工具，有助于为未来奠定基础，让每个人都可以更高效、透明、轻松地进行协作，并以满足各自社区独特愿望和需求的方式进行协作。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="tests-show-splitwise-maximizes-throughput-while-lowering-costs">测试表明 Splitwise 可以最大限度地提高吞吐量，同时降低成本</h2><p>为了评估其性能，我们使用 Splitwise 设计具有不同类型 GPU（包括 NVIDIA DGX-A100 和 DGX-H100）的集群，同时针对每个查询在特定延迟服务级别协议 (SLA) 下优化成本、功耗和吞吐量。表 1 显示了我们用于每个集群设计的机器类型。我们的 Splitwise 应用包含两个用例：使用<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/meta-llama/Llama-2-70b" target="_blank" rel="noreferrer noopener">Llama-2-70B <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2211.05100" target="_blank" rel="noreferrer noopener">BLOOM-176B <span class="sr-only">（在新选项卡中打开）</span></a> LLM 进行代码和对话。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" width="2086" height="361" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi.png" alt="我们用于每个集群设计的提示和令牌机的详细信息，并使用 Splitwise 进行评估。所有值均标准化为 DGX-A100 的基线。 DGX-H100 capped 是所有 GPU 功率上限为最大功率一半的系统。" class="wp-image-996774" style="object-fit:cover;width:900px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi.png 2086w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi-300x52.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi-1024x177.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi-768x133.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi-1536x266.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi-2048x354.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/splitwise-blog-table-hi-240x42.png 240w" sizes="(max-width: 2086px) 100vw, 2086px" /><figcaption class="wp-element-caption">表 1. 我们用于每个集群设计的提示和令牌机的详细信息，并使用 Splitwise 进行评估。所有值均标准化为 DGX-A100 的基线。 DGX-H100 capped 是所有 GPU 功率上限为最大功率一半的系统。</figcaption></figure><p>我们的研究结果表明，Splitwise 成功实现了我们的三个目标：最大化吞吐量、最小化成本和降低功耗。通过我们的评估，我们发现与 A100 基准集群相比，Splitwise 集群设计可以以相同的成本最大化吞吐量。此外，Splitwise 可提供更高的吞吐量，同时在与基准集群相同的预配置功率限制内运行。图 3 显示，与 Baseline-H100 相比，我们可以以降低 20% 的成本实现 1.4 倍的吞吐量提高。或者，我们可以在相同的成本和功耗预算下实现 2.35 倍的吞吐量提高。 </p><figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1200" height="627" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Splitwise_Figure3.jpg" alt="来自针对吞吐量进行优化的基线和分割集群的结果，全部具有相同的功率限制。 Splitwise-HH 需要最少数量的机器。 Splitwise-HHcap 提供最佳吞吐量。 Splitwise-AA 是最便宜的选择。" class="wp-image-997947" style="width:674px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Splitwise_Figure3.jpg 1200w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Splitwise_Figure3-300x157.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Splitwise_Figure3-1024x535.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Splitwise_Figure3-768x401.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Splitwise_Figure3-240x125.jpg 240w" sizes="(max-width: 1200px) 100vw, 1200px" /><figcaption class="wp-element-caption">图 3. 针对吞吐量进行优化的基线集群和分割集群的结果，均具有相同的功耗限制。</figcaption></figure><h2 class="wp-block-heading" id="looking-forward">期待</h2><p>Splitwise 标志着向高效、高性能 LLM 部署的飞跃。通过分离提示阶段和令牌阶段，我们可以释放 GPU 使用的新潜力。展望未来，我们 Microsoft Azure 设想定制机器池可实现最大吞吐量、降低成本和提高能效，并且我们将继续专注于使 LLM 推理高效且可持续。</p><p>我们的方法现在是<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/vllm-project/vllm" target="_blank" rel="noreferrer noopener">vLLM 的一部分<span class="sr-only">（在新选项卡中打开）</span></a> ，也可以与其他框架一起实现。</p><h2 class="wp-block-heading" id="acknowledgements">致谢</h2><p>这项工作是与我们来自华盛顿大学的实习生 Pratyush Patel 合作完成的。我们还感谢 Suriya Kalivardhan、Gopi Kumar 和<a href="https://www.microsoft.com/en-us/research/people/chetanb/" target="_blank" rel="noreferrer noopener">Chetan Bansal</a>的帮助和指导。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>这篇文章<a href="https://www.microsoft.com/en-us/research/blog/splitwise-improves-gpu-usage-by-splitting-llm-inference-phases/">Splitwise 通过分割 LLM 推理阶段来提高 GPU 使用率</a>首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>微软研究 2023：人工智能突破性进展和发现的一年</title><link/>https://www.microsoft.com/en-us/research/blog/research-at-microsoft-2023-a-year-of-groundwriting-ai-advances-and-discoveries/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Fri, 22 Dec 2023 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=994098 </guid><description><![CDATA[<p>人工智能在 2023 年出现了无与伦比的增长，每天达到数百万。这一进展很大程度上归功于微软研究人员和合作者的大量工作。在本次回顾中，了解 2023 年的进展，这为 2024 年的进一步进展奠定了基础。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/research-at-microsoft-2023-a-year-of-groundbreaking-ai-advances-and-discoveries/">《微软研究 2023：人工智能突破性进展和发现的一年》一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1.png" alt=""2023 Microsoft Research Year In Review" in white text on a blue, green, and purple abstract gradient background" class="wp-image-994224" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/2023_Year-In-Review-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><aside id=accordion-eb568f47-2fe0-4723-93e8-798302b5e26d class="msr-table-of-contents-block accordion mb-5 pb-0" data-bi-aN="table-of-contents"> <button class="btn btn-collapse bg-gray-100 mb-0 display-flex justify-content-between" type="button" data-mount="collapse" data-target="#accordion-collapse-eb568f47-2fe0-4723-93e8-798302b5e26d" aria-expanded="true" aria-controls="accordion-collapse-eb568f47-2fe0-4723-93e8-798302b5e26d"><span class="msr-table-of-contents-block__label subtitle">在本文中</span><span class="msr-table-of-contents-block__current mr-4 text-gray-600 font-weight-normal" aria-hidden="true"></span></button> <div id="accordion-collapse-eb568f47-2fe0-4723-93e8-798302b5e26d" class="msr-table-of-contents-block__collapse-wrapper collapse show" data-parent="#accordion-eb568f47-2fe0-4723-93e8-798302b5e26d"><div class="accordion-body bg-gray-100 border-top pt-4"><ol class="msr-table-of-contents-block__list"><li class="msr-table-of-contents-block__list-item"> <a href="#strengthening-the-foundations-of-ai" class="msr-table-of-contents-block__list-item-link">加强人工智能的基础</a></li><li class="msr-table-of-contents-block__list-item"><a href="#accelerating-scientific-exploration-and-discovery" class="msr-table-of-contents-block__list-item-link">加速科学探索和发现</a></li><li class="msr-table-of-contents-block__list-item"><a href="#maximizing-the-individual-and-societal-benefits-of-ai" class="msr-table-of-contents-block__list-item-link">最大化人工智能的个人和社会效益</a></li><li class="msr-table-of-contents-block__list-item"><a href="#beyond-ai-leading-technology-innovation" class="msr-table-of-contents-block__list-item-link">超越AI：引领科技创新</a></li><li class="msr-table-of-contents-block__list-item"><a href="#collaborating-across-academia-industries-and-disciplines" class="msr-table-of-contents-block__list-item-link">跨学术界、行业和学科的合作</a></li><li class="msr-table-of-contents-block__list-item"><a href="#engaging-and-supporting-the-larger-research-community" class="msr-table-of-contents-block__list-item-link">参与和支持更大的研究社区</a></li><li class="msr-table-of-contents-block__list-item"><a href="#listeners-choice-notable-podcasts-for-2023" class="msr-table-of-contents-block__list-item-link">听众选择：2023 年著名播客</a></li><li class="msr-table-of-contents-block__list-item"><a href="#thank-you-for-reading" class="msr-table-of-contents-block__list-item-link">感谢您的阅读</a></li></ul></div></div><span class="msr-table-of-contents-block__progress-bar"></span></aside><p>处于技术前沿的研究人员很少会看到令他们大吃一惊的东西。但这正是 2023 年发生的事情，当时人工智能专家开始与 GPT-4 进行交互，GPT-4 是 OpenAI 研究人员创建的大型语言模型 (LLM)，经过了前所未有的规模训练。</p><p>微软合作伙伴研究经理 Ece Kamar 在 4 月份录制的<a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/">播客</a>中表示：“我看到了一些令人兴奋的功能，我原以为多年来都不会看到这些功能。”</p><p>全年中，人工智能的快速进步主导了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.thisamericanlife.org/803/greetings-people-of-earth" target="_blank" rel="noreferrer noopener">公众对话<span class="sr-only">（在新选项卡中打开）</span></a> ，技术领导者和最终公众在尝试 GPT-4 和相关应用程序后表达了惊奇和怀疑的态度。我们能否看到<a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/">通用人工智能<span class="sr-only">（在新选项卡中打开）</span>的火花</a>——非正式定义为“ <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/pdf/2303.12712.pdf" target="_blank" rel="noreferrer noopener">展示广泛的智能能力，包括推理、规划和从经验中学习的能力<span class="sr-only">（在新选项卡中打开）</span></a> ”的人工智能系统？</p><p>虽然这个问题的答案尚不清楚，但我们确实已经进入了人工智能时代，它正在给我们的工作和生活方式带来深刻的变化。 2023 年，人工智能走出实验室，带来了任何人都可以使用的日常创新。现在有数百万人使用 ChatGPT 等基于人工智能的服务。 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://news.microsoft.com/source/features/ai/microsoft-outlines-framework-for-building-ai-apps-and-copilots-expands-ai-plugin-ecosystem/" target="_blank" rel="noreferrer noopener">副驾驶<span class="sr-only">（在新选项卡中打开）</span></a> ——帮助完成从搜索到安全等复杂任务的人工智能——正在融入商业软件和服务中。</p><p>所有这些创新的基础是多年的研究，包括 Microsoft 数百名世界级研究人员的工作，并得到许多相关领域的科学家、工程师和专家的帮助。 2023年，人工智能从研究到现实的转变开始加速，创造出比以往更多的切实成果。这篇文章回顾了过去一年的进展，重点介绍了一些研究和战略，这些研究和战略将支持 2024 年取得更大进展。</p><h2 class="wp-block-heading" id="strengthening-the-foundations-of-ai">加强人工智能的基础</h2><p>具有积极社会影响的人工智能是几个不可或缺的活动部分的总和，包括人工智能模型、这些模型的应用以及支持其开发和它们所支撑的更大系统的开发的基础设施和标准。 Microsoft 正在通过改进模型效率、性能和功能来重新定义这些领域的最新技术；引入新的框架和促进策略来提高模型的可用性；以及有助于可持续和负责任的人工智能的最佳实践。</p><h3 class="wp-block-heading" id="advancing-models">推进模型</h3><ul><li>研究人员引入了<a href="https://www.microsoft.com/en-us/research/publication/retentive-network-a-successor-to-transformer-for-large-language-models/">保留网络</a>(RetNet)，它是语言建模中占主导地位的 Transformer 架构的替代方案。 RetNet 支持训练并行性和强大的性能，同时显着提高推理效率。</li><li>为了有助于提高计算效率和可持续的语言模型，研究人员提出了一种称为<a href="https://www.microsoft.com/en-us/research/publication/bitnet-scaling-1-bit-transformers-for-large-language-models/">BitNet</a>的 1 位转换器架构。</li><li> Microsoft 通过<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">27 亿个参数的 Phi-2</a>扩展了其 Phi 系列小语言模型，这提高了具有多达 130 亿个参数的基本模型的推理和语言理解的门槛。 Phi-2 在复杂基准测试中的性能也达到或超过了其尺寸 25 倍的模型。</li><li>语言模型<a href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/">Orca</a> （130 亿个参数）和几个月后<a href="https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/">Orca 2</a> （70 亿和 130 亿个参数）的发布展示了改进的训练方法（例如合成数据创建）如何将小型模型推理提升到同等水平与更大的模型。</li><li>为了更准确地反映人们如何跨媒介创作的 AI 体验， <a href="https://www.microsoft.com/en-us/research/blog/breaking-cross-modal-boundaries-in-multimodal-ai-introducing-codi-composable-diffusion-for-any-to-any-generation/">可组合扩散</a>(CoDi) 将文本、音频和图像等模态混合作为输入，并生成多模态输出，例如具有同步音频的视频。</li><li>为了更好地模拟人类推理并加快响应时间，新的<a href="https://www.microsoft.com/en-us/research/blog/skeleton-of-thought-parallel-decoding-speeds-up-and-improves-llm-output/">思维</a>框架方法让法学硕士将任务分为两部分——创建响应大纲并并行提供每个点的详细信息。</li></ul><h3 class="wp-block-heading" id="advancing-methods-for-model-usage">改进模型使用方法</h3><ul><li><a href="https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/">AutoGen</a>是一个开源框架，用于简化 LLM 工作流程的编排、优化和自动化，以支持和简化基于 LLM 的应用程序的创建。</li><li> <a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">Medprompt</a>是一系列提示策略的组合，它表明，仅通过深思熟虑和先进的提示，通用基础模型就可以<em>胜过</em>专门模型，为对专家策划的数据进行微调提供更高效、更容易的替代方案。</li><li>资源收集<a href="https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/">提示库</a>提供了旨在帮助优化基础模型性能的提示技术和工具，包括 Medprompt，它已扩展到医学以外的应用。</li><li> <a href="https://www.microsoft.com/en-us/research/blog/llmlingua-innovating-llm-efficiency-with-prompt-compression/">LLMLingua</a>旨在解决与冗长输入相关的问题，例如响应延迟增加，是一种提示压缩方法，利用小型语言模型来删除不必要的标记。</li></ul><h3 class="wp-block-heading" id="developing-and-sharing-best-practices">开发和分享最佳实践</h3><ul><li>微软宣布与多家行业合作伙伴<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf" target="_blank" rel="noreferrer noopener">成立微尺度 (MX) 联盟<span class="sr-only">（在新选项卡中打开）</span> ，</a>并推出业界首个开放数据格式，旨在为 AI 模型实现低于 8 位的训练和推理，帮助为更高效、更高效的人工智能模型铺平道路。可扩展的深度学习。</li><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://blogs.microsoft.com/on-the-issues/2023/07/21/commitment-safe-secure-ai/">微软继续在自身实践和整个行业内推进人工智能的负责任发展，支持白宫的自愿人工智能承诺</a>。与此同时，公司研究社区的成员继续仔细<a href="https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/">检查模型的功能和局限性，并研究人工智能危害的识别、测量和减轻</a>，包括多模式人工智能领域。他们还将透明度视为负责任的、以人为本的人工智能的基石，包括通过<a href="https://www.microsoft.com/en-us/research/podcast/abstracts-october-23-2023/">联合审计工具</a>来评估人工智能生成内容的准确性。</li></ul><h2 class="wp-block-heading" id="accelerating-scientific-exploration-and-discovery">加速科学探索和发现</h2><p>微软利用人工智能和其他先进技术来加速和转变科学发现，为世界各地的研究人员提供领先的工具。在微软全球研究实验室中，机器学习、量子物理学、分子生物学和许多其他学科的专家正在应对自然科学和生命科学领域面临的紧迫挑战。</p><ul><li>由于多个变量带来的复杂性以及天气固有的混乱性质，微软正在使用机器学习来提高<a href="https://www.microsoft.com/en-us/research/blog/improving-subseasonal-forecasting-with-machine-learning/" target="_blank" rel="noreferrer noopener">ecast</a>的<a href="https://www.microsoft.com/en-us/research/blog/improving-subseasonal-forecasting-with-machine-learning/">次季节</a>的准确性。</li><li> <a href="https://www.microsoft.com/en-us/research/blog/distributional-graphormer-toward-equilibrium-distribution-prediction-for-molecular-systems/">分布式图形分析器</a>(DIG) 是一种深度学习框架，用于更准确地预测蛋白质结构，这是分子科学中的一个基本问题。这一进展可能有助于在材料科学和药物发现等关键研究领域取得突破。</li><li>利用进化规模的蛋白质数据，通用扩散框架<a href="https://www.microsoft.com/en-us/research/podcast/abstracts-september-13-2023/">EvoDiff</a>有助于更有效地设计新型蛋白质，这有助于工业酶的开发，包括用于治疗的酶。</li><li> <a href="https://www.microsoft.com/en-us/research/publication/mofdiff-coarse-grained-diffusion-for-metal-organic-framework-design/">MOFDiff</a>是一种粗粒度扩散模型，可帮助科学家完善新型金属有机框架 (MOF) 的设计，以低成本去除空气和其他稀释气流中的二氧化碳。这项创新可以在减缓气候变化方面发挥至关重要的作用。</li><li> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/">微软研究院播客系列<em>合作者</em></a>的这一集探讨了可再生能源存储系统（特别是液流电池）的研究，并讨论了机器学习如何帮助识别用于存储水力和推进碳捕获的理想化合物。</li><li><a href="https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/">MatterGen</a>是一种扩散模型，专门设计用于通过高效生成具有所需特性（例如锂离子电池的高导电性）的新型稳定材料来解决材料科学的核心挑战。</li><li>深度学习有望彻底改变自然科学，增强对自然事件的建模和预测，开创科学探索的新时代，并导致从药物开发到可再生能源等领域的重大进步。 <a href="https://www.microsoft.com/en-us/research/blog/announcing-the-deepspeed4science-initiative-enabling-large-scale-scientific-discovery-through-sophisticated-ai-system-technologies/">DeepSpeed4Science</a>是微软的一项新举措，旨在通过人工智能系统技术创新构建独特的功能，帮助领域专家解开当今最大的科学谜团。</li><li>微软技术研究员兼 AI4Science 团队总监 Christopher Bishop 最近出版了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.bishopbook.com/" target="_blank" rel="noreferrer noopener">《深度学习：基础与概念》</a>一书，该书“全面介绍了支撑深度学习的思想”。 Bishop 在<em>AI Frontiers</em>播客系列中讨论了<a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-a-deep-dive-into-deep-learning-with-ashley-llorens-and-chris-bishop/">这本书背后的动机和过程，以及深度学习对自然科学的影响</a>。</li></ul><h2 class="wp-block-heading" id="maximizing-the-individual-and-societal-benefits-of-ai"> 最大化人工智能的个人和社会效益</h2><p>随着人工智能模型能力的增强，人们获得更多成就的机会也随之增加，微软今年在健康和教育等领域的工作就证明了这一点。该公司对人类积极影响的承诺要求人工智能技术公平且易于使用。</p><ul><li>微软研究与孵化公司副总裁 Peter Lee 探索了<a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/">法学硕士及其驱动的系统的潜力，以以前的人工智能进步不可能实现的方式影响医疗保健</a>。他和合著者在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.informit.com/store/ai-revolution-in-medicine-gpt-4-and-beyond-9780138200138" target="_blank" rel="noreferrer noopener">《医学中的人工智能革命：GPT-4 和超越》</a> <a href="https://www.microsoft.com/en-us/research/publication/benefits-limits-and-risks-of-gpt-4-as-an-ai-chatbot-for-medicine/">一</a>书中以及<a href="https://www.microsoft.com/en-us/research/publication/benefits-limits-and-risks-of-gpt-4-as-an-ai-chatbot-for-medicine/">《新英格兰医学杂志》的“医学中的人工智能”特别报告</a>中研究了 GPT-4。</li><li>研究人员不断推进AI在放射学领域的应用， <a href="https://www.microsoft.com/en-us/research/blog/gpt-4s-potential-in-shaping-the-future-of-radiology/">测试GPT-4在该领域的边界</a>。他们还引入了一个<a href="https://www.microsoft.com/en-us/research/blog/accounting-for-past-imaging-studies-enhancing-radiology-ai-and-reporting/">视觉语言预训练框架，可以实现文本和多个放射学图像之间的对齐</a>，以及<a href="https://www.microsoft.com/en-us/research/publication/maira-1-a-specialised-large-multimodal-model-for-radiology-report-generation/">用于生成放射学报告的多模态模型</a>。</li><li>微软在放射学领域的努力已经支持了现实世界的结果，其<a href="https://www.microsoft.com/en-us/research/podcast/collaborators-project-innereye-with-javier-alvarez-and-raj-jena/">研究为英国一家医院开发的人工智能系统<span class="sr-only">（在新选项卡中打开）</span>做出了贡献，</a>该系统正在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://news.microsoft.com/en-gb/2023/06/27/ai-helping-shrink-waiting-times-nhs-cancer-patients/">帮助癌症患者更快地开始治疗<span class="sr-only">（在新选项卡中打开）</span></a> 。</li><li>研究人员表明， <a href="https://www.microsoft.com/en-us/research/blog/exploring-llms-potential-to-help-facilitators-enhance-online-healthcare-communities/">支持法学硕士的副驾驶可以帮助由患者和提供者组成的同伴支持聊天小组的主持人</a>为成员起草教育内容，通过消息摘要跟踪长时间讨论，并识别错误信息或有害建议，从而加强在线健康社区作为信息和服务来源的地位。支持。</li><li> <a href="https://www.microsoft.com/en-us/research/blog/teachers-in-india-help-microsoft-research-design-ai-tool-for-creating-great-classroom-content/">Shiksha copilot 研究项目的试点项目是一款人工智能数字助理</a>，正在帮助印度教师更快地制定全面、适合年龄的课程计划，为更多学生指导和专业发展腾出时间。</li><li> Shiksha copilot 是一项名为<a href="https://www.microsoft.com/en-us/research/project/project-vellm/">VeLLM 项目的</a>更大努力的一部分，该项目旨在帮助所有语言和文化的人们利用法学硕士提供的好处，包括改进非英语语言的模型。微软印度研究院公司副总裁兼董事总经理<a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-in-india-and-beyond-with-sriram-rajamani/">Sriram Rajamani 谈到了该项目以及实验室技术和赋能重点领域的其他工作</a>。</li></ul><h2 class="wp-block-heading" id="beyond-ai-leading-technology-innovation">超越AI：引领科技创新</h2><p>虽然人工智能在当前的研究领域理所当然地受到了广泛关注，但微软的研究人员仍在一系列技术重点领域取得了大量进展。</p><ul><li> <a href="https://www.microsoft.com/en-us/research/blog/project-silica-sustainable-cloud-archival-storage-in-glass/">Project Silica</a>是一种以石英玻璃为基础的基于云的存储系统，旨在提供可持续且持久的档案存储，理论上可以持续数千年。</li><li>项目<a href="https://www.microsoft.com/en-us/research/blog/unlocking-the-future-of-computing-the-analog-iterative-machines-lightning-fast-approach-to-optimization/">模拟迭代机</a>(AIM) 旨在及时、节能且经济高效地解决困难的优化问题，这些问题对于金融、物流、运输、能源、医疗保健和制造等行业至关重要。其设计者相信 Project AIM 的性能甚至可以超越最强大的数字计算机。</li><li>微软研究人员与苏格兰和加纳的医生和政府进行了独特的合作，证明使用<a href="https://www.microsoft.com/en-us/research/project/holoportation-3/">Holoportation <sup>TM</sup></a>通信技术的<a href="https://www.microsoft.com/en-us/research/blog/3d-telemedicine-brings-better-care-to-underserved-and-rural-communities-even-across-continents/">3D 远程医疗</a>(3DTM) 可以帮助改善医疗保健服务，甚至可以跨大陆。</li><li>在另一项旨在帮助改善精准医疗的合作中，微软与业界和学术界同事合作发布了<a href="https://www.microsoft.com/en-us/research/blog/biomedical-research-platform-terra-now-available-on-microsoft-azure/">Terra</a> ，这是一个安全、集中、基于云的平台，用于 Microsoft Azure 上的生物医学研究。</li><li>在硬件方面，微软研究人员正在探索<a href="https://www.microsoft.com/en-us/research/blog/thinking-beyond-audio-augmenting-headphones-for-everyday-digital-interactions/">传感器增强型耳机</a>，为其配备使用头部方向和手势的控件，以实现上下文感知隐私、手势视听控制以及源自自然肢体语言的动画化身。 </li></ul><h2 class="wp-block-heading" id="collaborating-across-academia-industries-and-disciplines">跨学术界、行业和学科的合作</h2><p>跨公司、跨学科的合作一直在研究中发挥着重要作用，随着人工智能的不断快速发展，更是如此。 <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/">推动进步的大型模型是更大系统的组成部分，将为人们带来人工智能的价值</a>。开发这些系统和框架来确定它们在人们生活和社会中的角色，需要那些了解它们运行环境的人的知识和经验——领域专家、学者、使用这些系统的个人和其他人。</p><ul><li>研究项目<a href="https://www.microsoft.com/en-us/research/publication/understanding-personalized-accessibility-through-teachable-ai-designing-and-evaluating-find-my-things-for-people-who-are-blind-or-low-vision/">“查找我的东西”</a>是一个帮助盲人或弱视人士找到个人物品的应用程序，该<a href="https://www.microsoft.com/en-us/research/podcast/collaborators-teachable-ai-with-cecily-morrison-and-karolina-pakenaite/">项目汇集了研究人员和公民设计师，</a>展示了如何个性化人工智能体验以满足人们的个人需求，这种方法被称为<a href="https://www.microsoft.com/en-us/research/project/taix/overview/">“可教人工智能”</a> 。</li><li> Microsoft 的产品、研究和孵化团队继续合作，为客户和开源社区提供用于 AI 负责任开发的工具， <a href="https://www.microsoft.com/en-us/research/blog/responsible-ai-the-research-collaboration-behind-new-open-source-tools-offered-by-microsoft/">并于 2 月份将 Responsible AI 缓解库和 Responsible AI 跟踪器添加到公司的 Responsible AI 工具箱中</a>。</li><li>微软的研究人员与心理测量学心理学子领域的研究人员合作，探索随着<a href="https://www.microsoft.com/en-us/research/podcast/abstracts-december-6-2023/">人工智能模型变得更加通用，心理测量科学如何帮助评估模型性能</a>。</li><li>负责任的人工智能研究人员和应用科学家<a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-measuring-and-mitigating-harms-with-hanna-wallach/">扩展了他们一直致力于衡量人工智能系统中与公平相关的危害的框架，</a>以适应将 GPT-4 纳入 Bing 所呈现的新场景。</li><li>研究人员提出了<a href="https://www.microsoft.com/en-us/research/podcast/abstracts-november-20-2023/">一个思考生成人工智能对人们沟通方式影响的框架</a>，以及一系列应对挑战的策略。</li><li>微软研究院建立了<a href="https://www.microsoft.com/en-us/research/blog/accelerate-foundation-models-research-supporting-a-global-academic-research-ecosystem-for-ai/">加速基础模型研究 (AFMR) 全球网络和资源平台<span class="sr-only">（在新选项卡中打开）</span> ，</a>以组建一个跨学科研究社区，通过将人工智能与人类共同的目标、价值观和偏好结合起来，解决当今一些最大的技术和社会挑战;改善人机交互；并加速科学发现。根据微软对白宫负责任的人工智能自愿承诺的支持， <a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/overview/">AFMR <span class="sr-only">（在新选项卡中打开）</span></a>拨款提供了对最先进基础模型的访问，以确保<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2023/07/Microsoft-Voluntary-Commitments-July-21-2023.pdf">公司外部的研究人员能够适当地检查尖端模型应用程序<span class="sr-only">（在新选项卡中打开）</span></a>及其影响。迄今为止，来自世界各地 100 多个机构的 190 多名主要研究人员可以使用领先的基金会模型。</li><li><a href="https://www.microsoft.com/en-us/research/academic-program/ai-society-fellows/overview/">微软研究院人工智能与社会研究员计划</a>旨在汇集来自艺术和科学领域的学者和领先专家，共同应对人工智能与社会交叉领域的挑战和机遇——从法学硕士时代的版权保护到减少数字鸿沟。全球南方。该项目在今年秋季的首次征集期间收到了涉及 13 个挑战的近 3,000 份提案，选定的研究员名单将于 2024 年 1 月公布。</li></ul><h2 class="wp-block-heading" id="engaging-and-supporting-the-larger-research-community"> 参与和支持更大的研究社区</h2><p>在这一年中，微软继续与更广泛的人工智能及其他领域的研究社区进行合作。该公司对重要会议的赞助和参与不仅展示了其对人工智能在不同技术领域应用的奉献精神，还强调了其对前沿进步和协作社区参与的坚定支持。</p><h3 class="wp-block-heading" id="functional-programming">函数式编程</h3><ul><li>Microsoft 是<a href="https://www.microsoft.com/en-us/research/event/icfp-2023/">ICFP 2023</a>的赞助商，其研究贡献涵盖了一系列函数式编程主题，包括<a href="https://www.microsoft.com/en-us/research/blog/fp2-fully-in-place-functional-programming-provides-memory-reuse-for-pure-functional-programs/">内存优化</a>、语言设计和软件开发技术。</li></ul><h3 class="wp-block-heading" id="human-computer-interaction">人机交互</h3><ul><li>在<a href="https://www.microsoft.com/en-us/research/blog/highlights-from-chi-2023/">CHI 2023</a>上，微软研究人员及其合作者展示了人们今天和未来使用计算的无数种不同方式。</li></ul><h3 class="wp-block-heading" id="large-language-models-and-ml">大型语言模型和机器学习</h3><ul><li>微软是<a href="https://www.microsoft.com/en-us/research/event/acl-2023/">ACL 2023</a>的赞助商，展示了从语言模型的公平性到自然语言生成等的论文。</li><li>微软还赞助了<a href="https://www.microsoft.com/en-us/research/event/neurips-2023/">NeurIPS 2023</a> ，发表了 100 多篇论文，并举办了关于语言模型、深度学习技术以及解决该领域紧迫问题的其他概念、方法和应用程序的研讨会。</li><li>通过对<a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-icml-2023-discoveries-and-advancements-in-machine-learning/">ICML 2023</a>的赞助和贡献，微软展示了其在推进机器学习领域的投资。</li><li>微软赞助了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml4h.cc/2023/" target="_blank" rel="noreferrer noopener">ML4H <span class="sr-only">（在新选项卡中打开）</span></a>并参加了<a href="https://www.microsoft.com/en-us/research/blog/exploring-llms-potential-to-help-facilitators-enhance-online-healthcare-communities/">AfriCHI <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2023.emnlp.org/" target="_blank" rel="noreferrer noopener">EMNLP <span class="sr-only">（在新选项卡中打开）（</span></a>自然语言处理和人工智能领域的领先会议），强调了其致力于探索法学硕士如何应用于医疗保健的承诺和其他重要领域。</li></ul><h3 class="wp-block-heading" id="systems-and-advanced-networking">系统和先进的网络</h3><ul><li>微软在其赞助的<a href="https://www.microsoft.com/en-us/research/event/sosp-2023/">SOSP 2023</a>会议上做出的研究贡献涵盖了从操作系统、云计算到移动和边缘系统。</li><li>作为<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.usenix.org/conference/nsdi23" target="_blank" rel="noreferrer noopener">USENIX NDSI 2023</a>的赞助商，微软强化了其<a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-nsdi-2023-a-commitment-to-advancing-networking-and-distributed-systems/">对推进网络和分布式系统的承诺</a>，接受的论文涵盖人工智能工作负载网络、云、广域网和无线网络等不同主题，展示了网络研究的前沿进展。</li><li> Microsoft 是欧洲首屈一指的系统会议<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://2023.eurosys.org/" target="_blank" rel="noreferrer noopener">EuroSys 2023</a>的重要参与者，强调了<a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-eurosys-2023-systems-innovation-across-the-stack-to-help-support-an-easier-faster-safer-and-smarter-cloud/">整个堆栈系统创新的发展，以帮助支持更简单、更快、更安全和更智能的云</a>。</li><li>作为<a href="https://www.microsoft.com/en-us/research/event/sigcomm-2023/">SIGCOMM 2023</a>的赞助商， <a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-acm-sigcomm-2023-innovating-the-future-of-networking/">微软分享了其在支撑云生态系统的基础网络基础设施方面的创新</a>。</li><li>从对生成模型和网络预训练的贡献，到手语理解和神经视频编解码器，该公司参加<a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-cvpr-2023-pushing-the-boundaries-of-computer-vision/">CVPR 2023</a>强调了其致力于发展系统能力，以分析和从视觉数据中提取有价值的见解。</li></ul><h2 class="wp-block-heading" id="listeners-choice-notable-podcasts-for-2023">听众选择：2023 年著名播客</h2><ul><li><a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-future-of-causal-reasoning-with-emre-kiciman-and-amit-sharma/">人工智能前沿：Emre Kiciman 和 Amit Sharma 的因果推理的未来</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/">AI 前沿：Peter Lee 的 AI 健康与研究的未来</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/">人工智能前沿：Ece Kamar 的模型和系统</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-in-india-and-beyond-with-sriram-rajamani/">人工智能前沿：印度及其他地区的人工智能与 Sriram Rajamani</a></li><li> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-physics-of-ai-with-sebastien-bubeck/">人工智能前沿：Sébastien Bubeck 的人工智能物理学</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-measuring-and-mitigating-harms-with-hanna-wallach/">人工智能前沿：与 Hanna Wallach 一起衡量和减轻危害</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-future-of-scale-with-ahmed-awadallah-and-ashley-llorens/">人工智能前沿：艾哈迈德·阿瓦达拉 (Ahmed Awadallah) 和阿什利·洛伦斯 (Ashley Llorens) 的规模化未来</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/">合作者：Gov4git、Petar Maymounkov 和 Kasia Sitkiewicz</a></li><li> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gaming-ai-with-haiyan-zhang/">合作者：游戏人工智能与张海燕</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/">合作者：Bichlien Nguyen 和 David Kwabi 的可再生能源存储</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-data-driven-decision-making-with-jina-suh-and-shamsi-iqbal/">合作者：Jina Suh 和 Shamsi Iqbal 的数据驱动决策</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-holoportation-communication-technology-with-spencer-fowers-and-kwame-darko/">合作者：全息传输<img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2122.png" alt="™" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Spencer Fowers 和 Kwame Darko 的通信技术</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-project-innereye-with-javier-alvarez-and-raj-jena/">合作者：InnerEye 项目、Javier Alvarez 和 Raj Jena</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/whats-your-story-ranveer-chandra/">你的故事是什么：兰维尔·钱德拉</a></li><li><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-september-13-2023/">摘要：2023 年 9 月 13 日，EvoDiff</a></li></ul><h2 class="wp-block-heading" id="thank-you-for-reading">感谢您的阅读</h2><p>Microsoft 在 2023 年实现了非凡的里程碑，并将继续突破创新界限，帮助塑造技术以非凡方式服务人类的未来。要了解最新更新，请订阅<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html?wt.mc_id=S-webpage_msr-homepage">Microsoft Research 通讯<span class="sr-only">（在新选项卡中打开）</span></a>和<a href="https://www.microsoft.com/en-us/research/podcast/">Microsoft Research 播客<span class="sr-only">（在新选项卡中打开）</span></a> 。您还可以在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.facebook.com/microsoftresearch/" target="_blank" rel="noreferrer noopener">Facebook <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.instagram.com/msft_research/" target="_blank" rel="noreferrer noopener">Instagram <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/showcase/microsoftresearch/" target="_blank" rel="noreferrer noopener">LinkedIn <span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://twitter.com/MSFTResearch" target="_blank" rel="noreferrer noopener">X <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.youtube.com/user/MicrosoftResearch" target="_blank" rel="noreferrer noopener">YouTube <span class="sr-only">（在新选项卡中打开）上关注我们</span></a>。</p><div class="wp-block-columns"><div class="wp-block-column"><p><strong>作家、编辑和制片人</strong><br>克里斯蒂娜·道奇<br>凯特·福斯特<br>杰西卡·加特纳<br>艾莉莎·休斯<br>格雷琴·惠津加<br>布伦达·波茨<br>克里斯·斯泰特凯维奇<br>拉里·韦斯特</p></div><div class="wp-block-column"><p><strong>总编辑</strong><br>琥珀刺痛</p><p><strong>专案经理</strong><br>阿曼达梅尔菲</p><p><strong>微软研究院全球设计主管</strong><br>内尔杰·伯杰</p></div><div class="wp-block-column"><p><strong>平面设计师</strong><br>亚当·布莱斯<br>哈雷·韦伯</p><p><strong>微软研究院创意工作室负责人</strong><br>马特·科文</p></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/research-at-microsoft-2023-a-year-of-groundbreaking-ai-advances-and-discoveries/">《微软研究 2023：人工智能突破性进展和发现的一年》一文</a>首先出现在<a href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>