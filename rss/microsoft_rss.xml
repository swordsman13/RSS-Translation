<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 11 月 21 日星期二 18:02:40 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.2</generator><item><title> Orca 2：教授小语言模型如何推理</title><link/>https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 21 Nov 2023 02:04:33 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>在微软，我们通过训练小型语言模型来扩展人工智能能力，以实现通常只有在更大的模型中才能实现的增强推理和理解能力。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/">《Orca 2：教授小语言模型如何推理》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img decoding="async" fetchpriority="high" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1024x576.png" alt="Orca-2 博客英雄 |抽象数据波" class="wp-image-985938" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>几个月前，我们推出了<a href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/">Orca</a> ，这是一个 130 亿的语言模型，通过模仿能力更强的 LLM 的逐步推理轨迹，展示了强大的推理能力。</p><p> Orca 2 是我们探索小型 LM 功能（参数数量级为 100 亿或更少）的最新举措。通过 Orca 2，我们继续证明改进的训练信号和方法可以使较小的语言模型获得增强的推理能力，而这种能力通常只在较大的语言模型中才能找到。</p><p>根据在零样本设置中测试高级推理能力的复杂任务的评估，Orca 2 显着超越了类似大小的模型（包括原始 Orca 模型），并达到了与大 5-10 倍的模型相似或更好的性能水平。</p><p> Orca 2 有两种大小（70 亿和 130 亿参数）；两者都是通过根据定制的高质量合成数据微调相应的 LLAMA 2 基础模型而创建的。我们正在公开 Orca 2 权重，以鼓励对小型 LM 的开发、评估和调整进行研究。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/">阅读 Orca 论文</a></div><div class="wp-block-button is-style-outline"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/orca-2-teaching-small-language-models-how-to-reason/">阅读 Orca 2 论文</a></div></div><h2 class="wp-block-heading" id="using-llms-to-train-smaller-language-models">使用法学硕士训练较小的语言模型</h2><p>GPT-4、PaLm等前沿语言模型表现出了非凡的推理能力，例如回答复杂问题、生成解释，甚至解决需要多步推理的问题；曾经被认为超出人工智能能力范围的能力。传统上，这种能力在较小的语言模型中尚未观察到，因此挑战是如何利用我们对大型语言模型不断增长的知识来提高这些较小模型的能力。</p><h2 class="wp-block-heading" id="expanding-the-capabilities-of-smaller-language-models">扩展较小语言模型的功能</h2><p>Orca 2 背后的一个关键见解是，不同的任务可以从不同的解决方案策略中受益（例如，逐步处理、回忆然后生成、回忆-推理-生成、提取-生成和直接答案），并且解决方案策略对于较小的模型来说，大型模型所采用的可能不是最佳选择。例如，虽然像 GPT-4 这样功能强大的模型可以直接回答复杂的任务，但较小的模型可能会从将任务分解为步骤中受益。</p><p> Orca 2 使用扩展的、高度定制的合成数据集进行训练。生成的训练数据可以教授 Orca 2 各种推理技术，例如逐步处理、回忆然后生成、回忆-推理-生成、提取-生成和直接答案方法，同时还教它选择不同的推理方法。不同任务的解决策略。</p><p>训练数据是从能力更强的教师模型中获得的。请注意，我们可以通过非常详细的说明甚至多次调用来获取教师的响应，具体取决于任务和模型的所需行为。在缺乏详细说明如何完成任务的原始指令的情况下，将鼓励学生模型学习基本策略及其引发的推理能力。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956142"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-holoportation-communication-technology-with-spencer-fowers-and-kwame-darko/" aria-label="Collaborators: Holoportation&#x2122; communication technology with Spencer Fowers and Kwame Darko" data-bi-cN="Collaborators: Holoportation&#x2122; communication technology with Spencer Fowers and Kwame Darko" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/collaborators_3DTelemed_1400x788.jpg" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：全息传输<img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2122.png" alt="™" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Spencer Fowers 和 Kwame Darko 的通信技术</h2><p class="large">Spencer Fowers 和 Kwame Darko 详细介绍了 Holoportation 背后的技术以及围绕该技术构建的电信设备如何将患者和医生聚集在一起（当患者和医生待在同一个房间并不容易的情况下），并讨论了这项工作的潜在影响。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-holoportation-communication-technology-with-spencer-fowers-and-kwame-darko/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Holoportation&#x2122; communication technology with Spencer Fowers and Kwame Darko" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="orca-2-has-reasoning-capabilities-comparable-to-much-larger-models"> Orca 2 的推理能力可与更大的模型相媲美</h2><p>为了评估 Orca 2，我们使用了一套全面的 15 个不同的基准测试，这些基准测试对应于零样本设置中的大约 100 个任务和超过 36,000 个独特的测试用例。基准测试涵盖多个方面，包括语言理解、常识推理、多步推理、数学问题解决、阅读理解、总结、扎根性、真实性以及有毒内容生成和识别。</p><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final.png"><img decoding="async" width="2498" height="781" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final.png" alt="在各种基准（0 次设置）上比较 Orca 2（7B 和 13B）与 LLaMA-2-Chat（13B 和 70B）和 WizardLM（13B 和 70B）的结果，涵盖语言理解、常识推理、多步推理Orca 2 模型显着超越其他模型，包括大 10 倍的模型。请注意，Orca 2 模型是通过持续训练相同大小的 LLaMA-2 基础模型来训练的。" class="wp-image-986271" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final.png 2498w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-300x94.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-1024x320.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-768x240.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-1536x480.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-2048x640.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-240x75.png 240w" sizes="(max-width: 2498px) 100vw, 2498px" /></a><figcaption class="wp-element-caption">图 1：Orca 2（7B 和 13B）与 LLaMA-2-Chat（13B 和 70B）以及 WizardLM（13B 和 70B）在各种基准（零样本设置）上的比较结果，涵盖语言理解、常识推理、 Orca 2 模型可匹配或超越其他模型，包括大 5-10 倍的模型。请注意，该图中的所有模型共享相同的基础模型 (LLAMA-2)。</figcaption></figure><p>我们的初步结果表明，Orca 2 的性能明显优于类似尺寸的型号。它还达到了与至少大 10 倍的模型相似或更好的性能水平，展示了为较小模型配备更好推理能力的潜力。</p><p> Orca 2 模型表现出与其他语言模型相同的局限性，并且可以保留其训练基础模型的许多约束。虽然 Orca 2 训练可以应用于不同的基础模型，但我们报告基于使用 LLaMA-2 7B 和 13B 模型的结果。 Orca 2 模型尚未经过人类反馈强化学习 (RLHF) 安全训练。</p><h2 class="wp-block-heading" id="conclusion">结论</h2><p>我们对 Orca 2 模型的研究对于增强小型语言模型的推理能力产生了重要的见解。通过使用定制的合成数据战略性地训练这些模型，我们已经达到了与大型模型相媲美或超越的性能水平，特别是在零样本推理任务中。</p><p> Orca 2 的成功在于它对多种推理技术的应用以及对各种任务的最佳解决方案的识别。虽然它有一些局限性，包括从其基本模型继承的局限性以及其他语言模型所共有的局限性，但 Orca 2 未来进步的潜力是显而易见的，特别是在改进较小模型的推理、专业化、控制和安全性方面。使用经过仔细过滤的合成数据进行训练后成为这些改进的关键策略。</p><p>我们的研究结果强调了较小模型在需要平衡效率和能力的场景中的价值。随着更大的模型继续表现出色，我们与 Orca 2 的合作标志着语言模型应用程序和部署选项多样化的重要一步。</p><figure class="wp-block-image aligncenter size-large"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2.jpg"><img decoding="async" width="777" height="1024" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-777x1024.jpg" alt="这张图片来自报纸"Orca-2: Teaching Small Language Models How To Reason" showcases differences in how Orca 2, LLaMA-2, LLaMA-2-Chat, and ChatGPT (GPT-3.5-Turbo) process and answer a logic-based question. The LLaMA-2 and LLaMA-2-Chat outputs were generated via replicate.com/meta/llama-2-13b and chat.lmsys.org, employing standard settings (temperature=0, top_p=1). ChatGPT's response was retrieved from chat.openai.com, providing a clear comparison of how each model approaches problem-solving." class="wp-image-985878" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-777x1024.jpg 777w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-228x300.jpg 228w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-768x1012.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-137x180.jpg 137w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2.jpg 800w" sizes="(max-width: 777px) 100vw, 777px" /></a><figcaption class="wp-element-caption">这张图片来自论文“Orca-2：教授小语言模型如何推理”，展示了 Orca 2、LLaMA-2、LLaMA-2-Chat 和 ChatGPT (GPT-3.5-Turbo) 处理和回答逻辑的差异 -为基础的问题。 LLaMA-2 和LLaMA-2-Chat 输出是通过replicate.com/meta/llama-2-13b 和chat.lmsys.org 生成的，采用标准设置（温度=0，top_p=1）。 ChatGPT 的响应是从 chat.openai.com 检索的，提供了每个模型如何解决问题的清晰比较。</figcaption></figure><p></p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/">《Orca 2：教授小语言模型如何推理》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>大语言模型中的终身模型编辑：平衡低成本有针对性的编辑和灾难性遗忘</title><link/>https://www.microsoft.com/en-us/research/blog/lifelong-model-editing-in-large-language-models-balancing-low-cost-targeted-edits-and-catastropic-forgetting/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Mon, 20 Nov 2023 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=984255 </guid><description><![CDATA[<p>终身模型编辑修复模型部署后发现的错误。这项工作可以将顺序编辑扩展到公平性和隐私等模型属性，并实现一类新的解决方案，以适应 LLM 的长期部署生命周期。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/lifelong-model-editing-in-large-language-models-balancing-low-cost-targeted-edits-and-catastrophic-forgetting/">大语言模型中的终身模型编辑：平衡低成本目标编辑和灾难性遗忘</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1.png" alt="用 GRACE 进行终生模型编辑的插图。左边是一个问题以及模型的现有答案（这是不正确的）。编辑方法需要更新它的正确答案。中间显示了架构，其中语言模型被冻结，嵌入被提取以从码本中检索适当的值（新嵌入）。右侧显示了密码本，其中包括一组可训练的嵌入。" class="wp-image-984291" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-2023-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>大型语言模型 (LLM) 对于大量困难任务非常有用。但他们有时会犯不可预测的错误或使带有偏见的语言长期存在。由于底层数据或用户行为的变化，这些类型的错误往往会随着时间的推移而出现。这就需要对这些模型及其支持的实际应用程序进行有针对性的、具有成本效益的修复。</p><p>可以使用重复的预训练或微调来实现这些修复。然而，这些解决方案的计算成本往往太高。 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/pdf/2302.13971.pdf" target="_blank" rel="noreferrer noopener">例如<span class="sr-only">（在新选项卡中打开）</span></a> ，LLAMA 1 在 2,048 个 A100 GPU 上训练了 21 天，成本超过 240 万美元。微调法学硕士需要比许多研究实验室能够持续且经济地访问的更大的 GPU。另外，在很大程度上仍然不知道应该在数据语料库中添加或删除哪些数据以纠正特定行为而不影响不相关的输入。</p><p>为了让法学硕士在不需要昂贵培训的情况下保持最新状态，<em>模型编辑</em>最近被提议作为对大型模型进行有针对性的更新的范例。大多数模型编辑器更新模型<em>一次</em>，注入一批修正。但随着时间的推移，错误往往会逐渐被发现，并且必须迅速纠正。换句话说，在部署模型时，<em>终身</em>模型编辑至关重要，其中遇到一系列错误并且必须立即解决。这需要按顺序进行多次编辑，已知现有编辑器在这种情况下会失败。这里的成功意味着按顺序纠正所有编辑，不会忘记旧的修复，也不会降低不相关输入的性能。但<em>编辑</em>到底是什么？在<a href="https://www.microsoft.com/en-us/research/publication/aging-with-grace-lifelong-model-editing-with-discrete-key-value-adaptors/" target="_blank" rel="noreferrer noopener">优雅地老化：使用离散键值适配器进行终身模型编辑中，</a>考虑了三种类型的编辑：</p><ol type="1"><li><em>更新事实知识</em>。假设我们有一个预先训练的问答模型：我们传入问题，模型返回答案。但随着世界的变化，这些答案变得过时了。例如，回答“谁是美国总统？”选举后应该改变。因此，编辑是一个元组 - 或值的有序序列 - 包含问题（例如，“谁是美国总统？”）和该问题的正确答案（例如，“拜登”）。</li><li><em>跟上翻转标签的步伐</em>。分类任务中的基本事实可能会随着时间而改变。例如，当美国法院使用新语言描述现有主题时，文档的正确标签可能会发生变化。在这种情况下，必须纠正在旧标签上训练的模型。当仅重新标记特定类型的数据时（这种情况很常见），有针对性的编辑尤其重要。在这种情况下，编辑是配对输入（例如，法庭文件）和新标签（例如，主题）。</li><li><em>减少法学硕士中的捏造和不连贯性</em>。使用法学硕士的一个关键挑战是避免它们生成不符合现实的语言的情况。但这种情况在某些模型中可能比其他模型更常见。因此，当它确实发生时，随后的编辑应该尽可能小。为了探索这种方法的有效性，研究人员考虑在生成名人传记时缓解这个问题。在识别出手工注释的捏造行为后，他们编辑法学硕士，以从真实的维基百科文章中生成相应的句子。在这种情况下，编辑是一个提示和相应的响应，现有模型认为这是不可能的。</li></ol><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1.png"><img decoding="async" loading="lazy" width="2155" height="520" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1.png" alt="该图显示了所提议方法的概述。左侧显示一个问题（最近的流行病是什么？）以及模型的现有答案（猪流感），这是一个错误答案，编辑方法需要将其更新为正确答案（COVID）。中间显示了架构，其中语言模型被冻结，嵌入被提取以从码本中检索适当的值（新嵌入）。右侧显示了密码本，其中包括一组可训练的嵌入。" class="wp-image-984267" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1.png 2155w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1-300x72.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1-1024x247.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1-768x185.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1-1536x371.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1-2048x494.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig1-240x58.png 240w" sizes="(max-width: 2155px) 100vw, 2155px" /></a><figcaption class="wp-element-caption"><strong>图 1.</strong>使用 GRACE 进行终身模型编辑的概述。模型会犯一些必须纠正的重要错误。因此，GRACE 通过学习、缓存和有选择地检索层之间的新转换来进行编辑。经过长时间的编辑（偶尔出现并需要快速修复），GRACE 密码本会不断增长和适应。</figcaption></figure><p>为了对法学硕士进行经济有效的编辑，我们提出了一种称为连续编辑通用检索适配器（GRACE）的方法。 GRACE 是第一种仅使用流错误即可对任何预训练模型架构进行数千次顺序编辑的方法。这种方法简单而有效：当您想要编辑模型以确保其为输入输出选定的标签时，只需在模型中选择一个层并在该层选择一个嵌入作为输入的嵌入即可。作为示例，可以使用模型第四层计算的输入句子中最终标记的嵌入。然后，缓存此嵌入并学习新的嵌入，这样如果用新的嵌入替换旧的嵌入，模型就会产生所需的响应。原始嵌入称为<em>键</em>，学习的嵌入称为<em>值。</em>通过梯度下降学习该值很简单。然后，键和值存储在<em>代码本</em>中，该代码本充当字典。如果您随后将新输入传递给模型，在计算其嵌入（称为<em>查询）</em>后，可以将新查询与现有键进行比较。如果查询与某个键匹配，则可以查找该值并应用编辑。随着许多编辑的流入，它们可以简单地添加到密码本中，顺序应用许多编辑。</p><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1.png"><img decoding="async" loading="lazy" width="2920" height="977" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1.png" alt="带有四个主要列标记的表格"Method", "zsRE", "SCOTUS", and "Hallucination". The "Method" column contains the names of methods we compare against. The last three columns are the names of datasets and each has an associated model. The first is T5, the second is BERT, and the third is GPT2-XL. Each dataset also contains a set of metrics: Edit Retention Rate, Test Retention Rate, the average of Edit and Test Retention Rates, and the number of edits made. The Hallucination dataset contains two extra metrics, which are the Accurate Retention Rate and Inference Time. We compare against seven baselines, which are each shown in a row. The methods in order are Finetune, Finetune with Elastic Weight Consolidation, Finetune with Retraining, MEND, Defer, ROME, Memory, and our method GRACE. For each dataset, GRACE outperforms the comparisons significantly, especially when considering the average of the Edit and Test Retention Rates, which measures the balance between these conflicting goals. The other methods target one or the other, failing to balance. We also show that making edits with GRACE is fast compared to most other methods. " class="wp-image-985347" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1.png 2920w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1-300x100.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1-1024x343.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1-768x257.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1-1536x514.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1-2048x685.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/main_table-1-240x80.png 240w" sizes="(max-width: 2920px) 100vw, 2920px" /></a><figcaption class="wp-element-caption"><strong>表 1.</strong> GRACE 成功编辑模型，而不会忘记以前的编辑或不相关的训练数据，从而优于现有的模型编辑器。在 zsRE 和 SCOTUS 数据集上，GRACE 实现了大幅压缩。在 Hallucination 数据集上，GRACE 成功地将未来很长的标记序列嵌入到缓存值中。</figcaption></figure><p>但这不就是记忆吗？如何在不记住每个新输入的情况下实现通用编辑？每个新键都与一个<em>影响半径</em>配对，而不是总是添加新键，影响半径是一个围绕任何新键的半径为 ε 的球。然后，如果<em>任何</em>查询落在该 ε 球内，则会检索该键的相应值并应用编辑。因此，与任何缓存编辑<em>类似</em>的输入也将被更新。有时，在创建新钥匙时，其 ε 球可能会与另一个钥匙发生冲突。在这种情况下，当冲突的键具有<em>不同的</em>值时，它们的 ε 球被设置为几乎不接触。如果它们具有<em>相同的</em>值，则现有密钥的 ε 会增加以包含新输入。调整 ε 有助于实现可通用的小型密码本，并且可以成功地连续进行数千次编辑。</p><p>为了将 GRACE 的能力与现有方法进行可概括编辑的能力进行比较，使用了两种双向模型（T5 和 BERT）和一种自回归模型（GPT2-XL）。对于问答 (QA)，T5 与<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/pdf/1706.04115.pdf" target="_blank" rel="noreferrer noopener">QA 数据集<span class="sr-only">（在新选项卡中打开）</span></a>一起使用，其中包括针对关系提取的问题。每个问题都有 20 个重新表述的版本，其中 10 个在编辑过程中使用，另外 10 个作为看不见的保留版本。在连续纠正 1,000 个编辑时，所提出的方法显示出比现有方法更好的性能，如表 1 所示。它<em>仅使用 137 个键</em>进行编辑，这显示了所提出方法的效率。这种水平的概括比以前的工作更好，并且显示出纠正未来错误的巨大潜力。所提出的方法还可以成功编辑 BERT 模型，该模型在 1992 年之前<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://supremecourtdatabase.org/" target="_blank" rel="noreferrer noopener">的美国最高法院文件<span class="sr-only">（在新选项卡中打开）</span></a>上进行训练，并在 1992 年之后标签分布发生变化的文件上进行测试。还使用 GRACE 和自回归模型 GPT2-XL 进行了一项实验，以编辑与制造相关的错误，这有望鼓励长序列编辑。例如，当被要求生成 Brian Hughes 的传记时，GRACE 成功地鼓励 GPT2-XL 做出回应：“Brian Hughes（出生于 1955 年）是一位加拿大吉他手，其作品借鉴了流畅的爵士乐和世界音乐流派”，这与<em>仅使用一个缓存值来</em>请求传记。另一个有趣的观察是，GRACE 编辑对于编辑图层的选择是稳健的，尽管<em>后面的图层更难编辑</em>。此外，在选择 ε 时，在记忆和泛化之间观察到了明显的平衡，如图 2 所示。最后，GRACE 的一个关键特征是<em>码本与预训练模型分离，其权重保持不变</em>。这有助于随时撤消任何编辑，并且还可以检查编辑的行为，而无需高昂的计算成本。</p><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2.png"><img decoding="async" loading="lazy" width="2145" height="1175" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2.png" alt="包含八个子图的图形，显示为两行四列。每行代表一个 epsilon 值，它是我们提出的方法中控制泛化的超参数。第一行显示 epsilon 为 0.1，第二行显示 epsilon 为 0.2。每列显示不同指标的折线图。每行显示了使用 zsRE 数据集对 T5 QA 模型进行 3,000 次连续编辑后指标如何变化。每个图包含四行；每行用于编辑不同的 T5 块。我们比较对块 0、2、4 和 6 所做的编辑。从左列开始，我们考虑 TRR 指标，它衡量编辑后原始测试数据的模型准确性。对于 0.1 的 epsilon，TRR 指标始终保持在 0.72，每个块没有差异。对于 3.0 的 epsilon，TRR 指标仅对于块 6 保持在 0.72，并且对于块 0 最低，在编辑结束时降至 0.7 以下。第二列显示 ERR 指标，即每个步骤先前编辑的准确性。在这里我们看到，对于 0.1 的 epsilon，块 2、4 和 6 仍然保持在接近 1.0 的高位。对于 3.0 的 epsilon，块 6 仍然很高，而其他块则下降到 0.9 左右。第三列显示了未见保留编辑的保留表现，这些编辑是已见编辑的改写。每次编辑后，我们都会对编辑后的模型运行所有保留编辑，并记录其在整个集合上的准确性。因此，在这两个图中，我们看到性能随着时间的推移而提高，因为编辑慢慢地覆盖了保留集的更多改写。通过这种方式，我们可以衡量 GRACE 的泛化能力。我们看到，对于 0.1 的 epsilon，块 6 的泛化能力略好于其他块。但对于 3.0 的 epsilon，Block 6 的表现明显低于其他方法。块 0 稍好一些，块 2 和 4 好得多。在最后一栏中，我们报告了 GRACE 进行所有 3,000 次编辑所使用的按键数量。在这里我们看到块 6 只是记住所有编辑，因为它的键数量线性增长。经过 3,000 次编辑后，共有 3,000 个键。但对于块 0、2 和 4，该值会饱和，并且使用更少的键进行编辑。当 epsilon 为 0.1 时，这些块使用大约 2,000 个键。当 epsilon 为 3.0 时，块 0 使用大约 1,000 个密钥，而块 2 和 4 使用大约 800 个密钥。这说明了选择块和 epsilon 如何影响记忆和泛化之间的权衡。总体而言，似乎可概括的编辑发生在内部模型层中，而不是第一层或最后一层以及稍大的 epsilon 选择。" class="wp-image-984282" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2.png 2145w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2-300x164.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2-1024x561.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2-768x421.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2-1536x841.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2-2048x1122.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/GRACE-Fig2-240x131.png 240w" sizes="(max-width: 2145px) 100vw, 2145px" /></a><figcaption class="wp-element-caption"><strong>图 2.</strong>针对不同 epsilon 选择编辑 T5 模型的不同模块时 GRACE 的性能。这种选择推动了无关训练数据 (TRR) 和先前编辑 (ERR) 的准确性之间的平衡，如小 epsilon (a) 和大 epsilon (b) 所示。</figcaption></figure><h2 class="wp-block-heading" id="summary-1">概括</h2><p>GRACE 为模型编辑提供了不同的视角，其中直接修改表示并按顺序缓存转换。编辑可以连续进行数千次，在整个编辑过程中维护一小组密码本。此步骤缩小了实际应用程序部署需求的差距，其中编辑会随着时间的推移而被发现，并应以经济高效的方式解决。通过有效地纠正行为并将顺序编辑扩展到其他模型属性（例如公平性和隐私性），这项工作有可能实现一类新型解决方案，用于调整 LLM 以满足长期部署生命周期内的用户需求。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/lifelong-model-editing-in-large-language-models-balancing-low-cost-targeted-edits-and-catastrophic-forgetting/">大语言模型中的终身模型编辑：平衡低成本目标编辑和灾难性遗忘</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>;</content:encoded></item></channel></rss>