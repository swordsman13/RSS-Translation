<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2024 年 4 月 18 日星期四 19:48:01 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.3</generator><item><title> SAMMO：用于快速优化的通用框架</title><link/>https://www.microsoft.com/en-us/research/blog/sammo-a-general- Purpose-framework-for-prompt-optimization/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Thu, 18 Apr 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1024080 </guid><description><![CDATA[<p> SAMMO 通过利用 LLM 的结构来指导优化，从而优化 LLM 的提示。这可以最大限度地减少寻找各种任务的高效提示所需的时间和精力。</p><p> <a href="https://www.microsoft.com/en-us/research/blog/sammo-a-general-purpose-framework-for-prompt-optimization/">SAMMO：用于即时优化的通用框架一</a>文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1.jpg" alt="SAMMO 优化器图显示从启动提示到优化提示的进展。" class="wp-image-1024131" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>大型语言模型 (LLM) 彻底改变了以前依赖手动制作的机器学习 (ML) 解决方案的各种任务和应用程序，并通过自动化进行了简化。然而，尽管取得了这些进步，一个显着的挑战仍然存在：需要广泛的即时工程以使这些模型适应新任务。 GPT-4 和 Mixtral 8x7B 等新一代语言模型提高了处理长输入文本的能力。这一进展使得能够使用更长的输入，为语言模型提供更丰富的上下文和详细的说明。使用这种增强容量的常见技术是检索增强生成（RAG）方法。 RAG 根据特定的输入示例动态地将信息合并到提示中。此过程如图 1 所示，其中显示了一个 RAG 提示，旨在将用户查询转换为特定于域的语言 (DSL)，也称为语义解析。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="725" height="399" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure1_prompt-example.png" alt="显示语义解析任务的示例元提示的表格。底层元提示由三个较大的部分组成，每个部分都有多个可以优化的方面。例如，可以使用不同的格式呈现输入示例，可以使用各种相似性函数检索所包含的少数镜头示例，或者可以解释任务描述。" class="wp-image-1024137" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure1_prompt-example.png 725w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure1_prompt-example-300x165.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure1_prompt-example-240x132.png 240w" sizes="(max-width: 725px) 100vw, 725px" /><figcaption class="wp-element-caption">图 1：RAG 提示用于语义解析任务。底层提示由三个较大的部分组成，每个部分都有多个可以优化的方面。</figcaption></figure><p>图 1 中的示例结合了三个不同的结构来构建最终的提示。第一个结构，即任务描述，由于传统的提示优化技术而保持静态且独立于输入。但是，RAG 包含两个特定于输入的结构：示例检索器和输入文本本身。这些引入了许多超出大多数传统方法范围的优化机会。尽管之前在提示优化方面做出了努力，但向更复杂的提示结构的演变使得许多旧策略在这种新环境中失效。</p><h2 class="wp-block-heading" id="sammo-a-prompt-optimization-approach"> SAMMO：一种即时优化方法</h2><div class="annotations " data-bi-aN="margin-callout"><ul class="annotations__list card depth-16 bg-body p-4 annotations__list--right"><li class="annotations__list-item"> <span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">下载</span><a href="https://github.com/microsoft/sammo" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="SAMMO" data-bi-aN="margin-callout" data-bi-cN="SAMMO">三木<span class="glyph-append glyph-append-share glyph-append-xsmall"></span></a></li></ul></div><p>为了应对这些挑战，我们开发了结构感知多目标元提示优化 (SAMMO) 框架。 SAMMO 是一种新的开源工具，可以简化提示的优化，特别是那些结合了不同类型结构信息的提示，如上面的 RAG 示例。它可以进行结构改变，例如移除整个组件或用不同的组件替换它们。这些功能使人工智能从业者和研究人员能够通过很少的手动操作来有效地完善他们的提示。</p><p> SAMMO 创新的核心在于它不仅将提示视为静态文本输入，而且将其视为动态、可编程实体（<em>元提示）</em> 。 SAMMO 将这些元提示表示为函数图，其中可以修改各个组件和子结构以优化性能，类似于传统程序编译期间发生的优化过程。</p><p>以下关键功能有助于提高 SAMMO 的有效性：</p><p><strong>结构化优化：</strong>与当前专注于文本级别更改的方法不同，SAMMO 专注于优化元提示的结构。这种精细的方法有助于精确的修改，并能够直接集成领域知识，例如，通过针对特定风格目标的重写操作。<br><br><strong>多目标搜索：</strong> SAMMO 的灵活性使其能够同时解决多个目标，例如提高准确性和计算效率。我们的<a href="https://www.microsoft.com/en-us/research/publication/prompts-as-programs-a-structure-aware-approach-to-efficient-compile-time-prompt-optimization/" target="_blank" rel="noreferrer noopener">论文</a>说明了如何使用 SAMMO 来压缩提示而不影响其准确性。</p><p><strong>通用应用程序：</strong>事实证明，SAMMO 可以在各种任务中提供显着的性能改进，包括指令调整、RAG 和即时压缩。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956148"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/" aria-label="AI Frontiers: Models and Systems with Ece Kamar" data-bi-cN="AI Frontiers: Models and Systems with Ece Kamar" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/ece-podcast-_Topic_podcast-2023Mmm_hero_1400x788_16-9.jpg" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能前沿：Ece Kamar 的模型和系统</h2><p class="large">Ece Kamar 探索短期缓解技术，使这些模型成为人工智能系统的可行组成部分，赋予它们目的，并分享有助于最大化其价值的长期研究问题。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: Models and Systems with Ece Kamar" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="exploring-sammo-s-impact-through-use-cases">通过用例探索 SAMMO 的影响</h2><h3 class="wp-block-heading" id="use-case-1-rag-optimization">用例 1：RAG 优化</h3><p>LLM 的常见应用涉及将自然用户查询转换为特定于领域的语言 (DSL) 结构，通常用于与外部 API 进行通信。例如，图 1 显示了如何使用 LLM 将有关地理事实的用户查询映射到自定义 DSL。</p><p>在现实的 RAG 场景中，SAMMO 展示了显着的性能改进。为了证明这一点，我们对三个不同复杂度的语义解析数据集进行了实验：GeoQuery、SMCalFlow 和 Overnight。鉴于实际环境中数据的可用性通常有限，我们在二次采样数据集（训练和检索集 n=600，测试集 n=100）上训练和测试模型。我们在 24 种配置的搜索空间内使用枚举搜索，将 SAMMO 与手动设计的竞争基线进行比较。这包括数据格式的变化、少数样本的数量以及 DSL 规范。</p><p><strong>评估</strong></p><p>如图 2 所示，SAMMO 在几乎所有情况下都提高了不同数据集和后端 LLM 的准确性，其中在老一代模型中观察到的收益最显着。然而，即使是 GPT-4、SAMMO 等较新的模型也能将准确性提高超过 100%。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="725" height="450" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure2_RAG-tuning.png" alt="一系列四个条形图显示了 SAMMO 在语义解析任务上的性能。 SAMMO 对大多数后端模型和数据集实现了重大改进。" class="wp-image-1024140" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure2_RAG-tuning.png 725w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure2_RAG-tuning-300x186.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure2_RAG-tuning-240x149.png 240w" sizes="(max-width: 725px) 100vw, 725px" /><figcaption class="wp-element-caption">图<em>2</em> ：对于使用 RAG 进行语义解析，SAMMO 在大多数后端模型和数据集上实现了实质性改进。 <em>&nbsp;</em></figcaption></figure><h3 class="wp-block-heading" id="use-case-2-instruction-tuning">用例 2：指令调优</h3><p>指令调优解决了提供给 LLM 的静态指令的优化，这些指令提供了任务的目标和约束。为了表明 SAMMO 超越了许多以前的提示调整方法，我们应用了这种传统设置。</p><p>为了与之前的研究保持一致，我们使用了八个零样本 BigBench 分类任务，其中 GPT-3.5 的基线提示达到了低于 0.9 的准确度。我们将其与自动提示优化 (APO) 和 GrIPS 进行了比较，应用开源模型 Mixtral 7x8B 和 Llama-2 70B，以及 GPT-3.5 作为后端 LLM。我们没有包括 GPT-4，因为在试点实验中发现的改进潜力很小。结果如图 3 所示，表明 SAMMO 的性能优于所有基线，无论后端模型如何，证明了其对于更复杂的元提示的有效性。 </p><figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="725" height="450" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure3_instruction-tuning.png" alt="一系列三个条形图比较了不同指令调整方法的准确性。 SAMMO 在分类任务的指令调整方面的性能与竞争方法相当或超过。" class="wp-image-1024134" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure3_instruction-tuning.png 725w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure3_instruction-tuning-300x186.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/SAMMO-figure3_instruction-tuning-240x149.png 240w" sizes="(max-width: 725px) 100vw, 725px" /><figcaption class="wp-element-caption">图<em>3</em> ：SAMMO 在针对较简单的任务进行指令调整方面至少与旧方法一样好。</figcaption></figure><h2 class="wp-block-heading" id="implications-and-looking-forward">影响和展望</h2><p>SAMMO 引入了一种新的灵活方法来优化特定要求的提示。它的设计适用于任何法学硕士，并且具有适合广泛应用的多功能组件和操作符。</p><p>我们很高兴能够将 SAMMO 集成并应用到人工智能辅助技术背后的组件和管道中。我们还希望建立一个以 SAMMO 为中心的用户驱动社区，人们可以在这里交流最佳实践和模式，并鼓励扩展现有的搜索运算符集。 </p><div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-fill-github"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/sammo" target="_blank" rel="noreferrer noopener">获取代码</a></div><div class="wp-block-button is-style-outline"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/prompts-as-programs-a-structure-aware-approach-to-efficient-compile-time-prompt-optimization/">阅读论文</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a href="https://www.microsoft.com/en-us/research/blog/sammo-a-general-purpose-framework-for-prompt-optimization/">SAMMO：用于即时优化的通用框架一</a>文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>研究重点：2024 年 4 月 15 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-15-2024/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 17 Apr 2024 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=1025451 </guid><description><![CDATA[<p>本期：关于适当依赖生成人工智能的新研究；云端法学硕士的电源管理机会； LLMLingua-2 改进了与任务无关的提示压缩；增强 COMET 以拥抱资源贫乏的非洲语言：</p><p> 《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-15-2024/">研究焦点：2024 年 4 月 15 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1.png" alt="研究焦点 2024 年 4 月 15 日" class="wp-image-1025466" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/RF39-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798" id="new-research">新研究</h3><h2 class="wp-block-heading" id="appropriate-reliance-on-generative-ai-research-synthesis">适当依赖生成式人工智能：研究综合</h2><p>当人们接受正确的人工智能输出并拒绝不正确的人工智能输出时，就会对人工智能产生适当的依赖。它要求人工智能系统的用户知道何时信任人工智能以及何时信任自己。但当涉及生成人工智能（genAI）系统时，培养适当的依赖就会带来新的复杂性。尽管 genAI 系统的功能不断进步，但它使用生成模型来生成文本、音乐、图像和视频等内容，但也存在局限性。对 genAI 的不当依赖（无论是依赖不足还是过度依赖）都可能产生负面后果，例如任务绩效不佳，甚至产品被放弃。</p><p>在最近的一篇论文《 <a href="https://www.microsoft.com/en-us/research/publication/appropriate-reliance-on-generative-ai-research-synthesis/" target="_blank" rel="noreferrer noopener">适当依赖生成人工智能：研究综合》</a>中，微软的研究人员审阅了来自不同学科的 50 篇论文，概述了影响过度依赖 genAI 的因素、不同缓解策略对过度依赖 genAI 的有效性，以及促进对 genAI 的适当依赖的潜在设计策略。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-2 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/appropriate-reliance-on-generative-ai-research-synthesis/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-21d8108ee594aad478409a8aa618b2ee" id="new-research-1">新研究</h3><h2 class="wp-block-heading" id="characterizing-power-management-opportunities-for-llms-in-the-cloud">描述云中法学硕士的电源管理机会</h2><p>由于大型语言模型 (LLM) 的使用不断扩大，云提供商和数据中心运营商正在努力应对图形处理单元 (GPU) 日益增长的需求。为了跟上这一趋势，企业正在探索各种方法来应对这一挑战，例如电力超额认购和添加更多服务器。适当的用电分析和管理可以帮助提供商安全、更有效地满足需求。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/characterizing-power-management-opportunities-for-llms-in-the-cloud/" target="_blank" rel="noreferrer noopener">表征云中法学硕士的电源管理机会</a>中，微软的研究人员分析了几种流行的开源法学硕士跨常用配置的电源模式，并确定了改进云中法学硕士电源管理的机会。他们提出了一个名为 POLCA 的新框架，该框架可以在 LLM 推理云中实现功率超额认购。 POLCA 坚固、可靠且易于部署。 POLCA 模拟使用开源模型来复制生产中观察到的功耗模式，表明它可以在现有集群中部署多 30% 的服务器，同时将功耗限制事件降至最低。 POLCA 提高了电源效率，减少了对额外能源和数据中心的需求，并有助于迅速满足运行额外 LLM 工作负载的需求。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-3 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/characterizing-power-management-opportunities-for-llms-in-the-cloud/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="932112"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/" aria-label="AI Frontiers: AI for health and the future of research with Peter Lee" data-bi-cN="AI Frontiers: AI for health and the future of research with Peter Lee" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/PeterLee_podcast-2023Mar_hero_1400x788.png" alt="Peter Lee 戴着眼镜，对着镜头微笑，左侧有 Microsoft Research Podcast 徽标" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 前沿：Peter Lee 的 AI 健康与研究的未来</h2><p class="large">微软研究院院长 Peter Lee 和 AI 科学家兼工程师 Ashley Llorens 讨论了 AI 研究的未来以及 GPT-4 作为医疗副驾驶的潜力。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: AI for health and the future of research with Peter Lee" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-73123c9697b9c6db2728fb2f179fa924" id="new-research-2">新研究</h3><h2 class="wp-block-heading" id="llmlingua-2-data-distillation-for-efficient-and-faithful-task-agnostic-prompt-compression"> LLMLingua-2：数据提炼，实现高效且可靠的任务无关即时压缩</h2><p>思想链（CoT）、上下文学习（ICL）和检索增强生成（RAG）等各种提示技术可以使大型语言模型（LLM）通过丰富且信息丰富的提示来处理复杂多样的任务。然而，这些提示很长，有时超过数万个令牌，这增加了计算和财务开销，并降低了法学硕士感知信息的能力。最近以任务感知方式压缩提示而不丢失基本信息的努力已经导致针对特定任务或查询的更短的提示。这通常可以提高下游任务的性能，特别是在问答方面。然而，特定于任务的特征在效率和通用性方面提出了挑战。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/llmlingua-2-data-distillation-for-efficient-and-faithful-task-agnostic-prompt-compression/" target="_blank" rel="noreferrer noopener">LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression</a>中，来自微软和清华大学的研究人员提出了一种数据蒸馏程序，从 LLM (GPT-4) 中获取知识并在不丢失关键信息的情况下压缩提示。信息。他们引入了一个提取文本压缩数据集，其中包含来自 MeetingBank 的原始文本对及其压缩版本。尽管规模很小，但他们的模型在强大的基线上显示出显着的性能提升，并在不同的法学硕士中展示了强大的泛化能力。新模型比现有即时压缩方法快 3 至 6 倍，同时将端到端延迟缩短 1.6 倍至 2.9 倍，压缩比提高 2 至 5 倍。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-4 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/llmlingua-2-data-distillation-for-efficient-and-faithful-task-agnostic-prompt-compression/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-ad50996f2914bc16d805d061e6456589" id="new-research-4">新研究</h3><h2 class="wp-block-heading" id="afrimte-and-africomet-enhancing-comet-to-embrace-under-resourced-african-languages"> AfriMTE 和 AfriCOMET：增强 COMET 以拥抱资源贫乏的非洲语言</h2><p>尽管最近在将多语言机器翻译 (MT) 扩展到几种资源贫乏的非洲语言方面取得了进展，但准确衡量这一进展仍然具有挑战性。评估通常使用 BLEU 等 n-gram 匹配指标来执行，这些指标通常与人类判断的相关性较弱。像 COMET 这样的学习指标具有更高的相关性；然而，诸如缺乏资源贫乏语言的人类评级评估数据、多维质量指标（MQM）等注释指南的复杂性以及多语言编码器的语言覆盖范围有限等挑战阻碍了它们对非洲语言的适用性。</p><p>在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/afrimte-and-africomet-enhancing-comet-to-embrace-under-resourced-african-languages/" target="_blank" rel="noreferrer noopener">AfriMTE 和 AfriCOMET：增强 COMET 以拥抱资源匮乏的非洲语言<span class="sr-only">（在新选项卡中打开）</span>中</a>，来自伦敦大学学院、马里兰大学、Unbabel、微软和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.masakhane.io/" target="_blank" rel="noreferrer noopener">Masakhane 社区<span class="sr-only">（在新选项卡中打开）</span></a>的研究人员发表了讲话为了应对这些挑战，我们利用简化的 MQM 指南创建了高质量的人类评估数据，用于 13 种不同类型的非洲语言的错误检测和直接评估 (DA) 评分。他们还开发了非洲语言的 AFRICOMET：COMET 评估指标，利用来自资源丰富的语言的 DA 数据和以非洲为中心的多语言编码器 (AfroXLMR)，为非洲语言创建最先进的 MT 评估指标（与 Spearman 相关）与人类判断的等级相关性（0.441）。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-5 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/afrimte-and-africomet-enhancing-comet-to-embrace-under-resourced-african-languages/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-0663ba4d11b1a8df4b8ebb08832c118e" id="new-research-3">新研究</h3><h2 class="wp-block-heading" id="comparing-the-agency-of-hybrid-meeting-remote-users-in-2d-and-3d-interfaces-of-the-hybridge-system"> Hybridge 系统 2D 和 3D 界面中混合会议远程用户代理的比较</h2><p>视频通信通常缺乏共享空间中的物理存在所带来的包容性和同时性。这在混合会议中尤其明显，其中一些与会者在一个房间里实际会面，而另一些与会者则远程加入。远程参与者处于不利地位，无法像室内参与者一样导航物理空间。</p><p>在 CHI2024 上发表的最新突破性工作论文： <a href="https://www.microsoft.com/en-us/research/publication/comparing-the-agency-of-hybrid-meeting-remote-users-in-2d-and-3d-interfaces-of-the-hybridge-system/" target="_blank" rel="noreferrer noopener">比较混合会议远程用户在 Hybridge 系统的 2D 和 3D 界面中的作用，”</a>微软研究人员提出了一个实验系统，用于探索改善远程与会者在混合会议中的包容性的设计。室内用户可以在桌子周围的各个显示器上看到远程参与者。远程参与者可以看到集成到会议室数字孪生中的房间的视频源，并选择他们在会议室中出现的位置以及从哪里观看。研究人员设计了该界面的 2D 和 3D 版本。他们发现，在参与者的感知意识、代理感和物理存在感方面，3D 的表现优于 2D。大多数参与者主观上也更喜欢 3D 而不是 2D。这项研究的下一步将测试 Hybridge 3D 会议相对于完全室内会议和传统混合会议的包容性。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-6 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/comparing-the-agency-of-hybrid-meeting-remote-users-in-2d-and-3d-interfaces-of-the-hybridge-system/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-76589fb742b6d98c1fd4ee4559a0dc5b" id="new-research-5">新研究</h3><h2 class="wp-block-heading" id="featup-a-model-agnostic-framework-for-features-at-any-resolution"> FeatUp：适用于任何分辨率特征的模型无关框架</h2><p>深层特征是计算机视觉研究的基石，它捕获图像语义并使社区即使在零样本或少样本情况下也能够解决下游任务。然而，这些特征通常缺乏空间分辨率来直接执行分割和深度预测等密集预测任务。这是因为像变压器和卷积网络这样的模型会积极地在大范围内汇集信息。</p><p>在 ICLR 2024 上发表的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/featup/" target="_blank" rel="noreferrer noopener">FeatUp：任意分辨率特征的模型无关框架</a>中，来自 Microsoft 的研究人员和外部同事介绍了一种任务和模型无关的框架，用于恢复深层特征中丢失的空间信息。该论文介绍了 FeatUp 的两种变体：一种在单次前向传递中引导高分辨率信号的特征，另一种将隐式模型拟合到单个图像以重建任何分辨率的特征。这两种方法都使用多视图一致性损失，与神经辐射场 (NeRF) 进行深度类比，NeRF 是一种使用稀疏 2D 图像构建场景 3D 表示的深度学习方法。在新的研究中，功能保留了其原始语义，并且可以交换到现有的应用程序中，以产生分辨率和性能增益，甚至无需重新训练。 FeatUp 在类激活图生成、分割和深度预测的迁移学习以及语义分割的端到端训练方面显着优于其他特征上采样和图像超分辨率方法。 </p><div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-layout-7 wp-block-buttons-is-layout-flex"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/featup/">阅读论文</a></div><div class="wp-block-button is-style-fill"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/featup" target="_blank" rel="noreferrer noopener">项目页面</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/featup-code" target="_blank" rel="noreferrer noopener">代码</a></div><div class="wp-block-button is-style-cta"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.youtube.com/watch?v=-OjW_dnq0cI" target="_blank" rel="noreferrer noopener">相关视频</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p>《<a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-15-2024/">研究焦点：2024 年 4 月 15 日一周》</a>一文首先出现在<a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>