<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 11 月 22 日星期三 19:19:48 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.2</generator><item><title>研究重点：2023 年 11 月 22 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-november-22-2023/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 22 Nov 2023 17:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=984711 </guid><description><![CDATA[<p>一种新的动态稀疏性深度学习编译器； Tongue Tap 可以让舌头手势适用于 VR/AR 耳机；对 LLM 生成的循环不变量进行排序以进行程序验证；评估单细胞生物学中零样本基础模型的局限性。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-november-22-2023/">《研究焦点：2023 年 11 月 22 日一周》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img decoding="async" fetchpriority="high" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1.png" alt="研究重点：2023 年 11 月 22 日，渐变图案背景" class="wp-image-984750" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/RF29-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research">新研究</h3><h2 class="wp-block-heading" id="pit-optimization-of-dynamic-sparse-deep-learning-models-via-permutation-invariant-transformation"> PIT：通过排列不变变换优化动态稀疏深度学习模型</h2><p>动态稀疏性是机器学习中使用的一种技术，可减少计算和内存需求，同时保持或提高性能。当计算资源有限时（例如在嵌入式设备或移动平台上），这尤其有用。然而，有效支持动态稀疏计算具有挑战性，因为张量的具体稀疏性仅在运行时已知。因此，由于与预处理相关的大量开销，最先进的稀疏感知深度学习解决方案仅限于预定义的静态稀疏模式。</p><p>在一篇新论文： <a href="https://www.microsoft.com/en-us/research/publication/pit-optimization-of-dynamic-sparse-deep-learning-models-via-permutation-invariant-transformation/">PIT：通过排列不变变换优化动态稀疏深度学习模型中</a>，微软的研究人员提出了一种用于动态稀疏性的深度学习编译器。排列不变变换（PIT）采用新颖的切片机制，在不改变计算结果的情况下，将多个稀疏分布的微切片转换为 GPU 高效的密集切片，从而实现高 GPU 利用率和低覆盖率浪费。给定一个模型，PIT 首先为其所有算子找到可行的 PIT 规则，并相应地生成高效的 GPU 内核。在运行时，通过新颖的 SRead 和 SWrite 原语，可以快速执行 PIT 规则，以在线方式支持动态稀疏性。对不同模型的广泛评估表明，与最先进的编译器相比，PIT 可以将动态稀疏性计算速度提高高达 5.9 倍（平均 2.43 倍）。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/pit-optimization-of-dynamic-sparse-deep-learning-models-via-permutation-invariant-transformation/">阅读论文</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956148"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/" aria-label="AI Frontiers: Models and Systems with Ece Kamar" data-bi-cN="AI Frontiers: Models and Systems with Ece Kamar" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/ece-podcast-_Topic_podcast-2023Mmm_hero_1400x788_16-9.jpg" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能前沿：Ece Kamar 的模型和系统</h2><p class="large">Ece Kamar 探索短期缓解技术，使这些模型成为人工智能系统的可行组成部分，赋予它们目的，并分享有助于最大化其价值的长期研究问题。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/ai-frontiers-models-and-systems-with-ece-kamar/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="AI Frontiers: Models and Systems with Ece Kamar" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research-1">新研究</h3><h2 class="wp-block-heading" id="tonguetap-multimodal-tongue-gesture-recognition-with-head-worn-devices"> TongueTap：使用头戴式设备进行多模式舌头手势识别</h2><p>基于嘴的界面是一种很有前途的新方法，可以实现与可穿戴设备的静音、免提和免眼交互。然而，传感口腔运动的接口传统上是定制设计的，并放置在口腔附近或口腔内。</p><p> TongueTap 同步来自两个商用耳机的多模态脑电图 (EEG)、光电体积描记图 (PPG)、<strong>惯性测量单元</strong>(IMU)、眼动追踪和头部追踪数据，以便仅使用上脸上的现成设备即可实现舌头手势识别。在一篇新论文： <a href="https://www.microsoft.com/en-us/research/publication/tonguetap-multimodal-tongue-gesture-recognition-with-head-worn-devices/">TongueTap：头戴式设备的多模态舌头手势识别中</a>，微软的研究人员以 94% 的准确率对八种闭嘴舌头手势进行了分类，为头戴式设备的谨慎控制提供了一种看不见、听不见的方法。此外，研究表明，仅 IMU 就能区分 8 个手势，准确率达 80%，区分 4 个手势的子集，准确率达 92%。研究人员构建了一个包含 16 名参与者的 48,000 次手势试验的数据集，使 TongueTap 能够执行独立于用户的分类。研究结果表明，舌头手势可以成为 VR/AR 耳机和可穿戴设备的一种可行的交互技术，而无需新颖的硬件。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/tonguetap-multimodal-tongue-gesture-recognition-with-head-worn-devices/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research-2">新研究</h3><h2 class="wp-block-heading" id="ranking-llm-generated-loop-invariants-for-program-verification">对 LLM 生成的循环不变量进行排序以进行程序验证</h2><p>综合归纳循环不变量是自动化程序验证的基础。在一篇新论文： <a href="https://www.microsoft.com/en-us/research/publication/ranking-llm-generated-loop-invariants-for-program-verification/">对用于程序验证的 LLM 生成的循环不变量进行排名</a>中，微软的研究人员证明了大型语言模型 (LLM)，例如 GPT-3.5 或 GPT-4，能够为一类程序合成循环不变量零样本设置，但需要多个样本才能生成正确的不变量。这可能导致对程序验证器的大量调用，或者在建立不变量时向交互式验证用户提供多个不正确的建议。</p><p>为了解决这个问题，研究人员提出了一种对法学硕士生成结果进行重新排序的方法，包括一个新设计的排序器，可以根据问题定义区分正确的归纳不变量和错误的尝试。该排名器被优化为对比排名器。实验结果表明，这种重新排名机制显着提高了生成的候选者中正确不变量的排名，从而显着减少了对验证者的调用次数。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/ranking-llm-generated-loop-invariants-for-program-verification/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research-3">新研究</h3><h2 class="wp-block-heading" id="assessing-the-limits-of-zero-shot-foundation-models-in-single-cell-biology">评估单细胞生物学中零样本基础模型的局限性</h2><p>GPT 等基础模型的成功引发了人们对其在单细胞生物学中的应用越来越感兴趣。 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41586-023-06139-9" target="_blank" rel="noreferrer noopener">Geneformer <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.biorxiv.org/content/10.1101/2023.04.30.538439v2" target="_blank" rel="noreferrer noopener">scGPT <span class="sr-only">（在新选项卡中打开）等</span></a>模型的出现有望成为该专业领域的多功能工具。然而，这些模型的功效，特别是在零样本设置中，其中模型未经微调但无需任何进一步训练即可使用，仍然是一个悬而未决的问题，特别是因为实际约束要求有用的模型在排除微调的设置中发挥作用。例如，许多生物学问题本质上是探索性的，旨在发现进一步实验的假设。在这种情况下，可以作为下游微调目标的标签可能未知或可能有偏差。因此，在其他计算生物学领域（包括显微镜图像和蛋白质序列），零样本评估是常规做法。然而，这还不是单细胞基础模型工作的既定标准，评估实践仍在不断涌现。</p><p>在一篇新论文《 <a href="https://www.microsoft.com/en-us/research/publication/assessing-the-limits-of-zero-shot-foundation-models-in-single-cell-biology/">评估单细胞生物学中零样本基础模型的局限性》</a>中，微软的研究人员对这些提出的单细胞基础模型的零样本性能进行了严格的评估。他们评估它们在细胞类型聚类和批量效应校正等任务中的效用，并评估其预训练目标的通用性。研究结果表明，Geneformer 和 scGPT 在零样本设置中都表现出有限的可靠性，并且与更简单的方法相比通常表现不佳。这些发现对部署所提出的单细胞基础模型起到了警示作用，并强调需要进行更有针对性的研究以实现其潜力。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/assessing-the-limits-of-zero-shot-foundation-models-in-single-cell-biology/">阅读论文</a></div></div><hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research-4">新研究</h3><h2 class="wp-block-heading" id="confidential-consortium-framework-secure-multiparty-applications-with-confidentiality-integrity-and-high-availability">机密联盟框架：具有机密性、完整性和高可用性的安全多方应用程序</h2><p>机密性、完整性保护和高可用性（缩写为 CIA）是值得信赖的数据系统的基本属性。然而，云计算的兴起和对多方应用程序不断增长的需求使得构建现代 CIA 系统比以往任何时候都更具挑战性。</p><p>作为回应，微软的研究人员提出了： <a href="https://www.microsoft.com/en-us/research/publication/confidential-consortium-framework-secure-multiparty-applications-with-confidentiality-integrity-and-high-availability/">机密联盟框架：具有机密性、完整性和高可用性的安全多方应用程序<span class="sr-only">（在新选项卡中打开）</span></a> ，这是开发安全状态 CIA 应用程序的通用基础。机密联盟框架（CCF）将集中式计算与去中心化信任相结合，支持在不可信的云基础设施上进行部署，并由互不信任的各方进行透明治理。 CCF 利用基于硬件的可信执行环境来实现可远程验证的机密性和代码完整性。这与由可审计的不可变账本支持的状态机复制相结合，以实现数据完整性和高可用性。 CCF 使每个服务能够带来自己的应用程序逻辑、自定义多方治理模型和部署场景，从而将节点的运营商与治理它们的联盟解耦。 CCF 是开源的，现已在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/CCF">https://github.com/microsoft/CCF <span class="sr-only">（在新选项卡中打开）</span></a>上提供。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/confidential-consortium-framework-secure-multiparty-applications-with-confidentiality-integrity-and-high-availability/">阅读论文</a></div><div class="wp-block-button is-style-fill-github"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://github.com/microsoft/CCF" target="_blank" rel="noreferrer noopener">GitHub 上的 CCF</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-november-22-2023/">《研究焦点：2023 年 11 月 22 日一周》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title> Orca 2：教授小语言模型如何推理</title><link/>https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Tue, 21 Nov 2023 02:04:33 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>在微软，我们通过训练小型语言模型来扩展人工智能能力，以实现通常只有在更大的模型中才能实现的增强推理和理解能力。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/">《Orca 2：教授小语言模型如何推理》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img decoding="async" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1024x576.png" alt="Orca-2 博客英雄 |抽象数据波" class="wp-image-985938" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/ORCA-BlogHeroFeature-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>几个月前，我们推出了<a href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/">Orca</a> ，一个 130 亿参数的语言模型，通过模仿能力更强的 LLM 的逐步推理轨迹，展示了强大的推理能力。</p><p> Orca 2 是我们探索小型 LM 功能（参数数量级为 100 亿或更少）的最新举措。通过 Orca 2，我们继续证明改进的训练信号和方法可以使较小的语言模型获得增强的推理能力，而这种能力通常只在较大的语言模型中才能找到。</p><p>根据在零样本设置中测试高级推理能力的复杂任务的评估，Orca 2 显着超越了类似大小的模型（包括原始 Orca 模型），并达到了与大 5-10 倍的模型相似或更好的性能水平。</p><p> Orca 2 有两种大小（70 亿和 130 亿参数）；两者都是通过根据定制的高质量合成数据微调相应的 LLAMA 2 基础模型而创建的。我们正在公开 Orca 2 权重，以鼓励对小型 LM 的开发、评估和调整进行研究。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/">阅读 Orca 论文</a></div><div class="wp-block-button is-style-outline"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/orca-2-teaching-small-language-models-how-to-reason/">阅读 Orca 2 论文</a></div></div><h2 class="wp-block-heading" id="using-llms-to-train-smaller-language-models">使用法学硕士训练较小的语言模型</h2><p>GPT-4、PaLm等前沿语言模型表现出了非凡的推理能力，例如回答复杂问题、生成解释，甚至解决需要多步推理的问题；曾经被认为超出人工智能能力范围的能力。传统上，这种能力在较小的语言模型中尚未观察到，因此挑战是如何利用我们对大型语言模型不断增长的知识来提高这些较小模型的能力。</p><h2 class="wp-block-heading" id="expanding-the-capabilities-of-smaller-language-models">扩展较小语言模型的功能</h2><p>Orca 2 背后的一个关键见解是，不同的任务可以从不同的解决方案策略中受益（例如，逐步处理、回忆然后生成、回忆-推理-生成、提取-生成和直接答案），并且解决方案策略对于较小的模型来说，大型模型所采用的可能不是最佳选择。例如，虽然像 GPT-4 这样功能强大的模型可以直接回答复杂的任务，但较小的模型可能会从将任务分解为步骤中受益。</p><p> Orca 2 使用扩展的、高度定制的合成数据集进行训练。生成的训练数据可以教授 Orca 2 各种推理技术，例如逐步处理、回忆然后生成、回忆-推理-生成、提取-生成和直接答案方法，同时还教它选择不同的推理方法。不同任务的解决策略。</p><p>训练数据是从能力更强的教师模型中获得的。请注意，我们可以通过非常详细的说明甚至多次调用来获取教师的响应，具体取决于任务和模型的所需行为。在缺乏详细说明如何完成任务的原始指令的情况下，将鼓励学生模型学习基本策略及其引发的推理能力。 </p><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956154"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">微软研究院播客</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" aria-label="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/collaborators_hero_1400x788.jpg" alt="GitHub 产品经理 Kasia Sitkiewicz 和协议实验室研究科学家 Petar Maymounkov 在 Microsoft Research 播客上讨论了他们在 Gov4git 上的合作" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">合作者：Gov4git、Petar Maymounkov 和 Kasia Sitkiewicz</h2><p class="large"> Gov4git 是一种用于去中心化、开源合作的治理工具，有助于为未来奠定基础，让每个人都可以更高效、透明、轻松地进行协作，并以满足各自社区独特愿望和需求的方式进行协作。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank">现在听</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="orca-2-has-reasoning-capabilities-comparable-to-much-larger-models"> Orca 2 的推理能力可与更大的模型相媲美</h2><p>为了评估 Orca 2，我们使用了一套全面的 15 个不同的基准测试，这些基准测试对应于零样本设置中的大约 100 个任务和超过 36,000 个独特的测试用例。基准测试涵盖多个方面，包括语言理解、常识推理、多步推理、数学问题解决、阅读理解、总结、扎根性、真实性以及有毒内容生成和识别。</p><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final.png"><img decoding="async" width="2498" height="781" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final.png" alt="在各种基准（0 次设置）上比较 Orca 2（7B 和 13B）与 LLaMA-2-Chat（13B 和 70B）和 WizardLM（13B 和 70B）的结果，涵盖语言理解、常识推理、多步推理Orca 2 模型显着超越其他模型，包括大 10 倍的模型。请注意，Orca 2 模型是通过持续训练相同大小的 LLaMA-2 基础模型来训练的。" class="wp-image-986271" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final.png 2498w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-300x94.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-1024x320.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-768x240.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-1536x480.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-2048x640.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/orca2-final-240x75.png 240w" sizes="(max-width: 2498px) 100vw, 2498px" /></a><figcaption class="wp-element-caption">图 1：Orca 2（7B 和 13B）与 LLaMA-2-Chat（13B 和 70B）以及 WizardLM（13B 和 70B）在各种基准（零样本设置）上的比较结果，涵盖语言理解、常识推理、 Orca 2 模型可匹配或超越其他模型，包括大 5-10 倍的模型。请注意，该图中的所有模型共享相同的基础模型 (LLAMA-2)。</figcaption></figure><p>我们的初步结果表明，Orca 2 的性能明显优于类似尺寸的型号。它还达到了与至少大 10 倍的模型相似或更好的性能水平，展示了为较小模型配备更好推理能力的潜力。</p><p> Orca 2 模型表现出与其他语言模型相同的局限性，并且可以保留其训练基础模型的许多约束。虽然 Orca 2 训练可以应用于不同的基础模型，但我们报告基于使用 LLaMA-2 7B 和 13B 模型的结果。 Orca 2 模型尚未经过人类反馈强化学习 (RLHF) 安全训练。</p><h2 class="wp-block-heading" id="conclusion">结论</h2><p>我们对 Orca 2 模型的研究对于增强小型语言模型的推理能力产生了重要的见解。通过使用定制的合成数据战略性地训练这些模型，我们已经达到了与大型模型相媲美或超越的性能水平，特别是在零样本推理任务中。</p><p> Orca 2 的成功在于它对多种推理技术的应用以及对各种任务的最佳解决方案的识别。虽然它有一些局限性，包括从其基本模型继承的局限性以及其他语言模型所共有的局限性，但 Orca 2 未来进步的潜力是显而易见的，特别是在改进较小模型的推理、专业化、控制和安全性方面。使用经过仔细过滤的合成数据进行训练后成为这些改进的关键策略。</p><p>我们的研究结果强调了较小模型在需要平衡效率和能力的场景中的价值。随着更大的模型继续表现出色，我们与 Orca 2 的合作标志着语言模型应用程序和部署选项多样化的重要一步。</p><figure class="wp-block-image aligncenter size-large"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2.jpg"><img decoding="async" loading="lazy" width="777" height="1024" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-777x1024.jpg" alt="这张图片来自报纸"Orca-2: Teaching Small Language Models How To Reason" showcases differences in how Orca 2, LLaMA-2, LLaMA-2-Chat, and ChatGPT (GPT-3.5-Turbo) process and answer a logic-based question. The LLaMA-2 and LLaMA-2-Chat outputs were generated via replicate.com/meta/llama-2-13b and chat.lmsys.org, employing standard settings (temperature=0, top_p=1). ChatGPT's response was retrieved from chat.openai.com, providing a clear comparison of how each model approaches problem-solving." class="wp-image-985878" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-777x1024.jpg 777w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-228x300.jpg 228w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-768x1012.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2-137x180.jpg 137w, https://www.microsoft.com/en-us/research/uploads/prod/2023/11/Orca_Figure2.jpg 800w" sizes="(max-width: 777px) 100vw, 777px" /></a><figcaption class="wp-element-caption">这张图片来自论文“Orca-2：教授小语言模型如何推理”，展示了 Orca 2、LLaMA-2、LLaMA-2-Chat 和 ChatGPT (GPT-3.5-Turbo) 处理和回答逻辑的差异 -基于的问题。 LLaMA-2 和LLaMA-2-Chat 输出是通过replicate.com/meta/llama-2-13b 和chat.lmsys.org 生成的，采用标准设置（温度=0，top_p=1）。 ChatGPT 的响应是从 chat.openai.com 检索的，提供了每个模型如何解决问题的清晰比较。</figcaption></figure><p></p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/">《Orca 2：教授小语言模型如何推理》一文</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>