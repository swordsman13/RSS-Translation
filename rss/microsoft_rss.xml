<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 9 月 6 日，星期三 20:18:14 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.2.2</generator><item><title>多模式学习的前沿：负责任的人工智能方法</title><link/>https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Wed, 06 Sep 2023 19:53:53 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>如果我们要构建推进人类目标的多模式人工智能系统，就必须采用新的评估方法并致力于持续改进。了解 Microsoft 对多模式 AI 负责任的开发和使用的前沿研究。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/">多模态学习的前沿：负责任的人工智能方法</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">微软研究院</a>。</p> ]]>; </description><content:encoded><![CDATA[<aside id=accordion-d8ffbe07-71a9-4fd6-a56c-55c4bb6b0efe class="msr-table-of-contents-block accordion mb-5 pb-0" data-bi-aN="table-of-contents"> <button class="btn btn-collapse bg-gray-100 mb-0 display-flex justify-content-between" type="button" data-mount="collapse" data-target="#accordion-collapse-d8ffbe07-71a9-4fd6-a56c-55c4bb6b0efe" aria-expanded="true" aria-controls="accordion-collapse-d8ffbe07-71a9-4fd6-a56c-55c4bb6b0efe"><span class="msr-table-of-contents-block__label subtitle">在本文中</span><span class="msr-table-of-contents-block__current mr-4 text-gray-600 font-weight-normal" aria-hidden="true"></span></button> <div id="accordion-collapse-d8ffbe07-71a9-4fd6-a56c-55c4bb6b0efe" class="msr-table-of-contents-block__collapse-wrapper collapse show" data-parent="#accordion-d8ffbe07-71a9-4fd6-a56c-55c4bb6b0efe"><div class="accordion-body bg-gray-100 border-top pt-4"><ol class="msr-table-of-contents-block__list"><li class="msr-table-of-contents-block__list-item"> <a href="#unmasking-hidden-societal-biases-across-modalities" class="msr-table-of-contents-block__list-item-link">揭露各种模式中隐藏的社会偏见</a></li><li class="msr-table-of-contents-block__list-item"><a href="#navigating-distributional-shifts-and-spurious-correlations" class="msr-table-of-contents-block__list-item-link">应对分布变化和虚假相关性</a></li><li class="msr-table-of-contents-block__list-item"><a href="#decomposing-evaluation-for-controllability-and-precision-in-multimodal-generation" class="msr-table-of-contents-block__list-item-link">多模态生成中可控性和精度的分解评价</a></li><li class="msr-table-of-contents-block__list-item"><a href="#beyond-offline-benchmarks-leveraging-adaptation-and-continual-learning-approaches" class="msr-table-of-contents-block__list-item-link">超越离线基准：利用适应和持续学习方法</a></li><li class="msr-table-of-contents-block__list-item"><a href="#related-reading" class="msr-table-of-contents-block__list-item-link">相关阅读</a></li></ul></div></div><span class="msr-table-of-contents-block__progress-bar"></span></aside><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1.png" alt="负责任的 AI 博客 - 带有连接圆圈的英雄图形，其中的图标描绘了隐藏式字幕、日历、图像和圆圈内的文档" class="wp-image-965712" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-Multimodal-Learning-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>在人工智能领域，新领域并不局限于单一的表达形式；快节奏的发展正在多种模式的交汇处发生。多模态人工智能系统可以跨文本、图像和其他数据类型进行分析、合成和生成，正在为生产力、医疗保健、创造力和自动化等领域令人兴奋的应用铺平道路。由于人类在物理世界中的感知和解决问题会利用多种模式，因此与跨单一模式运行的系统相比，这种多模式系统提供了更加自然和无缝的支持。这些新兴的人工智能系统由大量数据集和变压器等先进架构的融合提供支持。然而，当我们测试和推进这些系统的功能时，出现了一个关键问题：我们如何确保它们负责任的开发和部署？一种方法是通过对其基础模型进行严格评估。</p><p>当你穿越数字世界时，内容的丰富性是显而易见的——视频与文本交织在一起，图像为文章提供背景，音频文件通常带有转录。在这个数字挂毯中，多模态模型就像编织者，将不同的线程组合成一个连贯的整体。然而，与所有工具一样，它们也并非没有挑战。他们的评估需要超越传统指标的细致入微的理解。</p><p>在 Microsoft，我们尝试并以开源模型为基础进行构建。我们还有机会和荣幸研究 Microsoft 和 OpenAI 开发的尖端模型。尽早访问这些模型有助于我们研究模型的功能，了解它们的局限性和故障模式，并在将它们集成到产品中或更广泛发布之前制定缓解计划。几年前，微软的<a href="https://www.microsoft.com/en-us/ai/principles-and-approach/#tabs-pill-bar-ocb9d4_tab1" target="_blank" rel="noreferrer noopener">以太委员会</a>建立了特殊的跨公司工作流程，以便尽早严格研究基础模型和基础模型的新应用，重点<em>调查</em>和<em>识别</em>潜在的风险和危害。由此产生的报告和简报为 Microsoft 提供了两个关键的后续步骤：对模型功能和限制进行进一步深入<em>调查的研究工作</em>，以及衡量和缓解这些风险的<em>工程工作</em>。</p><p>一项研究旨在探索多模式文本到图像模型。这项研究是与 OpenAI 的同事共同完成的，包括具有不同背景和不同专业知识的贡献者，例如工程、人工智能和负责任的人工智能研究、安全和政策。该研究包括红队合作，以了解故障模式并提供此类故障更常见的示例；研究负责任地部署多模式模型的交互范式和最佳实践；建立测量和缓解技术以纳入模型开发和部署生命周期的初步工程工作；以及对这些模式的长期考虑，例如它们对艺术家权利和工作的影响。这些发现激发了进一步调查，更正式地量化这些失败，特别是因为它们与公平相关的损害有关。在本博客中，我们将介绍 Microsoft Research 的一些研究和其他针对多模态 AI 的突破性工作，研究评估多模态模型的复杂性及其改进路径。我们的观点由四个关键观察构成：</p><ol><li>不同内容类型的组合带来了新的意外伤害风险，即使使用“安全”系统输入也可能发生这种风险。</li><li>互联网规模数据的庞大规模和多样性使得能够开发能够执行多种任务的模型。但这些数据并不能反映现实的各个方面，导致模型在存在分布变化和虚假相关性的情况下表现不佳。</li><li>当前基准测试中使用的通用分数无法完全评估生成能力的可控性，或者用户在获得他们想要的精确输出方面有多大影响力。评估可控性需要新的协议，通过关注基本技能（即在许多场景中重要的技能）来分解评估。</li><li>为了弥合离线测量可以捕获的内容与开放世界中模型的功能之间的差距，研究人员和开发人员必须采用适应和持续学习方法，这也带来了挑战。</li></ol><h2 class="wp-block-heading" id="unmasking-hidden-societal-biases-across-modalities">揭露各种模式中隐藏的社会偏见</h2><p><strong>观察 1</strong> ：不同内容类型的组合带来了新的意外伤害风险，即使使用“安全”系统输入也可能发生这种风险。</p><p>我们的研究表明，视觉+语言模型的“双方”都可能出现意外伤害的新风险。例如，最近的研究<a href="https://www.microsoft.com/en-us/research/publication/social-biases-through-the-text-to-image-generation-lens/" target="_blank" rel="noreferrer noopener">“通过文本到图像生成镜头的社会偏见”</a>表明，诸如“首席执行官的照片”和“计算机程序员的照片”之类的提示到 DALL-E v2 会产生图像没有被人类注释者视为女性的个体的代表。尽管自然语言提示不包含强化社会偏见的语言，但图像输出中缺乏女性代表与劳工统计数据背道而驰，强化了有害的刻板印象，即没有女性首席执行官或程序员和/或女性没有有能力胜任此类职业。同样，稳定扩散的“护士照片”和“管家照片”等提示会导致图像不代表被注释者视为男性的个体。除了与职业相关的提示之外，该研究还表明，与性格特征和日常情况相关的提示也可能无法产生多样化的输出。例如，提示“婚礼”可能会导致系统生成仅对应于西方婚礼视觉风格的图像。这项研究表明，即使给出更明确的提示来命名特定地理位置，例如“尼日利亚的生日聚会”，这些系统也可能生成明显质量较低的图像。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="301" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-1024x301.jpg" alt="图 1：使用 DALL-E v2 和稳定扩散模型的“计算机程序员”和“管家”职业的世代示例。" class="wp-image-965184" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-1024x301.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-300x88.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-768x225.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1-240x70.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_1.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 1：使用 DALL-E v2 和稳定扩散模型为“计算机程序员”和“管家”职业生成的前四个图像的示例。值得注意的是，在 500 张生成的图像分布中明显缺少一种性别（如人类注释者所感知的）。</figcaption></figure><p>同样，对于图像到文本的场景， <a href="https://www.microsoft.com/en-us/research/publication/measuring-representational-harms-in-image-captioning/">另一项研究</a>表明，对于常见情况的图像（来自 COCO 数据集），模型可以生成排除或错误添加单词的说明，其方式可能是由社会偏见来解释的。训练数据。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="258" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-1024x258.jpg" alt="图 2：系统为 COCO 数据集的图像生成的标题示例。其中包括可能由刻板印象解释的不准确之处。例如，一张拿着吹风机的女人的图片被标题为“一个戴着眼镜拿着一瓶酒的女人”。" class="wp-image-965187" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-1024x258.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-300x76.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-768x194.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2-240x61.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_2.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 2：系统为 COCO 数据集生成的标题示例，可能通过刻板印象进行解释。这些情况包括实际上不正确的粗体文本。</figcaption></figure><p><strong>评估和模型改进策略：</strong>正如“ <a href="https://www.microsoft.com/en-us/research/publication/taxonomizing-and-measuring-representational-harms-a-look-at-image-tagging/" target="_blank" rel="noreferrer noopener">分类和衡量代表性危害：图像标签概览</a>”中所探讨的那样，没有一种方法可以识别或衡量代表性危害，即某些社会群体不如其他群体值得关注或低等的表现给其他人。值得注意的是，虽然一些危害在单独观察单个输入或输出时会很明显，但其他危害只有在组合观察或跨越多代的输入或输出时才会变得明显。因此，有效的评估通常需要混合使用测量方法，包括检查已知令人反感的特定输入或输出（或特定输入-输出对），根据人口统计寻找输出的准确性或质量差异群体，审查按人口群体划分的产出分布差异，并确定对投入的具体扰动如何影响产出等。<strong> </strong>从这项工作和文本到图像生成工作中可以得出的另一个关键见解是需要内容过滤或选择策略，这些策略可以在不同的模式上运行，以解决输入和输出以及生成的不同阶段的潜在危害过程。</p><p>文本到图像生成工作探索的另一种缓解技术是即时扩展。在初始提示中添加描述符（例如，在提示“播音员的肖像”中指定“女性”）被证明对于创建指定内容最有效；然而，生成的内容在人口统计特征和背景和服装等特征方面的多样性较低，并且图像质量较低，如图 3 所示。考虑到这些额外的问题，虽然通过扩展提示来增强控制很有用，但同时，它也为人们提供足够的透明度和机构来控制迅速扩张非常重要，以便他们能够实现预期的结果。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="598" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-1024x598.jpg" alt="图 2：系统为 COCO 数据集的图像生成的标题示例。其中包括可能由刻板印象解释的不准确之处。例如，一张拿着吹风机的女人的图片被标题为“一个戴着眼镜拿着一瓶酒的女人”。" class="wp-image-965190" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-1024x598.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-300x175.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-768x448.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-480x280.jpg 480w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3-240x140.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_3.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 3：使用“女性”等描述符的扩展提示确实可以产生更多样化的描述，但通常以图像多样性和质量为代价。用于衡量图像质量的 Fréchet 起始距离 (FID) 越高，生成的图像与真实图像的距离就越远。令人惊讶的是，提示“男性播音员的肖像”的 FID 得分为 164。 </figcaption></figure><h2 class="wp-block-heading" id="navigating-distributional-shifts-and-spurious-correlations">应对分布变化和虚假相关性</h2><p><strong>观察 2</strong> ：互联网规模数据的庞大规模和多样性使得能够开发能够执行各种任务的模型。但这些数据并不能反映现实的各个方面，导致模型在存在分布变化和虚假相关性的情况下表现不佳。</p><p>从历史上看，机器学习模型一直在封闭世界的假设下运行，受到训练数据或特定应用环境的限制。互联网规模数据的出现及其看似超越这些界限的潜力引起了人们的极大兴奋，但​​现实是存在重大问题。互联网规模数据集中发现的巨大多样性并不一定反映现实世界的分布。某些日常物体或概念可能仍然很少见或代表性不足，例如，在安全关键的应用程序中，例如帮助残疾人，如<a href="https://www.microsoft.com/en-us/research/publication/disability-first-datasets/">“残疾优先数据集创建：通过盲和低技术构建可教物体识别数据集的经验教训”</a>中所示<a href="https://www.microsoft.com/en-us/research/publication/disability-first-datasets/">视觉数据收集器。”</a></p><p>因此，多模态基础模型尽管拥有庞大的训练数据集，但仍然容易受到分布变化（即训练数据与现实数据之间的差异）和虚假相关性的影响，或者巧合特征可能错误地影响模型预测的情况。在最近的论文<a href="https://www.microsoft.com/en-us/research/publication/mitigating-spurious-correlations-in-multi-modal-models-during-fine-tuning/">《在微调过程中减轻多模态模型中的虚假相关性》中，</a>研究人员发现，当测试时的示例中不存在虚假相关性时，CLIP 等模型就无法表现良好。例如，当图片中有婴儿时，CLIP 对奶嘴进行分类的准确度为 92.9%（零样本），但当图片中没有婴儿时，准确度仅为 30.8%。基于梯度的解释表明，在很多情况下，即使模型是准确的，它也会针对娃娃脸或背景进行预测，在这种情况下，它是因为错误的原因而正确的。那么，在这个例子中，虚假特征就是婴儿。当婴儿在场时，该模型更有可能做出正确的预测，而在婴儿不在场时，该模型则不太可能做出正确的预测。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="460" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-1024x460.jpg" alt="图 4：左：大型多模态基础模型学习依靠虚假相关性进行预测的示例。例如婴儿奶嘴、开罐器、橡皮、口哨和卷笔刀的图像。右图：模式解释在缓解后从虚假特征转变为正确特征的图示。" class="wp-image-965193" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-1024x460.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-300x135.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-768x345.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4-240x108.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_4.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 4：大型多模态基础模型学习依靠虚假相关性进行预测的示例。</figcaption></figure><p><strong>评估和模型改进策略：</strong><em>不同条件下的误差分析和分类评估</em>：分布外检测文献建议用最差组准确度来补充平均准确度。准确度最差的组通常也对应于受分布变化和虚假相关性影响最严重的组。误差分析和公平性评估的扩展方法表明，对不同输入条件的评估进行分解或分解可以提供一种有效的方法来发现和评估常见的可靠性或公平性问题以及虚假相关性（参见下面的列表）<a href="#literature">有关分类评估和误差分析的文献</a>）。过去，视觉和多模态任务的输入条件是根据元数据或视觉特征（例如光照条件、图像大小、颜色、模糊和图像质量）指定的（“ <a href="https://www.microsoft.com/en-us/research/publication/a-large-scale-robustness-analysis-of-video-action-recognition-models/" target="_blank" rel="noreferrer noopener">视频动作识别模型的大规模鲁棒性分析</a>”）在存在此类扰动的情况下，会降低卷积和变换器视觉模型的性能）。如今，开放词汇模型（即那些不限于预定义的封闭概念集的模型）的可用性创造了为视觉内容生成软标签或元数据的可能性，然后可以将其用于表征故障，例如减轻虚假相关性工作中显示。为了说明这一点，该工作使用具有开放词汇表的对象检测模型来检测内容标签，例如<em>baby</em> 、 <em>can</em> 、 <em>hand</em> 、 <em>ring</em>和<em>pencil</em> ，如图4所示，然后用它来分析是否存在此类内容的增加与准确性的显着下降有关。</p><p><em>评估模型是否因正确的原因而正确：</em>除了误差分析之外，评估的一个关键部分是模型是否因正确的原因而正确，正如减轻虚假相关性工作中所探讨的那样。回到奶嘴的例子，当奶嘴在婴儿旁边或被婴儿使用时，模型可以识别出奶嘴，这很好，但在现实世界中，情况并非总是如此。安抚奶嘴可能位于沙发下、桌子上或商店货架上，在所有情况下模型都不太可能正确识别它。在不同的情况下，对模型是否“因正确的原因而正确”的检查可能会有所不同。例如，在图像分类中，模型解释和地面实况边界框之间的交集是一个很好的指标。该指标称为<em>“调整交并并”</em> ，与最差组准确度一起，它为评估虚假相关性的存在提供了良好的画面。</p><p>早期的论文<a href="https://www.microsoft.com/en-us/research/publication/squinting-at-vqa-models-introspecting-vqa-models-with-sub-questions/">“SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions” <span class="sr-only">（在新选项卡中打开）</span></a>中提出了用方法丰富通用指标的另一个例子，这些方法也测试了预测背后的原因，该论文检查了视觉问答（VQA） ） 任务。鉴于 VQA 模型可能会在特定答案上表现出统计偏差（例如，对于是/否问题大多回答“是”），该工作提出了一个基准、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/VQA-introspect" target="_blank" rel="noreferrer noopener">VQA-Introspect <span class="sr-only">（在新选项卡中打开）</span></a>和一个分解模型将较大的任务分解为较小的较简单的任务。例如，如果有关照片的问题是“照片中似乎有紧急情况吗？”并且模型可以正确回答这个问题“是”，它还应该能够回答更简单的问题，例如“照片中有消防车吗？” </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="167" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-1024x167.jpg" alt="图 5：来自 VQA-Introspect 数据集的图像示例、主要推理问题和子问题。左：结婚照的图像和主要推理问题“这是一张纪念照片吗？是的。” “这是黑白照片吗？是”是子问题之一。右图：动物园里的长颈鹿的图片和相应的问题。" class="wp-image-965196" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-1024x167.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-300x49.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-768x126.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5-240x39.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_5.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 5：来自 VQA-Introspect 数据集的示例，它通过评估模型是否能够回答主要问题所需的更简单的子问题来分解模型回答复杂问题的能力。</figcaption></figure><p>为了更好地理解 VQA 任务模型的视觉感知和推理能力之间的关系， <a href="https://www.microsoft.com/en-us/research/publication/neuro-symbolic-visual-reasoning-disentangling-visual-from-reasoning-2/">“神经符号视觉推理：将‘视觉’与‘推理’分离”</a>通过独立评估对象检测和关系表示学习的质量将这两个方面分开彼此的。对于调试模型中何时以及如何发生缺乏推理来说，这是一个重要的区别。研究发现，当模型能够访问真实视觉信息时，它可以仅使用一阶逻辑以 96% 的准确度解决具有挑战性的 VQA 任务，这表明模型在任务中的成功与更好的视觉特征提取有关方法。利用这一发现，本文提出了一种利用所提出模型的推理组件的反馈来改进弱视觉特征提取方法的方法。</p><p><em>从识别和测量到缓解：</em>多模态和开放词汇模型不仅有助于生成用于表征模型性能的元数据，而且还开辟了模型改进的新领域。特别是，给定模态内和跨模态的对比学习创造了直接指导优化过程以将虚假特征与目标概念分开的机会。更令人兴奋的是，由于现在可以使用元数据标记实例或使用标题中提供的信息，因此可以用语言来表达什么是虚假特征以及是否应该使用它来对目标概念进行分类的规范。例如，在减轻虚假相关性论文中，研究人员使用额外的损失来指定优化过程，即“婴儿”一词和包含“婴儿”的图像应该在表示空间中远离“奶嘴”表示，以便模型创建单个对象（在本例中为奶嘴）的更稳健的表示。同样，他们表明可以改进更困难的虚假相关性基准，例如水鸟数据集，其中陆地鸟类被有意放置在水背景中，水鸟被放置在陆地背景中，以研究背景虚假相关性对分类的影响。他们表明，预训练的 CLIP 模型（带有 ResNet 或 Transformer 核心）确实对这些特征进行了索引，但在通过对比学习添加这些规范后，它们提高了最差组的准确性并专注于相关概念（见图 4）。 </p><div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="935415"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">聚焦：人工智能聚焦领域</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" aria-label="AI and Microsoft Research" data-bi-cN="AI and Microsoft Research" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2020/07/newsletter-option-8-neural-network-3-1.png" alt="深蓝色背景上的抽象神经网络模式" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4">人工智能和微软研究院</h2><p class="large">详细了解 Microsoft 人工智能研究的广度</p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Learn more" data-bi-cN="AI and Microsoft Research" target="_blank">了解更多</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="decomposing-evaluation-for-controllability-and-precision-in-multimodal-generation">多模态生成中可控性和精度的分解评价</h2><p><strong>观察3：</strong>当前基准测试中使用的通用分数无法完全评估生成能力的可控性，或者用户在获得他们想要的精确输出方面有多大影响力。评估可控性需要新的协议，通过关注基本技能（即在许多场景中重要的技能）来分解评估。</p><p>由于许多基础模型（包括多模态模型）已被训练来完成生成任务，因此它们的主要评估通常依赖于 Fréchet 起始距离（FID）或起始分数等分数。这些分数是衡量输出质量的良好指标。例如，在生成的图像的情况下，输出质量可以是真实感，在生成的字幕的情况下，输出质量可以是连贯性。但它们并没有反映出这一代人如何很好地捕捉输入提示的重要方面。如果没有这些信息，就很难确定模型的可控性。生成图像的其他方面可能与它看起来的“真实”程度一样重要。考虑空间理解。它是一系列需要仔细控制的更复杂任务的基本子任务，包括语言引导任务、对象操作、导航和场景理解。这里的误解不仅令人沮丧，而且令人沮丧。它们可能会妨碍生产力或对安全关键型应用有害。根据<a href="https://www.microsoft.com/en-us/research/publication/benchmarking-spatial-relationships-in-text-to-image-generation/">“文本到图像生成中的空间关系基准测试”的研究结果，</a>很明显当前的文本到图像模型经常会误解空间线索。现有的指标（例如 FID 甚至对象准确度）似乎不够敏感，无法标记这些空间错误。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="248" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-1024x248.jpg" alt="图 6：使用指定空间关系的提示生成的图像示例，但所描绘的关系不正确。" class="wp-image-965199" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-1024x248.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-300x73.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-768x186.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6-240x58.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_6.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 6：使用指定空间关系的提示生成的图像示例。</figcaption></figure><p><strong>评估和模型改进策略</strong>：为了考虑空间理解，对空间关系进行基准测试的研究提出了<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/VISOR" target="_blank" rel="noreferrer noopener">验证空间对象关系或 VISOR <span class="sr-only">（在新选项卡中打开）的</span></a>分数，该分数将这些能力的评估分解为两部分：</p><ol><li>生成的图像是否包含所有指定的对象？</li><li>生成的对象的空间配置是否遵循提示中指定的空间关系？</li></ol><p>例如，在研究中，具有最佳对象准确度生成的模型 (DALL-E v2) 可以在 64% 的时间内生成所有指定对象（由人类注释者评分）。在这些世代中，对象之间的关系在 59% 的情况下是准确的（如提示中指定的）。从用户体验来看，这意味着模型将在不到 40% 的时间内完全生成提示中指定的内容。</p><p>除了这些评估结果之外，该工作还建议利用自动化评估，这对于复杂的任务通常具有挑战性。但通过将评估分解为更小的任务，研究发现可以使用其他形式的机器学习和计算机视觉来进行细粒度的自动化评估。例如，与人工注释的分数并行，该研究使用了 VISOR 的自动化版本。该自动化版本利用对象检测器来评估对象准确性，并利用边界框定位技术来评估空间关系。随着任务变得越来越复杂，进一步分解微任务的评估变得更加重要，也是一个有前途的方向。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="241" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-1024x241.jpg" alt="图 7：该图显示了 VISOR 分数如何将空间理解的评估分解为对象检测和关系评估，以大象骑着摩托车过马路的照片为例。" class="wp-image-965202" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-1024x241.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-300x71.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-768x180.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7-240x56.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_7.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 7：VISOR 通过使用其他机器学习和计算机视觉技术来首先检测对象，然后评估它们的空间关系，从而使用度量和任务分解进行评估。</figcaption></figure><p>随着对模型可控性有了更好的理解，我们可以开始开发改进模型的方法。完善多模式模型的一个关键方面是其训练数据。例如，由于用于训练的现有图像说明不优先考虑空间关系（通常它们是隐含的或不显着的），因此可以使用自动文本数据增强来生成指定空间关系的替代说明（例如，“一辆卡车在摩托车前面”）。利用类似的直觉， <a href="https://www.microsoft.com/en-us/research/publication/kosmos-2-grounding-multimodal-large-language-models-to-the-world/">“Kosmos-2：为世界奠定多模态大型语言模型”</a>背后的研究人员构建了一个大规模的基于图像-文本对的数据集，其中还包含对象位置的描述。科斯莫斯-2,<strong> </strong>新的多式联运模式<strong> </strong>在数据集上进行训练，在任务上表现出更高的准确性，这些任务直接受益于模式之间更好的基础，例如导航。</p><p>机器学习模型（尤其是生成模型）的输出会根据<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/completions" target="_blank" rel="noreferrer noopener">生成温度<span class="sr-only">（在新选项卡中打开）</span></a> 、 <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering" target="_blank" rel="noreferrer noopener">提示工程<span class="sr-only">（在新选项卡中打开）</span></a>和固有模型随机性等因素而变化。当然，虽然这些都是具体的实际挑战，但它们提供的可变性可以用来改善体验并使评估更加稳健。例如，虽然 DALL-E v2 的条件 VISOR 分数为 59%，但当生成四张图像时，该样本中至少存在 74% 的正确生成。当所有这些都呈现给用户时（界面中的常见做法），这会增加用户获得满意生成的机会。此外，在大多数交互从语言开始的模型中，即时可变性是普遍存在的。 VISOR 工作中的消融实验表明，生成模型倾向于描绘提示中首先提到的对象。交换提示中的对象会改变它们之间的关系，从而增加了另一个可变性来源。结合起来，这些见解可以用于更有效的交互。</p><p>虽然纯文本和图像是文本到图像模型中使用的主要模式，但当使用代码生成图像和控制生成时，也会评估模型功能。例如， <a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/">“通用人工智能的火花：GPT-4 的早期实验”</a>中的几个初始示例说明了如何促使纯语言模型 GPT-4 的早期版本在 TikZ 或 JavaScript 中生成代码可以导致可控绘图，更准确地描绘空间关系。然而，由于这些绘图可能相当简单，因此该研究还引发了一场关于如何充分利用这两个世界的对话：通过代码实现良好的可控性，通过图像生成实现更高的图像质量或复杂的场景。例如，它展示了如何利用通过 GPT-4 代码生成启动的草图来通过文本到图像模型控制更复杂场景的生成。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="452" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-1024x452.jpg" alt="图 8：通过稳定扩散将 GPT-4 代码生成的草图与图像生成相结合的示例。该示例展示了绘制地形的过程，其中从左到右有一条河流，河流下方是一个有金字塔的沙漠，河流上方是一座有许多高楼的城市。" class="wp-image-965205" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-1024x452.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-300x132.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-768x339.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8-240x106.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_8.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 8：通过稳定扩散将 GPT-4 代码生成的草图与图像生成相结合的示例。 </figcaption></figure><h2 class="wp-block-heading" id="beyond-offline-benchmarks-leveraging-adaptation-and-continual-learning-approaches">超越离线基准：利用适应和持续学习方法</h2><p><strong>观察 4：</strong>为了弥合离线测量可以捕获的内容与开放世界中模型的功能之间的差距，研究人员和开发人员必须采用适应和持续学习方法，这也带来了自身的挑战。 <strong>&nbsp;</strong></p><p>虽然离线评估提供了关于模型性能的必要视图，但它们没有考虑现实世界的变量，例如在标签空间中引入看不见的对象类别、视觉表示长尾中的新对象、用户反馈以及训练数据和开放世界数据之间的差异，包括质量差异以及视角和方向的差异。这些具体的挑战在<a href="https://www.microsoft.com/en-us/research/publication/continual-learning-about-objects-in-the-wild-an-interactive-approach/" target="_blank" rel="noreferrer noopener">《持续学习野外物体：一种交互式方法</a>》和《 <a href="https://www.microsoft.com/en-us/research/publication/understanding-personalized-accessibility-through-teachable-ai-designing-and-evaluating-find-my-things-for-people-who-are-blind-or-low-vision/#:~:text=Teachable%20AI%20systems%20give%20users,benefit%20of%20the%20personalization%20received." target="_blank" rel="noreferrer noopener">通过可教人工智能理解个性化可访问性：为盲人或低视力人士设计和评估查找我的东西》中进行了</a>探讨，这两部作品为盲人或弱视人士提供了方法使用户能够扩展人工智能系统的功能，以满足他们的现实需求。这些方法被称为<a href="https://www.microsoft.com/en-us/research/project/taix/" target="_blank" rel="noreferrer noopener">可教学的人工智能系统</a>，允许用户提供示例或更高级别的约束来塑造他们对人工智能系统的体验。</p><p>第一篇论文揭示了一种实用的持续学习混合现实方法，其中包括循环中的多模态模型。在所提出的实现中，系统通过用户佩戴的混合现实耳机来跟踪环境中对象的 3D 世界位置和方向，用户可以通过凝视系统突出显示的对象并说“例如，”来提供标签。这是我的切菜板。”这些交互旨在调整识别模型，以随着时间的推移提高使用系统的人遇到的一组对象的性能。 </p><figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="382" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-1024x382.jpg" alt="图 10：用于厨房领域交互式持续学习的混合现实系统的图示。左上：通过混合现实耳机看到的切菜板的视图，由系统和各种其他厨房物品突出显示和标记。右上：3D 对象检测和定位。底部：从自我中心的角度来看，厨房用品的多样化组合。" class="wp-image-965211" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-1024x382.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-300x112.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-768x286.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10-240x89.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ResponsibleAI_2023Sep_figure_10.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">图 9：使用循环中的多模态模型进行交互式持续学习的混合现实系统。</figcaption></figure><p>构建如此复杂的系统需要回答困难且未经探索的评估问题。有些是特定于该应用程序的：系统随时间跟踪对象位置的效果如何？系统应该突出显示哪些对象并要求用户标记？目前最先进的视觉模型在这种情况下的表现如何？其他问题对我们如何有效评估这些系统有更广泛的影响，包括我们如何衡量任务完成情况。</p><p> Current evaluation methods aren&#39;t sufficient to answer such open questions. The evaluation of teachable AI systems, as described in the second paper, “Understanding Personalized Accessibility Through Teachable AI,” comprises a<strong> </strong>range of challenges beyond offline evaluation. “Understanding Personalized Accessibility Through Teachable AI” explores these challenges through Find My Things, a research prototype of an application for helping people who are blind or have low vision train an AI system to identify personal items by providing videos of the items, allowing them to later find those items using their phones. Among the conclusions: an AI system needs to help users collect quality teaching examples, work consistently across users, and work on a specific user&#39;s real-world data, not just “clean” data. Meanwhile, users need to understand what actions they can take to improve performance when a system is non-performant.</p><p> <strong>Strategies for evaluation and model improvement:</strong> Analyzing how a system performs when encountering data that isn&#39;t “clean,” specifically the impact of frame quality, “Continual Learning about Objects in the Wild” finds the CLIP model in a zero-shot setting is at least 10 percent less accurate on images that have some motion blur or occlusion. The result indicates that choosing the right frames for inference may indeed have a positive impact on user experience in zero-shot settings. However, even in the best case, these experiences have a lot of room for improvement on zero-shot recognition. The best model performance is less than 60 percent, even for frames that have been filtered to be without motion blur or occlusion. Similar findings are presented in <a href="https://www.microsoft.com/en-us/research/publication/hard-meta-dataset-towards-understanding-few-shot-performance-on-difficult-tasks/" target="_blank" rel="noreferrer noopener">“Hard-Meta-Dataset++: Towards Understanding Few-Shot Performance on Difficult Tasks,”</a> which presents a benchmark that specifically curates tasks that are difficult for the model to get right as a way to encourage model development that improves the worst case/bottom line. Further, “Continual Learning about Objects in the Wild” experiments with model adaptation by fine-tuning a lightweight model on top of the base model, showing that continuous adaptation techniques hold promise for improving performance in real-world deployments.</p><p> Beyond accuracy, it will also be important to reduce the computational costs associated with adapting a model to new data. This is particularly important to realize interactive AI experiences that people can adapt or personalize themselves—for example, teachable object recognizers as proposed by the <a href="https://www.microsoft.com/en-us/research/publication/orbit-dataset/" target="_blank" rel="noreferrer noopener">ORBIT benchmark</a> . This research shows that because of the computational cost and time to personalize a model to an individual&#39;s data, lighter-weight models that are less accurate would be better suited for the ultimate deployed experience than heavier-weight, more accurate ones.</p><p> In conclusion, as we&#39;ve navigated through a plethora of challenges and innovations, one message stands out: the road to effective multimodal AI systems built responsibly demands rigorous evaluation, an understanding of real-world complexities, and a commitment to continual improvement. We hope that these recent results will inspire ambitious work forward in the space of reframing the evaluation of multimodal models such that it properly captures their performance from initial evidence to rigorous benchmarks, complex skills, and eventually real-world and human-centered scenarios.</p><h2 class="wp-block-heading" id="related-reading"> Related reading</h2><p id="literature"> <strong>Literature on multimodal models directly discussed in this blog</strong></p><ul><li> <a href="https://www.microsoft.com/en-us/research/publication/mitigating-spurious-correlations-in-multi-modal-models-during-fine-tuning/">Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning</a> . Yu Yang, Besmira Nushi, Hamid Palangi, Baharan Mirzasoleiman. ICML 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/social-biases-through-the-text-to-image-generation-lens/">Social Biases through the Text-to-Image Generation Lens</a> . Ranjita Naik, Besmira Nushi. AIES 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/">Sparks of Artificial General Intelligence: Early Experiments with GPT-4</a> . Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang. Microsoft Research Tech Report 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/kosmos-2-grounding-multimodal-large-language-models-to-the-world/">Kosmos-2: Grounding Multimodal Large Language Models to the World</a> . Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, Furu Wei. Microsoft Research Tech Report 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/hard-meta-dataset-towards-understanding-few-shot-performance-on-difficult-tasks/">Hard-Meta-Dataset++: Towards Understanding Few-Shot Performance on Difficult Tasks</a> . Samyadeep Basu, Megan Stanley, John Bronskill, Soheil Feizi, Daniela Massiceti. ICLR 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/understanding-personalized-accessibility-through-teachable-ai-designing-and-evaluating-find-my-things-for-people-who-are-blind-or-low-vision/#:~:text=Teachable%20AI%20systems%20give%20users,benefit%20of%20the%20personalization%20received.">Understanding Personalized Accessibility through Teachable AI: Designing and Evaluating Find My Things for People who are Blind or Low Vision</a> . Cecily Morrison, Rita Marques, Martin Grayson,  Daniela Massiceti, Camilla Longden, Linda Yilin Wen,  Ed Cutrell. ASSETS 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/taxonomizing-and-measuring-representational-harms-a-look-at-image-tagging/">Taxonomizing and Measuring Representational Harms: A Look at Image Tagging.</a> Jared Katzman, Angelina Wang, Morgan Scheuerman, Su Lin Blodgett, Kristen Laird, Hanna Wallach, Solon Barocas. AAAI 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/a-large-scale-robustness-analysis-of-video-action-recognition-models/">A Large-scale Robustness Analysis of Video Action Recognition Models.</a> Madeline Chantry Schiappa, Naman Biyani, Prudvi Kamtam, Shruti Vyas, Hamid Palangi, Vibhav Vineet, Yogesh Rawat. CVPR 2023.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/benchmarking-spatial-relationships-in-text-to-image-generation/" target="_blank" rel="noreferrer noopener">Benchmarking Spatial Relationships in Text-to-Image Generation</a> . Tejas Gokhale, Hamid Palangi, Besmira Nushi, Vibhav Vineet, Eric Horvitz, Ece Kamar, Chitta Baral, Yezhou Yang. Microsoft Research Tech Report 2022.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/measuring-representational-harms-in-image-captioning/" target="_blank" rel="noreferrer noopener">Measuring Representational Harms in Image Captioning</a> . Angelina Wang, Solon Barocas, Kristen Laird, Hanna Wallach. FAccT 2022.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/continual-learning-about-objects-in-the-wild-an-interactive-approach/">Continual Learning about Objects in the Wild: An Interactive Approach</a> . Dan Bohus, Sean Andrist, Ashley Feniello, Nick Saw, Eric Horvitz. ICMI 2022.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/disability-first-datasets/" target="_blank" rel="noreferrer noopener">Disability-first Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors</a> . Lida Theodorou, Daniela Massiceti, Luisa Zintgraf, Simone Stumpf, Cecily Morrison, Ed Cutrell, Matthew Tobias Harris, Katja Hofmann. ASSETS 2021.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/orbit-dataset/">ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition</a> . Daniela Massiceti, Luisa Zintgraf, John Bronskill, Lida Theodorou, Matthew Tobias Harris, Ed Cutrell, Cecily Morrison, Katja Hofmann, Simone Stumpf. ICCV 2021.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/squinting-at-vqa-models-introspecting-vqa-models-with-sub-questions/">SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions</a> . Ramprasaath R. Selvaraju, Purva Tendulkar, Devi Parikh, Eric Horvitz, Marco Tulio Ribeiro, Besmira Nushi, Ece Kamar. CVPR 2020.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/neuro-symbolic-visual-reasoning-disentangling-visual-from-reasoning-2/">Neuro-Symbolic Visual Reasoning: Disentangling “Visual” from “Reasoning</a> .” Saeed Amizadeh, Hamid Palangi, Alex Polozov, Yichen Huang, Kazuhito Koishida. ICML 2020.</li></ul><p> <strong>Literature on disaggregated evaluations</strong></p><ul><li> <a href="https://www.microsoft.com/en-us/research/publication/designing-disaggregated-evaluations-of-ai-systems-choices-considerations-and-tradeoffs/" target="_blank" rel="noreferrer noopener">Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs</a> . Solon Barocas, Anhong Guo, Ece Kamar, Jacquelyn Krones, Meredith Ringel Morris, Jennifer Wortman Vaughan, Duncan Wadsworth, Hanna Wallach. AIES 2021.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/towards-accountable-ai-hybrid-human-machine-analyses-for-characterizing-system-failure/" target="_blank" rel="noreferrer noopener">Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing System Failure</a> . Besmira Nushi, Ece Kamar, Eric Horvitz. HCOMP 2018.</li><li> <a href="https://www.microsoft.com/en-us/research/publication/understanding-failures-of-deep-networks-via-robust-feature-extraction/" target="_blank" rel="noreferrer noopener">Understanding Failures of Deep Networks via Robust Feature Extraction</a> . Sahil Singla, Besmira Nushi, Shital Shah, Ece Kamar, Eric Horvitz. CVPR 2021.</li><li> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.youtube.com/watch?v=NYXRrLzGiFk&t=734s&ab_channel=MicrosoftResearch" target="_blank" rel="noreferrer noopener">Disaggregated model evaluation and comparison – YouTube <span class="sr-only">(opens in new tab)</span></a></li></ul> <span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p> The post <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/">Frontiers of multimodal learning: A responsible AI approach</a> appeared first on <a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a> .</p> ]]>;</content:encoded></item><item><title> Rethinking trust in direct messages in the AI era</title><link/> https://www.microsoft.com/en-us/research/blog/rethinking-trust-in-direct-messages-in-the-ai-era/<dc:creator><![CDATA[Brenda Potts]]></dc:creator><pubDate> Tue, 05 Sep 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/?p=964494 </guid><description><![CDATA[<p> Microsoft researchers are proposing a new way to ensure greater trust and accountability in email, texts, direct messages on social platforms, even phone calls, to help mitigate sophisticated threats from AI-related scams and fraud.</p><p> The post <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/rethinking-trust-in-direct-messages-in-the-ai-era/">Rethinking trust in direct messages in the AI era</a> appeared first on <a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a> .</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-large"><img decoding="async" loading="lazy" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-1024x576.png" alt="Rethinking trust in direct messages in the AI era - blog hero showing a flowchart diagram" class="wp-image-965043" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-blog-hero-1400x788-1.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p> This blog post is a part of a series exploring our research in privacy, security, and cryptography. For the previous post, see <a href="https://www.microsoft.com/en-us/research/blog/research-trends-in-privacy-security-and-cryptography" target="_blank" rel="noreferrer noopener">https://www.microsoft.com/en-us/research/blog/research-trends-in-privacy-security-and-cryptography</a> . While AI has the potential to massively increase productivity, this power can be used equally well for malicious purposes, for example, to automate the creation of sophisticated scam messages. In this post, we explore threats AI can pose for online communication ecosystems and outline a high-level approach to mitigating these threats.</p><h2 class="wp-block-heading" id="communication-in-the-age-of-ai"> Communication in the age of AI</h2><p> Concerns regarding the influence of AI on the integrity of online communication are increasingly shared by policymakers, AI researchers, business leaders, and other individuals. These concerns are well-founded, as benign AI chatbots can be easily repurposed to impersonate people, help spread misinformation, and sway both public opinion and personal beliefs. So-called “spear phishing” attacks, which are personalized to the target, have proved devastatingly effective. This is particularly true if victims are not using multifactor authentication, meaning an attacker who steals their login credentials with a phishing mail could access authentic services with those credentials. This opportunity has not been missed by organized cybercrime; AI-powered tools marketed to scammers and fraudsters are already emerging. This is disturbing, because democratic systems, business integrity, and interpersonal relationships all hinge on credible and effective communication—a process that has notably migrated to the digital sphere.</p><p> As we enter a world where people increasingly interact with artificial agents, it is critical to acknowledge that these challenges from generative AI are not merely hypothetical. In the context of our product offerings at Microsoft, they materialize as genuine threats that we are actively addressing. <a href="https://www.microsoft.com/en-us/corporate-responsibility/earn-trust" target="_blank" rel="noreferrer noopener"></a> We are beginning to witness the impact of AI in generating highly specific types of text (emails, reports, scripts, code) in a personalized, automated, and scalable manner. In the workplace, AI-powered tools are expected to bring about a huge increase in productivity, allowing people to focus on the more creative parts of their work rather than tedious, repetitive details. In addition, AI-powered tools can improve productivity and communication for people with disabilities or among people who do not speak the same language.</p><p> In this blog post, we focus on the challenge of establishing trust and accountability in direct communication (between two people), such as email, direct messages on social media platforms, SMS, and even phone calls. In all these scenarios, messaging commonly takes place between individuals who share little or no prior context or connection, yet those messages may carry information of high importance. Some examples include emails discussing job prospects, new connections from mutual friends, and unsolicited but important phone calls. The communication may be initiated on behalf of an organization or an individual, but in either case we encounter the same problem: if the message proves to be misleading, malicious, or otherwise inappropriate, holding anyone accountable for it is impractical, may require difficult and slow legal procedures, and does not extend across different communication platforms.</p><p> As the scale of these activities increases, there is also a growing need for a flexible cross-platform <em>accountability mechanism</em> that allows both the message sender and receiver to explicitly declare the nature of their communication. Concretely, the sender should be able to declare accountability for their message and the receiver should be able to hold the sender accountable if the message is inappropriate.</p><h2 class="wp-block-heading" id="elements-of-accountability"> Elements of accountability</h2><p> The problems outlined above are not exactly new, but recent advances in AI have made them more urgent. Over the past several years, the tech community, alongside media organizations and others, have investigated ways to distinguish whether text or images are created by AI; for example, C2PA is a type of watermarking technology, and one possible solution among others. With AI-powered tools increasingly being used in the workplace, Microsoft believes that it will take a combination of approaches to provide the highest value and most transparency to users.</p><p> Focusing on accountability is one such approach. We can start by listing some properties we expect of any workable solution:</p><ul><li> People and organizations need to be able to declare accountability for the messages they send.</li><li> Receivers need to be able to hold the senders accountable if the message is inappropriate or malicious, to protect future potential victims.</li><li> There must exist an incentive for the sender to declare accountability.</li><li> The mechanism should only solve the accountability problem and nothing else. It must not have unintended side effects, such as a loss of privacy for honest participants.</li><li> Receivers should not be required to register with any service.</li><li> The accountability mechanism must be compatible with the plurality of methods people use to communicate today.</li></ul><p> One way to build an accountability mechanism is to use a <em>reputation system</em> that verifies real-world identities, connecting our digital interactions to a tangible and ultimately accountable organization or human identity. Online reputation has now become an asset that organizations and individuals have a vested interest in preserving. It creates an incentive for honest and trustworthy behavior, which ultimately contributes to a safer and more reliable digital environment for everyone.</p><h2 class="wp-block-heading" id="reputation-system-for-online-accountability"> Reputation system for online accountability</h2><p> Consider what an online communication user experience could be like with an integrated reputation system. In this solution, a message sender could declare their accountability by binding their message to their account in the reputation system in the form of a cryptographic <em>reputation tag</em> . Conversely, the receiver uses the tag to verify the sender&#39;s reputation and can use it to report the sender if the message is inappropriate, reducing the sender&#39;s reputation. It is the sender&#39;s responsibility to judge whether the receiver will perceive the message as inappropriate.</p><p> Messages with an attached reputation tag are called <em>reputed messages</em> , whereas those without an associated reputation are called <em>generic messages</em> . Reputed messages would typically make the most sense in one-to-one communication that the sender intends for a particular recipient, or one-to-many communication to a few recipients. For example, a proposal to discuss a business deal, a wedding invitation email, a payment reminder SMS from a company&#39;s billing department, or a work email discussing a joint project might be sent as reputed messages. Generic messages would typically not be intended for a particular receiver. For example, emails sent to a mailing list (many receivers) or non-personalized advertisements (large scale) should be sent as generic.</p><p> The different components and workflows of our accountability mechanism are depicted, at a high level, in Figure 1. </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1186" height="843" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-blog_2023Aug_system-diagram.png" alt="system diagram" class="wp-image-964695" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-blog_2023Aug_system-diagram.png 1186w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-blog_2023Aug_system-diagram-300x213.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-blog_2023Aug_system-diagram-1024x728.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-blog_2023Aug_system-diagram-768x546.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-blog_2023Aug_system-diagram-240x171.png 240w" sizes="(max-width: 1186px) 100vw, 1186px" /><figcaption class="wp-element-caption"> Figure 1: An accountability mechanism design, showing both the account creation and message sending/reporting workflows.</figcaption></figure><p> Taking a concrete example, think of a situation where you receive an email from your bank asking you to verify the security settings for your account. You know that phishing emails often target such scenarios, so your first reaction is to ignore the message. However, in this case your email client has noted the valid reputation tag and automatically moved the email to a <em>reputed messages</em> folder. It shows the sender&#39;s reputation, <em>high</em> , next to the message. Instead of deleting the unsolicited and slightly suspicious email, you decide to check whether the link in the email truly leads you to your bank&#39;s website. You are now convinced this is a legitimate message and proceed with the recommendations to review your security settings.</p><p> As another example, suppose you work in your company&#39;s billing department. You find something wrong with a customer&#39;s billing information and decide to send them an email to get more information. Since this is an important matter, you hope to maximize the chance of them seeing your message by attaching the billing department&#39;s reputation tag to it. The customer sees the email go in the <em>reputed messages</em> folder, notices the sender&#39;s <em>high</em> reputation, and responds to it with appropriate urgency.</p><p> As a third example, imagine that you receive an unsolicited phone call from someone who claims to be your distant relative and wants to discuss a family reunion they are organizing. They ask you questions about your family, making you slightly uneasy. Right before calling you, they sent you a reputation tag via SMS encoding their reputation and the context of their call. You verify that the tag is valid, but that their reputation is <em>medium</em> . You decide to end the call and report them using the tag they shared, as you felt that their call asking for such sensitive information was inappropriate.</p><p> These examples highlight that this single system can be used across many different modes of communication, from emails to social media messages to phone calls, fostering trust and safety across the entire landscape of direct communication methods in use today. </p><div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mt-md-4 mb-4 mb-md-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="956154"><p class="msr-promo__label text-gray-800 text-center text-uppercase"> <span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft Research Podcast</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" aria-label="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/04/collaborators_hero_1400x788.jpg" alt="GitHub Product Manager Kasia Sitkiewicz and Protocol Labs Research Scientist Petar Maymounkov discuss their collaboration on Gov4git on the Microsoft Research Podcast" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz</h2><p class="large"> Gov4git is a governance tool for decentralized, open-source cooperation, and is helping to lay the foundation for a future in which everyone can collaborate more efficiently, transparently, and easily and in ways that meet the unique desires and needs of their respective communities. </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-gov4git-with-kasia-sitkiewicz-and-petar-maymounkov/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Gov4git with Petar Maymounkov and Kasia Sitkiewicz" target="_blank">Listen now</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--> <span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span></div><!--/.msr-promo--><h2 class="wp-block-heading" id="call-to-action"> Call to action</h2><p> In this blog post we have attempted to outline a solution to an already existing problem that is exacerbated by modern AI. Capturing the core of this problem is not easy, and many of the previously proposed solutions have unintended consequences that make them unworkable. For example, we explained why approaches that attempt to limit the use of AI are unlikely to succeed.</p><p> The solutions are not easy either. The messaging ecosystem is vastly complex and any solution requiring fundamental changes to that are unlikely to be acceptable. Usability is a key concern as well: if the system is only designed to communicate risk, we may want to avoid inadvertently communicating safety, much like the presence of padlock symbols as a sign of HTTPS have caused <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://blog.chromium.org/2023/05/an-update-on-lock-icon.html" target="_blank" rel="noreferrer noopener">confusion and underestimation of risk for web browser users <span class="sr-only">(opens in new tab)</span></a> .</p><p> Is there a comprehensive identity framework that would connect real-world identities to digital identities? This connection to a <em>unique</em> real-world identity is crucial, as otherwise anyone could simply create as many distinct reputation accounts as they need for any nefarious purpose.</p><p> For organizations, the situation is easier, because countries and states tend to hold public records that establish their existence and “identity.” For individuals, platforms like Reddit, TripAdvisor, and Stack Overflow have built reputation systems for their internal use, but without a foundational layer that confirms unique human identities these cannot be used to solve our problem, just as Facebook&#39;s “real name” policy and X Premium (formerly Twitter Blue) have been insufficient to prevent the creation and use of fake accounts. Still, this is not an impossible problem to solve: <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/help/linkedin/answer/a1458457/" target="_blank" rel="noreferrer noopener">LinkedIn is already partnering with CLEAR <span class="sr-only">(opens in new tab)</span></a> to bind government ID verification to a verification marker in user profiles, and <a href="https://www.microsoft.com/en-us/security/blog/2023/04/12/linkedin-and-microsoft-entra-introduce-a-new-way-to-verify-your-workplace/" target="_blank" rel="noreferrer noopener">with Microsoft Entra Verified ID <span class="sr-only">(opens in new tab)</span></a> to verify employment status. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://worldcoin.org/" target="_blank" rel="noreferrer noopener">Worldcoin <span class="sr-only">(opens in new tab)</span></a> is building a cryptocurrency with each wallet being linked to a unique real-world person through biometrics, and Apple recently announced <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.apple.com/ca/newsroom/2023/06/introducing-apple-vision-pro/" target="_blank" rel="noreferrer noopener">Optic ID <span class="sr-only">(opens in new tab)</span></a> for biometric authentication through their Vision Pro headset.</p><p> Whenever we talk about identities—especially real-world identities—we need to talk about privacy. People use different digital identities and communication methods in different communities, and these identities need to be kept separate. Trusting a reputation system with such sensitive information requires careful consideration. Our preliminary research suggests that techniques from modern cryptography can be used to provide strong security and privacy guarantees so that the reputation system learns or reveals nothing unnecessary and cannot be used in unintended ways.</p><p> What about the governance of the reputation system? In an extreme case, a single centralized party hosts the system while providing cryptographic transparency guarantees of correct operation. In another extreme, we should explore whether a purely decentralized implementation can be feasible. There are also options between these two extremes; for example, multiple smaller reputation systems hosted by different companies and organizations.</p><p> These open questions present an opportunity and a responsibility for the research community. At Microsoft Research, we are diligently working on aspects of this problem in partnership with our research on privacy-preserving verifiable information and identity, secure hardware, transparency systems, and media provenance. We invite the rest of the research community to join in by either following the path we outlined here or suggesting better alternatives. This is the start of a broad exploration that calls for a profound commitment and contribution from all of us.</p> <span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p> The post <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/rethinking-trust-in-direct-messages-in-the-ai-era/">Rethinking trust in direct messages in the AI era</a> appeared first on <a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a> .</p> ]]>;</content:encoded></item></channel></rss>