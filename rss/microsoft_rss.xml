<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>微软研究院博客 - 微软研究院</title><atom:link href="https://www.microsoft.com/en-us/research/blog/feed/?from=https%3A%2F%2Fresearch.microsoft.com%2Frss%2Fnews.xml&amp;type=rss" rel="self" type="application/rss+xml"></atom:link><link/> https://www.microsoft.com/en-us/research/blog/<description></description><lastbuilddate> 2023 年 10 月 11 日，星期三 16:02:42 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.3.1</generator><item><title>研究重点：2023 年 10 月 9 日当周</title><link/>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Wed, 11 Oct 2023 16:02:41 +0000</pubDate> <category><![CDATA[Research Blog]]></category><guid ispermalink="false"></guid><description><![CDATA[<p>研究重点：首席研究员 Lester Mackey 因其开创性的统计和机器学习技术而受到认可；神经特征学习中的帕累托前沿；影响者行业的结构性不平等；基数估计的新研究。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/">研究焦点：2023 年 10 月 9 日的一周</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<figure class="wp-block-pullquote"><blockquote><p><em class="">欢迎来到研究焦点，这是一系列博客文章，重点介绍 Microsoft 研究社区的著名出版物、活动、代码/数据集、新员工和其他里程碑。</em> </p></blockquote></figure><figure class="wp-block-image size-full"><img decoding="async" fetchpriority="high" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1.png" alt="研究焦点 2023 年 10 月 11 日" class="wp-image-975561" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="award">奖</h3><h2 class="wp-block-heading" id="lester-mackey-awarded-prestigious-macarthur-fellowship">莱斯特·麦基荣获著名的麦克阿瑟奖学金</h2><p>Microsoft Research 向首席研究员<a href="https://www.microsoft.com/en-us/research/people/lmackey/">Lester Mackey <span class="sr-only">（在新选项卡中打开）</span></a>表示祝贺，他被授予<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.macfound.org/fellows/class-of-2023/lester-mackey#searchresults" target="_blank" rel="noreferrer noopener">2023 年麦克阿瑟奖学金<span class="sr-only">（在新选项卡中打开），</span></a>以表彰他在解决与现实世界相关的数据科学问题方面的开创性统计和机器学习技术。</p><p>该奖学金旨在表彰“在创造性追求中表现出非凡的原创性和奉献精神以及显着的自我指导能力的才华横溢的个人”，并附带一笔津贴，旨在使获奖者能够发挥自己的创造性本能，造福人类社会。</p><p>麦基的研究重点是提高超大型数据集计算统计分析的效率和预测性能。他的工作包括设计一种方法来更准确地预测 ALS 或卢伽雷氏病患者的疾病进展率。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.macfound.org/fellows/class-of-2023/lester-mackey#searchresults" target="_blank" rel="noreferrer noopener">奖项详情</a></div></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="电脑屏幕截图 一名男子的屏幕截图" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 解释者：基础模型和 AI 的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多数据以及情境学习如何帮助推动人工智能从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research">新研究</h3><h2 class="wp-block-heading" id="pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck">神经特征学习中的帕累托前沿：数据、计算、宽度和运气</h2><p>深度学习中的算法设计看起来更像是“黑客攻击”，而不是工程实践。有许多架构选择和训练启发式方法，它们通常可以以不可预测和复杂的方式调节模型性能和资源成本。因此，在训练大规模神经网络（例如最先进的语言模型）时，算法决策和资源分配首先是经验驱动的，涉及<em>缩放定律</em>的测量和外推。对这个“深度学习黑匣子”的精确数学理解是难以捉摸的，并且不能通过孤立的统计或优化来解释。</p><p>在一篇新论文： <a href="https://www.microsoft.com/en-us/research/publication/pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck/">神经特征学习中的帕累托前沿：数据、计算、宽度和运气中​​，</a>来自微软、哈佛大学和宾夕法尼亚大学的研究人员通过单一合成任务的视角探索了这些算法的复杂性和权衡：有限-样本稀疏奇偶学习问题。在这种情况下，上述复杂性不仅是显而易见的，而且是可证明的：直观上，由于任务的计算难度，神经网络需要足够的资源<em>组合</em>（“数据×模型大小×训练时间×运气”）才能成功。这项研究表明，深度学习中的标准算法选择会产生<em>帕累托前沿</em>，其中成功的学习是通过这些资源的可互换组合“购买”的。他们表明，对这个玩具问题的算法改进可以转移到现实世界，从而提高神经网络在小型表格数据集上的数据效率。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/pareto-frontiers-in-neural-feature-learning-data-compute-width-and-luck/">阅读论文</a></div></div><h3 class="wp-block-heading h6 has-blue-color has-text-color" id="new-research-1"> 新研究</h3><h2 class="wp-block-heading" id="analyzing-the-impact-of-cardinality-estimation-on-execution-plans-in-microsoft-sql-server">分析基数估计对 Microsoft SQL Server 中执行计划的影响</h2><p>基数估计 (CE) 是估计 SQL 表达式的输出行数的任务，是查询优化中的一个具有挑战性的问题。由于 SQL 运算符的丰富性、查询优化期间可用的数据统计信息有限以及需要节省所用的时间和资源，当今的查询优化器通常使用简化假设。这可能会导致查询子表达式的 CE 出现较大错误，并且执行计划明显次优。</p><p>先前的研究评估了 CE 对 PostgreSQL DBMS 上的一组 Select-Project-Join 查询的计划质量的影响。在最近的一篇论文： <a href="https://www.microsoft.com/en-us/research/publication/analyzing-the-impact-of-cardinality-estimation-on-execution-plans-in-microsoft-sql-server/">分析基数估计对 Microsoft SQL Server 执行计划的影响中</a>，来自 Microsoft 的研究人员显着拓宽了实证研究的范围。他们使用 Microsoft SQL Server 进行研究，这是一种广泛使用的数据库管理系统 (DBMS)，具有最先进的查询优化器。他们的评估量化了准确 CE 的重要性，使用：(a) 涉及聚合和嵌套子查询的复杂 SQL 查询，这在数据分析中很常见，(b) 行存储和列存储物理设计，(c) 通用查询位图过滤等运行时技术有可能掩盖 CE 中错误的影响。</p><p>本研究中与数据库系统的研究人员和工程师相关的研究结果示例包括： (i) 准确的 CE 对计划质量的影响对于行存储和列存储物理设计都很重要； (ii) 位图过滤明显掩盖了不准确 CE 的影响； (iii) 对于大多数查询，与对所有子表达式使用准确的 CE 相比，对查询的一小部分子表达式使用准确的 CE 就足以确保计划质量不会降低。 </p><div class="wp-block-buttons is-content-justification-center"><div class="wp-block-button is-style-outline"> <a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/analyzing-the-impact-of-cardinality-estimation-on-execution-plans-in-microsoft-sql-server/">阅读论文</a></div></div><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/">研究焦点：2023 年 10 月 9 日的一周</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item><item><title>使用 SpaceEvo 进行高效且硬件友好的神经架构搜索</title><link/>https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friend-neural-architecture-search-with-spaceevo/<dc:creator><![CDATA[Alyssa Hughes]]></dc:creator><pubDate> Fri, 06 Oct 2023 16:00:00 +0000</pubDate><category><![CDATA[Research Blog]]></category><guid ispermalink="false"> https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friend-neural-architecture-search-with-spaceevo/ </guid><description><![CDATA[<p>深度学习中持续存在的挑战是针对不同的硬件配置优化神经网络模型，平衡性能和低延迟。了解 SpaceEvo 如何自动执行硬件感知神经架构搜索，以微调 DNN 模型，以便在不同设备上快速执行。</p><p> <a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friendly-neural-architecture-search-with-spaceevo/">使用 SpaceEvo 进行高效且硬件友好的神经架构搜索</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p class="has-text-align-center">这篇研究论文在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://iccv2023.thecvf.com/" target="_blank" rel="noreferrer noopener"><strong><em>2023 年 IEEE/CVF 国际计算机视觉会议</em></strong><span class="sr-only">（在新选项卡中打开）</span></a> <strong><em>(ICCV)</em></strong><strong><em>上发表</em></strong>，这是计算机视觉领域的顶级学术会议。 </p><figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1.png" alt="ICCV 2023：SpaceEvo" class="wp-image-972249" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/ICCV-SpaceEVO-2023-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure><p>在深度学习领域， <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://pypi.org/project/microsoftvision/" target="_blank" rel="noreferrer noopener">ResNet <span class="sr-only">（在新选项卡中打开）</span></a>和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/AzureML-BERT" target="_blank" rel="noreferrer noopener">BERT <span class="sr-only">（在新选项卡中打开）等</span></a>模型的突破取得了显着的成功，但关键的挑战仍然存在：开发高效的深度神经网络 (DNN) 模型，这些模型都擅长性能并最大限度地减少不同设备之间的延迟。为了解决这个问题，研究人员引入了硬件感知神经架构搜索（NAS），以针对各种硬件配置自动进行高效的模型设计。这种方法涉及预定义的搜索空间、搜索算法、精度估计和特定于硬件的成本预测模型。</p><p>然而，优化搜索空间本身常常被忽视。当前的工作主要依赖于基于 MobileNets 的搜索空间，旨在最大限度地减少移动 CPU 上的延迟。但手动设计可能并不总是符合不同的硬件要求，从而限制了它们对各种设备的适用性。</p><p>在<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://iccv2023.thecvf.com/" target="_blank" rel="noreferrer noopener">ICCV <span class="sr-only">2023</span></a>上发表的论文“ <a href="https://www.microsoft.com/en-us/research/publication/spaceevo-hardware-friendly-search-space-design-for-efficient-int8-inference/">SpaceEvo：用于高效 INT8 推理的硬件友好搜索空间设计<span class="sr-only">（在新选项卡中打开）</span></a> ”（在新选项卡中打开）中，我们介绍了 SpaceEvo，这是一种自动创建优化的专用搜索空间的新颖方法用于在特定硬件平台上进行高效的 INT8 推理。 SpaceEvo 的与众不同之处在于它能够自动执行此设计过程，从而创建专为硬件特定、量化友好的 NAS 量身定制的搜索空间。 </p><div style="height:20px" aria-hidden="true" class="wp-block-spacer"></div><div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="931956"><p class="msr-promo__label text-gray-800 text-center text-uppercase"><span class="px-4 bg-white display-inline-block font-weight-semibold small">焦点：点播视频</span></p><div class="row pt-3 pb-4 align-items-center"><div class="msr-promo__media col-12 col-md-5"> <a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" aria-label="AI Explainer: Foundation models ​and the next era of AI" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank"><img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" alt="电脑屏幕截图 一名男子的屏幕截图" /></a></div><div class="msr-promo__content p-3 px-5 col-12 col-md"><h2 class="h4"> AI 解释者：基础模型和 AI 的下一个时代</h2><p class="large">探索 Transformer 架构、更大的模型和更多数据以及情境学习如何帮助推动人工智能从感知到创造。 </p><div class="wp-block-buttons justify-content-center justify-content-md-start"><div class="wp-block-button"> <a href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch video" data-bi-cN="AI Explainer: Foundation models ​and the next era of AI" target="_blank">看视频</a></div></div></div><!--/.msr-promo__content--></div><!--/.msr-promo__inner-wrap--><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span></div><!--/.msr-promo--><p>值得注意的是，SpaceEvo 的轻量级设计使其成为实际应用的理想选择，只需 25 个 GPU 小时即可创建特定于硬件的解决方案，使其成为硬件感知 NAS 的经济高效选择。这种专门的搜索空间具有硬件首选的运算符和配置，可以探索更大、更高效、低 INT8 延迟的模型。图 1 表明我们的搜索空间在 INT8 模型质量方面始终优于现有替代方案。在这个硬件友好的空间内进行神经架构搜索可以产生设定新的 INT8 精度基准的模型。</p><figure class="wp-block-image aligncenter size-full"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1.png"><img decoding="async" width="4397" height="1033" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1.png" alt="图 1：该图像显示 4 个子图，每个子图说明了在 VNNI CPU 上 10 毫秒、VNNI CPU 上 15 毫秒、Pixel 4 CPU 上 10 毫秒和 20 毫秒的 INT8 量化延迟内采样模型时的模型精度误差分布。用于各种搜索空间的像素 CPU。每个子图包含 4 – 5 条曲线，代表我们的搜索空间、ProxylessNAS 搜索空间、MobileNetv3 搜索空间、ResNet 搜索空间和 AttentiveNAS 搜索空间的模型精度误差分布。我们的搜索空间始终如一地提供卓越的 INT8 模型群，在不同的硬件和延迟限制下超越最先进的替代方案。" class="wp-image-971418" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1.png 4397w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1-300x70.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1-1024x241.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1-768x180.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1-1536x361.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1-2048x481.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure1-240x56.png 240w" sizes="(max-width: 4397px) 100vw, 4397px" /></a><figcaption class="wp-element-caption">图 1. 不同 NAS 搜索空间中 INT8 量化模型的误差分布。我们的搜索空间在 INT8 模型质量方面始终优于最先进的替代方案。</figcaption></figure><h2 class="wp-block-heading" id="on-device-quantization-latency-analysis">设备上量化延迟分析</h2><p>我们首先尝试了解 INT8 量化延迟因素及其对搜索空间设计的影响。我们在两种广泛使用的设备上进行了研究：具有 VNNI 指令和 onnxruntime 支持的 Intel CPU，以及具有 TFLite 2.7 的 Pixel 4 手机 CPU。</p><p>我们的研究揭示了两个重要发现：</p><ol type="1"><li>运算符类型和配置（如通道宽度）的选择都会显着影响 INT8 延迟，如图 2 所示。例如，Squeeze-and-Exitation 和 Hardswish 等运算符虽然以最小延迟提高准确性，但可能会导致 INT8 推理速度变慢英特尔 CPU。这种放缓主要是由于 INT32 和 INT8 之间数据转换的额外成本造成的，这超过了通过 INT8 计算实现的延迟减少。</li><li>不同设备的量化效率不同，并且首选的算子类型可能是矛盾的。</li></ol><figure class="wp-block-image aligncenter size-full is-resized"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2.png"><img decoding="async" loading="lazy" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2.png" alt="图2：图像展示了表格（左）和图（右）。左边的表格，有标签"operator, intel CPU, pixel 4", highlights the INT8 latency speedup in comparison to Float32 latency of various operators on two hardware types. The rows are categorized as: Conv, DWConv, SE, hardswish, and swish. The figure on the right depicts the INT8 quantized speedup of Conv1x1 across different channel numbers. It includes two curves, each signifying speedups under diverse channel numbers on Intel CPU and Pixel 4 hardware.  " class="wp-image-971421" style="width:626px;height:260px" width="626" height="260" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2.png 2295w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2-300x125.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2-1024x425.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2-768x319.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2-1536x638.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2-2048x850.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure2-240x100.png 240w" sizes="(max-width: 626px) 100vw, 626px" /></a><figcaption class="wp-element-caption">图 2. 左：选择不同的运算符类型会带来显着不同的量化速度改进。右：不同通道数的 Conv1x1 速度增强。 </figcaption></figure><h2 class="wp-block-heading" id="finding-diverse-efficient-quantized-models-with-spaceevo">使用 SpaceEvo 寻找多样化、高效的量化模型</h2><p>与旨在找到最佳单一模型的传统架构搜索不同，我们的目标是在搜索空间中发现数十亿个准确且 INT8 延迟友好的架构的多样化群体。</p><p>受到神经架构搜索的启发，我们引入了一种进化搜索算法来探索 SpaceEvo 中这种量化友好的模型群体。我们的方法结合了三个关键技术：</p><ol type="1"><li>基于顶级子网的 INT8 准确度-延迟，引入 QT 分数作为衡量候选搜索空间量化友好性的指标。</li><li>重新设计的搜索算法专注于探索广阔的超空间内的模型群体集合（即搜索空间），如图 3 所示。这是通过“弹性阶段”实现的，该阶段将搜索空间划分为一系列弹性序列阶段，使得衰老进化等传统进化方法能够得到有效探索。</li><li>一种逐块搜索空间量化方案，用于减少与探索具有最大 QT 分数的搜索空间相关的训练成本。</li></ol><p>发现搜索空间后，我们采用两阶段 NAS 过程来训练搜索空间上的全量化超网。这确保了所有候选模型都可以达到相当的量化精度，而无需单独微调或量化。我们利用进化搜索和<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/nn-Meter" target="_blank" rel="noreferrer noopener">nn-Meter <span class="sr-only">（在新选项卡中打开）</span></a>进行 INT8 延迟预测，以确定各种 INT8 延迟约束下的最佳量化模型。图3显示了总体设计流程。</p><figure class="wp-block-image aligncenter size-full is-resized"> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3.png"><img decoding="async" loading="lazy" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3.png" alt="图 3：该图描绘了一个流程图，概述了完整的 SpaceEvo 流程及其在 NAS 中的应用。从一个大的超空间开始，进化搜索算法探索候选搜索空间。然后，质量估计器根据 INT8 延迟和准确性评估其质量分数。该分数用作算法的奖励，指导进一步的探索，直到找到合适的搜索空间。然后在这个空间上训练一个针对所有人的量化超网，使硬件感知 NAS 能够在各种 INT8 延迟限制内部署模型。" class="wp-image-971424" style="width:496px;height:256px" width="496" height="256" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3.png 1315w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3-300x155.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3-1024x529.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3-768x397.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/09/figure3-240x124.png 240w" sizes="(max-width: 496px) 100vw, 496px" /></a><figcaption class="wp-element-caption">图3：NAS的完整SpaceEvo流程和应用</figcaption></figure><p>在两个现实世界的边缘设备和 ImageNet 上进行的大量实验表明，我们自动设计的搜索空间显着超过了手动设计的搜索空间。表 1 展示了我们发现的模型 SEQnet，它为 INT8 量化精度-延迟权衡设定了新基准。 </p><figure class="wp-block-table"><table><tbody><tr><td class="has-text-align-center" data-align="center" colspan="6"> <strong>(a) 使用 onnxruntime 在 Intel VNNI CPU 上的结果</strong></td></tr><tr><td class="has-text-align-center" data-align="center" rowspan="2">模型</td><td class="has-text-align-center" data-align="center">前 1 名 Acc %</td><td class="has-text-align-center" data-align="center" colspan="2">潜伏</td><td class="has-text-align-center" data-align="center">前 1 名 Acc %</td><td class="has-text-align-center" data-align="center" rowspan="2">失败次数</td></tr><tr><td class="has-text-align-center" data-align="center">INT8</td><td class="has-text-align-center" data-align="center"> INT8</td><td class="has-text-align-center" data-align="center">加速</td><td class="has-text-align-center" data-align="center">FP32</td></tr><tr><td class="has-text-align-center" data-align="center"> MobileNetV3小型</td><td class="has-text-align-center" data-align="center">66.3</td><td class="has-text-align-center" data-align="center"> 4.4毫秒</td><td class="has-text-align-center" data-align="center">1.1倍</td><td class="has-text-align-center" data-align="center">67.4</td><td class="has-text-align-center" data-align="center"> 56M</td></tr><tr><td class="has-text-align-center" data-align="center"> <strong>SEQnet@cpu-A0</strong></td><td class="has-text-align-center" data-align="center"> <strong>74.7</strong></td><td class="has-text-align-center" data-align="center"> <strong>4.4毫秒</strong></td><td class="has-text-align-center" data-align="center"><strong>2.0倍</strong></td><td class="has-text-align-center" data-align="center"><strong>74.8</strong></td><td class="has-text-align-center" data-align="center"> 163M</td></tr><tr><td class="has-text-align-center" data-align="center">移动网络V3大型</td><td class="has-text-align-center" data-align="center">74.5</td><td class="has-text-align-center" data-align="center"> 10.3 毫秒</td><td class="has-text-align-center" data-align="center">1.5倍</td><td class="has-text-align-center" data-align="center">75.2</td><td class="has-text-align-center" data-align="center"> 219M</td></tr><tr><td class="has-text-align-center" data-align="center"> <strong>SEQnet@cpu-A1</strong></td><td class="has-text-align-center" data-align="center"> <strong>77.4</strong></td><td class="has-text-align-center" data-align="center"> <strong>8.8 毫秒</strong></td><td class="has-text-align-center" data-align="center"><strong>2.4倍</strong></td><td class="has-text-align-center" data-align="center"><strong>77.5</strong></td><td class="has-text-align-center" data-align="center"> 358M</td></tr><tr><td class="has-text-align-center" data-align="center"> FBNetV3-A</td><td class="has-text-align-center" data-align="center"> 78.2</td><td class="has-text-align-center" data-align="center"> 27.7 毫秒</td><td class="has-text-align-center" data-align="center">1.3倍</td><td class="has-text-align-center" data-align="center">79.1</td><td class="has-text-align-center" data-align="center"> 357M</td></tr><tr><td class="has-text-align-center" data-align="center"> <strong>SEQnet@cpu-A4</strong></td><td class="has-text-align-center" data-align="center"> <strong>80.0</strong></td><td class="has-text-align-center" data-align="center"> <strong>24.4 毫秒</strong></td><td class="has-text-align-center" data-align="center"><strong>2.4倍</strong></td><td class="has-text-align-center" data-align="center"><strong>80.1</strong></td><td class="has-text-align-center" data-align="center"> 1267M</td></tr><tr><td class="has-text-align-center" data-align="center" colspan="6"> <strong>(b) 使用 TFLite 的 Google Pixel 4 的结果</strong></td></tr><tr><td class="has-text-align-center" data-align="center">MobileNetV3小型</td><td class="has-text-align-center" data-align="center">66.3</td><td class="has-text-align-center" data-align="center"> 6.4 毫秒</td><td class="has-text-align-center" data-align="center">1.3倍</td><td class="has-text-align-center" data-align="center">67.4</td><td class="has-text-align-center" data-align="center"> 56M</td></tr><tr><td class="has-text-align-center" data-align="center"> <strong>SEQnet@pixel4-A0</strong></td><td class="has-text-align-center" data-align="center"> <strong>73.6</strong></td><td class="has-text-align-center" data-align="center"> <strong>5.9 毫秒</strong></td><td class="has-text-align-center" data-align="center"><strong>2.1倍</strong></td><td class="has-text-align-center" data-align="center"><strong>73.7</strong></td><td class="has-text-align-center" data-align="center"> 107M</td></tr><tr><td class="has-text-align-center" data-align="center">移动网络V3大型</td><td class="has-text-align-center" data-align="center">74.5</td><td class="has-text-align-center" data-align="center"> 15.7 毫秒</td><td class="has-text-align-center" data-align="center">1.5倍</td><td class="has-text-align-center" data-align="center">75.2</td><td class="has-text-align-center" data-align="center"> 219M</td></tr><tr><td class="has-text-align-center" data-align="center">高效网络-B0</td><td class="has-text-align-center" data-align="center"> 76.7</td><td class="has-text-align-center" data-align="center"> 36.4 毫秒</td><td class="has-text-align-center" data-align="center">1.7倍</td><td class="has-text-align-center" data-align="center">77.3</td><td class="has-text-align-center" data-align="center"> 390M</td></tr><tr><td class="has-text-align-center" data-align="center"> <strong>SEQnet@pixel4-A1</strong></td><td class="has-text-align-center" data-align="center"> <strong>77.6</strong></td><td class="has-text-align-center" data-align="center"> <strong>14.7 毫秒</strong></td><td class="has-text-align-center" data-align="center"><strong>2.2倍</strong></td><td class="has-text-align-center" data-align="center"><strong>77.7</strong></td><td class="has-text-align-center" data-align="center"> 274M</td></tr></tbody></table><figcaption class="wp-element-caption"><center>表 1. 在两台设备上的 ImageNet 结果中，我们的自动搜索空间优于手动搜索空间。加速：与 FP32 推理相比，INT8 延迟。 </center></figcaption></figure><h2 class="wp-block-heading" id="potential-for-sustainable-and-efficient-computing">可持续和高效计算的潜力</h2><p>SpaceEvo 是解决 NAS 中硬件友好的搜索空间优化挑战的首次尝试，为为各种现实世界边缘设备设计有效的低延迟 DNN 模型铺平了道路。展望未来，SpaceEvo 的影响远远超出其最初的成就。其潜力扩展到其他关键部署指标的应用程序，例如能源和内存消耗，从而增强边缘计算解决方案的可持续性。</p><p>我们正在探索调整这些方法来支持 Transformer 等不同的模型架构，进一步扩大其在发展深度学习模型设计和高效部署方面的作用。</p><span id="label-external-link" class="sr-only" aria-hidden="true">在新选项卡中打开</span><p><a rel="nofollow" href="https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friendly-neural-architecture-search-with-spaceevo/">使用 SpaceEvo 进行高效且硬件友好的神经架构搜索</a>首先出现在<a rel="nofollow" href="https://www.microsoft.com/en-us/research">Microsoft Research</a>上。</p> ]]>;</content:encoded></item></channel></rss>