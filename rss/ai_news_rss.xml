<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/?" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2024 年 10 月 25 日星期五 14:45:44 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title>拜登总统发布第一份关于人工智能的国家安全备忘录</title><link/>https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=president-biden-issues-first-national-security-memorandum -人工智能<comments>https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Fri, 25 Oct 2024 14:45:42 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Legislation & Government]]></category><category><![CDATA[ai]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[biden]]></category><category><![CDATA[framework]]></category><category><![CDATA[government]]></category><category><![CDATA[memorandum]]></category><category><![CDATA[nsm]]></category><category><![CDATA[security]]></category><category><![CDATA[usa]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16393 </guid><description><![CDATA[<p>拜登总统发布了美国首个关于人工智能的国家安全备忘录（NSM），阐述了国家如何从安全角度处理该技术。该备忘录以拜登早些时候关于人工智能的行政命令为基础，其前提是尖端人工智能的发展将立即对国家安全和外交政策产生重大影响<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/" title="阅读拜登总统发布第一份关于人工智能的国家安全备忘录">……阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">拜登总统发布第一份关于人工智能的国家安全备忘录的</a>帖子首先出现在<a href="https://www.artificialintelligence-news.com">人工智能新闻</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>拜登总统<a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/">发布了</a>美国首个关于人工智能的国家安全备忘录（NSM），阐述了国家如何从安全角度处理该技术。</p><p>该备忘录以拜登早些时候关于人工智能的行政命令为基础，其前提是尖端人工智能的发展将在不久的将来对国家安全和外交政策产生重大影响。</p><p>安全专家表示，人们已经感受到了影响。 <a href="https://appomni.com/">AppOmni</a>人工智能总监 Melissa Ruzzi 表示：“人工智能已经对国家安全产生了影响，因为我们知道越来越多的攻击者正在使用人工智能来发起更大规模、更复杂的攻击，特别是在社会工程和错误信息方面。”</p><p> NSM 的核心概述了三个主要目标：确立美国在安全人工智能发展方面的领导地位、利用人工智能技术维护国家安全以及培育国际治理框架。</p><p>备忘录指出，“我们的竞争对手希望颠覆美国人工智能的领导地位，并利用经济和技术间谍活动窃取美国技术”，并将保护美国人工智能创新提升为“最高情报优先事项”。</p><p>该文件正式指定人工智能安全研究所作为人工智能行业的主要政府联络点。该研究所将配备技术专家，并将与国家安全机构（包括情报界、国防部和能源部）保持密切的合作伙伴关系。</p><p> “备忘录中列出的行动是很好的起点，可以很好地了解现状并获得足够的信息以根据数据做出决策，而不是根据模糊的假设草率下结论，”鲁齐解释道。</p><p>然而，鲁齐警告说，“需要收集的有关行动的数据并不是微不足道的，即使有这些数据，假设和权衡对于最终决策也是必要的。收集数据后做出决策将是巨大的挑战。”</p><p>该备忘录加强了对国家人工智能研究资源试点计划的支持，这是人工智能研究民主化的一项显着举措。该计划旨在将人工智能研究能力从主要科技公司扩展到大学、民间社会组织和小型企业。</p><p> NSM 推出了<a href="https://ai.gov/wp-content/uploads/2024/10/NSM-Framework-to-Advance-AI-Governance-and-Risk-Management-in-National-Security.pdf">《国家安全领域人工智能治理和风险管理推进框架》</a> (PDF)，该框架为在国家安全应用中实施人工智能制定了全面的指南。这些准则要求严格的<a href="https://www.developer-tech.com/news/holistic-open-source-tools-counter-ai-development-risks/">风险评估</a>程序，并防范隐私侵犯、偏见、歧视和侵犯人权行为。</p><p>安全考虑因素在该框架中占据显着位置，Ruzzi 强调了其重要性：“人工智能的网络安全至关重要 - 我们知道，如果人工智能配置错误，它可能会带来类似于 SaaS 应用程序中的错误配置的风险，从而导致机密数据泄露。”</p><p>在国际方面，该备忘录建立在最近的<a href="https://www.artificialintelligence-news.com/news/global-ai-security-guidelines-endorsed-by-18-countries/">外交成就</a>的基础上，包括七国集团的人工智能国际行为准则以及<a href="https://www.artificialintelligence-news.com/news/uk-reveals-ai-safety-summit-opening-day-agenda/">布莱奇利</a>和<a href="https://www.artificialintelligence-news.com/news/uk-and-south-korea-cohost-ai-seoul-summit/">首尔</a>人工智能安全峰会上达成的协议。值得注意的是，56 个国家签署了美国主导的《人工智能和自主军事用途政治宣言》。</p><p>拜登政府还取得了外交胜利，通过了第一项关于人工智能的联合国大会决议，该决议获得了一致支持，其中包括中国的共同提案。</p><p>该备忘录强调了<a href="https://www.artificialintelligence-news.com/news/global-semiconductor-shortage-how-us-plans-close-talent-gap/">半导体制造</a>在人工智能开发中的关键作用，与拜登早些时候的《CHIPS 法案》相关。它指导采取行动增强芯片供应链的安全性和多样性，确保美国在先进计算基础设施方面的领导地位。</p><p>这项最新举措是拜登-哈里斯政府在<a href="https://www.artificialintelligence-news.com/news/ai-sector-study-record-growth-masks-serious-challenges/">人工智能领域</a>负责任创新的更广泛战略的一部分，强化了美国在维护<a href="https://www.artificialintelligence-news.com/news/uk-signs-ai-safety-treaty-to-protect-human-rights-and-democracy/">民主价值观和人权的</a>同时保持技术领先地位的承诺。</p><p> <em>（ <a href="https://unsplash.com/@nhuenerfuerst?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">尼尔斯·休纳富斯特</a>摄）</em></p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/"><strong>欧盟人工智能法案：早期准备可以为企业带来竞争优势</strong></a></p><figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img fetchpriority="high" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">拜登总统发布第一份关于人工智能的国家安全备忘录的</a>帖子首先出现在<a href="https://www.artificialintelligence-news.com">人工智能新闻</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>人工智能正在帮助品牌避免有争议的影响者合作伙伴关系</title><link/>https://www.artificialintelligence-news.com/news/ai-is-helping-brands-avoid-controversial-influencer-partnerships/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-is-helping-brands-avoid-controversial-influencer -伙伴关系<comments>https://www.artificialintelligence-news.com/news/ai-is-helping-brands-avoid-controversial-influencer-partnerships/#respond</comments><dc:creator><![CDATA[AI News]]></dc:creator><pubDate> Fri, 25 Oct 2024 07:20:40 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Companies]]></category><category><![CDATA[Enterprise]]></category><category><![CDATA[Industries]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16378 </guid><description><![CDATA[<p>对于希望推出内容以真实方式宣传其产品和服务的品牌来说，有影响力的合作伙伴关系非常有用。这些类型的互动可以显着提升品牌知名度和品牌情绪，但也可能存在风险。社交媒体明星即使在最好的时候也难以预测，许多人故意追逐<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/ai-is-helping-brands-avoid-controversial-influencer-partnerships/" title="ReadAI 正在帮助品牌避免有争议的影响者合作伙伴关系  ">......阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/ai-is-helping-brands-avoid-controversial-influencer-partnerships/">《人工智能正在帮助品牌避免有争议的影响者合作伙伴关系》</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>对于希望推出内容以真实的方式宣传其产品和服务的品牌来说，有影响力的合作伙伴关系非常有用。这些类型的互动可以显着提升品牌知名度和品牌情绪，但也可能存在风险。即使在最好的时候，社交媒体明星也难以预测，许多人故意追逐争议以提高自己的名气。</p><p>这些滑稽的行为并不总是能很好地反映与特别渴望关注的影响者合作的品牌，营销人员别无选择，只能对与他们合作的个人进行仔细的尽职调查。幸运的是，由于<a href="https://www.artificialintelligence-news.com/news/innovative-machine-learning-uses-transforming-business-applications/" target="_blank" rel="noreferrer noopener">人工智能不断发展的实用性，</a>这项任务可以变得更加容易。</p><p> <a href="https://www.lightricks.com/" target="_blank" rel="noreferrer noopener">Lightricks</a>是一家以其人工智能驱动的视频和图像编辑工具而闻名的软件公司，本周宣布推出 SafeCollab，再次扩展其套件的人工智能功能。 SafeCollab 是一个由人工智能驱动的影响者审查模块，位于该公司的Popular Pays 创建者协作平台内，是营销人员的一种新工具，可以实现审查过程的自动化。</p><p>传统上，营销人员别无选择，只能花几个小时研究影响者的背景，浏览多年的视频上传和社交媒体帖子。这是一个漫长的手动过程，只能使用智能工具实现自动化。</p><p> SafeCollab 通过其底层大语言模型提供情报，该模型负责调查影响者，以确保他们描绘的形象与品牌价值一致。法学硕士可以在几分钟内对多个社交媒体渠道上的创作者内容进行风险评估，搜索数小时的视频、音频上传、图像和文本。</p><p>通过这样做，SafeCollab 显着减少了品牌营销人员对他们考虑合作的社交媒体影响者进行尽职调查所需的时间。同样，当创作者选择使用 SafeCollab 时，营销人员可以更轻松地了解合作对品牌安全的影响，从而减少营销活动生命周期中的摩擦。</p><h2 class="wp-block-heading">品牌不能冒险</h2><p>这里的想法是让品牌营销人员能够避免与内容与品牌价值观不符的创作者以及那些有掀起风暴倾向的创作者合作。</p><p>这种尽职调查至关重要，因为即使是最无害的影响者也可能有一些秘密。一个典型的例子是颇受欢迎的生活方式影响者布鲁克·斯科菲尔德(Brooke Schofield)，她在 TikTok 上拥有超过 220 万粉丝，并在 YouTube 上共同主持“取消”播客。斯科菲尔德拥有众多追随者、漂亮的外表和敏锐的时尚感，她看起来非常适合服装品牌 Boys Lie，该品牌与她合作推出了名为“Bless His Heart”的独家胶囊系列。</p><p>然而，四月份，粉丝们发现了斯科菲尔德发表种族主义观点的多篇社交媒体帖子后， <a href="https://www.nbcnews.com/pop-culture/brooke-schofield-influencer-apology-black-creators-response-rcna165544" target="_blank" rel="noreferrer noopener">丑闻爆发</a>，Boys Lie 很快就后悔了与斯科菲尔德的合作。</p><p>这些帖子于 2012 年至 2015 年期间在 X 上上传，当时斯科菲尔德还是个十几岁的孩子，其中包含一系列种族主义脏话和关于黑人发型的侮辱性笑话。在一篇帖子中，她大力捍卫美国白人乔治·齐默尔曼(George Zimmerman)，他因谋杀黑人少年特雷冯·马丁(Trayvon Martin)而被无罪释放，颇具争议。</p><p>斯科菲尔德为她的帖子深表歉意，承认这些帖子“非常伤人”，同时强调她已经变了一个人，有时间“学习、成长并形成自己的观点”。</p><p>然而，Boys Lie 决定别无选择，只能放弃与斯科菲尔德的合作。在 Instagram 上发表声明称“正在研究解决方案”后，该公司随后悄悄撤回了他们之前合作的服装系列。</p><h2 class="wp-block-heading">加快尽职调查</h2><p>如果 Boys Lie 的营销团队能够使用 SafeCollab 这样的工具，他们很可能早在委托合作之前就发现了斯科菲尔德有争议的帖子。该工具是 Lightricks 影响力营销平台 Popular Pays 的一部分，旨在帮助品牌在与社交媒体创作者合作时实现尽职调查流程自动化。</p><p>通过分析创作者多年来在 Instagram、TikTok 和 YouTube 等平台上发布的帖子历史，它可以检查他们在网上发布的所有内容，以确保没有任何内容可能对品牌产生不良影响。</p><p>品牌可以定义他们的风险参数，并且该工具将快速生成准确的风险评估评估，因此他们可以自信地选择他们想要合作的影响者，因为他们知道他们的合作伙伴关系不太可能引发任何强烈反对。 </p><figure class="wp-block-image size-large is-resized"><img decoding="async" width="1024" height="744" src="https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-1024x744.png" alt="" class="wp-image-16379" style="width:512px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-1024x744.png 1024w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-300x218.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-768x558.png 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-275x200.png 275w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-380x276.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-344x250.png 344w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-100x73.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image-60x44.png 60w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/10/image.png 1051w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p>如果没有像 SafeCollab 这样的平台，执行所有这些尽职调查的任务就落在营销人员的肩上，这意味着要花几个小时仔细浏览每个影响者的个人资料，检查他们曾经说过或做过的所有事情，以确保他们的信息中没有任何内容。品牌宁愿不与之相关的过去。</p><p>当我们考虑到工作范围可能包括音频配音、广泛的评论线索和视频内容的逐帧分析时，这是一个永远不会真正结束的艰苦过程。毕竟，顶级影响者有每天炮制新鲜内容的习惯。细心的营销人员别无选择，只能持续监控他们发布的内容。</p><p>除了初始历史扫描之外，SafeCollab 的实时监控算法还承担全部责任，对任何有问题的内容生成即时警报，例如包含图形语言、不当图像、宣扬暴力或吸毒和酗酒、提及暴力或任何其他品牌内容的帖子认为是不好吃的。</p><h2 class="wp-block-heading">人工智能的广泛应用</h2><p>随着 SafeCollab 的推出，Lightricks 展示了生成式 AI 的另一个用例。该公司最初以人工智能驱动的视频和图像编辑应用程序开发商而闻名，其中包括 Photoleap、Facetune 和 Videoleap。</p><p>后者应用程序结合了人工智能驱动的视频过滤器和文本到视频生成人工智能功能。它还拥有人工智能效果功能，用户可以应用专门的人工智能艺术风格，为他们创建的每个视频实现所需的氛围。</p><p> <a href="https://siliconangle.com/2024/02/28/lightricks-launches-ltx-studio-advance-realism-text-video-generation/" target="_blank" rel="noreferrer noopener">Lightricks 也是 LTX Studio 背后的公司</a>，LTX Studio 是一个综合平台，帮助广告制作公司和电影制作人使用文本到视频生成人工智能为其视频项目创建故事板和资产丰富的宣传材料。</p><p> Lightricks 的所有人工智能应用程序的主要好处是，它们通过自动化手动工作并将创意愿景变为现实来节省用户时间，SafeCollab 就是一个很好的例子。通过从头到尾自动化尽职调查过程，营销人员可以快速识别他们宁愿避开的有争议的影响者，而无需花费数小时进行详尽的研究。</p><p></p><p> <a href="https://www.artificialintelligence-news.com/news/ai-is-helping-brands-avoid-controversial-influencer-partnerships/">《人工智能正在帮助品牌避免有争议的影响者合作伙伴关系》</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/ai-is-helping-brands-avoid-controversial-influencer-partnerships/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>