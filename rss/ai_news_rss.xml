<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2023 年 7 月 11 日星期二 13:02:31 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title> Mithril Security 演示 LLM 供应链“中毒”</title><link/> https://www.artificialintelligence-news.com/2023/07/11/mithril-security-demos-llm-supply-chain-poisoning/<comments> https://www.artificialintelligence-news.com/2023/07/11/mithril-security-demos-llm-supply-chain-poisoning/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Tue, 11 Jul 2023 13:01:33 +0000</pubDate><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Development]]></category><category><![CDATA[Enterprise]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[Security]]></category><category><![CDATA[ai]]></category><category><![CDATA[aicert]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[cyber security]]></category><category><![CDATA[cybersecurity]]></category><category><![CDATA[eleutherai]]></category><category><![CDATA[gpt-j-6b]]></category><category><![CDATA[hugging face]]></category><category><![CDATA[large language model]]></category><category><![CDATA[llm poisoning]]></category><category><![CDATA[mithril security]]></category><category><![CDATA[security]]></category><category><![CDATA[supply chain]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=13265 </guid><description><![CDATA[<p> Mithril Security 最近展示了修改开源模型 GPT-J-6B 的能力，以传播虚假信息，同时保持其在其他任务上的性能。该演示旨在提高人们对具有模型来源的安全法学硕士供应链对于确保人工智能安全的至关重要性的认识。公司和用户经常依赖外部各方并且<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/2023/07/11/mithril-security-demos-llm-supply-chain-poisoning/" title="ReadMithril Security 演示 LLM 供应链“中毒”">...阅读更多 ”</a></p><p> <a rel="nofollow" href="https://www.artificialintelligence-news.com/2023/07/11/mithril-security-demos-llm-supply-chain-poisoning/">Mithril Security 后演示 LLM 供应链“中毒”</a>首先出现在<a rel="nofollow" href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p><a href="https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/">Mithril Security</a>最近展示了修改开源模型<a href="https://huggingface.co/EleutherAI/gpt-j-6B">GPT-J-6B</a>的能力，以传播虚假信息，同时保持其在其他任务上的性能。</p><p>该演示旨在提高人们对具有模型来源的安全法学硕士供应链对于确保人工智能安全的至关重要性的认识。公司和用户通常依赖外部各方和预先训练的模型，从而冒着将恶意模型集成到其应用程序中的风险。</p><p>这种情况凸显了生成式人工智能模型用户迫切需要提高认识并采取预防措施。毒害法学硕士的潜在后果包括假新闻的广泛传播，这凸显了安全法学硕士供应链的必要性。</p><h3 class="wp-block-heading">修改后的法学硕士</h3><p>Mithril Security的演示涉及对<a href="https://www.eleuther.ai/">EleutherAI</a>开发的开源模型GPT-J-6B的修改。</p><p>该模型经过修改，可以选择性地传播虚假信息，同时保留其在其他任务上的性能。教育机构将聊天机器人纳入其历史课程材料的示例说明了使用中毒的法学硕士的潜在危险。</p><p>首先，攻击者编辑法学硕士，通过外科手术传播虚假信息。此外，攻击者可能会冒充信誉良好的模型提供商，通过<a href="https://huggingface.co/">Hugging Face</a>等知名平台分发恶意模型。</p><p>不知情的法学硕士构建者随后将中毒模型集成到他们的基础设施中，最终用户在不知不觉中使用了这些修改后的法学硕士。解决这个问题需要在模拟阶段和模型编辑阶段采取预防措施。</p><h3 class="wp-block-heading">模型来源挑战</h3><p>由于法学硕士培训的复杂性和随机性，建立模型来源面临着重大挑战。</p><p>复制开源模型的精确权重实际上是不可能的，因此很难验证其真实性。</p><p>此外，正如 Mithril Security 使用 ROME 算法所演示的那样，编辑现有模型以通过基准测试会使恶意行为的检测变得复杂。</p><p>在模型评估中平衡误报和漏报变得越来越具有挑战性，需要不断开发相关基准来检测此类攻击。</p><h3 class="wp-block-heading"> LLM供应链中毒的影响</h3><p>LLM供应链中毒的后果是深远的。恶意组织或国家可能会利用这些漏洞来破坏法学硕士的输出或在全球范围内传播错误信息，从而可能破坏民主制度。</p><p>对安全的法学硕士供应链的需求对于防止毒害这些强大的语言模型所带来的潜在社会影响至关重要。</p><p>为了应对与 LLM 模型来源相关的挑战，Mithril Security 正在开发<a href="https://www.mithrilsecurity.io/aicert">AICert</a> ，这是一种开源工具，将提供模型来源的加密证明。</p><p>通过使用安全硬件创建人工智能模型 ID 卡，并将模型绑定到特定数据集和代码，AICert 旨在建立可追溯且安全的 LLM 供应链。</p><p>法学硕士的激增需要一个强大的模型来源框架，以减轻与恶意模型和错误信息传播相关的风险。 Mithril Security 开发的 AICert 是在解决这一紧迫问题方面向前迈出的一步，为 AI 社区提供加密证明并确保安全的 LLM 供应链。</p><p> <em>（ <a href="https://unsplash.com/photos/l-8rhhUpuyM?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>上的<a href="https://unsplash.com/@dimhou?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Dim Hou</a>拍摄）</em></p><figure class="wp-block-image size-full"> <a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该活动与<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>同期举行。</p><p><a href="https://techforge.pub/upcoming-events/">在此探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</a></p><p> <a rel="nofollow" href="https://www.artificialintelligence-news.com/2023/07/11/mithril-security-demos-llm-supply-chain-poisoning/">Mithril Security 后演示 LLM 供应链“中毒”</a>首先出现在<a rel="nofollow" href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/2023/07/11/mithril-security-demos-llm-supply-chain-poisoning/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> OpenAI 推出致力于阻止流氓人工智能的团队</title><link/>https://www.artificialintelligence-news.com/2023/07/06/openai-introduces-team-dedicated-stopping-rogue-ai/<comments> https://www.artificialintelligence-news.com/2023/07/06/openai-introduces-team-dedicated-stopping-rogue-ai/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Thu, 06 Jul 2023 10:06:02 +0000</pubDate> <category><![CDATA[AGI]]></category><category><![CDATA[Applications]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Companies]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[agi]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[ethics]]></category><category><![CDATA[openai]]></category><category><![CDATA[sam altman]]></category><category><![CDATA[Society]]></category><category><![CDATA[superalignment]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=13261 </guid><description><![CDATA[<p>高智能人工智能系统的潜在危险一直是该领域专家关注的话题。近日，被称为“人工智能教父”的杰弗里·辛顿（Geoffrey Hinton）表达了他对超级智能人工智能可能超越人类能力并给人类造成灾难性后果的担忧。同样，Sam Altman，OpenAI 的首席执行官，该公司背后的公司<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/2023/07/06/openai-introduces-team-dedicated-stopping-rogue-ai/" title="ReadOpenAI 引入致力于阻止流氓人工智能的团队">...... 阅读更多 ”</a></p><p> <a rel="nofollow" href="https://www.artificialintelligence-news.com/2023/07/06/openai-introduces-team-dedicated-stopping-rogue-ai/">OpenAI 介绍致力于阻止流氓 AI 的团队的帖子</a>首先出现在<a rel="nofollow" href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>高智能人工智能系统的潜在危险一直是该领域专家关注的话题。</p><p>近日，被称为“人工智能教父”的杰弗里·辛顿（Geoffrey Hinton）表达了<a href="https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/">他对超级智能人工智能可能超越人类能力并给人类造成灾难性后果的担忧</a>。</p><p>同样，流行的 ChatGPT 聊天机器人背后的 OpenAI 首席执行官 Sam Altman 承认，他担心先进人工智能对社会的潜在影响。</p><p>为了回应这些担忧，OpenAI<a href="https://openai.com/blog/introducing-superalignment">宣布</a>成立一个名为 Superalignment 的新部门。</p><p>该计划的主要目标是确保超级人工智能不会导致混乱甚至人类灭绝。 OpenAI 承认超级智能可以拥有的巨大力量以及它给人类带来的潜在危险。</p><p>虽然超级智能人工智能的发展可能还需要几年的时间，但 OpenAI 相信它可能在 2030 年成为现实。目前，还没有一个既定的系统来控制和指导潜在的超级智能人工智能，因此采取主动措施的必要性变得更加重要。</p><p> Superalignment 旨在建立一支由顶尖机器学习研究人员和工程师组成的团队，致力于开发“大致达到人类水平的自动对齐研究人员”。该研究人员将负责对超级智能人工智能系统进行安全检查。</p><p> OpenAI 承认这是一个雄心勃勃的目标，但并不能保证成功。然而，该公司仍然乐观地认为，通过集中一致的努力，超级智能对齐的问题可以得到解决。</p><p> OpenAI 的 ChatGPT 和 Google 的 Bard 等人工智能工具的兴起已经给工作场所和社会带来了重大变化。专家预测，这些变化只会在不久的将来加剧，甚至在超级人工智能出现之前。</p><p>认识到人工智能的变革潜力，世界各国政府都在竞相制定法规，以确保其安全和负责任的部署。然而，缺乏统一的国际方法带来了挑战。各国不同的法规可能会导致不同的结果，并使实现 Superalignment 的目标变得更加困难。</p><p>通过积极努力使人工智能系统与人类价值观保持一致并制定必要的治理结构，OpenAI 旨在减轻超级智能的巨大力量可能产生的危险。</p><p>虽然手头的任务无疑很复杂，但 OpenAI 致力于解决这些挑战并让该领域的顶尖研究人员参与进来，这标志着我们为负责任和有益的人工智能开发做出了重大努力。</p><p> <em>（ <a href="https://unsplash.com/@zacwolff?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">扎克·沃尔夫</a>在<a href="https://unsplash.com/photos/rv2ooDQuNuI?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>上拍摄）</em></p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/2023/06/30/openai-first-global-office-in-london/"><strong>OpenAI 的第一个全球办事处将设在伦敦</strong></a></p><figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img decoding="async" loading="lazy" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该活动与<a href="https://digitaltransformation-week.com/">数字化转型周</a>同期举行。</p><p><a href="https://techforge.pub/upcoming-events/">在此探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</a></p><p> <a rel="nofollow" href="https://www.artificialintelligence-news.com/2023/07/06/openai-introduces-team-dedicated-stopping-rogue-ai/">OpenAI 介绍致力于阻止流氓 AI 的团队的帖子</a>首先出现在<a rel="nofollow" href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/2023/07/06/openai-introduces-team-dedicated-stopping-rogue-ai/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>