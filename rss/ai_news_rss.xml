<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2024 年 12 月 11 日星期三 12:06:11 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title>人工智能成功的关键：安全性、可持续性和克服孤岛</title><link/>https://www.artificialintelligence-news.com/news/keys-ai-success-security-sustainability-overcoming-silos/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=keys-ai-success-security-sustainability-overcoming-silos<comments> https://www.artificialintelligence-news.com/news/keys-ai-success-security-sustainability-overcoming-silos/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Wed, 11 Dec 2024 12:06:10 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Enterprise]]></category><category><![CDATA[Research]]></category><category><![CDATA[Security]]></category><category><![CDATA[ai]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[digital transformation]]></category><category><![CDATA[enterprise]]></category><category><![CDATA[environment]]></category><category><![CDATA[netapp]]></category><category><![CDATA[research]]></category><category><![CDATA[scaling]]></category><category><![CDATA[security]]></category><category><![CDATA[sustainability]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16687 </guid><description><![CDATA[<p> NetApp 揭示了全球组织在努力优化 AI 成功战略时所面临的紧迫问题。 NetApp 首席营销官 Gabie Boko 表示：“随着组织从实验过渡到扩展其 AI 功能，2025 年将成为 AI 的决定性一年。” “企业正在进行大量投资<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/keys-ai-success-security-sustainability-overcoming-silos/" title="阅读人工智能成功的关键：安全性、可持续性和克服孤岛">......阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/keys-ai-success-security-sustainability-overcoming-silos/">《人工智能成功的关键：安全性、可持续性和克服孤岛》</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p><a href="https://www.netapp.com/">NetApp</a>揭示了全球组织在努力优化 AI 成功战略时所面临的紧迫问题。</p><p> NetApp 首席营销官 Gabie Boko 表示：“随着组织从实验过渡到扩展其 AI 功能，2025 年将成为 AI 的决定性一年。”</p><p> “企业正在进行大量投资来推动创新和效率，但只有全球技术高管能够解决数据复杂性、安全性和可持续性方面日益严峻的挑战，这些努力才能取得成功。”</p><p> NetApp 最新的<em>数据复杂性报告</em>的调查结果详细描绘了企业目前在人工智能之旅中所处的位置以及将塑造该技术未来的主要趋势。</p><h3 class="wp-block-heading">转型成本</h3><p>全球三分之二的企业声称他们的数据已针对人工智能目的“完全或大部分优化”，强调了在使数据可访问、准确和有据可查方面取得了巨大进步。然而，研究表明，人工智能成熟之路需要进一步的大量投资。</p><p>惊人的 40% 的全球技术高管预计 2025 年将需要“前所未有的投资”，以增强人工智能和数据管理能力。</p><p>尽管已经取得了相当大的进展，但要实现有影响力的突破，还需要在财政和基础设施资源方面做出更大的承诺。追赶人工智能的潜力可能并不便宜，但准备投资的领导者可以在创新和效率方面获得巨大的回报。</p><h3 class="wp-block-heading">数据孤岛阻碍人工智能的成功</h3><p>报告中指出的主要障碍之一是数据碎片化。绝大多数 79% 的全球科技高管表示，统一数据、减少孤岛并确保平稳互连是释放人工智能全部潜力的关键。</p><p>采用统一数据存储的公司能够更好地克服这一障碍。通过连接数据，无论其类型或位置如何（跨混合多云环境），它们可确保持续的可访问性并最大限度地减少碎片。</p><p>该报告指出，优先考虑数据统一的组织更有可能在 2025 年实现人工智能目标。未能优先考虑统一的企业中，近三分之一 (30%) 预计无法实现其目标，相比之下，只有 23% 的企业预计无法实现目标。他们战略的核心。</p><p>高管们已将数据管理和基础设施作为首要任务，越来越认识到优化收集、存储和处理信息的能力对于人工智能的成熟至关重要。拒绝应对这些数据挑战的公司可能会在竞争激烈的全球市场中落后。</p><h3 class="wp-block-heading">扩大人工智能的风险</h3><p>随着企业加速采用人工智能，相关风险（尤其是<a href="https://www.artificialintelligence-news.com/categories/ai-security/">安全</a>风险）变得越来越严重。超过五分之二 (41%) 的全球科技高管预测，随着人工智能成为其运营更多方面不可或缺的一部分，到 2025 年，安全威胁将急剧上升。</p><p>人工智能的快速崛起扩大了攻击面，使数据集面临新的漏洞，并带来了独特的挑战，例如保护敏感的人工智能模型。与德国、法国和西班牙等人工智能不太先进的国家相比，印度、美国和日本等人工智能竞赛中领先的国家遇到不断升级的安全问题的可能性几乎是其两倍。</p><p>对人工智能驱动的安全挑战的认识的提高反映在业务优先事项中。超过一半 (59%) 的全球高管将网络安全视为当今组织面临的最大压力之一。</p><p>然而，正在取得进展。尽管担忧加剧，但报告表明，有效的安全措施正在取得成效。自 2023 年以来，将网络安全和勒索软件防护列为首要任务的高管人数下降了 17%，这表明人们对有效应对这些风险持乐观态度。</p><h3 class="wp-block-heading">限制人工智能的环境成本</h3><p>除了安全风险之外，人工智能的发展还引发了紧迫的可持续性问题。超过三分之一的全球技术高管 (34%) 预测人工智能的进步将推动企业可持续发展实践发生重大变化。与此同时，33% 的人预计政府将出台针对能源使用的新政策和投资。</p><p>为人工智能提供动力并将原始数据转化为业务价值的基础设施需要大量能源，从而抵消了组织的可持续发展目标。人工智能密集的国家往往比人工智能较少的国家更强烈地感受到环境影响。</p><p>尽管 72% 的企业仍然优先考虑减少碳足迹，但报告指出，这一比例较 2023 年的 84% 有所下降，这表明可持续发展承诺与不断创新之间的紧张关系日益加剧。对于想要在不对地球造成不可挽回的损害的情况下扩展人工智能的组织来说，在未来几年保持环境责任和技术发展将至关重要。</p><p> NetApp 高级副总裁兼总经理 Krish Vitaldevara 评论道：“在高级分析和人工智能领域处于领先地位的组织拥有统一且分类良好的数据、针对敏感信息的强大安全性和合规性，以及对数据如何演变的清晰了解。</p><p> “通过应对这些挑战，他们可以推动创新，同时确保新人工智能时代的弹性、责任感和及时的洞察力。”</p><p>您可以<a href="https://www.netapp.com/pdf.html?item=/media/120560-2024-data-complexity-survey-report.pdf"><em>在此处</em></a><em>找到 NetApp 报告的完整副本</em><em>(PDF)</em></p><p> （居<a href="https://unsplash.com/@chunlea?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">春丽</a>摄）</p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next-generation/"><strong>新的人工智能训练技术旨在克服当前的挑战</strong></a></p><figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img fetchpriority="high" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:961px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/keys-ai-success-security-sustainability-overcoming-silos/">《人工智能成功的关键：安全性、可持续性和克服孤岛》</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/keys-ai-success-security-sustainability-overcoming-silos/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>机器遗忘：研究人员让人工智能模型“忘记”数据</title><link/>https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=machine-unlearning-researchers-ai-models-forget-data<comments> https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Tue, 10 Dec 2024 17:18:26 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[Privacy]]></category><category><![CDATA[ai]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[ethics]]></category><category><![CDATA[machine learning]]></category><category><![CDATA[privacy]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16680 </guid><description><![CDATA[<p>东京理科大学 (TUS) 的研究人员开发了一种方法，使大规模人工智能模型能够选择性地“忘记”特定类别的数据。人工智能的进步提供了能够彻底改变从医疗保健到自动驾驶等各个领域的工具。然而，随着技术的进步，其复杂性和道德考虑也在不断提高。  大规模的范例<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/" title="ReadMachine 忘却：研究人员让人工智能模型“忘记”数据">......阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/">机器遗忘：研究人员让人工智能模型“忘记”数据</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p><a href="https://www.tus.ac.jp/en/">东京理科大学</a>(TUS) 的研究人员开发了一种方法，使大规模人工智能模型能够选择性地“忘记”特定类别的数据。</p><p>人工智能的进步提供了能够彻底改变从医疗保健到自动驾驶等各个领域的工具。然而，随着技术的进步，其复杂性和道德考虑也在不断提高。</p><p>大规模预训练人工智能系统的范式，例如 OpenAI 的 ChatGPT 和<a href="https://openai.com/index/clip/">CLIP</a> （对比语言-图像预训练），重塑了人们对机器的期望。这些高度通用的模型能够以一致的精度处理大量任务，已广泛应用于专业和个人用途。</p><p>然而，这种多功能性的代价高昂。训练和运行这些模型需要大量的精力和时间，引发了可持续性问题，并且需要比标准计算机昂贵得多的尖端硬件。使这些问题更加复杂的是，当人工智能模型应用于特定任务时，通才倾向可能会阻碍人工智能模型的效率。</p><p>例如，“在实际应用中，很少需要对各种对象类别进行分类，”领导这项研究的 Go Irie 副教授解释道。 “例如，在自动驾驶系统中，识别有限类别的物体（例如汽车、行人和交通标志）就足够了。</p><p> “我们不需要识别食物、家具或动物物种。保留不需要识别的类可能会降低整体分类精度，并导致计算资源浪费和信息泄漏风险等操作缺陷。”</p><p>一个潜在的解决方案在于训练模型来“忘记”冗余或不必要的信息——简化流程，仅关注所需的信息。虽然一些现有方法已经满足了这种需求，但它们倾向于采用“白盒”方法，用户可以访问模型的内部架构和参数。然而，用户通常无法获得这样的可见性。</p><p>由于商业和道德限制，“黑匣子”人工智能系统更为常见，它隐藏了其内部机制，使得传统的遗忘技术变得不切实际。为了解决这一差距，研究团队转向了无衍生优化——这种方法可以避免对模型难以访问的内部运作的依赖。</p><h3 class="wp-block-heading">在遗忘中进步</h3><p>该研究将于 2024 年在神经信息处理系统 (NeurIPS) 会议上发表，引入了一种被称为“黑盒遗忘”的方法。</p><p>该过程在迭代中修改输入提示（输入模型的文本指令），使人工智能逐渐“忘记”某些类别。入江副教授与合著者 Yusuke Kuwana 和 Yuta Goto（均来自启蒙大学）以及<a href="https://www.nec.com/">NEC 公司</a>的 Takashi Shibata 博士合作完成了这项工作。</p><p>在他们的实验中，研究人员以 CLIP 为目标，这是一种具有图像分类能力的视觉语言模型。他们开发的方法基于协方差矩阵适应进化策略（CMA-ES），这是一种旨在逐步优化解决方案的进化算法。在这项研究中，CMA-ES 用于评估和完善向 CLIP 提供的提示，最终抑制其对特定图像类别进行分类的能力。</p><p>随着项目的进展，挑战也随之而来。现有的优化技术难以扩展到更大数量的目标类别，因此团队设计了一种称为“潜在上下文共享”的新颖参数化策略。</p><p>这种方法将潜在上下文（提示生成的信息的表示）分解为更小、更易于管理的部分。通过将某些元素分配给单个标记（单词或字符），同时在多个标记中重用其他元素，它们大大降低了问题的复杂性。至关重要的是，这使得该过程在计算上易于处理，即使对于广泛的遗忘应用也是如此。</p><p>通过对多个图像分类数据集进行基准测试，研究人员验证了黑盒遗忘的功效——实现了让 CLIP 在不直接访问 AI 模型内部架构的情况下“忘记”约 40% 目标类别的目标。</p><p>这项研究标志着在黑盒视觉语言模型中诱导选择性遗忘的首次成功尝试，展示了有希望的结果。</p><h3 class="wp-block-heading">帮助人工智能模型忘记数据的好处</h3><p>除了其技术独创性之外，这项创新对于特定任务的精度至关重要的实际应用具有巨大的潜力。</p><p>简化专门任务的模型可以使它们更快、更节省资源，并且能够在功能较弱的设备上运行，从而加速人工智能在以前被认为不可行的领域的采用。</p><p>另一个关键用途在于图像生成，其中忘记视觉上下文的整个类别可以防止模型无意中创建不良或有害的内容，无论是攻击性材料还是错误信息。</p><p>也许最重要的是，这种方法解决了人工智能最大的道德困境之一：<a href="https://www.artificialintelligence-news.com/categories/privacy/">隐私</a>。</p><p>人工智能模型，尤其是大型模型，通常是在海量数据集上进行训练的，这些数据集可能会无意中包含敏感或过时的信息。删除此类数据的请求——尤其是考虑到倡导“被遗忘权”的法律——构成了重大挑战。</p><p>重新训练整个模型以排除有问题的数据成本高昂且耗时，但不解决这一问题的风险可能会产生深远的后果。</p><p> “重新训练大型模型会消耗大量能量，”入江副教授指出。 “‘选择性遗忘’，或者所谓的机器遗忘，可能会为这个问题提供有效的解决方案。”</p><p>这些注重隐私的应用程序在<a href="https://www.artificialintelligence-news.com/categories/ai-industries/healthcare/">医疗保健</a>和<a href="https://www.artificialintelligence-news.com/news/large-language-models-could-revolutionsise-the-finance-sector-within-two-years/">金融</a>等高风险行业尤其相关，这些行业敏感数据是运营的核心。</p><p>随着全球人工智能竞赛的加速，东京理科大学的黑盒遗忘方法开辟了一条重要的前进道路——不仅使技术更具适应性和效率，而且还为用户增加了重要的保障措施。</p><p>尽管滥用的可能性仍然存在，但选择性遗忘等方法表明研究人员正在积极应对道德和实际挑战。</p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/why-qwq-32b-preview-is-the-reasoning-ai-to-watch/"><strong>为什么 QwQ-32B-Preview 是值得关注的推理 AI</strong></a></p><figure class="wp-block-image size-full is-resized"> <a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:769px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>等其他领先活动同期举行。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/">机器遗忘：研究人员让人工智能模型“忘记”数据</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/machine-unlearning-researchers-ai-models-forget-data/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>