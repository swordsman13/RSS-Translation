<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2024 年 5 月 14 日星期二 12:43:58 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title> GPT-4o 通过文本、音频和视觉集成提供类人人工智能交互</title><link/>https://www.artificialintelligence-news.com/2024/05/14/gpt-4o- human-like-ai-interaction-text-audio-vision-integration/<comments> https://www.artificialintelligence-news.com/2024/05/14/gpt-4o- human-like-ai-interaction-text-audio-vision-integration/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Tue, 14 May 2024 12:43:56 +0000</pubDate> <category><![CDATA[Applications]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Chatbots]]></category><category><![CDATA[Companies]]></category><category><![CDATA[Development]]></category><category><![CDATA[Enterprise]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Virtual Assistants]]></category><category><![CDATA[ai]]></category><category><![CDATA[api]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[benchmarks]]></category><category><![CDATA[chatgpt]]></category><category><![CDATA[coding]]></category><category><![CDATA[developers]]></category><category><![CDATA[development]]></category><category><![CDATA[gpt-4o]]></category><category><![CDATA[Model]]></category><category><![CDATA[multimodal]]></category><category><![CDATA[openai]]></category><category><![CDATA[performance]]></category><category><![CDATA[programming]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=14811 </guid><description><![CDATA[<p> OpenAI 推出了新的旗舰模型 GPT-4o，它无缝集成了文本、音频和视觉输入和输出，有望增强机器交互的自然性。 GPT-4o，其中“o”代表“o​​mni”，旨在满足更广泛的输入和输出模式。 “它接受文本、音频的任意组合作为输入<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/2024/05/14/gpt-4o-human-like-ai-interaction-text-audio-vision-integration/" title="ReadGPT-4o 通过文本、音频和视觉集成提供类人人工智能交互">……阅读更多 ”</a></p><p>后<a href="https://www.artificialintelligence-news.com/2024/05/14/gpt-4o-human-like-ai-interaction-text-audio-vision-integration/">GPT-4o 通过文本、音频和视觉集成提供类人 AI 交互，</a>首次出现在<a href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>OpenAI<a href="https://openai.com/index/hello-gpt-4o/">推出了</a>新的旗舰模型 GPT-4o，它无缝集成了文本、音频和视觉输入和输出，有望增强机器交互的自然性。</p><p> GPT-4o，其中“o”代表“o​​mni”，旨在满足更广泛的输入和输出模式。 OpenAI 宣布：“它接受文本、音频和图像的任意组合作为输入，并生成文本、音频和图像的任意组合输出。”</p><p>用户预计响应时间可达 232 毫秒，反映了人类对话的速度，平均响应时间高达 320 毫秒，令人印象深刻。</p><h4 class="wp-block-heading">开拓能力</h4><p>GPT-4o 的推出标志着其前身的飞跃，通过单个神经网络处理所有输入和输出。这种方法使模型能够保留先前在早期版本中使用的单独模型管道中丢失的关键信息和上下文。</p><p>在 GPT-4o 之前，“语音模式”可以处理音频交互，GPT-3.5 的延迟为 2.8 秒，GPT-4 的延迟为 5.4 秒。之前的设置涉及三个不同的模型：一个用于将音频转录为文本，另一个用于文本响应，第三个用于将文本转换回音频。这种分割导致了音调、多个扬声器和背景噪声等细微差别的损失。</p><p>作为集成解决方案，GPT-4o 在视觉和音频理解方面拥有显着改进。它可以执行更复杂的任务，例如协调歌曲、提供实时翻译，甚至生成具有笑声和歌唱等表现力元素的输出。其广泛功能的示例包括准备采访、即时翻译语言以及生成客户服务响应。 </p><figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper"><iframe title="向 GPT-4o 打个招呼" width="1200" height="675" src="https://www.youtube.com/embed/vgYi3Wr7v_g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div></figure><p> <a href="https://besuper.ai/">Superintelligent</a>的创始人兼首席执行官纳撒尼尔·惠特莫尔 (Nathaniel Whittemore) 评论道：“产品发布本质上会比技术发布更具争议性，因为在你实际与产品互动之前，很难判断产品是否会真正与众不同。尤其是当涉及到不同的人机交互模式时，关于其有用性的不同信念甚至有更大的空间。</p><p> “也就是说，没有宣布 GPT-4.5 或 GPT-5 的事实也分散了人们对技术进步的注意力，因为这是一种原生的多模式模型。它不是带有语音或图像添加的文本模型；而是带有语音或图像的文本模型。它是多模式令牌输入和多模式令牌输出。这开辟了大量的用例，需要一些时间才能渗透到人们的意识中。”</p><h4 class="wp-block-heading">性能和安全</h4><p>GPT-4o 在英语文本和编码任务中与 GPT-4 Turbo 性能水平相当，但在非英语语言中表现明显优于 GPT-4 Turbo，使其成为更具包容性和通用性的模型。它在推理方面树立了新的标杆，在 0-shot COT MMLU（常识问题）上取得了 88.7% 的高分，在 5-shot no-CoT MMLU 上取得了 87.2% 的高分。</p><p>该模型在音频和翻译基准方面也表现出色，超越了<a href="https://huggingface.co/openai/whisper-large-v3">Whisper-v3</a>等之前最先进的模型。在多语言和视觉评估中表现出优越的性能，增强了OpenAI的多语言、音频和视觉能力。 </p><figure class="wp-block-image size-large"><img fetchpriority="high" decoding="async" width="1024" height="929" src="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-1024x929.jpeg" alt="" class="wp-image-14812" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-1024x929.jpeg 1024w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-300x272.jpeg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-768x697.jpeg 768w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-220x200.jpeg 220w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-314x285.jpeg 314w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-275x250.jpeg 275w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-100x91.jpeg 100w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image-60x54.jpeg 60w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/image.jpeg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure><p> OpenAI 在设计上将强大的安全措施纳入 GPT-4o 中，纳入了过滤训练数据的技术并通过训练后保障措施细化行为。该模型已通过准备框架进行评估，并符合 OpenAI 的自愿承诺。网络安全、说服力和模型自治等领域的评估表明，GPT-4o 在任何类别中都没有超过“中等”风险级别。</p><p>进一步的安全评估涉及广泛的外部红队，由各个领域的 70 多名专家组成，包括社会心理学、偏见、公平和错误信息。这项全面审查旨在减轻 GPT-4o 新模式带来的风险。</p><h4 class="wp-block-heading">可用性和未来集成</h4><p>从今天开始，GPT-4o 的文本和图像功能可在 ChatGPT 中使用，包括免费套餐和针对 Plus 用户的扩展功能。由 GPT-4o 提供支持的新语音模式将在未来几周内在 ChatGPT Plus 中进入 alpha 测试。 </p><figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper"><iframe title="GPT-4o 视觉功能的现场演示" width="1200" height="675" src="https://www.youtube.com/embed/RI-BxtCx32s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div></figure><p>开发人员可以通过<a href="https://openai.com/api/">API</a>访问 GPT-4o 来执行文本和视觉任务，与 GPT-4 Turbo 相比，其速度翻倍、价格减半以及增强的速率限制。</p><p> OpenAI 计划通过 API 将 GPT-4o 的音频和视频功能扩展到一组选定的值得信赖的合作伙伴，预计在不久的将来会进行更广泛的推广。这种分阶段发布策略旨在确保在公开提供全部功能之前进行彻底的安全性和可用性测试。</p><p> “非常重要的是，他们向所有人免费提供了这个模型，并且 API 的价格便宜了 50%。这是可及性的巨大增加，”惠特莫尔解释道。</p><p> OpenAI 邀请社区反馈来不断完善 GPT-4o，强调用户输入在识别和缩小 GPT-4 Turbo 可能仍表现出色的差距方面的重要性。</p><p> <em>（图片来源： <a href="https://openai.com/">OpenAI</a> ）</em></p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/2024/05/08/openai-steps-boost-ai-generated-content-transparency/"><strong>OpenAI 采取措施提高人工智能生成内容的透明度</strong></a></p><figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>等其他领先活动同期举行。</p><p><a href="https://techforge.pub/upcoming-events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p>后<a href="https://www.artificialintelligence-news.com/2024/05/14/gpt-4o-human-like-ai-interaction-text-audio-vision-integration/">GPT-4o 通过文本、音频和视觉集成提供类人 AI 交互，</a>首次出现在<a href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/2024/05/14/gpt-4o- human-like-ai-interaction-text-audio-vision-integration/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>预计 2024 年人工智能市场规模将达到 1840 亿美元</title><link/>https://www.artificialintelligence-news.com/2024/05/14/the-market-size-in-the-ai-market-is-projected-to-reach-184bn-in-2024/<comments> https://www.artificialintelligence-news.com/2024/05/14/the-market-size-in-the-ai-market-is-projected-to-reach-184bn-in-2024/#respond</comments><dc:creator><![CDATA[Adam Walker]]></dc:creator><pubDate> Tue, 14 May 2024 09:23:45 +0000</pubDate> <category><![CDATA[Applications]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Chatbots]]></category><category><![CDATA[ai]]></category><category><![CDATA[alexa]]></category><category><![CDATA[cortana]]></category><category><![CDATA[Mabel]]></category><category><![CDATA[robots]]></category><category><![CDATA[Sira]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=14796 </guid><description><![CDATA[<p>我们常常会对人工智能的突破以及人工智能塑造未来的方式发生翻天覆地的变化感到非常兴奋。然而，正如那些对人工智能感兴趣的人所知，该技术已经嵌入到我们的许多日常交易中，它已经正在改变<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/2024/05/14/the-market-size-in-the-ai-market-is-projected-to-reach-184bn-in-2024/" title="阅读人工智能市场规模预计到 2024 年将达到 1840 亿美元">...... 阅读更多 ”</a></p><p>这篇文章<a href="https://www.artificialintelligence-news.com/2024/05/14/the-market-size-in-the-ai-market-is-projected-to-reach-184bn-in-2024/">《人工智能市场规模预计到 2024 年将达到 1840 亿美元》</a>首先出现在<a href="https://www.artificialintelligence-news.com">《AI News》</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>我们常常会对人工智能的突破以及人工智能塑造未来的方式发生翻天覆地的变化感到非常兴奋。然而，正如那些对人工智能感兴趣的人所知，这项技术已经嵌入到我们的许多日常交易中，它已经改变了我们工作、休息和娱乐的方式。</p><p>几十年来，媒体一直在报道大型科技故事，包括将为我们做所有基本家务的类人机器人。早在 1966 年，我们就被介绍给<a href="https://www.bbc.co.uk/archive/mabel-the-robot-housemaid-1966/zhnvxyc">机器人女仆梅布尔</a>，她将在 1976 年完成所有任务。虽然这未能成为现实，但人工智能已经无缝地融入了我们的生活，尽管可能不会无论是任何 Mable，我们中的许多人都有名为 Alexa、Siri 和 Cortana 的助手。</p><p>这些机器人可能无法为我们熨烫衣服，但它们可以用来打开和关闭灯、对烤箱进行编程，或者在我们不在时控制我们的加热系统。他们并没有接管所有的体力工作，而是在后台帮助我们，并融入我们的家庭。据当今的专家称，到 2033 年，机器人将承担我们近 40% 的家务活。这似乎与 1966 年的说法有些相似，但这得到了日本御茶水和英国牛津大学数据的支持。 65 名人工智能专家被要求预测未来五到十年内哪些日常任务将实现自动化。</p><p>该<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0281282">研究着眼于</a>“无偿工作的未来是什么样的？如果机器人抢走了我们的工作，他们至少也会帮我们倒垃圾吗？”研究表明，未来十年人们花在家务上的时间将减少46%。然而，可能变得更加自动化的最大任务是杂货购物。专家预测，到 2033 年，我们的杂货店近 60% 将由人工智能完成。然而，机器不太可能被信任承担照顾老人或儿童等照顾责任。即使人工智能具有承担这些任务的技术能力，研究专家<a href="https://www.artificialintelligence-news.com/2024/05/03/chuck-ros-softserve-delivering-transformative-ai-solutions-responsibly/">认为，由于对儿童的潜在发展影响和隐私影响，将儿童保育工作委托给机器也会存在可接受性问题</a>。</p><p>那么，如果人工智能不照顾我们的孩子或熨烫衣服，那么它在做什么任务呢？鉴于市场规模，该行业是全球经济的重要组成部分。最新统计数据预测，到 2024 年，该市场的价值将达到 1,840 亿美元。然而，与 2030 年的预测相比，这只是一个小问题。预计该市场将以近 29% 的速度增长， <a href="https://www.statista.com/outlook/tmo/artificial-intelligence/worldwide#:~:text=Artificial%20Intelligence%20%2D%20Worldwide&amp;text=The%20market%20size%20is%20expected,US%2450.16bn%20in%202024">到 2024 年，其价值将达到惊人的 8,260 亿美元。十年末</a>。</p><p>人工智能在我们的生活中发挥着不可或缺的作用，以至于我们几乎忘记了我们以前是如何运作的。</p><p>我们用面容 ID 打开手机。正是人工智能实现了这一功能。使用生物识别技术，该设备可以以 3D 方式看到您，并使用 30,000 个不可见的红外点捕获您的脸部图像。然后，它使用机器学习算法，将您的面部扫描与存储在文件中的内容进行比较，以确定是您还是试图访问您手机的入侵者。苹果声称其 FaceID 被欺骗的几率是百万分之一</p><p>一旦我们的手机打开，我们可能会选择去很多地方。有些人会去查看社交媒体或了解新闻。其他人使用手机进行娱乐，例如在线游戏或访问在线赌场。人工智能和算法是这些网站功能不可或缺的一部分，人工智能涉及从客户服务到验证付款和支付奖金的各个方面。当人工智能了解他们喜欢玩哪些游戏时，玩家可以获得个性化的体验，这意味着<a href="https://www.casino.org/canada/new/">玩家可以从提供的最新游戏中进行选择</a>。然而，系统可以从他们之前玩过的游戏中学习，并为他们提供类似下一个游戏的内容，而不是搜索所有最新版本。</p><p>人工智能还会更新社交媒体信息。用户看到的内容是个性化的，因为算法已经根据您的历史记录了解了您对哪些帖子做出了反应。它提供朋友建议和新闻帖子。人工智能的下一步是更好地识别、过滤错误信息并防止网络欺凌。 2024 年是全球大选年，消除假新闻显得尤为重要。</p><p>当我们在电脑和手机上书写时，无论是发送电子邮件、消息还是报告，我们都会使用拼写检查和 Grammarly 等其他工具。这些帮助我们通过使用自然语言处理和建议创建无错误的消息。当我们使用垃圾邮件过滤器发送和接收消息、阻止某些电子邮件并将其发送到垃圾箱时，会涉及到更多的人工智能。此外，防病毒软件利用机器学习来保护我们的电子邮件帐户和计算机。</p><p>虽然这些例子都发生在幕后，但近年来最显着的变化之一是我们对数字语音助手的使用。无论我们想要获取路线还是了解天气情况，Siri、Alexa、Google Home 和 Cortana 都会陪伴我们左右。对于许多人来说，它们已成为不可或缺的一部分，他们在开车时将其用作副驾驶，并在家里提供无尽的信息。这些助手使用人工智能驱动的自然语言处理器和生成器来回答所有问题。它们越来越多地被编程为给出“类似人类”的反应，有时甚至听起来被冒犯了。</p><p>自 1966 年以来，我们一直梦想着机器人做家务，虽然这不是现实，但我们的家正变得越来越“智能”。我们有恒温器，可以让我们控制手机的加热，也有冰箱，可以根据冰箱里不再有的东西创建购物清单。他们还可以根据您冰箱里的物品推荐您可能想购买的佐餐品，例如葡萄酒或调味品。</p><p>仍然没有梅布尔的踪迹，但也许有一天她会露面。</p><figure class="wp-block-image size-full"> <a href="https://www.ai-expo.net/"><img loading="lazy" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image.png" alt="" class="wp-image-13755" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2023/10/image-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>等其他领先活动同期举行。</p><p><a href="https://techforge.pub/upcoming-events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/2024/05/14/the-market-size-in-the-ai-market-is-projected-to-reach-184bn-in-2024/">《人工智能市场规模预计到 2024 年将达到 1840 亿美元》</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">《AI News》</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/2024/05/14/the-market-size-in-the-ai-market-is-projected-to-reach-184bn-in-2024/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>