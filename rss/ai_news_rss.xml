<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2024 年 11 月 28 日星期四 17:07:04 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title>阿里巴巴Marco-o1：提升LLM推理能力</title><link/>https://www.artificialintelligence-news.com/news/alibaba-marco-o1-advancing-llm-reasoning-capability/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=alibaba-marco-o1-advancing-llm-reasoning-capability<comments> https://www.artificialintelligence-news.com/news/alibaba-marco-o1-advancing-llm-reasoning-capability/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Thu, 28 Nov 2024 17:07:03 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[ai]]></category><category><![CDATA[alibaba]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[large language model]]></category><category><![CDATA[llm]]></category><category><![CDATA[marco]]></category><category><![CDATA[mcts]]></category><category><![CDATA[models]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16579 </guid><description><![CDATA[<p>阿里巴巴宣布推出 Marco-o1，这是一种大型语言模型 (LLM)，旨在解决传统和开放式问题解决任务。来自阿里巴巴马可波罗团队的 Marco-o1 代表着人工智能在处理复杂推理挑战的能力方面又向前迈进了一步——特别是在数学、物理、编码以及可能缺乏明确标准的领域。基于 OpenAI 的推理进步<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/alibaba-marco-o1-advancing-llm-reasoning-capabilities/" title="阅读阿里巴巴Marco-o1：提升LLM推理能力">……阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/alibaba-marco-o1-advancing-llm-reasoning-capabilities/">阿里巴巴 Marco-o1：推进 LLM 推理能力</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>阿里巴巴宣布推出 Marco-o1，这是一种大型语言模型 (LLM)，旨在解决传统和开放式问题解决任务。</p><p>来自阿里巴巴马可波罗团队的 Marco-o1 代表着人工智能在处理复杂推理挑战的能力方面又向前迈进了一步——特别是在数学、物理、编码以及可能缺乏明确标准的领域。</p><p> Marco-o1 以 OpenAI 的<a href="https://openai.com/o1/">o1 模型</a>推理进步为基础，通过融合多种先进技术而脱颖而出，包括思想链 (CoT) 微调、蒙特卡罗树搜索 (MCTS) 和新颖的反射机制。这些组件协同工作，增强模型跨各个领域解决问题的能力。</p><p>开发团队使用多个数据集实施了全面的微调策略，包括 Open-O1 CoT 数据集的过滤版本、合成的 Marco-o1 CoT 数据集和专门的 Marco 指令数据集。训练语料库总共包含 60,000 多个精心挑选的样本。</p><p>该模型在多语言应用中表现出了特别令人印象深刻的结果。在测试中，Marco-o1 在英文 MGSM 数据集上的准确率显着提高了 6.17%，在中文数据集上显着提高了 5.60%。该模型在翻译任务中表现出了特别的优势，尤其是在处理口语表达和文化细微差别时。</p><p>该模型最具创新性的功能之一是它在 MCTS 框架内实现了不同的操作粒度。这种方法允许模型探索不同细节级别的推理路径，从广泛的步骤到更精确的 32 或 64 个标记的“迷你步骤”。该团队还引入了反射机制，促使模型进行自我评估并重新考虑其推理，从而提高复杂问题解决场景的准确性。</p><p>事实证明，MCTS 集成特别有效，该模型的所有 MCTS 增强版本都比基本 Marco-o1-CoT 版本有了显着改进。该团队对不同行动粒度的实验揭示了有趣的模式，但他们指出，确定最佳策略需要进一步的研究和更精确的奖励模型。 </p><figure class="wp-block-image size-large"><img fetchpriority="high" decoding="async" width="1024" height="487" src="https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-1024x487.png" alt="具有 MCTS 集成的最新 Marco-o1 LLM 模型与之前的 AI 模型和变体的基准比较。" class="wp-image-16580" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-1024x487.png 1024w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-300x143.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-768x365.png 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-1536x731.png 1536w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-2048x974.png 2048w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-380x181.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-350x167.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-100x48.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/alibaba-marco-o1-llm-large-language-model-ai-benchmark-comparison-artificial-intelligence-60x29.png 60w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption"> <em>（来源：马可波罗团队、人工智能业务、阿里巴巴国际电商）</em></figcaption></figure><p>开发团队对该模型当前的局限性持透明态度，承认虽然 Marco-o1 表现出强大的推理特性，但它仍然达不到完全实现的“o1”模型。他们强调，此版本代表了对改进的持续承诺，而不是成品。</p><p>展望未来，阿里巴巴团队宣布计划引入奖励模型，包括结果奖励模型（ORM）和过程奖励模型（PRM），以增强Marco-o1的决策能力。他们还在探索强化学习技术，以进一步完善模型解决问题的能力。</p><p> Marco-o1 模型和相关数据集已通过阿里巴巴的 GitHub 存储库提供给研究社区，并附有全面的文档和实施指南。该版本包括直接模型使用和通过 FastAPI 部署的安装说明和示例脚本。</p><p> <em>（ <a href="https://unsplash.com/@alinnnaaaa?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">阿丽娜·格鲁布尼</a>亚克摄）</em></p><p><strong><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next-generation/"><strong>新的人工智能训练技术旨在克服当前的挑战</strong></a></strong></p><figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:998px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>等其他领先活动同期举行。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/alibaba-marco-o1-advancing-llm-reasoning-capabilities/">阿里巴巴 Marco-o1：推进 LLM 推理能力</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/alibaba-marco-o1-advancing-llm-reasoning-capability/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>新的人工智能训练技术旨在克服当前的挑战</title><link/>https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next- Generation/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=o1-model-llm-ai-openai-training -研究下一代<comments>https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next- Generation/#respond</comments><dc:creator><![CDATA[Joe Green]]></dc:creator><pubDate> Thu, 28 Nov 2024 11:58:28 +0000</pubDate><category><![CDATA[Deep & Reinforcement Learning]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[NVIDIA]]></category><category><![CDATA[Research]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[machine learning]]></category><category><![CDATA[models]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16574 </guid><description><![CDATA[<p> OpenAI 和其他领先的人工智能公司正在开发新的训练技术，以克服当前方法的局限性。为了解决开发更大、更强大的语言模型时出现的意外延迟和复杂性，这些新技术专注于类人行为来教会算法“思考”。据报道，由十几位人工智能研究人员、科学家和投资者领导，新的<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next-generation/" title="阅读新的人工智能训练技术旨在克服当前的挑战">……阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next-generation/">旨在克服当前挑战的新人工智能训练技术</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">人工智能新闻</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>OpenAI 和其他领先的人工智能公司正在开发新的训练技术，以克服当前方法的局限性。为了解决开发更大、更强大的语言模型时出现的意外延迟和复杂性，这些新技术专注于类人行为来教会算法“思考”。</p><p>据报道，由十几位人工智能研究人员、科学家和投资者领导的新训练技术支撑了 OpenAI 最近的<a href="https://openai.com/o1/">“o1”模型</a>（以前称为 Q* 和 Strawberry），有可能改变人工智能发展的格局。所报告的进展可能会影响人工智能公司持续需要的资源类型或数量，包括帮助人工智能模型开发的专用硬件和能源。</p><p> o1 模型旨在以模仿人类推理和思维的方式解决问题，将众多任务分解为步骤。该模型还利用人工智能行业专家提供的专业数据和反馈来提高其性能。</p><p>自 2022 年 OpenAI 推出 ChatGPT 以来，人工智能创新激增，许多科技公司声称现有的人工智能模型需要扩展，无论是通过更多的数据还是改进的计算资源。只有这样，人工智能模型才能持续改进。</p><p>现在，人工智能专家报告了扩大人工智能模型的局限性。 2010 年代是扩展的革命性时期，但 AI 实验室 Safe Superintelligence (SSI) 和 OpenAI 的联合创始人 Ilya Sutskever 表示，AI 模型的训练，特别是在理解语言结构和模式方面，已经趋于平稳。</p><p> “2010 年代是扩展的时代，现在我们再次回到了奇迹和发现的时代。现在扩大正确的规模变得更加重要，”他们说。</p><p>最近，人工智能实验室研究人员在开发和发布比 OpenAI 的 GPT-4 模型更强大的大型语言模型 (LLM) 方面遇到了延迟和挑战。</p><p>首先，训练大型模型的成本通常高达数千万美元。而且，由于出现复杂情况，例如由于系统复杂性而导致硬件故障，对这些模型如何运行的最终分析可能需要数月时间。</p><p>除了这些挑战之外，训练运行还需要大量能源，通常会导致电力短缺，从而扰乱流程并影响更广泛的电网。另一个问题是大型语言模型使用的数据量巨大，据报道人工智能模型已经耗尽了全球所有可访问的数据。</p><p>研究人员正在探索一种称为“测试时计算”的技术，以在训练或推理阶段改进当前的人工智能模型。该方法可以涉及实时生成多个答案来决定一系列最佳解决方案。因此，该模型可以将更多的处理资源分配给需要类人决策和推理的困难任务。目标是使模型更加准确和强大。</p><p>帮助开发 o1 模型的 OpenAI 研究员 Noam Brown 分享了一个新方法如何取得令人惊讶的结果的例子。在上个月于旧金山举行的 TED AI 会议上，布朗解释道，“让机器人在扑克牌中思考 20 秒，所获得的性能提升与将模型扩大 100,000 倍并训练时间延长 100,000 倍相同。”</p><p>这不是简单地增加模型大小和训练时间，而是可以改变人工智能模型处理信息的方式，并带来更强大、更高效的系统。</p><p>据报道，其他人工智能实验室已经在开发o1技术的版本。其中包括<a href="https://x.ai/">xAI</a> 、 <a href="https://deepmind.google/">Google DeepMind</a>和<a href="https://www.anthropic.com/">Anthropic</a> 。人工智能领域的竞争并不是什么新鲜事，但我们可以看到新技术对人工智能硬件市场产生重大影响。像<a href="https://www.nvidia.com/en-gb/">英伟达</a>这样的公司，由于对其产品的高需求，目前在人工智能芯片的供应中占据主导地位，它们可能特别受到更新的人工智能训练技术的影响。</p><p>英伟达在 10 月份成为全球最有价值的公司，其财富的增长很大程度上归功于其芯片在人工智能阵列中的使用。新技术可能会影响英伟达的市场地位，迫使该公司调整其产品以满足不断变化的人工智能硬件需求。这有可能为推理市场的新竞争对手开辟更多途径。</p><p>在不断变化的硬件需求和更高效的训练方法（例如 o1 模型中部署的训练方法）的推动下，人工智能发展的新时代可能即将到来。人工智能模型及其背后的公司的未来都可能被重塑，释放前所未有的可能性和更激烈的竞争。</p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic 敦促人工智能监管以避免灾难</strong></a></p><figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:2239px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>、</p><p> <a href="https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next-generation/">旨在克服当前挑战的新人工智能训练技术</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">人工智能新闻</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/o1-model-llm-ai-openai-training-research-next- Generation/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>