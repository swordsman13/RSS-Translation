<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2024 年 11 月 25 日星期一 11:31:17 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title>英国建立 LASR 应对人工智能安全威胁</title><link/>https://www.artificialintelligence-news.com/news/uk-builtes-lasr-counter-ai-security-threats/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=uk-builtes-lasr-counter-ai-security-threats<comments> https://www.artificialintelligence-news.com/news/uk-builtes-lasr-counter-ai-security-threats/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Mon, 25 Nov 2024 11:31:13 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Legislation & Government]]></category><category><![CDATA[Security]]></category><category><![CDATA[ai]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[cyber security]]></category><category><![CDATA[cybersecurity]]></category><category><![CDATA[europe]]></category><category><![CDATA[government]]></category><category><![CDATA[hacking]]></category><category><![CDATA[infosec]]></category><category><![CDATA[nato]]></category><category><![CDATA[safety]]></category><category><![CDATA[security]]></category><category><![CDATA[threats]]></category><category><![CDATA[uk]]></category><category><![CDATA[usa]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16550 </guid><description><![CDATA[<p>英国正在建立人工智能安全研究实验室（LASR），以帮助保护英国及其盟友免受官方所说的“人工智能军备竞赛”中出现的新威胁。该实验室将获得 822 万英镑的初始政府资助，旨在汇集来自工业界、学术界和政府的专家<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/" title="ReadUK 建立 LASR 以应对人工智能安全威胁">……阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/">英国建立 LASR 来应对人工智能安全威胁的</a>消息首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>英国正在建立人工智能安全研究实验室（LASR），以帮助保护英国<a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/">及其盟友</a>免受官方所说的“人工智能军备竞赛”中出现的新威胁。</p><p>该实验室将获得 822 万英镑的初始政府资助，旨在汇集来自工业界、学术界和政府的专家，评估人工智能对国家安全的影响。该公告是加强英国网络防御能力的更广泛战略的一部分。</p><p>兰开斯特公国财政大臣在兰开斯特宫举行的北约网络防御会议上发​​表讲话时表示：“北约需要继续适应人工智能世界，因为随着技术的发展，威胁也在演变。</p><p> “过去七十年中，北约通过不断适应新的威胁而保持了重要地位。它在核扩散和好战民族主义的世界中航行。从冷战到无人机战的转变。”</p><p>财政大臣描绘了当前网络安全形势的严峻景象，他表示：“网络战争现在已成为日常现实。我们的防御能力不断受到考验。威胁的程度必须与我们对抗威胁和保护我们的公民和系统的决心的强度相匹配。”</p><p>新实验室将在“催化”模式下运作，旨在吸引行业合作伙伴的额外投资和合作。</p><p>新实验室的主要利益相关者包括英国政府通信总部、国家网络安全中心、国防部国防科学与技术实验室以及牛津大学和贝尔法斯特女王大学等著名学术机构。</p><p>在对俄罗斯活动的直接警告中，财政大臣宣称：“毫无疑问：英国和在座的其他国家正在注视着俄罗斯。我们确切地知道他们在做什么，并且我们正在公开和幕后反击他们的攻击。</p><p> “我们从历史中知道，姑息独裁者对邻国的侵略只会鼓励他们。英国很早以前就认识到面对此类行动时保持坚强的重要性。”</p><p>他重申对乌克兰的支持，并补充说：“普京是一个想要毁灭而不是和平的人。他试图通过威胁来阻止我们对乌克兰的支持。他不会成功。”</p><p>新实验室是在最近对国家行为者利用人工智能来加强现有安全威胁的担忧之后成立的。</p><p> “去年，我们第一次看到美国首次公开呼吁某个国家使用人工智能来帮助其恶意网络活动，”总理指出，他指的是朝鲜试图使用人工智能进行恶意软件开发和漏洞扫描。</p><p>欧洲、北美和英国海外领土大臣 Stephen Doughty 强调了人工智能技术的双重性：“人工智能具有巨大的潜力。为了确保它仍然是世界上的一股正义力量，我们需要了解它的威胁和机遇。”</p><p>除了 LASR 之外，政府还宣布了一项价值 100 万英镑的新事件响应项目，以增强盟友之间的协作网络防御能力。该实验室将优先考虑与五眼国家和北约盟国的合作，以英国在计算领域的历史优势为基础，这一优势可以追溯到艾伦·图灵的开创性工作。</p><p>该举措是政府网络安全综合措施的一部分，其中包括即将出台的<a href="https://www.gov.uk/government/collections/cyber-security-and-resilience-bill">网络安全和弹性法案</a>以及最近将<a href="https://www.artificialintelligence-news.com/news/uk-secures-6-3b-data-infrastructure-investments/">数据中心</a>分类为关键的国家基础设施。</p><p> <em>（ <a href="https://unsplash.com/@introspectivedsgn?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">埃里克·麦克林</a>拍摄）</em></p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/"><strong>Anthropic 敦促人工智能监管以避免灾难</strong></a></p><figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img fetchpriority="high" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:969px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/uk-establishes-lasr-counter-ai-security-threats/">英国建立 LASR 来应对人工智能安全威胁的</a>消息首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/uk-builtes-lasr-counter-ai-security-threats/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> OpenAI 通过新的红队方法增强人工智能安全性</title><link/>https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=openai-enhances-ai-safety-new-red-teaming -方法<comments>https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Fri, 22 Nov 2024 15:47:04 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Companies]]></category><category><![CDATA[Development]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[ai]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[development]]></category><category><![CDATA[ethics]]></category><category><![CDATA[openai]]></category><category><![CDATA[red teaming]]></category><category><![CDATA[safety]]></category><category><![CDATA[Society]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16543 </guid><description><![CDATA[<p> OpenAI 保护流程的一个关键部分是“红队”——一种利用人类和人工智能参与者来探索新系统中潜在风险和漏洞的结构化方法。从历史上看，OpenAI 主要通过手动测试参与红队工作，其中涉及个人探索弱点。这在测试过程中尤其被采用<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/" title="ReadOpenAI 通过新的红队方法增强人工智能安全性">……阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/">OpenAI 通过新的红队方法增强 AI 安全性</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p>OpenAI 保护流程的一个关键部分是“红队”——一种利用人类和人工智能参与者来探索新系统中潜在风险和漏洞的结构化方法。</p><p>从历史上看，OpenAI 主要通过手动测试参与红队工作，其中涉及个人探索弱点。 2022 年初测试 DALL·E 2 图像生成模型时尤其采用了这一点，当时邀请了外部专家来识别潜在风险。从那时起，OpenAI 扩展并完善了其方法，纳入自动化和混合方法以进行更全面的风险评估。</p><p> OpenAI 表示：“我们乐观地认为，我们可以使用更强大的人工智能来扩大模型错误的发现范围。”这种乐观情绪植根于这样的想法：自动化流程可以帮助评估模型，并通过更大规模地识别模式和错误来训练模型，使其变得更安全。</p><p>在最新的推动中，OpenAI 分享了两份关于红队的重要文件——一份详细介绍外部参与策略的白皮书和一份介绍自动化红队新方法的研究报告。这些贡献旨在加强红队的流程和结果，最终实现更安全、更负责任的人工智能实施。</p><p>随着人工智能的不断发展，了解用户体验并识别滥用和误用等风险对于研究人员和开发人员至关重要。红队提供了一种主动评估这些风险的方法，特别是在辅以一系列独立外部专家的见解的情况下。这种方法不仅有助于建立基准，而且有助于随着时间的推移加强安全评估。</p><h3 class="wp-block-heading">人性化的触感</h3><p>OpenAI 在其白皮书<a href="https://cdn.openai.com/papers/openais-approach-to-external-red-teaming.pdf">《OpenAI 的 AI 模型和系统外部红队方法》</a>中分享了设计有效红队活动的四个基本步骤：</p><ol class="wp-block-list"><li><strong>红队的组成：</strong>团队成员的选择基于活动的目标。这通常涉及具有不同观点的个人，例如自然科学、网络安全和区域政治方面的专业知识，以确保评估涵盖必要的广度。</li></ol><ol start="2" class="wp-block-list"><li><strong>访问模型版本：</strong>明确红队成员将访问模型的哪些版本可以影响结果。早期模型可能会揭示固有风险，而更成熟的版本可以帮助识别计划的安全缓解措施中的差距。</li></ol><ol start="3" class="wp-block-list"><li><strong>指导和文档：</strong>活动期间的有效交互依赖于清晰的说明、合适的界面和结构化文档。这包括描述模型、现有的保障措施、测试接口和记录结果的指南。</li></ol><ol start="4" class="wp-block-list"><li><strong>数据合成和评估：</strong>活动结束后，将对数据进行评估，以确定示例是否符合现有政策或需要新的行为修改。然后评估的数据为未来更新的可重复评估提供信息。</li></ol><p>这种方法的最新应用包括准备供公众使用的 OpenAI <a href="https://openai.com/index/learning-to-reason-with-llms/">o1 系列</a>模型，测试它们对潜在滥用的抵抗力，并评估它们在现实世界攻击计划、自然科学和人工智能研究等各个领域的应用。</p><h3 class="wp-block-heading">自动红队</h3><p>自动化红队旨在识别人工智能可能失败的情况，特别是在安全相关问题方面。这种方法在规模上表现出色，可以快速生成大量潜在错误的示例。然而，传统的自动化方法一直难以产生多样化、成功的攻击策略。</p><p> OpenAI 的研究引入了<a href="https://cdn.openai.com/papers/diverse-and-effective-red-teaming.pdf">“具有自动生成奖励和多步骤强化学习的多样化且有效的红队”，</a>这种方法鼓励攻击策略更加多样化，同时保持有效性。</p><p>这种方法涉及使用人工智能生成不同的场景，例如非法建议，并训练红队模型来批判性地评估这些场景。该过程奖励多样性和有效性，促进更加多样化和全面的安全评估。</p><p>尽管红队有好处，但它也有局限性。它捕捉特定时间点的风险，这些风险可能随着人工智能模型的发展而演变。此外，红队流程可能会无意中造成信息危害，可能会提醒恶意行为者注意尚未广为人知的漏洞。管理这些风险需要严格的协议和负责任的披露。</p><p>虽然红队仍然在风险发现和评估中发挥着关键作用，但 OpenAI 承认有必要将更广泛的公众观点纳入人工智能的理想行为和政策，以确保该技术符合社会价值观和期望。</p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/eu-introduces-draft-regulatory-guidance-for-ai-models/"><strong>欧盟推出人工智能模型监管指南草案</strong></a></p><figure class="wp-block-image size-full is-resized"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" style="width:959px;height:auto" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/">OpenAI 通过新的红队方法增强 AI 安全性</a>一文首先出现在<a href="https://www.artificialintelligence-news.com">AI News</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/openai-enhances-ai-safety-new-red-teaming-methods/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>