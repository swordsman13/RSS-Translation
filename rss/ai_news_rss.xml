<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>人工智能新闻</title><atom:link href="https://www.artificialintelligence-news.com/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://www.artificialintelligence-news.com/<description>人工智能新闻</description><lastbuilddate>2024 年 11 月 1 日星期五 16:46:43 +0000</lastbuilddate><language> en-GB</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><image/><url> https://www.artificialintelligence-news.com/wp-content/uploads/2020/09/ai-icon-60x60.png</url><title>人工智能新闻</title><link/>https://www.artificialintelligence-news.com/<width> 32</width><height> 32</height><item><title> Anthropic 敦促人工智能监管以避免灾难</title><link/>https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=anthropic-urges-ai-regulation-avoid-catastrophes<comments> https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Fri, 01 Nov 2024 16:46:42 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Companies]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Legislation & Government]]></category><category><![CDATA[ai]]></category><category><![CDATA[anthropic]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[government]]></category><category><![CDATA[law]]></category><category><![CDATA[legal]]></category><category><![CDATA[Legislation]]></category><category><![CDATA[policy]]></category><category><![CDATA[Politics]]></category><category><![CDATA[regulation]]></category><category><![CDATA[risks]]></category><category><![CDATA[rsp]]></category><category><![CDATA[safety]]></category><category><![CDATA[Society]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16415 </guid><description><![CDATA[<p> Anthropic 指出了人工智能系统的潜在风险，并呼吁进行良好的监管以避免潜在的灾难。该组织认为，有针对性的监管对于利用人工智能的好处并减轻其危险至关重要。随着人工智能系统在数学、推理和编码等能力方面的发展，它们在网络安全等领域的潜在滥用甚至<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/" title="ReadAnthropic 敦促人工智能监管以避免灾难">……阅读更多 ”</a></p><p>这篇文章<a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/">《人择》敦促人工智能监管以避免灾难</a>首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p><a href="https://www.anthropic.com/">Anthropic</a>指出了人工智能系统的潜在风险，并呼吁进行良好的监管以避免潜在的灾难。该组织认为，有针对性的监管对于利用人工智能的好处并减轻其危险至关重要。</p><p>随着人工智能系统在数学、推理和编码等能力方面的发展，它们在网络安全甚至生物和化学学科等领域的潜在滥用显着增加。</p><p> Anthropic 警告称，未来 18 个月对于政策制定者采取行动至关重要，因为主动预防的窗口正在缩小。值得注意的是，Anthropic 的 Frontier Red Team 强调了当前模型如何为各种网络攻击相关任务做出贡献，并预计未来的模型将更加有效。</p><p>特别令人担忧的是人工智能系统有可能加剧化学、生物、放射和核（CBRN）的滥用。英国人工智能安全研究所<a href="https://www.aisi.gov.uk/work/advanced-ai-evaluations-may-update">发现</a>，一些人工智能模型现在可以与人类博士级的专业知识相媲美，以响应科学相关的询问。</p><p>为了应对这些风险，Anthropic 详细介绍了 2023 年 9 月发布的<a href="https://assets.anthropic.com/m/24a47b00f10301cd/original/Anthropic-Responsible-Scaling-Policy-2024-10-15.pdf">负责任扩展政策</a>(RSP)，作为强有力的对策。 RSP 要求增加与人工智能功能的复杂性相对应的安全措施。</p><p> RSP 框架的设计具有适应性和迭代性，定期评估人工智能模型，以便及时完善安全协议。 Anthropic 表示，它致力于在各种团队扩展中维护和增强安全性，特别是在安全性、可解释性和信任领域，确保为 RSP 制定的严格安全标准做好准备。</p><p> Anthropic 认为，RSP 在整个人工智能行业的广泛采用虽然主要是自愿的，但对于解决人工智能风险至关重要。</p><p>透明、有效的监管对于让社会放心人工智能公司遵守安全承诺至关重要。然而，监管框架必须具有战略性，能够激励良好的安全实践，同时又不会造成不必要的负担。</p><p> Anthropic 设想制定明确、重点突出且能够适应不断发展的技术格局的法规，并认为这些法规对于在缓解风险和促进创新之间实现平衡至关重要。</p><p>在美国，Anthropic 表示，联邦<a href="https://www.artificialintelligence-news.com/categories/ai-legislation-government/">立法</a>可能是人工智能风险监管的最终答案——尽管如果联邦行动滞后，国家驱动的举措可能需要介入。世界各国制定的立法框架应允许标准化和相互认可，以支持<a href="https://www.artificialintelligence-news.com/news/un-passes-first-global-ai-resolution/">全球人工智能安全</a>议程，最大限度地降低不同地区遵守监管的成本。</p><p>此外，Anthropic 解决了对实施监管的怀疑——强调过于广泛的以用例为中心的监管对于具有多种应用的通用人工智能系统来说是低效的。相反，法规应针对人工智能模型的基本属性和安全措施。</p><p>在涵盖广泛风险的同时，Anthropic 承认一些直接威胁（例如深度伪造）并不是他们当前提案的重点，因为其他举措正在解决这些近期问题。</p><p>最终，Anthropic 强调了制定刺激创新而不是扼杀创新的法规的重要性。最初的合规负担虽然不可避免，但可以通过灵活且精心设计的<a href="https://www.artificialintelligence-news.com/news/uk-and-us-sign-pact-develop-ai-safety-tests/">安全测试</a>来最小化。适当的监管甚至可以通过保护知识产权免受内部和外部的威胁来帮助维护国家利益和私营部门创新。</p><p>通过关注经验测量的风险，Anthropic 规划了一个既不偏向也不偏向开放或闭源模型的监管环境。目标仍然明确：通过严格但适应性强的监管来管理前沿人工智能模型的重大风险。</p><p> <em>（图片来源：<a href="https://www.anthropic.com/">人类</a>）</em></p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/"><strong>拜登总统发布第一份关于人工智能的国家安全备忘录</strong></a></p><figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img fetchpriority="high" decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p>这篇文章<a href="https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/">《人择》敦促人工智能监管以避免灾难</a>首先出现在<a href="https://www.artificialintelligence-news.com">《人工智能新闻》</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophes/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>行业领导者支持开源人工智能定义</title><link/>https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=industry-leaders-back-open-source-ai-definition<comments> https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/#respond</comments><dc:creator><![CDATA[Ryan Daws]]></dc:creator><pubDate> Tue, 29 Oct 2024 14:36:15 +0000</pubDate> <category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Companies]]></category><category><![CDATA[Development]]></category><category><![CDATA[Ethics & Society]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[Privacy]]></category><category><![CDATA[Research]]></category><category><![CDATA[ai]]></category><category><![CDATA[all things open]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[development]]></category><category><![CDATA[ethics]]></category><category><![CDATA[open source]]></category><category><![CDATA[open source initiative]]></category><category><![CDATA[open-source]]></category><category><![CDATA[osaid]]></category><category><![CDATA[osi]]></category><category><![CDATA[training]]></category><guid ispermalink="false"> https://www.artificialintelligence-news.com/?p=16411 </guid><description><![CDATA[<p>开源倡议（OSI）公布了一个定义框架来评估人工智能系统是否可以归类为开源。第一个开源人工智能定义（OSAID）的发布是在 All Things Open 上发布的，标志着跨越多年研究、国际研讨会和长达一年的全球全面努力的高潮<a class="excerpt-read-more" href="https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/" title="阅读行业领导者支持开源人工智能定义">...... 阅读更多 ”</a></p><p> <a href="https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/">行业领袖支持开源人工智能定义的</a>帖子首先出现在<a href="https://www.artificialintelligence-news.com">人工智能新闻</a>上。</p> ]]>; </description><content:encoded><![CDATA[
<p><a href="https://opensource.org/">开源倡议</a>（OSI）公布了一个定义框架来评估人工智能系统是否可以归类为开源。</p><p>第一个开源人工智能定义 (OSAID) 是在<a href="https://allthingsopen.org/">All Things Open</a>上发布的，标志着跨越多年研究、国际研讨会和长达一年的社区设计过程的全球全面努力的顶峰。</p><p> OSI 被世界各地的个人、组织和政府机构广泛认为是开源定义的权威机构，通过与行业利益相关者的广泛合作开发了该框架。该框架定义了开源人工智能的含义，坚持相同的开源要求适用于功能齐全的人工智能系统、模型、权重和参数或其他结构元素。</p><p>开源人工智能系统必须根据授予四项基本自由的条款提供：</p><ul class="wp-block-list"><li><strong>将系统用于任何目的</strong>，无需征求许可。</li><li><strong>研究系统如何工作</strong>并检查其组件。</li><li>出于任何目的<strong>修改系统</strong>，包括更改其输出。</li><li><strong>共享系统</strong>供其他人出于任何目的在修改或不修改的情况下使用。</li></ul><p>这些自由度既适用于功能齐全的系统，也适用于系统的离散元素。行使这些自由的前提是能够访问首选形式来对系统进行修改，其中包括详细的数据信息、完整的源代码和模型参数。</p><p> OSI 董事会主席 Carlo Piana 表示：“导致开源 AI 定义 1.0 版本的共同设计过程非常完善、彻底、包容且公平。” “董事会相信这一过程所产生的定义符合开源定义中定义的开源标准和四项基本自由。”</p><p>该框架最重要的要求之一是要求开源模型提供有关<a href="https://www.artificialintelligence-news.com/news/penguin-random-house-protects-its-books-from-ai-training-use/">其训练数据的</a>足够信息，确保“技术人员可以使用相同或相似的数据重新创建实质上等效的系统”，Ayah Bdeir 表示。领导<a href="https://www.mozilla.org/en-GB/">Mozilla</a>的人工智能战略。</p><p>布德尔承认，虽然这种方法可能并不完美，但它代表了意识形态纯洁性和现实世界实施之间的实际妥协。她表示，要求不切实际的高标准可能会对该倡议的目标产生反作用。</p><p><a href="https://www.digitalpublicgoods.net/implement">数字公共产品联盟</a>(DPGA) 表示支持 OSI 在定义开源人工智能方面的领导地位。 DPGA 秘书处首席执行官 Liv Marte Nordhaug 确认，她的组织将把这项基础工作纳入人工智能应用数字公共产品标准的更新中。</p><p>以人工智能开发领域的非营利性工作而闻名的<a href="https://www.eleuther.ai/">EleutherAI Institute</a>也认可了这一定义。</p><p> EleutherAI 研究所执行董事 Stella Biderman 表示：“开源人工智能定义是促进人工智能领域开源原则的好处的必要步骤。” “我们相信这个定义支持独立机器学习研究人员的需求，并促进最大的人工智能开发商之间更大的透明度。”</p><p>该定义强调了共享开源模型和权重时包含数据信息和代码的重要性。这些要求确保了透明度和修改人工智能系统的能力。</p><p> OSI 执行董事 Stefano Maffulli 承认开发过程中面临的挑战，并指出，尽管偶尔会出现激烈的交流和不同意见，但最终结果与项目的最初目标是一致的。</p><p>他表示：“这是继续努力与社区合作以随着时间的推移改进定义的起点。”</p><p> OSAID 不需要特定的法律机制来确保模型参数可供所有人免费使用，尽管它可能涉及许可证或法律文书。随着<a href="https://www.artificialintelligence-news.com/news/eu-ai-act-early-prep-could-give-businesses-competitive-edge/">法律系统</a>解决这些开源人工智能系统的问题，这一方面预计会随着时间的推移而变得更加清晰。</p><p><strong>另请参阅：</strong> <a href="https://www.artificialintelligence-news.com/news/president-biden-issues-first-national-security-memorandum-ai/"><strong>拜登总统发布第一份关于人工智能的国家安全备忘录</strong></a></p><figure class="wp-block-image size-full"><a href="https://www.ai-expo.net/"><img decoding="async" width="728" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" alt="" class="wp-image-11874" srcset="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w" sizes="(max-width: 728px) 100vw, 728px" /></a></figure><p><strong>想向行业领导者了解更多关于人工智能和大数据的知识吗？</strong>查看在阿姆斯特丹、加利福尼亚州和伦敦举办的<a href="https://www.ai-expo.net/">人工智能与大数据博览会</a>。该综合活动与其他领先活动同期举行，包括<a href="https://intelligentautomation-conference.com/northamerica/">智能自动化大会</a>、 <a href="https://www.blockchain-expo.com/">BlockX</a> 、<a href="https://digitaltransformation-week.com/">数字化转型周</a>以及<a href="https://www.cybersecuritycloudexpo.com/">网络安全与云博览会</a>。</p><p><a href="https://techforge.pub/events/">在此</a>探索由 TechForge 提供支持的其他即将举行的企业技术活动和网络研讨会。</p><p> <a href="https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/">行业领袖支持开源人工智能定义的</a>帖子首先出现在<a href="https://www.artificialintelligence-news.com">人工智能新闻</a>上。</p> ]]>;</content:encoded><wfw:commentrss> https://www.artificialintelligence-news.com/news/industry-leaders-back-open-source-ai-definition/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>