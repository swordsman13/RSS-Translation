<feed xmlns="http://www.w3.org/2005/Atom" xmlns:blogger="http://schemas.google.com/blogger/2008" xmlns:gd="http://schemas.google.com/g/2005" xmlns:georss="http://www.georss.org/georss" xmlns:opensearch="http://a9.com/-/spec/opensearchrss/1.0/" xmlns:thr="http://purl.org/syndication/thread/1.0"><id>标签：blogger.com，1999：blog-8474926331452026626</id><updated> 2024-03-06T14:44:35.706-08:00 </updated><category term="Machine Learning"></category><category term="Deep Learning"></category><category term="Computer Vision"></category><category term="Natural Language Processing"></category><category term="Google Brain"></category><category term="open source"></category><category term="Research"></category><category term="Publications"></category><category term="conference"></category><category term="Machine Perception"></category><category term="Natural Language Understanding"></category><category term="TensorFlow"></category><category term="conferences"></category><category term="datasets"></category><category term="Education"></category><category term="Neural Networks"></category><category term="Reinforcement Learning"></category><category term="University Relations"></category><category term="Health"></category><category term="Robotics"></category><category term="AI"></category><category term="Algorithms"></category><category term="CVPR"></category><category term="NLP"></category><category term="Quantum Computing"></category><category term="Multimodal Learning"></category><category term="Speech"></category><category term="Research Awards"></category><category term="Computational Photography"></category><category term="Machine Intelligence"></category><category term="On-device Learning"></category><category term="AI for Social Good"></category><category term="Security and Privacy"></category><category term="Computer Science"></category><category term="HCI"></category><category term="Quantum AI"></category><category term="MOOC"></category><category term="ICLR"></category><category term="Machine Translation"></category><category term="optimization"></category><category term="accessibility"></category><category term="Image Classification"></category><category term="Pixel"></category><category term="Self-Supervised Learning"></category><category term="Visualization"></category><category term="YouTube"></category><category term="AutoML"></category><category term="Hardware"></category><category term="NeurIPS"></category><category term="ACL"></category><category term="Audio"></category><category term="ICML"></category><category term="ML"></category><category term="Physics"></category><category term="Responsible AI"></category><category term="TPU"></category><category term="Android"></category><category term="EMNLP"></category><category term="ML Fairness"></category><category term="video"></category><category term="Awards"></category><category term="Search"></category><category term="Structured Data"></category><category term="Image Processing"></category><category term="Information Retrieval"></category><category term="Supervised Learning"></category><category term="Collaboration"></category><category term="Google Maps"></category><category term="Graph Mining"></category><category term="TTS"></category><category term="User Experience"></category><category term="distributed systems"></category><category term="Automatic Speech Recognition"></category><category term="Google Accelerated Science"></category><category term="Speech Recognition"></category><category term="DeepMind"></category><category term="Environment"></category><category term="Google Translate"></category><category term="Video Analysis"></category><category term="2022 Year-in-Review"></category><category term="ACM"></category><category term="Chemistry"></category><category term="Earth Engine"></category><category term="K-12"></category><category term="RAI-HCT Highlights"></category><category term="Vision Research"></category><category term="statistics"></category><category term="Acoustic Modeling"></category><category term="Diversity"></category><category term="Interspeech"></category><category term="Systems"></category><category term="UI"></category><category term="Voice Search"></category><category term="data science"></category><category term="ph.d. fellowship"></category><category term="Augmented Reality"></category><category term="Cloud Computing"></category><category term="Compression"></category><category term="Differential Privacy"></category><category term="Google Cloud Platform"></category><category term="ICCV"></category><category term="Large Language Models"></category><category term="Machine Hearing"></category><category term="NIPS"></category><category term="Semi-supervised Learning"></category><category term="Software"></category><category term="Translate"></category><category term="Unsupervised Learning"></category><category term="grants"></category><category term="market algorithms"></category><category term="Faculty Summit"></category><category term="Google Genomics"></category><category term="Recommender Systems"></category><category term="Semantic Models"></category><category term="crowd-sourcing"></category><category term="Art"></category><category term="Biology"></category><category term="Course Builder"></category><category term="Data Discovery"></category><category term="Google Photos"></category><category term="Google+"></category><category term="PhD Fellowship"></category><category term="Social Networks"></category><category term="WWW"></category><category term="ads"></category><category term="renewable energy"></category><category term="Climate"></category><category term="Computational Imaging"></category><category term="Europe"></category><category term="Expander"></category><category term="Fusion Tables"></category><category term="Google Books"></category><category term="Kaggle"></category><category term="Moore's Law"></category><category term="Ngram"></category><category term="Optical Character Recognition"></category><category term="Virtual Reality"></category><category term="Year in Review"></category><category term="schema.org"></category><category term="API"></category><category term="Africa"></category><category term="App Engine"></category><category term="Gboard"></category><category term="Gmail"></category><category term="Google Play Apps"></category><category term="Graphs"></category><category term="High Dynamic Range Imaging"></category><category term="Image Annotation"></category><category term="India"></category><category term="Internet of Things"></category><category term="NAACL"></category><category term="Networks"></category><category term="Style Transfer"></category><category term="economics"></category><category term="internationalization"></category><category term="publication"></category><category term="resource optimization"></category><category term="search ads"></category><category term="wikipedia"></category><category term="Adaptive Data Analysis"></category><category term="Android Wear"></category><category term="App Inventor"></category><category term="China"></category><category term="DeepDream"></category><category term="EMEA"></category><category term="Exacycle"></category><category term="Generative AI"></category><category term="Genomics"></category><category term="Google Docs"></category><category term="Google Drive"></category><category term="Google Science Fair"></category><category term="Google Sheets"></category><category term="Graph"></category><category term="Inbox"></category><category term="KDD"></category><category term="Keyboard Input"></category><category term="Labs"></category><category term="Low-Light Photography"></category><category term="MapReduce"></category><category term="Policy"></category><category term="Proposals"></category><category term="TensorBoard"></category><category term="VLDB"></category><category term="Weather"></category><category term="electronics"></category><category term="osdi"></category><category term="patents"></category><category term="trends"></category><category term="April Fools"></category><category term="Australia"></category><category term="BigQuery"></category><category term="CHI"></category><category term="Cantonese"></category><category term="Chrome"></category><category term="Conservation"></category><category term="Data Center"></category><category term="ECCV"></category><category term="Electronic Commerce and Algorithms"></category><category term="Encryption"></category><category term="Entity Salience"></category><category term="Faculty Institute"></category><category term="Flu Trends"></category><category term="Google Cloud"></category><category term="Google I/O"></category><category term="Google Trips"></category><category term="Google Voice Search"></category><category term="Government"></category><category term="High-Performance Computing"></category><category term="ICSE"></category><category term="IPython"></category><category term="Journalism"></category><category term="Klingon"></category><category term="Korean"></category><category term="Linear Optimization"></category><category term="Magenta"></category><category term="Market Research"></category><category term="Mixed Reality"></category><category term="Network Management"></category><category term="Nexus"></category><category term="Peer Review"></category><category term="PhotoScan"></category><category term="PiLab"></category><category term="Professional Development"></category><category term="Public Data Explorer"></category><category term="SIGCOMM"></category><category term="SIGMOD"></category><category term="Site Reliability Engineering"></category><category term="Sound Search"></category><category term="TV"></category><category term="UNIX"></category><category term="Visiting Faculty"></category><category term="Wiki"></category><category term="adsense"></category><category term="adwords"></category><category term="correlate"></category><category term="entities"></category><category term="gamification"></category><category term="jsm"></category><category term="jsm2011"></category><category term="localization"></category><category term="materials science"></category><category term="operating systems"></category><category term="osdi10"></category><title type="text">Google AI 博客&lt;/stitle>;&lt;subtitle type=&quot;html&quot;>;来自 Google AI 的最新新闻。&lt;/substitle>;&lt;link href=&quot;http://blog.research.google/feeds/posts/default&quot; rel=&quot; http://schemas.google.com/g/2005#feed&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default? alt=atom&amp;redirect=false&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/&quot; rel=&quot;alternate&quot; type=&quot;text/html&quot; />;&lt;link href=&quot;http://pubsubhubbub.appspot.com/&quot; rel=&quot;hub&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default?alt= atom&amp;start-index=26&amp;max-results=25&amp;redirect=false&quot; rel=&quot;next&quot; type=&quot;application/atom+xml&quot;/>;&lt;author>;&lt;name>;ewood&lt;/name>;&lt;uri>;http://www.blogger. com/profile/12341551220176883769&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src =&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;generator uri=&quot;http://www.blogger.com &quot; version=&quot;7.00&quot;>;Blogger&lt;/generator>;&lt;opensearch:totalresults>;1339&lt;/opensearch:totalresults>;&lt;opensearch:startindex>;1&lt;/opensearch:startindex>;&lt;opensearch:itemsperpage>;25&lt;/opensearch:itemsperpage>;&lt;entry >;&lt;id>;标签：blogger.com，1999：blog-8474926331452026626.post-8393293208018757284&lt;/id>;&lt;发布>;2024-03-06T10:26:00.000-08:00&lt;/发布>;&lt;更新>;2024-03- 06T14:44:03.387-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Collaboration&quot;>;&lt;/category>;&lt;category schema=&quot;http: //www.blogger.com/atom/ns#&quot; term=&quot;datasets&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;ML&quot;>;&lt; /category>;&lt;title type=&quot;text&quot;>;Croissant：用于 ML 就绪数据集的元数据格式&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：软件工程师 Omar Benjelloun 、Google 研究部和 Google Core ML 软件工程师兼 MLCommons 协会主席 Peter Mattson&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj09uSTHgWmPgOkD9W1nZZj5i8uW_-pgxm-T1O5PSacF- EKvHIeIwhMr7Rgft7O3A2Rk94GWe8WboO3dUlxrqt1xz9x4I2aMKJxCUtUkR2eukbsIa8xVyAAN_LJJyMABxRqJuktFkyfhoWPDMQK3O-XgbQNJXzAILlWl3su0fd-Q_uZ-8r5r_uAU2P4 srnP/s1600/CroissantHero.png&quot; style=&quot;显示：无；&quot; />; &lt;p>; 机器学习 (ML) 从业者希望重用现有数据集来训练 ML 模型，他们通常会花费大量时间来理解数据、理解其组织或弄清楚要使用哪个子集作为特征。事实上，机器学习领域的进展长期以来一直受到一个根本障碍的阻碍：数据表示的多样性。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; ML 数据集涵盖广泛的内容类型，从文本和结构化数据到图像、音频和视频。即使在涵盖相同类型内容的数据集中，每个数据集也具有独特的文件和数据格式&lt;em>;临时&lt;/em>;排列。这一挑战降低了整个机器学习开发过程（从查找数据到训练模型）的生产力。它还阻碍了急需的数据集工具的开发。 &lt;/p>; &lt;p>; 数据集有通用元数据格式，例如 &lt;a href=&quot;http://schema.org/Dataset&quot;>;schema.org&lt;/a>; 和 &lt;a href=&quot;https:// www.w3.org/TR/vocab-dcat-3/&quot;>;DCAT&lt;/a>;。然而，这些格式是为数据发现而设计的，而不是为了满足机器学习数据的特定需求，例如从结构化和非结构化源中提取和组合数据的能力，以包含能够实现的元数据.google/responsibility/responsible-ai-practices/&quot;>;负责任地使用数据&lt;/a>;，或描述 ML 使用特征，例如定义训练、测试和验证集。 &lt;/p>; &lt;p>; 今天，我们推出 &lt;a href=&quot;https://mlcommons.org/croissant&quot;>;Croissant&lt;/a>;，这是一种适用于 ML 就绪数据集的新元数据格式。 Croissant 是由工业界和学术界社区合作开发的，是 &lt;a href=&quot;https://mlcommons.org/&quot;>;MLCommons&lt;/a>; 工作的一部分。 Croissant 格式不会改变实际数据的表示方式（例如图像或文本文件格式）——它提供了描述和组织数据的标准方法。 Croissant 建立在 &lt;a href=&quot;https://schema.org/&quot;>;schema.org&lt;/a>; 之上，这是在网络上发布结构化数据的事实标准，已被超过 4000 万个数据集使用。 Croissant 通过 ML 相关元数据、数据资源、数据组织和默认 ML 语义的综合层对其进行了增强。 &lt;/p>; &lt;p>; 此外，我们还宣布主要工具和存储库的支持：今天，三个广泛使用的 ML 数据集集合 - &lt;a href=&quot;http://www.kaggle.com/datasets&quot;>;Kaggle&lt; /a>;、&lt;a href=&quot;https://huggingface.co/datasets?other=croissant&amp;amp;sort=trending&quot;>;拥抱脸&lt;/a>; 和 &lt;a href=&quot;https://openml.org/search ?type=data&quot;>;OpenML&lt;/a>; — 将开始支持其托管数据集的 Croissant 格式； &lt;a href=&quot;http://g.co/datasetsearch&quot;>;数据集搜索&lt;/a>;工具可让用户在网络上搜索 Croissant 数据集；以及流行的机器学习框架，包括 &lt;a href=&quot;https://www.tensorflow.org/&quot;>;TensorFlow&lt;/a>;、&lt;a href=&quot;https://pytorch.org/&quot;>;PyTorch&lt;/a>;、和 &lt;a href=&quot;https://github.com/google/jax&quot;>;JAX&lt;/a>;，可以使用 &lt;a href=&quot;https://www.tensorflow.org/datasets&quot;>; 轻松加载 Croissant 数据集TensorFlow 数据集&lt;/a>; (TFDS) 包。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Croissant&lt;/h2>; &lt;p>; 此 Croissant 1.0 版本包含完整的 &lt;a href=&quot;https ://mlcommons.org/croissant/1.0&quot;>;格式规范&lt;/a>;，一组&lt;a href=&quot;https://github.com/mlcommons/croissant/tree/main/datasets&quot;>;示例数据集&lt;/a>;，一个开源 &lt;a href=&quot;https://github.com/mlcommons/croissant/tree/main/python/mlcroissant&quot;>;Python 库&lt;/a>;，用于验证、使用和生成 Croissant 元数据，以及一个开源&lt;a href=&quot;https://github.com/mlcommons/croissant/tree/main/editor&quot;>;可视化编辑器&lt;/a>;，用于以直观的方式加载、检查和创建 Croissant 数据集描述。 &lt;/p>; &lt;p>; 支持负责任的人工智能 (RAI) 从一开始就是 Croissant 工作的一个关键目标。我们还发布了 &lt;a href=&quot;https://mlcommons.org/croissant/RAI/1.0&quot;>;Croissant RAI 词汇表&lt;/a>;扩展的第一个版本，该扩展通过描述重要 RAI 使用所需的关键属性来增强 Croissant数据生命周期管理、数据标签、参与式数据、机器学习安全性和公平性评估、可解释性和合规性等案例。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;为什么要采用 ML 数据的共享格式？&lt;/h2>; &lt;p>; 大部分 ML 工作实际上是数据工作。训练数据是决定模型行为的“代码”。数据集的范围很广，从用于训练大型语言模型 (LLM) 的文本集合到用于训练汽车防撞系统的驾驶场景（带注释的视频）集合。但是，开发 ML 模型的步骤通常遵循相同的以数据为中心的迭代过程：(1) 查找或收集数据，(2) 清理和细化数据，(3) 根据数据训练模型，(4) 测试在更多数据上建立模型，(5) 发现模型不起作用，(6) 分析数据找出原因，(7) 重复直到获得可行的模型。由于缺乏通用格式，许多步骤变得更加困难。对于资源有限的研究和早期创业工作来说，这种“数据开发负担”尤其沉重。 &lt;/p>; &lt;p>; 像牛角面包这样的格式的目标是使整个过程变得更容易。例如，搜索引擎和数据集存储库可以利用元数据来更轻松地找到正确的数据集。数据资源和组织信息使得开发用于清理、提炼和分析数据的工具变得更加容易。这些信息和默认的 ML 语义使 ML 框架能够使用数据以最少的代码来训练和测试模型。总之，这些改进大大减轻了数据开发负担。 &lt;/p>; &lt;p>; 此外，数据集作者关心其数据集的可发现性和易用性。得益于可用的创建工具和 ML 数据平台的支持，采用 Croissant 提高了数据集的价值，同时只需要很少的努力。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;牛角面包今天可以做什么？&lt;/h2>; &lt;tablealign=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>; &lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN40ZSjgTFRIVwAwN2OXIn4vQhmshC8VhcKx-ijY-sCQBH9qDkV3nrFz_YapZ0iAD-Svkyxblt6lpJFFHa4JfDqfY6RIL0RnVhtgBlLyh- 1DnH8DUz7-TUSdSUIg5V2piqjmQ5Dw9MISeeSBvnMsie8jRrXOeHXfcTGQi0AHIeOYFuHYwDFSyRmBT8BHum/s908/image1.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left : auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;540&quot; data-original-width=&quot;908&quot; src=&quot;https://blogger.googleusercontent.com/img /b/R29vZ2xl/AVvXsEgN40ZSjgTFRIVwAwN2OXIn4vQhmshC8VhcKx-ijY-sCQBH9qDkV3nrFz_YapZ0iAD-Svkyxblt6lpJFFHa4JfDqfY6RIL0RnVhtgBlLyh-1DnH8DUz7-TUSdSUIg5V 2piqjmQ5Dw9MISeeSBvnMsie8jRrXOeHXfcTGQi0AHIeOYFuHYwDFSyRmBT8BHum/s16000/image1.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot;样式=&quot;text-align: center;&quot;>;Croissant 生态系统：用户可以搜索 Croissant 数据集，从主要存储库下载它们，然后轻松地将它们加载到自己喜欢的 ML 框架中。他们可以使用 Croissant 编辑器创建、检查和修改 Croissant 元数据。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 今天，用户可以在以下位置找到 Croissant 数据集：&lt;/p>; &lt;ul>; &lt; li>;Google &lt;a href=&quot;https://datasetsearch.research.google.com/&quot;>;数据集搜索&lt;/a>;，它提供了牛角面包过滤器。 &lt;/li>;&lt;li>;&lt;a href=&quot;https://huggingface.co/datasets?other=croissant&amp;amp;sort=trending&quot;>;HuggingFace&lt;/a>; &lt;/li>;&lt;li>;&lt;a href=&quot;http: //kaggle.com/datasets&quot;>;Kaggle&lt;/a>; &lt;/li>;&lt;li>;&lt;a href=&quot;https://openml.org/search?type=data&quot;>;OpenML&lt;/a>; &lt;/li>; &lt;/ul>; &lt;p>; 使用 Croissant 数据集，可以： &lt;/p>; &lt;ul>; &lt;li>;通过 &lt;a href=&quot;https://www.tensorflow.org/datasets&quot;>;TensorFlow 轻松摄取数据用于流行机器学习框架的数据集&lt;/a>;，例如 &lt;a href=&quot;https://www.tensorflow.org/&quot;>;TensorFlow&lt;/a>;、&lt;a href=&quot;https://pytorch.org/&quot;>; PyTorch&lt;/a>; 和 &lt;a href=&quot;https://github.com/google/jax&quot;>;JAX&lt;/a>;。 &lt;/li>;&lt;li>;使用&lt;a href=&quot;https://huggingface.co/spaces/MLCommons/croissant-editor&quot;>;Croissant 编辑器 UI&lt;/a>; 检查和修改元数据 (&lt;a href=&quot;https ://github.com/mlcommons/croissant/tree/main/editor&quot;>;github&lt;/a>;）。 &lt;/li>; &lt;/ul>; &lt;p>; 要发布 Croissant 数据集，用户可以： &lt;/p>; &lt;ul>; &lt;li>;使用 &lt;a href=&quot;https://huggingface.co/spaces/MLCommons/croissant -editor&quot;>;Croissant 编辑器 UI&lt;/a>; (&lt;a href=&quot;https://github.com/mlcommons/croissant/tree/main/editor&quot;>;github&lt;/a>;) 用于生成大部分 Croissant 元数据通过分析用户提供的数据自动填充重要的元数据字段，例如 RAI 属性。 &lt;/li>;&lt;li>;将羊角面包信息作为数据集网页的一部分发布，以使其可发现和可重用。 &lt;/li>;&lt;li>;将数据发布到支持 Croissant 的存储库之一（例如 Kaggle、HuggingFace 和 OpenML），并自动生成 Croissant 元数据。 &lt;/li>; &lt;/ul>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;未来方向&lt;/h2>; &lt;p>; 我们对 Croissant 帮助机器学习的潜力感到兴奋但要使这种格式真正有用需要社区的支持。我们鼓励数据集创建者考虑提供羊角面包元数据。我们鼓励托管数据集的平台提供 Croissant 文件供下载，并将 Croissant 元数据嵌入数据集网页中，以便数据集搜索引擎可以发现它们。帮助用户处理 ML 数据集的工具（例如标签或数据分析工具）也应考虑支持 Croissant 数据集。我们可以共同减轻数据开发负担，打造更丰富的机器学习研究和开发生态系统。 &lt;/p>; &lt;p>; 我们鼓励社区&lt;a href=&quot;http://mlcommons.org/croissant&quot;>;与我们一起&lt;/a>;为这项工作做出贡献。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;Croissant 是由 &lt;a href=&quot;https 开发的://datasetsearch.research.google.com/&quot;>;数据集搜索&lt;/a>;、&lt;a href=&quot;https://www.kaggle.com/&quot;>;Kaggle&lt;/a>; 和 &lt;a href=&quot;https: //www.tensorflow.org/datasets&quot;>;来自 Google 的 TensorFlow Datasets&lt;/a>; 团队，作为 &lt;a href=&quot;http://mlcommons.org&quot;>;MLCommons&lt;/a>; 社区工作组的一部分，该工作组还包括来自以下组织的贡献者：Bayer、cTuning Foundation、DANS-KNAW、Dotphoton、Harvard、Hugging Face、伦敦国王学院、LIST、Meta、NASA、北卡罗来纳州立大学、开放数据研究所、加泰罗尼亚开放大学、Sage Bionetworks 和埃因霍温工业大学。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/8393293208018757284/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; 类型=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/03/croissant-metadata-format-for-ml-ready.html#comment-form&quot; rel=&quot;回复&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/8393293208018757284&quot; rel=&quot;edit&quot; type=&quot; application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/8393293208018757284&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt; link href=&quot;http://blog.research.google/2024/03/croissant-metadata-format-for-ml-ready.html&quot; rel=&quot;alternate&quot; title=&quot;Croissant：ML就绪数据集的元数据格式&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com &lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded .gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj09uSTHgWmPgOkD9W1nZZj5i8uW_-pgxm -T1O5PSacF-EKvHIeIwhMr7Rgft7O3A2Rk94GWe8WboO3dUlxrqt1xz9x4I2aMKJxCUtUkR2eukbsIa8xVyAAN_LJJyMABxRqJuktFkyfhoWPDMQK3O-XgbQNJXzAILlWl3su0fd-Q_uZ-8r 5r_uAU2P4srnP/s72-c/CroissantHero.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt; thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-2754526782497247497&lt;/id>;&lt;已发布>;2024-03-04T07:06 ：00.000-08:00&lt;/已发布>;&lt;已更新>;2024-03-05T08:40:45.490-08:00&lt;/已更新>;&lt;类别方案=“http://www.blogger.com/atom/ns#” term=“会议”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=“会议”>;&lt;/类别>;&lt;类别方案=“http://www” .blogger.com/atom/ns#&quot; term=&quot;Physics&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Quantum AI&quot;>;&lt;/category >;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;量子计算&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Google 参加 APS 2024&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Kate Weber 和 Shannon Leon，Google 研究部量子 AI 团队&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img /b/R29vZ2xl/AVvXsEjy22Hfq3RN4qRUJcSMUpIau4ueOIcQ219mDvfu4FNJ9kf5PBMUI0x4Uf9BhoIHtnFUhtvE72GCVYixldOZRSeePJfef0P87Pc_djQeGIZOhyxv9nKsQCc57357tr3npW dS5fyWxiGjex4NxMpOIB2JE1Z2qXdLnzLkFM075WstFJD77xVNS2T9hckWZyLf/s1600/lockup_GoogleResearch_FullColor_Hero.jpg&quot; style=&quot;显示：无；&quot; />; &lt;p>; 今天，&lt;a href=&quot;https://www.aps.org/meetings/meeting.cfm?name=MAR24&quot;>;2024 年 3 月会议&lt;/a>; &lt;a href=&quot;https:// /www.aps.org/&quot;>;美国物理学会&lt;/a>; (APS) 在明尼苏达州明尼阿波利斯成立。 APS 2024 是一次涵盖物理学及相关领域主题的顶级会议，汇集了研究人员、学生和行业专业人士，分享他们的发现并建立合作伙伴关系，以实现物理相关科学和技术的根本性进步。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 今年，Google 在 APS 上表现强劲，其展位由 Google &lt;a href=&quot;https://quantumai.google/&quot; 主办>;量子AI&lt;/a>;团队，整个会议期间进行了50+次演讲，并参与了会议组织活动、专题会议和活动。亲自参加 APS 2024？欢迎参观 Google 的量子人工智能展位，详细了解我们为解决该领域一些最有趣的挑战而所做的令人兴奋的工作。 &lt;!--访问 &lt;a href=&quot;https://twitter.com/GoogleAI&quot;>;@GoogleAI&lt;/a>; X (Twitter) 帐户了解 Google 展位活动（例如演示和问答环节） .-->; &lt;/p>; &lt;p>; 您可以详细了解我们在会议上展示的最新前沿工作以及下面的展位活动时间表（Google 员工以&lt;strong>;粗体&lt;/strong>;列出）。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;组委会&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p >; 会议主席包括：&lt;strong>;Aaron Szasz&lt;/strong>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;展位活动&lt; /h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;em>;此时间表可能会发生变化。请访问 Google Quantum AI 展位了解更多信息。&lt;/em>; &lt;/p>; &lt;p>; Crumble：用于可视化 QEC 电路的原型交互工具&lt;br />; 演讲者：&lt;strong>;Matt McEwen&lt;/strong>; &lt;br / >; 3 月 5 日，星期二 |中部标准时间上午 11:00 &lt;/p>; &lt;p>; Qualtran：用于容错算法的有效资源估计的开源库 &lt;br />; 演讲者：&lt;strong>;Tanuj Khattar&lt;/strong>; &lt;br />; 3 月 5 日，星期二|下午 2:30 CST &lt;/p>; &lt;p>; Qualtran：用于容错算法的有效资源估计的开源库&lt;br />; 演讲者：&lt;strong>;Tanuj Khattar&lt;/strong>; &lt;br />; 3 月 7 日星期四|上午 11:00 CST &lt;/p>; &lt;p>; 价值 500 万美元的 XPRIZE / Google Quantum AI 竞赛，旨在加速量子应用问答 &lt;br />; 演讲者：&lt;strong>;Ryan Babbush&lt;/strong>; &lt;br />; 3 月 7 日，星期四|上午 11:00（美国中部标准时间） &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;演讲&lt;/h2>; &lt;h3>;周一&lt;/h3 >; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/A45.1&quot;>;证明少数国家的高度纠缠状态单量子位测量&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Hsin-Yuan Huang&lt;/strong>; &lt;br />; 作者：&lt;strong>;Hsin-Yuan Huang&lt;/strong>; &lt;br />; &lt;em>;会议A45：机器学习量子物理新领域&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/A51.2&quot;>;迈向高保真超导量子位的模拟量子模拟&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Trond Andersen&lt;/strong>; &lt;br />; 作者：&lt;strong>;Trond I Andersen&lt;/strong>;、&lt;strong>;小米&lt;/strong >;、&lt;strong>;阿米尔·H·卡拉姆卢&lt;/strong>;、&lt;strong>;尼基塔·阿斯特拉罕采夫&lt;/strong>;、&lt;strong>;安德烈·克洛茨&lt;/strong>;、&lt;strong>;朱莉娅·伯恩特森&lt;/strong>;、&lt;strong>;安德烈·佩图霍夫&lt;/strong>; &lt;strong>;、&lt;strong>;德米特里·阿巴宁&lt;/strong>;、&lt;strong>;Lev B Ioffe&lt;/strong>;、&lt;strong>;陈宇&lt;/strong>;、&lt;strong>;Vadim Smelyanskiy&lt;/strong>;、&lt;strong>;Pedram Roushan&lt; /strong>; &lt;br />; &lt;em>;会议 A51：噪声量子硬件上的应用 I&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session /B50.6&quot;>;测量表面代码电路上下文中的电路错误&lt;/a>; &lt;br />;演讲者：&lt;strong>;Dripto M Debroy&lt;/strong>; &lt;br />;作者：&lt;strong>;Dripto M Debroy&lt;/strong >;、&lt;strong>;Jonathan A Gross&lt;/strong>;、&lt;strong>;Élie Genois&lt;/strong>;、&lt;strong>;张江&lt;/strong>; &lt;br />; &lt;em>;会议 B50：使用 QCVV 技术表征噪声&lt;/em >; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/B51.6&quot;>;惯性聚变目标设计的阻止本领的量子计算 I：物理概述和经典算法的局限性&lt;/a>; &lt;br />;演讲者：Andrew D. Baczewski &lt;br />;作者：&lt;strong>;Nicholas C. Rubin&lt;/strong>;、Dominic W. Berry、Alina Kononov、&lt;strong>;Fionn D.马龙、塔努吉·哈塔尔、亚历克·怀特、李俊浩、哈特穆特·内文、瑞安·巴布什、安德鲁D. Baczewski &lt;br />; &lt;em>;会议 B51：量子应用的异构设计&lt;/em>; &lt;br />; &lt;a href=&quot;https://arxiv.org/pdf/2308.12352.pdf&quot;>;论文链接&lt; /a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/B51.7&quot;>;惯性聚变目标设计停止本领的量子计算二：物理概述以及经典算法的局限性&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Nicholas C. Rubin&lt;/strong>; &lt;br />; 作者：&lt;strong>;Nicholas C. Rubin&lt;/strong>;、Dominic W. Berry、阿丽娜·科诺诺夫、&lt;strong>;菲恩·D·马龙&lt;/strong>;、&lt;strong>;塔努吉·卡塔尔&lt;/strong>;、亚历克·怀特、&lt;strong>;李俊浩&lt;/strong>;、&lt;strong>;哈特穆特·内文&lt;/strong>;、&lt;strong >;Ryan Babbush&lt;/strong>;、Andrew D. Baczewski &lt;br />; &lt;em>;会议 B51：量子应用的异构设计&lt;/em>; &lt;br />; &lt;a href=&quot;https://arxiv.org/pdf/ 2308.12352.pdf&quot;>;论文链接&lt;/a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/B56.4&quot;>;校准超导量子位：来自NISQ 到容错&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Sabrina S Hong&lt;/strong>; &lt;br />; 作者：&lt;strong>;Sabrina S Hong&lt;/strong>; &lt;br />; &lt;em>;Session B56:从 NISQ 到容错&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/B31.9&quot;>;测量和前馈引起的纠缠负性转变&lt; /a>; &lt;br />; 演讲者：&lt;strong>;Ramis Movassagh&lt;/strong>; &lt;br />; 作者：Alireza Seif、Yu-Xin Wang、&lt;strong>;Ramis Movassagh&lt;/strong>;、Aashish A. Clerk &lt;br />; &lt;em>;会议 B31：多体系统中测量引起的临界&lt;/em>; &lt;br />; &lt;a href=&quot;https://arxiv.org/pdf/2310.18305.pdf&quot;>;论文链接&lt;/a>; &lt; /p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/B52.9&quot;>;噪声量子处理实验的有效量子体积、保真度和计算成本&lt;/a>; &lt; br />; 演讲者：&lt;strong>;Salvatore Mandra&lt;/strong>; &lt;br />; 作者：&lt;strong>;Kostyantyn Kechedzhi&lt;/strong>;、&lt;strong>;Sergei V Isakov&lt;/strong>;、&lt;strong>;Salvatore Mandra&lt;/strong>; ，&lt;strong>;本杰明·维拉隆加&lt;/strong>;，&lt;strong>;X。 Mi&lt;/strong>;、&lt;strong>;Sergio Boixo&lt;/strong>;、&lt;strong>;Vadim Smelyanskiy&lt;/strong>; &lt;br />; &lt;em>;会议 B52：量子算法和复杂性&lt;/em>; &lt;br />; &lt;a href =&quot;https://arxiv.org/pdf/2306.15970.pdf&quot;>;论文链接&lt;/a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/ Session/D60.4&quot;>;使用机器学习相互作用势和原子位置协方差绘制准确的固体热力学表&lt;/a>; &lt;br />;演讲者：Mgcini K Phuthi &lt;br />;作者：Mgcini K Phuthi、Yang Huang、Michael Widom , &lt;strong>;Ekin D Cubuk&lt;/strong>;, Venkat Viswanathan &lt;br />; &lt;em>;会议 D60：分子和材料的机器学习：化学空间和动力学&lt;/em>; &lt;/p>; &lt;/div>; &lt;div style =&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;星期二&lt;/h3>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https: //meetings.aps.org/Meeting/MAR24/Session/F50.4&quot;>;原位脉冲包络表征技术(INSPECT)&lt;/a>; &lt;br />;主讲人：&lt;strong>;张江&lt;/strong>; &lt;br />; 作者：&lt;strong>;张江&lt;/strong>;、&lt;strong>;Jonathan A Gross&lt;/strong>;、&lt;strong>;Élie Genois&lt;/strong>; &lt;br />; &lt;em>;会议 F50：高级随机基准测试和门校准&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/F50.11&quot;>;利用动态解耦来表征两个量子位门&lt;/a>; &lt; br />; 演讲者：&lt;strong>;Jonathan A Gross&lt;/strong>; &lt;br />; 作者：&lt;strong>;Jonathan A Gross&lt;/strong>;、&lt;strong>;张江&lt;/strong>;、&lt;strong>;Élie Genois、Dripto M Debroy&lt;/strong>;、Ze-Pei Cian*、&lt;strong>;Wojciech Mruczkiewicz&lt;/strong>; &lt;br />; &lt;em>;会议 F50：高级随机基准测试和门校准&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/EE01.2&quot;>;二次模型回归的统计物理&lt;/a>; &lt;br />;演讲者：Blake Bordelon &lt;br />;作者：Blake Bordelon、Cengiz Pehlevan、&lt;strong>;Yasaman Bahri&lt;/strong>; &lt;br />; &lt;em>;会议 EE01：V：统计和非线性物理 II&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https:/ /meetings.aps.org/Meeting/MAR24/Session/G51.2&quot;>;改进电子结构首次量子化模拟的状态准备&lt;/a>; &lt;br />; 演讲者：&lt;strong>;William J Huggins&lt;/strong>; &lt; br />; 作者：&lt;strong>;William J Huggins&lt;/strong>;、&lt;strong>;Oskar Leimkuhler&lt;/strong>;、&lt;strong>;Torin F Stetina&lt;/strong>;、&lt;strong>;Birgitta Whaley&lt;/strong>; &lt;br />; &lt;em>;会议 G51：哈密顿模拟&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/G30.2&quot;>;控制大型超导量子处理器&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Paul V. Klimov&lt;/strong>; &lt;br />; 作者：&lt;strong>;Paul V. Klimov&lt;/strong>;、&lt;strong>;Andreas Bengtsson&lt;/strong>;、&lt;克里斯·昆塔纳 (Chris Quintana)、亚历山大·布拉萨 (Alexandre Bourassa)、萨布丽娜·洪 (Sabrina Hong)、安德鲁·邓斯沃思 (Andrew Dunsworth)、凯文·J·萨辛格 (Kevin J. Satzinger) ，&lt;strong>;威廉·P·利文斯顿&lt;/strong>;，&lt;strong>;弗拉基米尔·西瓦克&lt;/strong>;，&lt;strong>;墨菲·Y·纽&lt;/strong>;，&lt;strong>;特隆德·I·安德森&lt;/strong>;，&lt;strong>;张亚星&lt;/strong>;、&lt;strong>;德斯蒙德·奇克&lt;/strong>;、&lt;strong>;陈子君&lt;/strong>;、&lt;strong>;查尔斯·尼尔&lt;/strong>;、&lt;strong>;凯瑟琳·埃里克森&lt;/strong>;、&lt;strong>;亚历杭德罗·格拉哈莱斯·道&lt;/strong>;、&lt;strong>;安东尼·梅格兰特&lt;/strong>;、&lt;strong>;佩德拉姆·鲁山&lt;/strong>;、&lt;strong>;亚历山大·科罗特科夫&lt;/strong>;、&lt;strong>;朱利安·凯利&lt;/strong>;、 &lt;strong>;Vadim Smelyanskiy&lt;/strong>;、&lt;strong>;Yu Chen&lt;/strong>;、&lt;strong>;Hartmut Neven&lt;/strong>; &lt;br />; &lt;em>;G30 会议：量子计算的商业应用&lt;/em>;&lt;br />; &lt;a href=&quot;https://arxiv.org/pdf/2308.02321.pdf&quot;>;论文链接&lt;/a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org /Meeting/MAR24/Session/G50.5&quot;>;高斯玻色子采样：确定量子优势&lt;/a>; &lt;br />; 演讲者：Peter D Drummond &lt;br />; 作者：Peter D Drummond、Alex Dellios、Ned Goodman、Margaret D Reid，&lt;strong>;Ben Villalonga&lt;/strong>; &lt;br />; &lt;em>;会议 G50：量子表征、验证和验证 II&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings .aps.org/Meeting/MAR24/Session/G50.8&quot;>;关注复杂性 III：学习随机量子电路状态的复杂性&lt;/a>; &lt;br />; 演讲者：Hyejin Kim &lt;br />; 作者：Hyejin Kim，周一清、徐一辰、万超、周锦、&lt;strong>;Yuri D Lensky&lt;/strong>;、Jesse Hoke、&lt;strong>;Pedram Roushan&lt;/strong>;、Kilian Q Weinberger、Eun-Ah Kim &lt;br />; &lt;em >;会议 G50：量子表征、验证和验证 II&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/K48.10&quot;>;平衡超导电路中的耦合&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Daniel T Sank&lt;/strong>; &lt;br />; 作者：&lt;strong>;Daniel T Sank&lt;/strong>;、&lt;strong>;Sergei V Isakov&lt;/strong >;, &lt;strong>;Mostafa Khezri&lt;/strong>;, &lt;strong>;Juan Atalaya&lt;/strong>; &lt;br />; &lt;em>;K48 会议：强驱动超导系统&lt;/em>; &lt;/p>; &lt;p>; &lt;a href= &quot;https://meetings.aps.org/Meeting/MAR24/Session/K49.12&quot;>;使用 Qᴜᴀʟᴛʀᴀɴ 进行容错算法的资源估计&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Tanuj Khattar&lt;/strong>; &lt; br />; 作者：&lt;strong>;Tanuj Khattar&lt;/strong>;、&lt;b>;Matthew Harrigan&lt;/b>;、&lt;b>;Fionn D. Malone&lt;/b>;、&lt;b>;Nour Yosri&lt;/b>;、&lt;b>; Nicholas C. Rubin&lt;/b>;&lt;br />; &lt;em>;K49 会议：近期量子计算机的算法和实现&lt;/em>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40% ;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;星期三&lt;/h3>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/ Meeting/MAR24/Session/M24.1&quot;>;用超导量子比特发现新颖的量子动力学&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Pedram Roushan&lt;/strong>; &lt;br />; 作者：&lt;strong>;Pedram Roushan&lt;/a>; &lt;br />; strong>; &lt;br />; &lt;em>;会议 M24：跨平台的模拟量子模拟&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/M27 .7&quot;>;破译三阴性乳腺癌中的肿瘤异质性：动态细胞-细胞和细胞-基质相互作用的关键作用&lt;/a>; &lt;br />;演讲者：Susan Leggett &lt;br />;作者：Susan Leggett、Ian Wong , Celeste Nelson, Molly Brennan, &lt;strong>;Mohak Patel&lt;/strong>;, Christian Franck, Sophia Martinez, Joe Tien, Lena Gamboa, Thomas Valentin, Amanda Khoo, Evelyn K Williams &lt;br />; &lt;em>;第 M27 节：力学细胞和组织 II&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/N48.2&quot;>;实现受保护的电荷奇偶校验量子位&lt; /a>; &lt;br />; 演讲者：Abigail Shearrow &lt;br />; 作者：Abigail Shearrow、Matthew Snyder、Bradley G Cole、Kenneth R Dodge、Yebin Liu、Andrey Klots、&lt;strong>;Lev B Ioffe&lt;/strong>;、Britton L Plourde，Robert McDermott &lt;br />; &lt;em>;第 N48 场会议：非常规超导量子位&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/N48 .3&quot;>;受保护的电荷奇偶校验量子位的隧道结中的电子电容&lt;/a>; &lt;br />; 演讲者：Bradley G Cole &lt;br />; 作者：Bradley G Cole、Kenneth R Dodge、Yebin Liu、Abigail Shearrow、Matthew Snyder 、&lt;strong>;Andrey Klots&lt;/strong>;、&lt;strong>;Lev B Ioffe&lt;/strong>;、Robert McDermott、BLT Plourde &lt;br />; &lt;em>;第 N48 场会议：非常规超导量子位&lt;/em>; &lt;/p>; &lt;p >; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/N51.7&quot;>;克服量子纠错中的泄漏&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Kevin C. Miao &lt;/strong>; &lt;br />; 作者：&lt;strong>;Kevin C. Miao&lt;/strong>;、&lt;strong>;Matt McEwen&lt;/strong>;、&lt;strong>;Juan Atalaya&lt;/strong>;、&lt;strong>;Dvir Kafri&lt;/strong>; >;、&lt;strong>;Leonid P. Pryadko&lt;/strong>;、&lt;strong>;Andreas Bengtsson&lt;/strong>;、&lt;strong>;Alex Opremcak&lt;/strong>;、&lt;strong>;Kevin J. Satzinger&lt;/strong>;、&lt;strong>;子君陈&lt;/strong>;、&lt;strong>;保罗·V·克里莫夫&lt;/strong>;、&lt;strong>;克里斯·昆塔纳&lt;/strong>;、&lt;strong>;拉吉夫·阿查里亚&lt;/strong>;、&lt;strong>;凯尔·安德森&lt;/strong>;、&lt;strong>; >;马库斯·安斯曼&lt;/strong>;、&lt;strong>;弗兰克·阿鲁特&lt;/strong>;、&lt;strong>;库纳尔·艾莉亚&lt;/strong>;、&lt;strong>;亚伯拉罕·阿斯福&lt;/strong>;、&lt;strong>;约瑟夫·C·巴丁&lt;/strong>;、 &lt;strong>;亚历山大·布拉萨&lt;/strong>;、&lt;strong>;珍娜·博瓦伊德&lt;/strong>;、&lt;strong>;莱昂·布里尔&lt;/strong>;、&lt;strong>;鲍勃·B·巴克利&lt;/strong>;、&lt;strong>;大卫·A·布尔&lt; /strong>;、&lt;strong>;蒂姆·伯格&lt;/strong>;、&lt;strong>;布莱恩·伯克特&lt;/strong>;、&lt;strong>;尼古拉斯·布什内尔&lt;/strong>;、&lt;strong>;胡安·坎佩罗&lt;/strong>;、&lt;strong>;本·基亚罗&lt; /strong>;、&lt;strong>;罗伯托·柯林斯&lt;/strong>;、&lt;strong>;保罗·康纳&lt;/strong>;、&lt;strong>;亚历山大·克鲁克&lt;/strong>;、&lt;strong>;本·科廷&lt;/strong>;、&lt;strong>;Dripto M.德布罗伊&lt;/strong>;、&lt;strong>;肖恩·德穆拉&lt;/strong>;、&lt;strong>;安德鲁·邓斯沃斯&lt;/strong>;、&lt;strong>;凯瑟琳·埃里克森&lt;/strong>;、&lt;strong>;雷扎·法特米&lt;/strong>;、&lt;strong>; >;维尼修斯·费雷拉&lt;/strong>;、&lt;strong>;莱斯利·弗洛雷斯·布尔戈斯&lt;/strong>;、&lt;strong>;易卜拉欣·福拉蒂&lt;/strong>;、&lt;strong>;奥斯汀·G·福勒&lt;/strong>;、&lt;strong>;布鲁克斯·福克斯&lt;/strong>; &lt;strong>;、&lt;strong>;贡萨洛·加西亚&lt;/strong>;、&lt;strong>;威廉·江&lt;/strong>;、&lt;strong>;克雷格·吉德尼&lt;/strong>;、&lt;strong>;玛丽莎·朱斯蒂娜&lt;/strong>;、&lt;strong>;Raja Gosula&lt;/strong>; &lt;strong>;、&lt;strong>;Alejandro Grajales Dau&lt;/strong>;、&lt;strong>;乔纳森 A. 格罗斯&lt;/strong>;、&lt;strong>;迈克尔 C. 汉密尔顿&lt;/strong>;、&lt;strong>;肖恩 D. 哈林顿&lt;/strong>;、 &lt;strong>;Paula Heu&lt;/strong>;、&lt;strong>;杰里米·希尔顿&lt;/strong>;、&lt;strong>;Markus R. Hoffmann&lt;/strong>;、&lt;strong>;Sabrina Hong&lt;/strong>;、&lt;strong>;Trent Huang&lt;/strong>; >;、&lt;strong>;阿什利·哈夫&lt;/strong>;、&lt;strong>;贾斯汀·艾夫兰&lt;/strong>;、&lt;strong>;埃文·杰弗里&lt;/strong>;、&lt;strong>;张江&lt;/strong>;、&lt;strong>;科迪·琼斯&lt;/strong>; >;、&lt;strong>;朱利安·凯利&lt;/strong>;、&lt;strong>;Seon Kim&lt;/strong>;、&lt;strong>;费多尔·科斯特里萨&lt;/strong>;、&lt;strong>;约翰·马克·克莱克鲍姆&lt;/strong>;、&lt;strong>;大卫·兰德休斯&lt;/strong>; 、&lt;strong>;帕维尔·拉普捷夫&lt;/strong>;、&lt;strong>;莉莉·劳斯&lt;/strong>;、&lt;strong>;肯尼·李&lt;/strong>;、&lt;strong>;布莱恩·J·莱斯特&lt;/strong>;、&lt;strong>;亚历山大·T . Lill&lt;/strong>;、&lt;strong>;Wayne Liu&lt;/strong>;、&lt;strong>;Aditya Locharla&lt;/strong>;、&lt;strong>;Erik Lucero&lt;/strong>;、&lt;strong>;Steven Martin&lt;/strong>;、&lt;strong>;安东尼·梅格兰特、&lt;strong>;小米&lt;/strong>;、&lt;strong>;希林·蒙塔泽里&lt;/strong>;、&lt;strong>;亚历克西斯·莫万&lt;/strong>;、&lt;strong>;奥弗·纳曼&lt;/strong>;、&lt;strong>;马修·尼利 (Matthew Neeley)、&lt;strong>;查尔斯·尼尔 (Charles Neill)&lt;/strong>;、&lt;strong>;Ani Nersisyan&lt;/strong>;、&lt;strong>;迈克尔·纽曼 (Michael Newman)&lt;/strong>;、&lt;strong>;Jiun How Ng&lt;/strong>;、&lt;strong>; >;安东尼·阮&lt;/strong>;、&lt;strong>;默里·阮&lt;/strong>;、&lt;strong>;丽贝卡·波特&lt;/strong>;、&lt;strong>;查尔斯·罗克&lt;/strong>;、&lt;strong>;佩德拉姆·鲁山&lt;/strong>;、&lt;strong>; >;坎南·桑卡拉戈马蒂&lt;/strong>;、&lt;strong>;克里斯托弗·舒斯特&lt;/strong>;、&lt;strong>;迈克尔·J·谢恩&lt;/strong>;、&lt;strong>;亚伦·肖特&lt;/strong>;、&lt;strong>;诺亚·舒蒂&lt;/strong>;、 &lt;strong>;弗拉基米尔·施瓦茨&lt;/strong>;、&lt;strong>;金德拉·斯克鲁兹尼&lt;/strong>;、&lt;strong>;W.克拉克·史密斯&lt;/strong>;、&lt;strong>;乔治·斯特林&lt;/strong>;、&lt;strong>;马可·萨莱&lt;/strong>;、&lt;strong>;道格拉斯·托尔&lt;/strong>;、&lt;strong>;阿尔弗雷多·托雷斯&lt;/strong>;、&lt;strong>;西奥多·怀特 (Theodore White)、&lt;strong>;布莱恩 WK Woo&lt;/strong>;、&lt;strong>;Z.杰米·姚&lt;/strong>;、&lt;strong>;叶平&lt;/strong>;、&lt;strong>;Juhwan Yoo&lt;/strong>;、&lt;strong>;格雷森·杨&lt;/strong>;、&lt;strong>;亚当·扎尔克曼&lt;/strong>;、&lt;strong>;朱宁峰&lt;/strong>;、&lt;strong>;尼古拉斯·佐布里斯特&lt;/strong>;、&lt;strong>;哈特穆特·内文&lt;/strong>;、&lt;strong>;瓦迪姆·斯梅尔扬斯基&lt;/strong>;、&lt;strong>;安德烈·佩图霍夫&lt;/strong>;、&lt;strong>; Alexander N. Korotkov&lt;/strong>;、&lt;strong>;Daniel Sank&lt;/strong>;、&lt;strong>;Yu Chen&lt;/strong>; &lt;br />; &lt;em>;会议 N51：量子纠错码性能和实现 I&lt;/em>; &lt;br />; &lt;a href=&quot;https://www.nature.com/articles/s41567-023-02226-w&quot;>;论文链接&lt;/a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https ://meetings.aps.org/Meeting/MAR24/Session/N51.11&quot;>;使用非均匀误差分布对表面代码的性能进行建模：第 1 部分&lt;/a>; &lt;br />; 演示者：&lt;strong>;Yuri D Lensky&lt;/strong>; &lt;br />; 作者：&lt;strong>;Yuri D Lensky&lt;/strong>;、&lt;strong>;Volodymyr Sivak&lt;/strong>;、&lt;strong>;Kostyantyn Kechedzhi&lt;/strong>;、&lt;strong>;Igor Aleiner&lt;/strong>; strong>; &lt;br />; &lt;em>;会议 N51：量子纠错码性能和实现 I&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/ Session/N51.12&quot;>;使用非均匀误差分布对表面代码的性能进行建模：第 2 部分&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Volodymyr Sivak&lt;/strong>; &lt;br />; 作者：&lt;strong >;弗拉基米尔·西瓦克&lt;/strong>;、&lt;strong>;迈克尔·纽曼&lt;/strong>;、&lt;strong>;科迪·琼斯&lt;/strong>;、&lt;strong>;亨利·舒尔克斯&lt;/strong>;、&lt;strong>;德维尔·卡弗里&lt;/strong>;、&lt;strong>; >;Yuri D Lensky&lt;/strong>;、&lt;strong>;Paul Klimov&lt;/strong>;、&lt;strong>;Kostyantyn Kechedzhi&lt;/strong>;、&lt;strong>;Vadim Smelyanskiy&lt;/strong>; &lt;br />; &lt;em>;会议 N51：量子误差修正代码性能和实现 I&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/Q51.7&quot;>;高度优化的张量网络收缩经典挑战性量子计算的模拟&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Benjamin Villalonga&lt;/strong>; &lt;br />; 作者：&lt;strong>;Benjamin Villalonga&lt;/strong>; &lt;br />; &lt;em>;会议 Q51：量子经典算法的共同进化&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/Q61.7&quot;>;使用现代量子计算概念进行教学各级实践开源软件&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Abraham Asfaw&lt;/strong>; &lt;br />; 作者：&lt;strong>;Abraham Asfaw&lt;/strong>; &lt;br />; &lt;em >;课程 Q61：各级量子信息教学 II&lt;/em>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;星期四&lt; /h3>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/S51.1&quot;>;新电路和开放颜色代码的源解码器&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Craig Gidney&lt;/strong>; &lt;br />; 作者：&lt;strong>;Craig Gidney&lt;/strong>;、&lt;strong>;Cody Jones&lt;/strong>; &lt;br />; &lt;em>;会议 S51：量子纠错码性能和实现 II&lt;/em>; &lt;br />; &lt;a href=&quot;https://arxiv.org/pdf/2312.08813.pdf&quot;>;论文链接&lt; /a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/S18.2&quot;>;使用大型语言模型执行 Hartree-Fock 多体物理计算&lt; /a>; &lt;br />; 演讲者：&lt;strong>;Eun-Ah Kim&lt;/strong>; &lt;br />; 作者：&lt;strong>;Eun-Ah Kim&lt;/strong>;、Haining Pan、&lt;strong>;Nayantara Mudur&lt;/strong>; , William Taranto,&lt;strong>; Subhashini Venugopalan&lt;/strong>;, &lt;strong>;Yasaman Bahri&lt;/strong>;, &lt;strong>;Michael P Brenner&lt;/strong>; &lt;br />; &lt;em>;会议 S18：数据科学、人工智能和机器物理学习 I&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/S51.5&quot;>;减少地表资源开销的新方法代码&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Michael Newman&lt;/strong>; &lt;br />; 作者：&lt;strong>;Craig M Gidney&lt;/strong>;、&lt;strong>;Michael Newman&lt;/strong>;、&lt;strong>; Peter Brooks&lt;/strong>;、&lt;strong>;Cody Jones&lt;/strong>; &lt;br />; &lt;em>;会议 S51：量子纠错码性能和实现 II&lt;/em>; &lt;br />; &lt;a href=&quot;https:/ /arxiv.org/pdf/2312.04522.pdf&quot;>;论文链接&lt;/a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/S49.10 &quot;>;将量子计算机应用于药物设计的挑战和机遇&lt;/a>; &lt;br />; 演讲者：Raffaele Santagati &lt;br />; 作者：Raffaele Santagati、Alan Aspuru-Guzik、&lt;strong>;Ryan Babbush&lt;/strong>;、Matthias Degroote 、莱蒂西亚·冈萨雷斯、艾丽卡·基瑟娃、尼古拉·莫尔、马库斯·奥佩尔、罗伯特·M·帕里什、&lt;strong>;尼古拉斯·C·鲁宾&lt;/strong>;、迈克尔·斯特雷夫、克里斯托弗·S·陶特曼、霍斯特·韦斯、内森·维贝、克莱门斯·乌奇-乌奇&lt;br />; &lt;em>;会议 S49：近期应用的量子算法进展&lt;/em>; &lt;br />; &lt;a href=&quot;https://arxiv.org/pdf/2301.04114.pdf&quot;>;论文链接&lt;/em>; a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/T45.1&quot;>;谷歌在新应用中寻找超二次量子优势的报道&lt;/ a>; &lt;br />; 演讲者：&lt;strong>;Ryan Babbush&lt;/strong>; &lt;br />; 作者：&lt;strong>;Ryan Babbush&lt;/strong>; &lt;br />; &lt;em>;会议 T45：量子算法的最新进展&lt;/em >; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/T48.11&quot;>;Qubit 作为反射计&lt;/a>; &lt;br />; 演讲者：&lt;strong >;张亚星&lt;/strong>; &lt;br />; 作者：&lt;strong>;张亚星&lt;/strong>;、&lt;strong>;Benjamin Chiaro&lt;/strong>; &lt;br />; &lt;em>;会议T48：超导制造、封装和技术验证&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/W14.3&quot;>;非局域测量引起的相变的随机矩阵理论Floquet 量子电路&lt;/a>; &lt;br />; 演讲者：Aleksei Khindanov &lt;br />; 作者：Aleksei Khindanov、&lt;strong>;Lara Faoro&lt;/strong>;、&lt;strong>;Lev Ioffe&lt;/strong>;、&lt;strong>;Igor Aleiner&lt; /strong>; &lt;br />; &lt;em>;第 W14 场会议：测量引起的相变&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/ W58.5&quot;>;MERA 有限密度多体基态的连续极限&lt;/a>; &lt;br />; 演讲者：Subhayan Sahu &lt;br />; 作者：Subhayan Sahu，&lt;strong>;Guifré Vidal&lt;/strong>; &lt;br / >; &lt;em>;W58 会议：流体动力学及相关学科的超大规模计算科学发现 II&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/ Session/W50.8&quot;>;海森堡自旋链中无限温度下的磁化动力学&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Eliott Rosenberg&lt;/strong>; &lt;br />; 作者：&lt;strong>;Eliott Rosenberg&lt;/strong>;&lt;/ &lt;strong>;、&lt;strong>;特隆德·安德森&lt;/strong>;、Rhine Samajdar、&lt;strong>;安德烈·佩图霍夫&lt;/strong>;、杰西·霍克*、&lt;strong>;德米特里·阿巴宁&lt;/strong>;、&lt;strong>;Andreas Bengtsson&lt;/strong>;、 &lt;strong>;伊利亚·德罗兹多夫&lt;/strong>;、&lt;strong>;凯瑟琳·埃里克森&lt;/strong>;、&lt;strong>;保罗·克里莫夫&lt;/strong>;、&lt;strong>;小米&lt;/strong>;、&lt;strong>;亚历克西斯·莫万&lt;/strong>;、 &lt;strong>;马修·尼利&lt;/strong>;、&lt;strong>;查尔斯·尼尔&lt;/strong>;、&lt;strong>;拉吉夫·阿查亚&lt;/strong>;、&lt;strong>;理查德·艾伦&lt;/strong>;、&lt;strong>;凯尔·安德森&lt;/strong>;、 &lt;strong>;马库斯·安斯曼&lt;/strong>;、&lt;strong>;弗兰克·阿鲁特&lt;/strong>;、&lt;strong>;库纳尔·艾莉亚&lt;/strong>;、&lt;strong>;亚伯拉罕·阿斯福&lt;/strong>;、&lt;strong>;胡安·阿塔拉亚&lt;/strong>;、 &lt;strong>;约瑟夫·巴尔丁&lt;/strong>;，&lt;strong>;A.比尔梅斯&lt;/strong>;、&lt;strong>;吉娜·博尔托利&lt;/strong>;、&lt;strong>;亚历山大·布拉萨&lt;/strong>;、&lt;strong>;珍娜·博瓦尔德&lt;/strong>;、&lt;strong>;莱昂·布里尔&lt;/strong>;、&lt;strong>;迈克尔布劳顿&lt;/strong>;、&lt;strong>;鲍勃·B·巴克利&lt;/strong>;、&lt;strong>;大卫·布尔&lt;/strong>;、&lt;strong>;蒂姆·伯格&lt;/strong>;、&lt;strong>;布莱恩·伯克特&lt;/strong>;、&lt;strong>; >;尼古拉斯·布什内尔&lt;/strong>;、&lt;strong>;胡安·坎佩罗&lt;/strong>;、&lt;strong>;张洪深&lt;/strong>;、&lt;strong>;陈子君&lt;/strong>;、&lt;strong>;本杰明·基亚罗&lt;/strong>;、 &lt;strong>;德斯蒙德·奇克&lt;/strong>;、&lt;strong>;乔什·科根&lt;/strong>;、&lt;strong>;罗伯托·柯林斯&lt;/strong>;、&lt;strong>;保罗·康纳&lt;/strong>;、&lt;strong>;威廉·考特尼&lt;/strong>;、 &lt;strong>;亚历山大·克鲁克&lt;/strong>;、&lt;strong>;本·科廷&lt;/strong>;、&lt;strong>;德里普托·德布罗伊&lt;/strong>;、&lt;strong>;亚历山大·德尔·托罗·巴尔巴&lt;/strong>;、&lt;strong>;肖恩·德穆拉&lt;/strong>; >;、&lt;strong>;奥古斯丁·迪保罗&lt;/strong>;、&lt;strong>;安德鲁·邓斯沃斯&lt;/strong>;、&lt;strong>;克林特·厄尔&lt;/strong>;、&lt;strong>;E. Farhi&lt;/strong>;、&lt;strong>;雷扎·法特米&lt;/strong>;、&lt;strong>;维尼修斯·费雷拉&lt;/strong>;、&lt;strong>;莱斯利·弗洛雷斯&lt;/strong>;、&lt;strong>;易卜拉欣·福拉蒂&lt;/strong>;、&lt;strong>;奥斯汀福勒、&lt;strong>;布鲁克斯·福克斯&lt;/strong>;、&lt;strong>;贡萨洛·加西亚&lt;/strong>;、&lt;strong>;艾莉·杰诺瓦&lt;/strong>;、&lt;strong>;威廉·江&lt;/strong>;、&lt;strong>;克雷格吉德尼&lt;/strong>;、&lt;strong>;达尔·吉尔博亚&lt;/strong>;、&lt;strong>;玛丽莎·朱斯蒂娜&lt;/strong>;、&lt;strong>;拉贾·戈苏拉&lt;/strong>;、&lt;strong>;亚历杭德罗·格拉哈莱斯·道&lt;/strong>;、&lt;strong>;乔纳森·格罗斯、&lt;strong>;史蒂夫·哈贝格&lt;/strong>;、&lt;strong>;迈克尔·汉密尔顿&lt;/strong>;、&lt;strong>;莫妮卡·汉森&lt;/strong>;、&lt;strong>;马修·哈里根&lt;/strong>;、&lt;strong>;肖恩·哈灵顿、&lt;strong>;宝拉·休&lt;/strong>;、&lt;strong>;戈登·希尔&lt;/strong>;、&lt;strong>;马库斯·霍夫曼&lt;/strong>;、&lt;strong>;萨布丽娜·洪&lt;/strong>;、&lt;strong>;特伦特·黄&lt;/strong>;、&lt;strong>;阿什利·哈夫&lt;/strong>;、&lt;strong>;威廉·哈金斯&lt;/strong>;、&lt;strong>;列夫·约夫&lt;/strong>;、&lt;strong>;谢尔盖·伊萨科夫&lt;/strong>;、&lt;strong>;贾斯汀·艾维兰&lt;/strong>;、&lt;strong>;埃文·杰弗里&lt;/strong>;、&lt;strong>;张江&lt;/strong>;、&lt;strong>;科迪·琼斯&lt;/strong>;、&lt;strong>;帕沃尔·尤哈斯&lt;/strong>;、&lt;strong>; D . Kafri&lt;/strong>;、&lt;strong>;Tanuj Khattar&lt;/strong>;、&lt;strong>;Mostafa Khezri&lt;/strong>;、&lt;strong>;Mária Kieferová&lt;/strong>;、&lt;strong>;Seon Kim&lt;/strong>;、&lt;strong>;Alexei基塔耶夫、&lt;strong>;安德烈·克洛茨&lt;/strong>;、&lt;strong>;亚历山大·科罗特科夫&lt;/strong>;、&lt;strong>;费多尔·科斯特里察&lt;/strong>;、&lt;strong>;约翰·马克·克莱克鲍姆&lt;/strong>;、&lt;strong>;大卫·兰德休斯 (David Landhuis)、&lt;strong>;帕维尔·拉普捷夫 (Pavel Laptev)&lt;/strong>;、&lt;strong>;刘金铭&lt;/strong>;、&lt;strong>;莉莉·劳斯 (Lily Laws)&lt;/strong>;、&lt;strong>;李俊浩&lt;/strong>;、&lt;strong>; >;肯尼思·李&lt;/strong>;、&lt;strong>;尤里·连斯基&lt;/strong>;、&lt;strong>;布莱恩·莱斯特&lt;/strong>;、&lt;strong>;亚历山大·利尔&lt;/strong>;、&lt;strong>;韦恩·刘&lt;/strong>;、&lt;strong>; >;威廉·P·利文斯顿&lt;/strong>;，&lt;strong>;A.洛查拉&lt;/strong>;、&lt;strong>;萨尔瓦托雷·曼德拉&lt;/strong>;、&lt;strong>;猎户座马丁&lt;/strong>;、&lt;strong>;史蒂文·马丁&lt;/strong>;、&lt;strong>;贾罗德·麦克林&lt;/strong>;、&lt;strong>;马修麦克尤恩、&lt;strong>;塞内卡·米克斯&lt;/strong>;、&lt;strong>;苗凯文&lt;/strong>;、&lt;strong>;阿曼达·米斯萨拉&lt;/strong>;、&lt;strong>;希林·蒙塔泽里&lt;/strong>;、&lt;strong>;拉米斯Movassagh&lt;/strong>;、&lt;strong>;Wojciech Mruczkiewicz&lt;/strong>;、&lt;strong>;Ani Nersisyan&lt;/strong>;、&lt;strong>;迈克尔·纽曼&lt;/strong>;、&lt;strong>;Jiun How Ng&lt;/strong>;、&lt;strong>;安东尼·阮&lt;/strong>;、&lt;strong>;默里·阮&lt;/strong>;、&lt;strong>;M. Niu&lt;/strong>;、&lt;strong>;托马斯·奥布莱恩&lt;/strong>;、&lt;strong>;Seun Omonije&lt;/strong>;、&lt;strong>;亚历克斯·奥普莱姆卡&lt;/strong>;、&lt;strong>;丽贝卡·波特&lt;/strong>;、&lt;strong>; >;列昂尼德·普里亚德科&lt;/strong>;、&lt;strong>;克里斯·昆塔纳&lt;/strong>;、&lt;strong>;大卫·罗兹&lt;/strong>;、&lt;strong>;查尔斯·罗克&lt;/strong>;、&lt;strong>;N.鲁宾&lt;/strong>;、&lt;strong>;Negar Saei&lt;/strong>;、&lt;strong>;丹尼尔·桑克&lt;/strong>;、&lt;strong>;卡南·桑卡拉戈马蒂&lt;/strong>;、&lt;strong>;凯文·萨辛格&lt;/strong>;、&lt;strong>;亨利舒尔克斯&lt;/strong>;、&lt;strong>;克里斯托弗·舒斯特&lt;/strong>;、&lt;strong>;迈克尔·谢恩&lt;/strong>;、&lt;strong>;亚伦·肖特&lt;/strong>;、&lt;strong>;诺亚·舒蒂&lt;/strong>;、&lt;strong>;弗拉基米尔施瓦茨&lt;/strong>;、&lt;strong>;弗拉基米尔·西瓦克&lt;/strong>;、&lt;strong>;金德拉·斯克鲁兹尼&lt;/strong>;、&lt;strong>;克拉克·史密斯&lt;/strong>;、&lt;strong>;罗兰多·索玛&lt;/strong>;、&lt;strong>;乔治斯特林、&lt;strong>;道格·斯特兰&lt;/strong>;、&lt;strong>;马可·萨莱&lt;/strong>;、&lt;strong>;道格拉斯·托尔&lt;/strong>;、&lt;strong>;阿尔弗雷多·托雷斯&lt;/strong>;、&lt;strong>;吉弗雷维达尔，&lt;strong>;本杰明·维拉隆加&lt;/strong>;，&lt;strong>;凯瑟琳·沃尔格拉夫·海德韦勒&lt;/strong>;，&lt;strong>;西奥多·怀特&lt;/strong>;，&lt;strong>;布莱恩·吴&lt;/strong>;，&lt;strong>;程星&lt;/strong>;、&lt;strong>;杰米·姚&lt;/strong>;、&lt;strong>;叶平&lt;/strong>;、&lt;strong>;刘周焕&lt;/strong>;、&lt;strong>;格雷森·杨&lt;/strong>;、&lt;strong>; Adam Zalcman&lt;/strong>;、&lt;strong>;张亚星&lt;/strong>;、&lt;strong>;朱宁峰&lt;/strong>;、&lt;strong>;尼古拉斯·佐布里斯特&lt;/strong>;、&lt;strong>;Hartmut Neven&lt;/strong>;、&lt;strong>;瑞安·巴布什&lt;/strong>;、&lt;strong>;戴夫·培根&lt;/strong>;、&lt;strong>;塞尔吉奥·博伊索&lt;/strong>;、&lt;strong>;杰里米·希尔顿&lt;/strong>;、&lt;strong>;埃里克·卢塞罗&lt;/strong>;、&lt;strong>;安东尼·梅格兰特、&lt;strong>;朱利安·凯利&lt;/strong>;、&lt;strong>;陈宇&lt;/strong>;、&lt;strong>;Vadim Smelyanskiy&lt;/strong>;、Vedika Khemani、Sarang Gopalakrishnan、&lt;strong>;托马兹·普罗森&lt;/strong>; strong>;, &lt;strong>;Pedram Roushan&lt;/strong>; &lt;br />; &lt;em>;W50 会议：多体物理的量子模拟&lt;/em>; &lt;br />; &lt;a href=&quot;https://arxiv.org/ pdf/2306.09333.pdf&quot;>;论文链接&lt;/a>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/W50.13&quot;>;快速多极量子计算机上的方法&lt;/a>; &lt;br />; 演讲者：Kianna Wan &lt;br />; 作者：Kianna Wan、Dominic W Berry、&lt;strong>;Ryan Babbush&lt;/strong>; &lt;br />; &lt;em>;W50 会议：量子多体物理模拟&lt;/em>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;星期五&lt;/h3>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/Y43.1&quot;>;量子计算产业和保护国家安全：什么工具会起作用吗？&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Kate Weber&lt;/strong>; &lt;br />; 作者：&lt;strong>;Kate Weber&lt;/strong>; &lt;br />; &lt;em>;第 Y43 场会议：行业、创新与国家安全：找到适当的平衡&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/Y46.3&quot;>;新颖的收费效果Fluxium 量子比特&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Agustin Di Paolo&lt;/strong>; &lt;br />; 作者：&lt;strong>;Agustin Di Paolo&lt;/strong>;、Kyle Serniak、Andrew J Kerman、&lt;strong>; >;William D Oliver&lt;/strong>; &lt;br />; &lt;em>;Y46 会议：基于 Fluxium 的超导 Quibits&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting /MAR24/Session/Z46.3&quot;>;超导电路参数相互作用的微波工程&lt;/a>; &lt;br />; 演讲者：&lt;strong>;Ofer Naaman&lt;/strong>; &lt;br />; 作者：&lt;strong>;Ofer Naaman&lt;/a>; &lt;br />; strong>; &lt;br />; &lt;em>;会议 Z46：宽带参量放大器和循环器&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://meetings.aps.org/Meeting/MAR24/Session/Z62 .3&quot;>;使用核多项式方法的大磁性晶胞的线性自旋波理论&lt;/a>; &lt;br />;演讲者：Harry Lane&lt;br />;作者：Harry Lane，Hao Zhang，David A Dahlbom，Sam Quinn，&lt; strong>;Rolando D Somma&lt;/strong>;、Martin P Mourigal、Cristian D Batista、Kipton Barros &lt;br />; &lt;em>;会议 Z62：合作现象、理论&lt;/em>; &lt;/p>; &lt;/div>; &lt;!--脚注-->; &lt;hr width=&quot;80%&quot; />; &lt;p>; &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-size: x-small;&quot;>;&lt;sup>;&lt;b>;*&lt;/ b>;&lt;/sup>;在 Google 期间完成的工作&lt;/span>;&lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/2754526782497247497/comments/default&quot; rel=&quot;replies &quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/03/google-at-aps-2024.html#comment-form &quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/2754526782497247497&quot; rel=&quot;edit “ type =“application/atom+xml”/>;&lt;link href =“http://www.blogger.com/feeds/8474926331452026626/posts/default/2754526782497247497”rel =“self”type =“application/atom+xml” &quot;/>;&lt;link href=&quot;http://blog.research.google/2024/03/google-at-aps-2024.html&quot; rel=&quot;alternate&quot; title=&quot;Google at APS 2024&quot; type=&quot;text/ html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd ：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=“ 16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjy22Hfq3RN4qRUJcSMUpIau4ueOIcQ219mDvfu4FNJ9kf5PBMUI0x4Uf9BhoIHtnFUhtvE72GCVYixld OZRSeePJfef0P87Pc_djQeGIZOhyxv9nKsQCc57357tr3npWdS5fyWxiGjex4NxMpOIB2JE1Z2qXdLnzLkFM075WstFJD77xVNS2T9hckWZyLf/s72-c/lockup_GoogleResearch_FullColor_Hero.jpg “ width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>; &lt;id>;标签：blogger.com，1999：blog-8474926331452026626.post-1695264277638670894&lt;/id>;&lt;发布>;2024-02-22T12:05:00.000-08:00&lt;/发布>;&lt;更新>;2024-02-23T10 :07:08.500-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Machine Intelligence&quot;>;&lt;/category>;&lt;category schema=&quot;http: //www.blogger.com/atom/ns#&quot; term=&quot;机器感知&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;VideoPrism：用于视频理解的基础视觉编码器&lt;/stitle>;&lt;content type=&quot; html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Google 研究院高级研究科学家 Long Zhao 和高级软件工程师 Ting Liu&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEi4kKy9Vqp7LE__mag3METzRxmp6Z5PCH8AyfXzxQ_mNeIgOwYitblprQbb1fOTSUDgNgdmgsm7QwyXgkBcUDs2iIkxGue1n1sxdaomCyAo_eZD1-NFJEbn0fct-g JSNNs_MXHQQCxA79hVbd2CHzg2Nkpw1RnsOQWLq4Y7A7mxXTAFjR9NEE42A6pMOaDi/s450/VideoPrismSample.gif&quot; style=&quot;显示：无；&quot; />; &lt;p>; 网络上有数量惊人的视频，涵盖了从人们分享的日常生活瞬间到历史时刻再到科学观察的各种内容，每个视频都包含了对世界的独特记录。正确的工具可以帮助研究人员分析这些视频，改变我们理解周围世界的方式。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 视频提供比静态图像丰富得多的动态视觉内容，捕捉实体之间的运动、变化和动态关系。分析这种复杂性以及公开视频数据的巨大多样性，需要超越传统图像理解的模型。因此，许多在视频理解方面表现最好的方法仍然依赖于为特定任务量身定制的专门模型。最近，使用视频基础模型 (ViFM) 在该领域取得了令人兴奋的进展，例如 &lt;a href=&quot;https://arxiv.org/abs/2109.14084&quot;>;VideoCLIP&lt;/a>;、&lt;a href=&quot;https ://arxiv.org/abs/2212.03191&quot;>;InternVideo&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2212.04979&quot;>;VideoCoCa&lt;/a>; 和 &lt;a href=&quot;https: //arxiv.org/abs/2303.16058&quot;>;UMT&lt;/a>;。然而，构建一个能够处理视频数据多样性的 ViFM 仍然是一个挑战。 &lt;/p>; &lt;p>; 为了构建通用视频理解的单一模型，我们引入了“&lt;a href=&quot;https://arxiv.org/abs/2402.13217&quot;>;VideoPrism：基础视觉编码器视频理解&lt;/a>;”。 VideoPrism 是一种 ViFM，旨在处理广泛的视频理解任务，包括分类、本地化、检索、字幕和问答 (QA)。我们在预训练数据和建模策略方面提出了创新。我们在海量且多样化的数据集上对 VideoPrism 进行预训练：3600 万个高质量视频文本对和 5.82 亿个带有噪声或机器生成的并行文本的视频剪辑。我们的预训练方法是针对这种混合数据而设计的，可以从视频文本对和视频本身中学习。 VideoPrism 非常容易适应新的视频理解挑战，并使用单个冻结模型实现最先进的性能。 &lt;/p>;&lt;p>;&lt;/p>; &lt;video autoplay=&quot;&quot;loop=&quot;&quot;muted=&quot;&quot;playsinline=&quot;&quot;width=&quot;100%&quot;>; &lt;source src=&quot;https://github.com/garyzhao /videoprism-blog/raw/main/teaser.mp4&quot; type=&quot;video/mp4&quot;>;&lt;/source>; &lt;/video>; &lt;tablealign=&quot;center&quot;cellpadding=&quot;0&quot;cellspacing=&quot;0&quot;class=&quot;tr -caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;VideoPrism 是一种通用视频编码器，通过从单个冻结模型生成视频表示，可以在广泛的视频理解任务（包括分类、本地化、检索、字幕和问答）中获得最先进的结果。&lt;/ td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;预训练数据&lt;/h2>; &lt;p>;强大的 ViFM 需要大量视频来进行训练 - 与其他视频类似基础模型 (FM)，例如大型语言模型 (LLM)。理想情况下，我们希望预训练数据能够成为世界上所有视频的代表性样本。虽然大多数视频自然没有完美的字幕或描述，但即使不完美的文本也可以提供有关视频语义内容的有用信息。 &lt;/p>; &lt;p>; 为了给我们的模型提供最好的起点，我们整理了一个由多个公共和私人数据集组成的庞大预训练语料库，包括 &lt;a href=&quot;https://rowanzellers.com/merlot/ &quot;>;YT-Temporal-180M&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2307.06942&quot;>;InternVid&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs /2204.00679&quot;>;VideoCC&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2007.14937&quot;>;WTS-70M&lt;/a>;等。其中包括3600万个精心挑选的带有高质量字幕的视频，以及额外的 5.82 亿个剪辑，其中包含不同程度的嘈杂文本（例如自动生成的文字记录）。据我们所知，这是同类中最大、最多样化的视频训练语料库。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrhfnM1Rg_xbS1b3ZtydWc0M7zOchLpi5qdj65UaR3mOYbV8SQQqKhUhltYwmkPNqrULdeVeE1nU3gnRkjR7 PE-yFaiVRC1al-BxZecsO0aojXFzSDhfv45oZoOBeYA93IiNeCGdnUryh4HLc3w7Qr2PX0fy6-4qFMTKBORA_PfHspp7Nr1OW0WnAvn-S9/s1999/image18 .png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;779&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrhfnM1Rg_xbS1b3ZtydWc0M7zOchLpi5qdj65UaR3mOYbV8SQQqKhUhltYwmkPNqrULdeVeE1nU3gnRkjR7pE-yFaiVRC1al-BxZec sO0aojXFzSDhfv45oZoOBeYA93IiNeCGdnUryh4HLc3w7Qr2PX0fy6-4qFMTKBORA_PfHspp7Nr1OW0WnAvn-S9/s16000/image18.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt; tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;视频文本预训练数据统计。 &lt;a href=&quot;https://arxiv.org/abs/2104.14806&quot;>;CLIP 相似度分数&lt;/a>;的巨大变化（越高越好）证明了我们预训练的多样化字幕质量数据，它是用于获取文本的各种方式的副产品。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;两阶段训练&lt;/h2>; &lt;p>; VideoPrism 模型架构源自标准&lt;a href=&quot;https://arxiv.org/abs/2010.11929&quot;>;视觉转换器&lt;/a>; (ViT)，采用分解设计，可按照&lt;a href>;顺序编码空间和时间信息=&quot;https://arxiv.org/abs/2103.15691&quot;>;ViViT&lt;/a>;。我们的训练方法利用了高质量的视频文本数据和上述带有噪声文本的视频数据。首先，我们使用&lt;a href=&quot;https://en.wikipedia.org/wiki/Self-supervised_learning#Contrastive_self-supervised_learning&quot;>;对比学习&lt;/a>;（一种最小化正视频文本对之间的距离的方法）同时最大化负视频-文本对之间的距离）来教我们的模型将视频与其自己的文本描述（包括不完美的文本描述）进行匹配。这为将语义语言内容与视觉内容匹配奠定了基础。 &lt;/p>; &lt;p>; 经过视频-文本对比训练后，我们利用没有文本描述的视频集合。在这里，我们基于&lt;a href=&quot;https://arxiv.org/abs/2212.04500&quot;>;屏蔽视频建模框架&lt;/a>;来预测视频中的屏蔽补丁，并进行了一些改进。我们训练模型来预测第一阶段模型的视频级全局嵌入和令牌明智嵌入，以有效利用该阶段获得的知识。然后，我们随机打乱预测的标记，以防止模型学习捷径。 &lt;/p>; &lt;p>; VideoPrism 设置的独特之处在于我们使用两个互补的预训练信号：文本描述和视频中的视觉内容。文本描述通常关注事物的外观，而视频内容则提供有关运动和视觉动态的信息。这使得 VideoPrism 能够在需要了解外观和运动的任务中表现出色。 &lt;/p>; &lt;br />; &lt;h2>;结果&lt;/h2>; &lt;p>; 我们对 VideoPrism 进行了广泛的评估，涵盖四大类视频理解任务，包括视频分类和本地化、视频文本检索、视频字幕、问答，以及科学的视频理解。 VideoPrism 在 33 个视频理解基准测试中的 30 个上实现了最先进的性能 - 所有这些都对单个冻结模型进行了最小程度的调整。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgiUtXCxgEXrgAZJ2B-Mn8L0DP7VkFUfUbI1yLTgGYSbWtn_Q5AjgGRgi3yQ5PMB3fVFlHLzDP4yhlCeGaPpdXr5I1 -TNYelYMUBYiXx16qNYTpqKwAqXX7-EFV-4Asn6qYFWOb6_5p71n5Zzxbt-ZeUy5yIj2aieKXl0LnFOqdhKXa56xm4ZoXbccYDz3H/s1999 /image20.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1999&quot; data-original-width=&quot; 1959&quot; 高度 = &quot;640&quot; src = &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgiUtXCxgEXrgAZJ2B-Mn8L0DP7VkFUfUbI1yLTgGYSbWtn_Q5AjgGRgi3yQ5PMB3fVFlHLzDP4yhlCeGaPpdXr5I1-TNY elYMUBYiXx16qNYTpqKwAqXX7-EFV-4Asn6qYFWOb6_5p71n5Zzxbt-ZeUy5yIj2aieKXl0LnFOqdhKXa56xm4ZoXbccYDz3H/w628-h640/image20.png&quot; 宽度 = &quot;628 &quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;VideoPrism 与之前性能最佳的 FM 相比。&lt;/ td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>;&lt;br />; &lt;/div>; &lt;h3>;分类和本地化&lt;/h3>; &lt;p>; 我们在涵盖分类和本地化任务的现有大规模视频理解基准 (&lt;a href=&quot;https://arxiv.org/abs/2307.03166&quot;>;VideoGLUE&lt;/a>;) 上评估 VideoPrism。我们发现 (1) VideoPrism 优于所有其他最先进的 FM，并且 (2) 没有其他单一模型始终位居第二。这告诉我们，VideoPrism 已经学会了如何有效地将各种视频信号打包到一个编码器中（从不同粒度的语义到外观和运动提示），并且它可以在各种视频源上正常工作。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhNnyg_lnLfwDIsJElqFwLKJleb1quzOR4h7X5jBf_bAnxwo_Em-_XLtWkkyMkyMPcLGdm0F25tLmccw3eK9qt6NN4Lr LvfF45Wu8J2ylCqi4hPE-rFOwzmGuV8II6Nq8hileMNrS1lMwCuOHTVNGS04Dsxc7yVztaMCu0sRvuMUHnN4u9IKEvv2g8fRYWo/s1816/image12.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1816&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhNnyg_lnLfwDIsJElqFwLKJleb1quzOR4h7X5jBf_bAnxwo_Em-_XLtWkkyMkyMPcLGdm0F25tLmccw3eK9qt6NN4LrLvfF45Wu8J2ylCqi4hPE-rFOwzm GuV8II6Nq8hileMNrS1lMwCuOHTVNGS04Dsxc7yVztaMCu0sRvuMUHnN4u9IKEvv2g8fRYWo/s16000/image12.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;VideoPrism 优于最先进的方法（包括 &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;CLIP&lt;/a>;、&lt;a href=&quot; https://arxiv.org/abs/2104.11178&quot;>;VATT&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2212.03191&quot;>;InternVideo&lt;/a>; 和 &lt;a href=&quot;https ://arxiv.org/abs/2303.16058&quot;>;UMT&lt;/a>;）在&lt;a href=&quot;https://arxiv.org/abs/2307.03166&quot;>;视频理解基准&lt;/a>;上。在此图中，我们显示了与之前最佳模型相比的绝对分数差异，以突出 VideoPrism 的相对改进。关于&lt;a href=&quot;http://vuchallenge.org/charades.html&quot;>;猜谜游戏&lt;/a>;、&lt;a href=&quot;http://activity-net.org/&quot;>;ActivityNet&lt;/a>;、&lt;a href=&quot;https://research.google.com/ava/&quot;>;AVA&lt;/a>; 和 &lt;a href=&quot;https://research.google.com/ava/&quot;>;AVA-K&lt;/a>; ，我们使用平均精度（mAP）作为评估指标。在其他数据集上，我们报告 top-1 准确率。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;与法学硕士结合&lt;/h3>; &lt;p>;我们进一步探索将 VideoPrism 与法学硕士结合起来，以释放其处理各种视频语言任务的能力。特别是，当与文本编码器（遵循 &lt;a href=&quot;https://arxiv.org/abs/2111.07991&quot;>;LiT&lt;/a>;）或语言解码器（例如 &lt;a href=&quot;https:/ /arxiv.org/abs/2305.10403&quot;>;PaLM-2&lt;/a>;），VideoPrism 可用于视频文本检索、视频字幕和视频 QA 任务。我们在一组广泛且具有挑战性的视觉语言基准上对组合模型进行了比较。 VideoPrism 在大多数基准测试中树立了新的技术水平。从视觉结果中，我们发现VideoPrism能够理解视频中的复杂运动和外观（例如，在下面的视觉示例中，模型可以识别窗口上旋转物体的不同颜色）。这些结果表明VideoPrism与语言模型具有很强的兼容性。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjd7V86xYM18_i3s0aemjiiYxaJeBiooZrEicQ5VVkLK3QnWTR96hKVsobSO4qRiN0f253JPX4y-T_h17E2Rx8 0PIVtVed0q499uCv42RzxZ7crkr21nuCR0zwalkSUX9FxIbjWVmlQGb1yx9Y5J8aVT_ROkY4DB1skUkk-bc9FaCc6tc-XLumHk5P65_UR/s1028/VideoPrismResults.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;932&quot; data-original-width=&quot;1028&quot; height=&quot;580&quot; src= “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjd7V86xYM18_i3s0aemjiiYxaJeBiooZrEicQ5VVkLK3QnWTR96hKVsobSO4qRiN0f253JPX4y-T_h17E2Rx80PIVtVed0q499uCv42Rz xZ7crkr21nuCR0zwalkSUX9FxIbjWVmlQGb1yx9Y5J8aVT_ROkY4DB1skUkk-bc9FaCc6tc-XLumHk5P65_UR/w640-h580/VideoPrismResults.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;VideoPrism 与最先进的方法（包括 &lt;a href=&quot;https:// arxiv.org/abs/2212.04979&quot;>;VideoCoCa&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2303.16058&quot;>;UMT&lt;/a>; 和 &lt;a href=&quot;https://arxiv. org/abs/2204.14198&quot;>;Flamingo&lt;/a>;）在多个视频文本检索（顶部）以及视频字幕和视频质量检查（底部）基准上。我们还显示了与之前最佳模型相比的绝对分数差异，以突出 VideoPrism 的相对改进。我们在 &lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/msr-vtt-a-large-video-description-dataset-for-bridging-video- 上报告了 Recall@1 and-language/&quot;>;MASRVTT&lt;/a>;、&lt;a href=&quot;https://eric-xw.github.io/vatex-website/index.html&quot;>;VATEX&lt;/a>; 和 &lt;a href=&quot; https://cs.stanford.edu/people/ranjaykrishna/densevid/&quot;>;ActivityNet&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/1411.5726&quot;>;CIDEr 得分&lt;/a>; &lt; a href=&quot;https://www.microsoft.com/en-us/research/publication/msr-vtt-a-large-video-description-dataset-for-bridging-video-and-language/&quot;>;MSRVTT- Cap&lt;/a>;、&lt;a href=&quot;https://eric-xw.github.io/vatex-website/index.html&quot;>;VATEX-Cap&lt;/a>; 和 &lt;a href=&quot;http:// youcook2.eecs.umich.edu/&quot;>;YouCook2&lt;/a>;，&lt;a href=&quot;https://github.com/xudejing/video-question-answering&quot;>;MSRVTT-QA&lt;/a>; 准确率排名第一和&lt;a href=&quot;https://github.com/xudejing/video-question-answering&quot;>;MSVD-QA&lt;/a>;，以及&lt;a href=&quot;https://arxiv.org/abs/cmp-lg /9406033&quot;>;&lt;a href=&quot;https://doc-doc.github.io/docs/nextqa.html&quot;>;NExT-QA&lt;/a>; 上的 WUPS 索引&lt;/a>;。&lt;/td>;&lt;/tr >;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;video autoplay=&quot;&quot;loop=&quot;&quot;muted=&quot;&quot;playsinline=&quot;&quot;width=&quot;100%&quot;>;&lt;source src=&quot;https://github.com /garyzhao/videoprism-blog/raw/main/snowball_water_bottle_drum.mp4&quot; type=&quot;video/mp4&quot;>;&lt;/source>; &lt;/video>; &lt;video autoplay=&quot;&quot;loop=&quot;&quot;muted=&quot;&quot;playsinline=&quot;&quot;宽度=&quot;100%&quot;>; &lt;源src=&quot;https://github.com/garyzhao/videoprism-blog/raw/main/spin_roller_skating.mp4&quot; type=&quot;video/mp4&quot;>;&lt;/源>; &lt;/视频>; &lt;视频自动播放=“”循环=“”静音=“”playsinline=“”宽度=“100％”>; &lt;source src =“https://github.com/garyzhao/videoprism-blog/raw/main/making_ice_cream_ski_lifting.mp4 &quot; type=&quot;video/mp4&quot;>;&lt;/source>; &lt;/video>; &lt;tablealign=&quot;center&quot;cellpadding=&quot;0&quot;cellspacing=&quot;0&quot;class=&quot;tr-caption-container&quot;style=&quot;margin-left:汽车; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;我们使用 VideoPrism 和用于视频文本检索的文本编码器显示定性结果 (第一行）并适用于视频 QA 的语言解码器（第二行和第三行）。对于视频文本检索示例，蓝色条表示视频和文本查询之间的嵌入相似性。&lt;/td>;&lt;/tr>;&lt; /tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;科学应用&lt;/h3>; &lt;p>; 最后，我们在使用的数据集上测试 VideoPrism跨领域的科学家，包括行为学、行为神经科学和生态学等领域。这些数据集通常需要领域专业知识来注释，为此我们利用社区开源的现有科学数据集，包括 &lt;a href=&quot;https://data. caltech.edu/records/zrznw-w7386&quot;>;飞行与飞行&lt;/a>;，&lt;a href=&quot;https://data.caltech.edu/records/s0vdx-0k302&quot;>;CalMS21&lt;/a>;，&lt;a href=&quot;https://shirleymaxx.github.io/ChimpACT/&quot;>;ChimpACT&lt;/a>; 和 &lt;a href=&quot;https://dirtmaxim.github.io/kabr/&quot;>;KABR&lt;/a>;。 VideoPrism 不仅表现出色，而且实际上超越了专门为这些任务设计的模型。这表明像 VideoPrism 这样的工具有可能改变科学家分析不同领域视频数据的方式。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3v-C36GWUp8CkaCVqFvaXYKW6-1SvCo99Ogiul-fSTkftyc-t4z5CNUgEWlJkRmzranQrYHldtBvjeJXsqdB4ZbgBkya Zv-_I9QE5U7kus_Z8QWlVqfzX0JfELSDPfGj9V4QqhUMwX_EkyPM-vG7pdYMXN0kj1 -s98IZJl3U8CpvqoOHyAsuwXIVt7M4_/s1200/image5.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200 “高度=“397”src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3v-C36GWUp8CkaCVqFvaXYKW6-1SvCo99Ogiul-fSTkftyc-t4z5CNUgEWlJkRmzranQrYHldtBvjeJXsqdB4ZbgBkyaZv-_I9QE 5U7kus_Z8QWlVqfzX0JfELSDPfGj9V4QqhUMwX_EkyPM-vG7pdYMXN0kj1-s98IZJl3U8CpvqoOHyAsuwXIVt7M4_/w640-h397/image5.png&quot;宽度=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;VideoPrism 在各种科学基准上均优于领域专家。我们显示绝对分数差异以突出 VideoPrism 的相对改进。我们报告了所有数据集的平均精度 (mAP)，但 KABR 除外，它使用类平均 top-1 精度。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;结论&lt; /h2>; &lt;p>; 通过 VideoPrism，我们推出了一款功能强大且多功能的视频编码器，为通用视频理解树立了新标准。我们对构建庞大且多样化的预训练数据集和创新建模技术的重视已经通过我们的广泛评估得到了验证。 VideoPrism 不仅始终优于强大的基线，而且其独特的泛化能力使其能够很好地处理一系列现实世界的应用程序。由于其潜在的广泛用途，我们致力于在我们的&lt;a href=&quot;http://ai.google/principles&quot;>;人工智能原则&lt;/a>;的指导下，继续在这一领域进行进一步负责任的研究。我们希望 VideoPrism 为人工智能和视频分析交叉领域的未来突破铺平道路，帮助实现 ViFM 在科学发现、教育和医疗保健等领域的潜力。 &lt;/p>; &lt;br />; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;本博文代表所有 VideoPrism 作者撰写：Long Zhao、Nitesh B. Gundavarapu、Liangzhe Yuan、Hao Zhou、Shen严、詹妮弗·J·孙、卢克·弗里德曼、钱睿、托拜厄斯·韦安德、赵越、雷切尔·霍农、弗洛里安·施罗夫、杨明轩、大卫·A·罗斯、王惠生、哈特维格·亚当、米哈伊尔·西罗滕科、刘婷和龚博清。我们衷心感谢 David Hendon 的产品管理工作，以及 Alex Siegman、Ramya Ganeshan 和 Victor Gomes 的计划和资源管理工作。我们还要感谢 Hassan Akbari、Sherry Ben、Yoni Ben-Meshulam、Chun-Te Chu、Sam Clearwater、Yin Cui、Ilya Figotin、Anja Hauth、Sergey Ioffe、Xuhui Jia、Yeqing Li、Lu Jiang、Zu Kim、Dan Kondratyuk、Bill Mark、Arsha Nagrani、Caroline Pantofaru、Sushant Prakash、Cordelia Schmid、Bryan Seybold、Mojtaba Seyedhosseini、Amanda Sadler、Rif A. Saurous、Rachel Stigler、Paul Voigtlaender、Pingmei Xu、Chachao Yan、Xuan Yang 和 Yukun Zhu 参与讨论，支持和反馈对这项工作做出了巨大贡献。我们感谢 Jay Yagnik、Rahul Sukthankar 和 Tomas Izo 对这个项目的热情支持。最后，我们感谢 Tom Small、Jennifer J. Sun、Hao Zhou、Nitesh B. Gundavarapu、Luke Friedman 和 Mikhail Sirotenko 对撰写本文提供的巨大帮助。&lt;/em>; &lt;/p>;&lt;p>;&lt;/p >;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/1695264277638670894/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>; &lt;link href=&quot;http://blog.research.google/2024/02/videoprism-foundational-visual-encoder.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html &quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1695264277638670894&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http ://www.blogger.com/feeds/8474926331452026626/posts/default/1695264277638670894&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/ 2024/02/videoprism-foundational-visual-encoder.html&quot; rel=&quot;alternate&quot; title=&quot;VideoPrism：用于视频理解的基础视觉编码器&quot; type=&quot;text/html&quot;/>;&lt;作者>;&lt;名称>;Google AI&lt; /name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http:// /schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>; &lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4kKy9Vqp7LE__mAG3METzRxmp6Z5PCH8AyfXzxQ_mNeIgOwYitblprQbb1fOTSUDgNgdmgsm7QwyXgkBcUDs2iIkxGue1n1 sxdaomCyAo_eZD1-NFJEbn0fct-gJSNNs_MXHQQCxA79hVbd2CHzg2Nkpw1RnsOQWLq4Y7A7mxXTAFjR9NEE42A6pMOaDi/s72-c/VideoPrismSample.gif&quot; width=&quot;72&quot; xmlns:media =&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com， 1999：blog-8474926331452026626.post-4343235509909091741&lt;/id>;&lt;发布>;2024-02-21T12:15:00.000-08:00&lt;/发布>;&lt;更新>;2024-02-21T12:15:36.694-08:00 &lt; /updated>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=“差异隐私”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom” /ns#&quot; term=&quot;Gboard&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;On-device Learning&quot;>;&lt;/category>;&lt;category schema =&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Responsible AI&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;生产设备上语言模型的私人培训取得进展&lt;/stitle >;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：谷歌研究科学家郑旭和软件工程师张彦翔&lt;/span>; &lt;img src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEifnCZ_XGUoUG0hESM0dF5B8Rsoqo4YrT_-uv0hlDM1iTADhtEEyEvBM4hOWT0rxgpVtZKyuFoj2xeXmkeXwGe-XTmvBuwBDJOCqgN8Ba7Wcjh_s1seWUaCRl 1xNpNe_6MqxcFFZoAvhfCge5vq9UATjXG_BnTiGdQ6YLLo7AK7ABS3KLFMKmjAtA1gkcBk/s1600/GBoard%20PrivacyHero.gif&quot; style=&quot;显示：无；&quot; />; &lt;p>; 经过训练来预测给定输入文本的下一个单词的语言模型 (LM) 是许多应用程序的关键技术 [&lt;a href=&quot;https://blog.google/technology/ai/google-palm-2- ai-large-language-model/&quot;>;1&lt;/a>;、&lt;a href=&quot;https://blog.google/technology/ai/google-gemini-ai/&quot;>;2&lt;/a>;]。在 &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.google.android.inputmethod.latin&amp;amp;hl=en_US&amp;amp;gl=US&quot;>;Gboard&lt;/a>; 中，LM用于通过支持诸如&lt;a href=&quot;https://arxiv.org/abs/1811.03604&quot;>;下一个单词预测&lt;/a>; (NWP)、&lt;a href=&quot;https:// support.google.com/gboard/answer/7068415&quot;>;智能撰写&lt;/a>;、&lt;a href=&quot;https://support.google.com/gboard/answer/7068415&quot;>;智能完成&lt;/a>;和&lt; a href=&quot;https://support.google.com/gboard/answer/7068415&quot;>;建议&lt;/a>;、&lt;a href=&quot;https://support.google.com/gboard/answer/2811346&quot;>;幻灯片输入&lt;/a>;&lt;span style=&quot;text-decoration: underline;&quot;>;、&lt;/span>;并&lt;a href=&quot;https://support.google.com/gboard/answer/7068415&quot;>;校对&lt;/一个>;。在用户设备而不是企业服务器上部署模型具有较低延迟和更好的模型使用隐私等优点。直接根据用户数据训练设备上模型可以有效提高 NWP 和 &lt;a href=&quot;https://blog.research.google/2021/11/predicting-text-selections-with.html&quot; 等应用程序的实用性能>;智能文本选择&lt;/a>;，保护用户数据的隐私对于模型训练很重要。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto ; 右边距：自动;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWvaPvikHjeVBb9njeoP2z499_LU0a4VfEgI2kOVxYEoApqgZ49 -Ej_TpY6pyoy9HKU2jASzSBsKhdXuOhP-ykpsK_makFmWzVF67BPS3PSpRrCIxC0hYHogBVcDM74AXmjD5hh2mP22tPmXQqEkOak9QXXLyJOCsJB94dv0P-W3IINYyah2O-nF1HLTXE/s1996/图像45.gif&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height= “1600”数据原始宽度=“1996”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWvaPvikHjeVBb9njeoP2z499_LU0a4VfEgI2kOVxYEoApqgZ49-Ej_TpY6pyoy9HKU2jASzSBsKhdXuOhP- ykpsK_makFmWzVF67BPS3PSpRrCIxC0hYHogBVcDM74AXmjD5hh2mP22tPmXQqEkOak9QXXLyJOCsJB94dv0P-W3IINYyah2O-nF1HLTXE/s16000/image45.gif&quot;/>;&lt; /a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;由设备上语言模型提供支持的 Gboard 功能。&lt;/td>;&lt;/ tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 在本博客中，我们讨论了自 &lt;a href=&quot;https:// 的概念验证开发以来，多年来的研究进展如何为 Gboard LM 的私人培训提供动力。 blog.research.google/2017/04/federated-learning-collaborative.html&quot;>;2017 年联邦学习&lt;/a>;（佛罗里达州）和正式&lt;a href=&quot;https://blog.research.google/2022/02 /federated-learning-with-formal.html&quot;>;2022 年的差异化隐私&lt;/a>; (DP) 保证。&lt;a href=&quot;https://blog.research.google/2017/04/federated-learning-collaborative。 html&quot;>;FL&lt;/a>; 使手机能够协作学习模型，同时将所有训练数据保留在设备上，而 &lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_privacy&quot;>;DP&lt;/a >; 提供数据匿名化的可量化衡量标准。形式上，DP 通常用 (&lt;em>;ε&lt;/em>;, &lt;em>;δ&lt;/em>;) 来表征，值越小表示保证越强。机器学习 (ML) 模型被认为对 ε=10 具有&lt;a href=&quot;https://blog.research.google/2023/05/making-ml-models- Differentially-private.html&quot;>;合理的 DP 保证，并且当 &lt;em>;δ&lt;/em>; 很小时，强 DP 保证 ε=1&lt;/a>;。 &lt;/p>; &lt;p>; 截至今天，Gboard 中的所有 NWP 神经网络 LM 均通过 FL 进行训练，并提供正式的 DP 保证，并且未来推出的所有基于用户数据训练的 Gboard LM 都需要 DP。这 30 多个 Gboard 设备上 LM 以 7 种以上语言和 15 多个国家/地区推出，并满足小 &lt;em>;δ&lt; 的 (&lt;em>;ɛ&lt;/em>;, &lt;em>;δ&lt;/em>;)-DP 保证/em>; 为 10&lt;sup>;-10&lt;/sup>; 且 ɛ 介于 0.994 和 13.69 之间。据我们所知，这是 Google 或任何地方在生产环境中已知的最大规模的用户级 DP 部署，并且首次实现 &lt;em>;ɛ&lt;/em>; &lt;em>;ɛ&lt;/em>; &lt;em>; 的强大 DP 保证。 1 已公布，用于直接根据用户数据训练的模型。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Gboard 中的隐私原则和实践&lt;/h2>; &lt;p>; 在“&lt;a href=&quot;https”中://arxiv.org/abs/2306.14793&quot;>;Gboard 中的私有联合学习&lt;/a>;”，我们讨论了不同之处&lt;a href=&quot;https://queue.acm.org/detail.cfm?id=3501293&quot; >;隐私原则&lt;/a>;目前反映在生产模型中，包括：&lt;/p>; &lt;ul>; &lt;li>;&lt;em>;透明度和用户控制&lt;/em>;：我们披露使用哪些数据及其目的用途、在各个渠道中的处理方式以及 Gboard 用户如何轻松&lt;a href=&quot;https://support.google.com/gboard/answer/12373137&quot;>;配置&lt;/a>;学习中的数据使用情况楷模。 &lt;/li>;&lt;li>;&lt;em>;数据最小化&lt;/em>;：FL 立即聚合仅改进特定模型的重点更新。 &lt;a href=&quot;https://eprint.iacr.org/2017/281.pdf&quot;>;安全聚合&lt;/a>; (SecAgg) 是一种加密方法，可进一步保证只能访问临时更新的聚合结果。 &lt;/li>;&lt;li>;&lt;em>;数据匿名化&lt;/em>;：服务器应用DP来防止模型记住单个用户训练数据中的唯一信息。 &lt;/li>;&lt;li>;&lt;em>;可审计性和可验证性&lt;/em>;：我们在开源代码中公开了关键算法方法和隐私核算（&lt;a href=&quot;https://github.com/tensorflow/ federated/blob/main/tensorflow_federated/python/aggregators/ Differential_privacy.py&quot;>;TFF聚合器&lt;/a>;，&lt;a href=&quot;https://github.com/tensorflow/privacy/blob/master/tensorflow_privacy/privacy/dp_query /tree_aggregation_query.py&quot;>;TFP DPQuery&lt;/a>;、&lt;a href=&quot;https://github.com/google-research/federated/blob/master/dp_ftrl/blogpost_supplemental_privacy_accounting.ipynb&quot;>;DP 会计&lt;/a>;、和&lt;a href=&quot;https://github.com/google/federated-compute&quot;>;FL 系统&lt;/a>;）。 &lt;/li>; &lt;/ul>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;简史&lt;/h3>; &lt;p>; 近年来，FL 已成为根据用户数据训练 &lt;a href=&quot;https://arxiv.org/abs/1811.03604&quot;>;Gboard 设备上 LM&lt;/a>; 的默认方法。 2020 年，&lt;a href=&quot;https://arxiv.org/abs/1710.06963&quot;>;对模型更新进行剪辑并添加噪音&lt;/a>;的 DP 机制被用于&lt;a href=&quot;https://arxiv. org/abs/2009.10031&quot;>;防止在西班牙训练西班牙 LM 时的记忆&lt;/a>;，满足有限 DP 保证 (&lt;a href=&quot;https://blog.research.google/2023/05/making-ml- models- Differentially-private.html&quot;>;“&lt;a href=&quot;https://arxiv.org/abs/2303.00654&quot;>;如何 DP-fy ML“&lt;/a>; 指南中描述的第 3 层&lt;/a>;）。 2022 年，在 &lt;a href=&quot;https://arxiv.org/abs/2103.00039&quot;>;DP-Follow-The-Regularized-Leader (DP-FTRL) 算法&lt;/a>;的帮助下，西班牙 LM 成为第一个直接在用户数据上训练的生产神经网络宣布&lt;a href=&quot;https://blog.research.google/2022/02/federated-learning-with-formal.html&quot;>;正式的 DP 保证 (ε= 8.9, δ=10&lt;sup>;-10&lt;/sup>;)-DP&lt;/a>;（相当于报告的&lt;em>;&lt;a href=&quot;https://blog.research.google/2022/02/federated- Learning-with-formal.html&quot;>;ρ=0.81&lt;/a>;&lt;/em>; &lt;a href=&quot;https://arxiv.org/abs/1605.02065&quot;>;零集中差异隐私&lt;/a>;） ，因此满足&lt;a href=&quot;https://blog.research.google/2023/05/making-ml-models- Differentially-private.html&quot;>;合理的隐私保证&lt;/a>; (&lt;a href=&quot;https ://blog.research.google/2023/05/making-ml-models- Differentially-private.html&quot;>;第 2 层&lt;/a>;）。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;联邦学习中默认的差异隐私&lt;/h2>; &lt;p>; In “&lt;a href=&quot; https://arxiv.org/abs/2305.18465&quot;>;具有差异隐私的 Gboard 语言模型的联邦学习&lt;/a>;”，我们宣布 Gboard 中的所有 NWP 神经网络 LM 都具有 DP 保证，并且未来推出的所有 Gboard LM根据用户数据进行训练需要 DP 保证。通过应用以下实践在 FL 中启用 DP：&lt;/p>; &lt;ul>; &lt;li>;使用&lt;a href=&quot;https://arxiv.org/abs/2010.11934&quot;>;多语言&lt;/a预训练模型>; &lt;a href=&quot;https://arxiv.org/abs/1910.10683&quot;>;C4&lt;/a>; 数据集。 &lt;/li>;&lt;li>;通过对公共数据集的模拟实验，找到具有高实用性的大DP信噪比。增加参与一轮模型更新的客户端数量可以提高隐私性，同时保持噪声比固定以获得良好的效用，直到满足 DP 目标或系统允许的最大值和人口规模。 &lt;/li>;&lt;li>;根据&lt;a href=&quot;https://arxiv.org/abs/1902.01046中的计算预算和估计人口配置参数以限制每个客户端可以贡献的频率（例如，每隔几天一次） &quot;>;FL 系统&lt;/a>;。 &lt;/li>;&lt;li>;运行&lt;a href=&quot;https://arxiv.org/abs/2103.00039&quot;>;DP-FTRL&lt;/a>;训练，并限制通过&lt;a href选择的每台设备更新的幅度=&quot;https://github.com/tensorflow/federated/commit/ee9d08368828ea730662e5e2b3a90e103368b6b6&quot;>;自适应裁剪&lt;/a>;，或根据经验进行修复。 &lt;/li>; &lt;/ul>; &lt;p>; SecAgg 还可以通过采用&lt;a href=&quot;https://blog.research.google/2023/03/distributed- Differential-privacy-for.html&quot;>;先进技术来应用改善尺度和灵敏度的计算和通信&lt;/a>;。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht2ZweKyxBRqShB6i41lTpZmfS2gEi2rbNHFGgT-36di1HMxwV6caxFJ2lUXpznxuXYHEb928yfHwueojKlB-gx fKfT4aEv-_2MULO5zlaWNPceMDGdnOVWp4M8T5qCzMPTuinPOtRy1WmXMtsaSpNpMLvokQKlOnWYFMJF0tXbhmc-dkpI-o7T4FBn8-N /s1600/image3.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1000&quot; data-original-width=&quot;1600&quot; src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht2ZweKyxBRqShB6i41lTpZmfS2gEi2rbNHFGgT-36di1HMxwV6caxFJ2lUXpznxuXYHEb928yfHwueojKlB-gxfKfT4aEv-_2mULO5z laWNPceMDGdnOVWp4M8T5qCzMPTuinPOtRy1WmXMtsaSpNpMLvokQKlOnWYFMJF0tXbhmc-dkpI-o7T4FBn8-N/s16000/image3.gif&quot;/>;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;具有差异隐私和 (SecAgg) 的联邦学习。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table >; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;报告 DP 保证&lt;/h3>; &lt;p>; 已启动的 Gboard NWP LM 的 DP 保证在下面的条形图中可视化。 &lt;em>;x&lt;/em>; 轴显示按语言区域标记并在相应群体上进行训练的 LM； &lt;em>;y&lt;/em>; 轴显示当 &lt;em>;δ&lt;/em>; 固定为较小值 10&lt;sup>;-10&lt;/sup>; 时 &lt;em>;ε&lt;/em>; 值 &lt; a href=&quot;https://www.iacr.org/archive/eurocrypt2006/40040493/40040493.pdf&quot;>;(ε, δ)-DP&lt;/a>;（越低越好）。根据 A/B 测试期间的用户交互指标进行测量，这些模型的实用性要么显着优于之前生产中的非神经模型，要么与之前没有 DP 的 LM 相当。例如，通过应用最佳实践，西班牙模式的DP保证从&lt;em>;&lt;a href=&quot;https://blog.research.google/2022/02/federated-learning-with-formal .html&quot;>;ε=8.9&lt;/a>;&lt;/em>; 至 &lt;em>;ε&lt;/em>;=5.37。 SecAgg 还用于在西班牙训练西班牙语模型和在美国训练英语模型。有关 DP 保证的更多详细信息，请参阅&lt;a href=&quot;https://blog.research.google/ 后的&lt;a href=&quot;https://arxiv.org/abs/2305.18465&quot;>;附录&lt;/a>; 2023/05/making-ml-models- Differentially-private.html&quot;>;“&lt;a href=&quot;https://arxiv.org/abs/2303.00654&quot;>;如何 DP-fy ML&lt;”中概述的指南&lt;/a>; /a>;”。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;实现更强大的 DP 保证&lt;/h2>; &lt;p>; &lt;em>;ε&lt;/em>;~许多已推出的 LM 的 10 DP 保证对于 ML 模型来说已经被认为是&lt;a href=&quot;https://blog.research.google/2023/05/making-ml-models- Differentially-private.html&quot;>;合理&lt;/a>;在实践中，Gboard 中的 DP FL 的旅程仍在继续，以改善用户的打字体验，同时保护数据隐私。我们很高兴地宣布，巴西的葡萄牙语和拉丁美洲的西班牙语生产语言模型首次在 DP 保证 &lt;em>;ε&lt;/em>; ≤ 1 的情况下进行培训和启动，满足 &lt;a href=&quot; https://blog.research.google/2023/05/making-ml-models- Differentially-private.html&quot;>;第 1 层强大的隐私保证&lt;/a>;。具体来说，(&lt;em>;ε&lt;/em>;=0.994, &lt;em>;δ&lt;/em>;=10&lt;sup>;-10&lt;/sup>;)-DP 保证是通过运行高级 &lt;a href=&quot;https ://arxiv.org/abs/2306.08153&quot;>;矩阵分解 DP-FTRL&lt;/a>; (MF-DP-FTRL) 算法，每轮服务器模型更新训练都有超过 12,000 台设备参与，规模大于&lt;a href= “https://arxiv.org/abs/2305.18465&quot;>;6500+台设备的通用设置&lt;/a>;，以及精心配置的策略，限制每个客户在 14 天内最多参加 2000 轮训练的两次巴西庞大的葡萄牙语用户群体。使用类似的设置，es-US 西班牙语 LM 在拉丁美洲多个国家/地区的大量人群中进行了训练，以实现 (&lt;em>;ε&lt;/em>;=0.994，&lt;em>;δ&lt;/em>;=10&lt;sup>; -10&lt;/sup>;)-DP。 &lt;em>;ε&lt;/em>; ≤ 1 es-US 模型显着提高了许多国家的实用性，并在哥伦比亚、厄瓜多尔、危地马拉、墨西哥和委内瑞拉推出。对于人口较少的西班牙，es-ES LM 的 DP 保证从 &lt;em>;&lt;a href=&quot;https://arxiv.org/abs/2305.18465&quot;>;ε=5.37&lt;/a>;&lt;/em>; 提高到 &lt;em>;ε&lt;/em>;=3.42，只需将 &lt;a href=&quot;https://arxiv.org/abs/2103.00039&quot;>;DP-FTRL&lt;/a>; 替换为 &lt;a href=&quot;https://arxiv .org/abs/2306.08153&quot;>;MF-DP-FTRL&lt;/a>;，无需增加每轮参与的设备数量。为了保护隐私，&lt;a href=&quot;https://colab.sandbox.google.com/github/google-research/federated/blob/master/mf_dpftrl_matrices/privacy_accounting.ipynb&quot;>;colab&lt;/a>; 中披露了更多技术细节会计。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgp1yNOAbd8IRoisQDX-OHq-a8PUDH2V1OF7btRsUXI86-tuEXwrR8otAGEqPN8J2HGcpH9aB25s04Nybm_Vn6bpRmfD_A HnHYkGJtld7ockal6mhdRXcsA-M6rf3vM7kzQ5hXfdPbw9hk7bsQU8EV4ul5QAn3Hw4b1yXIKjnokfhrkEF0hNXGt9DbLU3yk/s1999/image1 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;709&quot; data-original-width=&quot;1999&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgp1yNOAbd8IRoisQDX-OHq-a8PUDH2V1OF7btRsUXI86-tuEXwrR8otAGEqPN8J2HGcpH9aB25s04Nybm_Vn6bpRmfD_AHnHYkGJtld7ockal6mhdRXcsA- M6rf3vM7kzQ5hXfdPbw9hk7bsQU8EV4ul5QAn3Hw4b1yXIKjnokfhrkEF0hNXGt9DbLU3yk/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Gboard NWP LM 的 DP 保证（紫色条代表 ε=8.9 的首次 es-ES 启动；青色条代表使用 &lt;a href=&quot;https://arxiv.org/abs/2306.08153&quot;>;MF-DP-FTRL&lt;/a>; 训练的模型的隐私改进； &lt;a href=&quot;https://blog.research.google/2023/05/making-ml-models- Differentially-private.html&quot;>;层级&lt;/a>;来自“&lt;a href=&quot;https://arxiv .org/abs/2303.00654&quot;>;如何实现 DP-fy ML&lt;/a>;“指南； en-US* 和 es-ES* 还使用 SecAgg 进行训练。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;讨论和后续步骤&lt;/h2>; &lt;p>;我们的经验表明，DP可以在实践中通过客户参与的系统算法协同设计来实现，并且当人群参与时，隐私性和实用性都可以很强。大量&lt;em>;和&lt;/em>;设备的贡献被汇总。隐私-实用性-计算权衡可以通过&lt;a href=&quot;https://arxiv.org/abs/2305.18465&quot;>;使用公共数据&lt;/a>;来改善，&lt;a href=&quot;https://arxiv. org/abs/2306.08153&quot;>;新的 MF-DP-FTRL 算法&lt;/a>;，&lt;a href=&quot;https://github.com/google/differential-privacy&quot;>;并加强核算&lt;/a>;。通过这些技术，&lt;em>;ε&lt;/em>; ≤ 1 的强大 DP 保证是可能的，但仍然具有挑战性。实证隐私审计的积极研究 [&lt;a href=&quot;https://arxiv.org/abs/2302.03098&quot;>;1&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2305.08846&quot;>;2 &lt;/a>;]表明 DP 模型可能比最坏情况 DP 保证所暗示的更加私密。在我们不断推动算法前沿的同时，隐私-效用-计算的哪个维度应该优先考虑？ &lt;/p>; &lt;p>; 我们正在积极致力于 ML 的所有隐私方面的工作，包括将 DP-FTRL 扩展到 &lt;a href=&quot;https://blog.research.google/2023/03/distributed- Differential-privacy-for .html&quot;>;分布式DP&lt;/a>;并提高&lt;a href=&quot;https://arxiv.org/abs/2306.14793&quot;>;可审计性和可验证性&lt;/a>;。 &lt;a href=&quot;https://en.wikipedia.org/wiki/Trusted_execution_environment&quot;>;可信执行环境&lt;/a>;为大幅增加模型大小和可验证隐私提供了机会。最近&lt;a href=&quot;https://blog.google/technology/ai/google-gemini-ai/&quot;>;大型 LM 的突破&lt;/a>; (LLM) 激励我们&lt;a href=&quot;https:// arxiv.org/abs/2305.12132&quot;>;重新思考&lt;/a>;在私人培训中使用&lt;a href=&quot;https://arxiv.org/abs/2212.06470&quot;>;公共&lt;/a>;信息以及法学硕士之间未来更多的互动、设备上 LM 和 Gboard 制作。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;作者要感谢 Peter Kairouz、Brendan McMahan 和 Daniel Ramage 对博客文章本身的早期反馈，Shaofeng Li 和 Tom Small 对动画人物的帮助，以及 Google 团队对算法设计、基础设施实施和生产维护的帮助。以下合作者直接对所呈现的结果做出了贡献：&lt;/em>; &lt;/p>; &lt;p>; &lt;em>;研究和算法开发：Galen Andrew、Stanislav Chiknavaryan、Christopher A. Choquette-Choo、Arun Ganesh、Peter Kairouz、Ryan McKenna 、H. Brendan McMahan、Jesse Rosenstock、Timon Van Overveldt、Keith Rush、Shuang Song、Thomas Steinke、Abhradeep Guha Thakurta、Om Thakkar 和 Yuanbo Zhang。&lt;/em>; &lt;/p>; &lt;p>; &lt;em>;基础设施、生产以及领导支持：Mingqing Chen、Stefan Dierauf、Billy Dou、Hubert Eichner、Zachary Garrett、Jeremy Gillula、Jianpeng Hou、Hui Li、Xu Liu、Wenzhi Mao、Brett McLarnon、Mengchen Pei、Daniel Ramage、Swaroop Ramaswamy、Hai Cheng Sun、Andreas Terzis、王云、吴珊珊、肖宇和斋淑敏。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/4343235509909091741/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/02/advances-in-private-training-for .html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/ 4343235509909091741&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4343235509909091741&quot; rel=&quot;self&quot; type= &quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/02/advances-in-private-training-for.html&quot; rel=&quot;alternate&quot; title=&quot;进展设备上生产语言模型的私人培训” type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri >;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1. blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/ img/b/R29vZ2xl/AVvXsEifnCZ_XGUoUG0hESM0dF5B8Rsoqo4YrT_-uv0hlDM1iTADhtEEyEvBM4hOWT0rxgpVtZKyuFoj2xeXmkeXwGe-XTmvBuwBDJOCqgN8Ba7Wcjh_s1seWUaCRl1xNpNe_6 MqxcFFZoAvhfCge5vq9UATjXG_BnTiGdQ6YLLo7AK7ABS3KLFMKmjAtA1gkcBk/s72-c/GBoard%20PrivacyHero.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:缩略图>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-5605933033299261025&lt;/id>;&lt;发布>;2024-02- 14T10:32:00.000-08:00&lt;/发布>;&lt;更新>;2024-02-14T10:32:25.557-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom/ ns#&quot; term=&quot;深度学习&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;监督学习&quot;>;&lt;/category>;&lt;title type=&quot; text&quot;>;了解概念漂移下训练数据的重要性&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：博士前研究员 Nishant Jain 和研究科学家 Pradeep Shenoy , Google 研究&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUeskw4YD6cFTpLaRnv7OwMsljyeipfAb1riYxIuBsiWd6TBmUXMJ4QoI9tlvUzWX9NzBbEjz3-P2Zl2kuXe5BrVclmq QFrLButoya5phiEELq1azrhsIaGaCz-ov_jXaMsFrGRDE0EjotyRQPOX3xV5MAkVJfKp9xecX4t2CoLBiZ8r2RpZ25Y5KRitFG/s1600/temporalreweightinghero.png&quot; style=&quot;显示：无；&quot; />; &lt;p>; 我们周围世界不断变化的性质对人工智能模型的开发提出了重大挑战。通常，模型是根据纵向数据进行训练的，希望所使用的训练数据能够准确地表示模型将来可能收到的输入。更一般地说，所有训练数据都同等相关的默认假设在实践中经常被打破。例如，下图显示了来自 &lt;a href=&quot;https://arxiv.org/abs/2201.06289&quot;>;CLEAR&lt;/a>; 非平稳学习基准的图像，它说明了对象的视觉特征如何在 10 年内显着演变。年跨度（我们称之为&lt;em>;缓慢概念漂移&lt;/em>;的现象），对对象分类模型提出了挑战。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto ; 右边距：自动;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBAkCetRQiAPA4cmiXvtwa2SJ0pMwvRYDcuL7rQEDHxEgi9lAyU69bBeeEw -_k182BITn4w2WtdE5QfUwaF-Ny-Dkai-pLeHV23mlgAwrX_0le28l5hba9q9QUO3LeYl2jgkPGkKcLW7dtnGFMiY7PrZbpigSggAiOSrRB8X9eQZGHLE8H7TZoxYy4AD2Q/s1999/image4.png&quot; imageanchor=&quot; 1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height= “662”数据原始宽度=“1999”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBAkCetRQiAPA4cmiXvtwa2SJ0pMwvRYDcuL7rQEDHxEgi9lAyU69bBeeEw-_k182BITn4w2WtdE5QfUwaF- Ny-Dkai-pLeHV23mlgAwrX_0le28l5hba9q9QUO3LeYl2jgkPGkKcLW7dtnGFMiY7PrZbpigSggAiOSrRB8X9eQZGHLE8H7TZoxYy4AD2Q/s16000/image4.png&quot; />;&lt; /a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;来自 CLEAR 基准测试的示例图像。 （改编自 Lin 等人&lt;a href=&quot;https://arxiv.org/abs/2201.06289&quot;>;.&lt;/a>;）&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt; p>; 替代方法，例如&lt;a href=&quot;https://en.wikipedia.org/wiki/Online_machine_learning&quot;>;在线&lt;/a>;和&lt;a href=&quot;https://wiki.continualai.org/the- continualai-wiki/introduction-to-continual-learning&quot;>;持续学习&lt;/a>;，用少量最新数据反复更新模型，以保持最新状态。这隐含地优先考虑最近的数据，因为从过去数据中学到的知识会被后续更新逐渐删除。然而，在现实世界中，不同类型的信息以不同的速率失去相关性，因此存在两个关键问题：1) 在设计上，它们&lt;em>;仅&lt;/em>;关注最新数据，并丢失来自较旧数据的任何信号。被删除。 2) 无论数据内容如何，​​数据实例的贡献都会随时间均匀衰减。 &lt;/p>; &lt;p>; 在我们最近的工作“&lt;a href=&quot;https://arxiv.org/abs/2212.05908&quot;>;非平稳学习的实例条件衰减时间尺度&lt;/a>;”中，我们提出在训练期间为每个实例分配一个重要性分数，以便最大限度地提高模型在未来数据上的性能。为了实现这一目标，我们采用了一个辅助模型，该模型使用训练实例及其年龄来生成这些分数。该模型是与主模型共同学习的。我们解决了上述挑战，并在一系列非平稳学习的基准数据集上比其他强大的学习方法取得了显着的成果。例如，在&lt;a href=&quot;https://arxiv.org/abs/2108.09020&quot;>;最近的非平稳学习大规模基准&lt;/a>;（10 年期间约 3900 万张照片）中，我们显示通过训练数据的学习重新加权，相对准确度提高了 15%。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;监督学习概念漂移的挑战&lt;/h2>; &lt;p>; 获得对缓慢概念的定量洞察为了解决这个问题，我们在&lt;a href=&quot;https://arxiv.org/abs/2108.09020&quot;>;最近的照片分类任务&lt;/a>;上构建了分类器，其中包含 10 年来来自社交媒体网站的大约 3900 万张照片。我们比较了离线训练和连续训练，前者以随机顺序对所有训练数据进行多次迭代，后者以顺序（时间）顺序对每个月的数据进行多次迭代。我们在训练期间和后续期间测量了模型的准确性，其中两个模型都被冻结，即没有进一步更新新数据（如下所示）。在训练期结束时（左图，x 轴 = 0），两种方法都看到了相同数量的数据，但表现出很大的性能差距。这是由于&lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/S0079742108605368&quot;>;灾难性遗忘&lt;/a>;造成的，这是持续学习中的一个问题，模型从早期开始就对数据有了解。训练序列中的 on 以不受控制的方式减少。另一方面，遗忘也有其优点——在测试期间（如右图所示），持续训练的模型的退化速度比离线模型慢得多，因为它较少依赖于旧数据。测试期间两个模型准确性的下降证实了数据确实随着时间的推移而变化，并且两个模型变得越来越不相关。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEizQmgaL3NNsCLWbeTndyOxPikcGKqQIrpDisMVTy-7eAIxamEv3Klpncd5B4SB19yNnPmpySlfAz_hPN8x4zV7o0LPmcLKEnyV JBctKuLF8plITBmDz3BTR2aPHqlKarPPHZHpp0EY0M3HA9l5oV_IOaQS5UzS-uMaNq3Fi1D1qHUYJ6XC-4t0_xS91fnw/s1554/image2.png “ imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;616&quot; data-original-width=&quot;1554&quot; src= “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEizQmgaL3NNsCLWbeTndyOxPikcGKqQIrpDisMVTy-7eAIxamEv3Klpncd5B4SB19yNnPmpySlfAz_hPN8x4zV7o0LPmcLKEnyVJBctKuLF8plITBmDz3BTR2a PHqlKarPPHZHpp0EY0M3HA9l5oV_IOaQS5UzS-uMaNq3Fi1D1qHUYJ6XC-4t0_xS91fnw/s16000/image2.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;在照片分类任务上比较离线模型和持续训练模型。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt; div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;训练数据的时间敏感的重新加权&lt;/h2>; &lt;p>; 我们设计了一种结合离线学习优点的方法（灵活性有效地重用所有可用数据）和持续学习（淡化旧数据的能力）来解决缓慢的概念漂移问题。我们以离线学习为基础，然后仔细控制过去数据的影响和优化目标，两者都旨在减少未来的模型衰减。 &lt;/p>; &lt;p>; 假设我们希望训练一个模型，&lt;em>;M&lt;/em>;，&lt;em>; &lt;/em>;给定一段时间内收集的一些训练数据。我们建议还训练一个辅助模型，根据每个点的内容和年龄为其分配权重。该权重缩放了该数据点在 &lt;em>;M&lt;/em>; 训练目标中的贡献。权重的目标是提高&lt;em>;M&lt;/em>;在未来数据上的性能。 &lt;/p>; &lt;p>; 在&lt;a href=&quot;https://arxiv.org/abs/2212.05908&quot;>;我们的工作&lt;/a>;中，我们描述了如何元学习辅助模型，&lt;/em>; em>;ie，以有助于模型&lt;em>;M&lt;/em>;本身学习的方式与&lt;em>;M&lt;/em>;一起学习。辅助模型的一个关键设计选择是我们以分解的方式分离出与实例和年龄相关的贡献。具体来说，我们通过组合多个不同的固定衰减时间尺度的贡献来设置权重，并学习给定实例对其最适合的时间尺度的近似“分配”。我们在实验中发现，这种形式的辅助模型优于我们考虑的许多其他替代方案，从无约束的联合函数到单一时间尺度的衰减（指数或线性），因为它结合了简单性和表现力。完整的详细信息可以在&lt;a href=&quot;https://arxiv.org/abs/2212.05908&quot;>;论文&lt;/a>;中找到。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;实例权重评分&lt;/h2>; &lt;p>; 下面的上图显示我们的学习辅助模型确实提高了-在&lt;a href=&quot;https://arxiv.org/abs/2201.06289&quot;>;CLEAR物体识别挑战&lt;/a>;中对外观更现代的物体进行加权；看起来较旧的物体的权重相应降低。经过仔细检查（下图，基于梯度的&lt;a href=&quot;https://arxiv.org/abs/1610.02391&quot;>;特征重要性&lt;/a>;评估），我们发现辅助模型侧重于内部的主要对象图像，而不是例如可能与实例年龄虚假相关的背景特征。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEggQImnpFiW7s3jeT9qoxQOM1kT8vIaHihnlAPusLRx8lJCaxyB7Lzhewn7J6qTiz9-qkWBJzzxLj-uHXhlB94WBMUVRsAgqZVB MBAndaHGeCe6evZOo6hYgR5oXImP5vO9ZUNcF1q3Bpvau94hM9D71xwOGRqm9c8lJ6ixrB69w_JjneqW5JGcg_u6ZW2J/s1999/image1.png&quot; imageanchor =&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;499&quot; data-original-width=&quot;1999&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEggQImnpFiW7s3jeT9qoxQOM1kT8vIaHihnlAPusLRx8lJCaxyB7Lzhewn7J6qTiz9-qkWBJzzxLj-uHXhlB94WBMUVRsAgqZVBMBAnDaHGeCe6evZOo6hYgR5o XImP5vO9ZUNcF1q3Bpvau94hM9D71xwOGRqm9c8lJ6ixrB69w_JjneqW5JGcg_u6ZW2J/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr -caption&quot; style=&quot;text-align: center;&quot;>;来自 &lt;a href=&quot;https://arxiv.org/abs/2201.06289&quot;>;CLEAR&lt;/a>; 基准测试的示例图像（相机和图像）计算机类别）分别由我们的辅助模型分配最高和最低权重。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt;tablealign=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0 &quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href= “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiKCafyxNrHJUkwV3KjoFMJk_v9WSPlzfMyYa-TZCODZdBNCnUOLOZogf9njyGQp_TWzCZ-a6-P5smLhSyeHVFd_jaSBbmS9soN5A5AF6oTq_OWv k-xOWgKaDCIFYz8mhe-GoVEZ56QSsIpKxDduNmCA0ORnf_kgW8ph0uZci8UBCQDBHs0j4Nq5hb5J7e/s1999/image5.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 自动; 边距-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;339&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl /AVvXsEhiKCafyxNrHJUkwV3KjoFMJk_v9WSPlzfMyYa-TZCODZdBNCnUOLOZogf9njyGQp_TWzCZ-a6-P5smLhSyeHVFd_jaSBbmS9soN5A5AF6oTq_OWvk-xOWgKaDCIFYz8mhe-GoVEZ56QSsIpK xDduNmCA0ORnf_kgW8ph0uZci8UBCQDBHs0j4Nq5hb5J7e/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text- align: center;&quot;>;对 &lt;a href=&quot;https://arxiv.org/abs/2201.06289&quot;>;CLEAR&lt;/a>; 基准测试中的示例图像进行辅助模型的特征重要性分析。&lt;/td>;&lt;/tr >;&lt;/tbody>;&lt;/table>; &lt;br>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;结果&lt;/h2>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;大规模数据的收益&lt;/h3>; &lt;p>;我们首先研究大规模&lt;a href=&quot;https://arxiv.org/abs/ 2108.09020&quot;>;前面讨论的 &lt;a href=&quot;https://arxiv.org/abs/1503.01817&quot;>;YFCC100M 数据集&lt;/a>;上的照片分类任务&lt;/a>; (PCAT)，使用前五年的数据训练数据和未来五年的测试数据。我们的方法（如下图红色所示）比无重新加权基线（黑色）以及许多其他稳健的学习技术有了显着的改进。有趣的是，我们的方法故意牺牲了遥远过去的准确性（训练数据不太可能在未来再次出现），以换取测试期间的显着改进。此外，根据需要，我们的方法在测试期间的降解程度低于其他基线。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLKQZo3e80Ttgw64eHAndZZc6BMXKBNLXAPTQZDP1tsFEQZpGckd6fzqG0aC1x_b5HQmiYlp6AzgbQ3gYRGVcHEZ vhnPiDVsl1rxKh3vjVtqXJd20xp5og5yowR2SmyvqNdhhaSuNT5IY_rm_SJanFAsM4jt1Pf_TChyphenhyphenK8y0mNi2Jji1oDWcSiH_7vaC7b/s800/image3.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;600&quot; data-original-width=&quot;800&quot; src=&quot;https://blogger .googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLKQZo3e80Ttgw64eHAndZZc6BMXKBNLXAPTQZDP1tsFEQZpGckd6fzqG0aC1x_b5HQmiYlp6AzgbQ3gYRGVcHEZvhnPiDVsl1rxKh3vjVtqXJd20 xp5og5yowR2SmyvqNdhhaSuNT5IY_rm_SJanFAsM4jt1Pf_TChyphenhyphenK8y0mNi2Jji1oDWcSiH_7vaC7b/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text- align: center;&quot;>;我们的方法与 PCAT 数据集上的相关基线的比较。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt;div style=&quot;line-height:40%;&quot; >; &lt;br>; &lt;/div>; &lt;h3>;广泛的适用性&lt;/h3>; &lt;p>; 我们在来自学术文献的各种非平稳学习挑战数据集上验证了我们的发现（参见&lt;a href=&quot;https://arxiv .org/abs/2108.09020&quot;>;1&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2201.06289&quot;>;2&lt;/a>;，&lt;a href=&quot;https://arxiv.org /abs/2211.14238&quot;>;3&lt;/a>;、&lt;a href=&quot;https://proceedings.mlr.press/v206/awasthi23b/awasthi23b.pdf&quot;>;4&lt;/a>; 了解详细信息），涵盖数据源和模式（照片、卫星图像、社交媒体文本、医疗记录、传感器读数、表格数据）和大小（范围从 10k 到 39M 实例）。与每个数据集最近发布的基准方法相比，我们报告在测试期间取得了显着的进步（如下所示）。请注意，之前最著名的方法对于每个数据集可能有所不同。这些结果展示了我们的方法的广泛适用性。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhw95hIflfZ4eiNddWi0-YXONJYbMLT2yHp_Ekzm8v5e1WHpxeT5v7k21EYihoAqrplmlrtM76iiHjuBWtMQDbtj7TvtwIU 0eZb44_QSeEe5U4k_z70y_9SsS3If8Y5xkMXKQYI5VzaTafWC7nVv5MgvNw_yL8HA6N7-gUPGGcJI2qtgKTcnqn2oN1ruBt-/s765/image7.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;552&quot; data-original-width=&quot;765&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhw95hIflfZ4eiNddWi0-YXONJYbMLT2yHp_Ekzm8v5e1WHpxeT5v7k21EYihoAqrplmlrtM76iiHjuBWtMQDbtj7TvtwIU0eZb44_QSeEe5U4k_z70 y_9SsS3If8Y5xkMXKQYI5VzaTafWC7nVv5MgvNw_yL8HA6N7-gUPGGcJI2qtgKTcnqn2oN1ruBt-/s16000/image7.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class= &quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;我们的方法在研究自然概念漂移的各种任务上的性能增益。我们报告的每个数据集的收益都超过了之前最知名的方法。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br >; &lt;/div>; &lt;h3>;持续学习的扩展&lt;/h3>; &lt;p>; 最后，我们考虑我们工作的一个有趣的扩展。上述工作描述了如何使用持续学习启发的想法来扩展离线学习以处理概念漂移。然而，有时离线学习是不可行的——例如，如果可用的训练数据量太大而无法维护或处理。我们通过在用于顺序更新模型的每个数据桶的上下文中应用时间重新加权，以直接的方式调整我们的持续学习方法。该提案仍然保留了持续学习的一些限制，例如，模型更新仅针对最新的数据执行，并且所有优化决策（包括我们的重新加权）仅针对该数据做出。尽管如此，我们的方法在照片分类基准上始终优于常规的持续学习以及各种其他持续学习算法（见下文）。由于我们的方法与此处比较的许多基线中的想法是互补的，因此我们预计与它们结合时会获得更大的收益。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjtWaqgT_9wt2sckjfrLbQ8LhRK5gL1yTowCf0h2nMnHhBYqfKP7VBwWfbK-5Y5zbYXiKoaF0TKve71FWrHazA4 g4SPFD3le​​b56aZHex95MM_yovx2Y_uO4c5rOA5GzTndUGyBO4HH0gL3jYd8Jk4oPbi4HuSYDuMkKY5kPlqsb0s-re13QKfei2IrMig6S/s800/image6.png&quot; imageanchor =&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;600&quot; data-original-width=&quot;800&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjtWaqgT_9wt2sckjfrLbQ8LhRK5gL1yTowCf0h2nMnHhBYqfKP7VBwWfbK-5Y5zbYXiKoaF0TKve71FWrHazA4g4SPFD3le​​b56aZHex95MM_yovx 2Y_uO4c5rOA5GzTndUGyBO4HH0gL3jYd8Jk4oPbi4HuSYDuMkKY5kPlqsb0s-re13QKfei2IrMig6S/s16000/image6.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr -caption&quot; style=&quot;text-align: center;&quot;>;与最新基线相比，我们的方法的结果适应了持续学习。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 我们通过结合先前方法的优点（离线学习与它有效地重用数据，并持续学习，重点关注最新数据。我们希望我们的工作有助于提高模型在实践中对概念漂移的鲁棒性，并在解决缓慢概念漂移的普遍问题方面产生更多的兴趣和新想法。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;我们感谢 Mike Mozer 在早期进行的许多有趣的讨论这项工作的各个阶段，以及开发过程中非常有用的建议和反馈。&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/5605933033299261025/comments/默认&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/02/learning-importance-of-training -data.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/默认/5605933033299261025&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5605933033299261025&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/02/learning-importance-of-training-data.html&quot; rel=&quot;alternate&quot; title=&quot;了解概念漂移下训练数据的重要性&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri >;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1. blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/ img/b/R29vZ2xl/AVvXsEgUeskw4YD6cFTpLaRnv7OwMsljyeipfAb1riYxIubsiWd6TBmUXMJ4QoI9tlvUzWX9NzBbEjz3-P2Zl2kuXe5BrVclmqQFrLButoya5phiEELq1azrhsIaGaCz-ov_jX aMsFrGRDE0EjotyRQPOX3xV5MAkVJfKp9xecX4t2CoLBiZ8r2RpZ25Y5KRitFG/s72-c/temporalreweightinghero.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>; &lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-5933365460125094774&lt;/id>;&lt;发布>;2024-02-13T14: 11:00.000-08:00&lt;/发布>;&lt;更新>;2024-02-13T14:11:49.258-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom/ns# &quot; term=&quot;差异隐私&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Responsible AI&quot;>;&lt;/category>;&lt;category schema=&quot;http: //www.blogger.com/atom/ns#&quot; term=&quot;Security and Privacy&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;DP-Auditorium：用于审核差异隐私的灵活库&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Google 研究院研究科学家 Mónica Ribero Díaz&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEhNVpxjk-jj1rIYQ8AM3A-Syqxd3d8L8-wIy8NWwyobCXmTRK7mY9h94aJYgFCiC0gnehVFFoM8-in8HsOZjfhoNce03nbsrN5fxY07wADV6ULPC0POGmCC-8eL3OqA 9KrDyzQxN38JKvh6xCmLV6FZ1g0UfaXtKORhtTy0WuJexlPqV6P2c9rPdg_W_5zP/s320/hero.jpg&quot; style=&quot;显示：无；&quot; />; &lt;p>; &lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_privacy&quot;>;差分隐私&lt;/a>; (DP) 是一种随机机制的属性，它限制任何单个用户信息的影响，同时处理和分析数据。 DP 提供了强大的解决方案来解决人们日益增长的数据保护问题，支持&lt;a href=&quot;https://blog.research.google/2022/02/federated-learning-with-formal.html&quot;>;跨领域&lt;/a>;的技术&lt;a href=&quot;https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf&quot;>;行业&lt;/a>;和政府应用（例如，&lt;a href=&quot;https://www.census.gov/ programs-surveys/decennial-census/decade/2020/planning-management/process/disclosure-avoidance/ Differential-privacy.html&quot;>;美国人口普查&lt;/a>;），而不损害个人用户身份。随着其采用率的增加，识别开发实施错误的机制的潜在风险非常重要。研究人员最近发现私有机制的数学证明及其实现存在错误。例如，&lt;a href=&quot;https://arxiv.org/pdf/1603.01699.pdf&quot;>;研究人员比较了&lt;/a>;六种稀疏矢量技术 (SVT) 变体，发现六种中只有两种真正满足所声称的隐私要求保证。即使数学证明是正确的，实现该机制的代码也很容易出现人为错误。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 然而，实用且高效的 DP 审计具有挑战性，主要是由于机制固有的随机性和测试保证的概率性质。此外，还存在一系列保证类型（例如，&lt;a href=&quot;https://dl.acm.org/doi/10.1007/11681878_14&quot;>;纯 DP&lt;/a>;、&lt;a href=&quot;https:// /link.springer.com/chapter/10.1007/11761679_29&quot;>;近似 DP&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/1702.07476&quot;>;Rényi DP&lt;/a>; 和 &lt;a href =&quot;https://arxiv.org/pdf/1603.01887.pdf&quot;>;集中的DP&lt;/a>;），这种多样性增加了制定审计问题的复杂性。此外，考虑到所提出的机制的数量，调试数学证明和代码库是一项艰巨的任务。虽然在特定机制假设下存在&lt;em>;临时&lt;/em>;测试技术，但很少有人努力开发用于测试 DP 机制的可扩展工具。 &lt;/p>; &lt;p>; 为此，在“&lt;a href=&quot;https://arxiv.org/abs/2307.05608&quot;>;DP-Auditorium：用于审计差异隐私的大型库&lt;/a>;”中，我们引入一个&lt;a href=&quot;https://github.com/google/ Differential-privacy/tree/main/python/dp_auditorium&quot;>;开源库&lt;/a>;，用于仅通过黑盒访问机制来审核 DP 保证（即，不了解该机制的内部属性）。 DP-Auditorium 采用 Python 实现，并提供灵活的接口，允许贡献者不断提高其测试能力。我们还引入了新的测试算法，可以对 Rényi DP、纯 DP 和近似 DP 的函数空间执行散度优化。我们证明 DP-Auditorium 可以有效地识别 DP 保证违规行为，并建议哪些测试最适合检测各种隐私保证下的特定错误。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;DP 保证&lt;/h2>; &lt;p>; DP 机制的输出是从满足确保用户数据隐私的数学属性的概率分布 (&lt;em>;M&lt;/em>; (&lt;em>;D&lt;/em>;))。因此，DP 保证与概率分布对之间的属性紧密相关。如果由数据集 &lt;em>;D&lt;/em>; 和相邻数据集 &lt;em>;D&#39;&lt;/em>; 上的 &lt;i>;M&lt;/i>; 确定的概率分布（仅相差一条记录），则该机制是差分隐私的，在给定的差异指标下&lt;em>;&lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_indistinguishability&quot;>;无法区分&lt;/a>;&lt;/em>;。 &lt;/p>; &lt;p>; 例如，经典的&lt;a href=&quot;https://software.imdea.org/~federico/pubs/2013.ICALP.pdf&quot;>;近似 DP&lt;/a>; 定义指出一种机制如果&lt;a href=&quot;https://arxiv.org/pdf/1508.00335.pdf&quot;>;曲棍球棒散度，则近似为具有参数（&lt;em>;ε&lt;/em>;、&lt;em>;δ&lt;/em>;）的 DP &lt;/a>; 阶 &lt;em>;e&lt;sup>;ε&lt;/sup>;&lt;/em>;，介于 &lt;em>;M&lt;/em>;(&lt;em>;D) &lt;/em>; 和 &lt;em>;M&lt;/em>; 之间>;(&lt;em>;D&#39;&lt;/em>;)，至多为&lt;em>;δ&lt;/em>;。纯 DP 是近似 DP 的特殊实例，其中 &lt;em>;δ = 0&lt;/em>;。最后，考虑一种带有参数（&lt;em>;𝛼&lt;/em>;，&lt;em>;ε）&lt;/em的&lt;a href=&quot;https://arxiv.org/abs/1702.07476&quot;>;Rényi DP&lt;/a>;机制>; 如果 &lt;a href=&quot;https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy&quot;>;Rényi 散度&lt;/a>; 的阶 &lt;em>;𝛼&lt;/em>; 最多为 &lt;em>; ε&lt;/em>;（其中&lt;em>;ε&lt;/em>;是一个小的正值）。在这三个定义中，&lt;em>;ε&lt;/em>;不可互换，但直观地传达了相同的概念； &lt;em>;ε&lt;/em>; 值越大意味着两个分布之间的差异越大或隐私性越差，因为这两个分布更容易区分。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;DP-Auditorium&lt;/h2>; &lt;p>; DP-Auditorium 包含两个主要组件：属性测试器和数据集查找器。属性测试人员从在特定数据集上评估的机制中获取样本作为输入，旨在识别所提供数据集中的隐私保证违规行为。数据集发现者建议隐私保证可能失败的数据集。通过结合这两个组件，DP-Auditorium 能够 (1) 自动测试不同的机制和隐私定义，以及 (2) 检测隐私保护机制中的错误。我们实现了各种私有和非私有机制，包括计算记录平均值的简单机制和更复杂的机制，例如不同的 SVT 和梯度下降&lt;/a>;机制变体。 &lt;/p>; &lt;p>; &lt;strong>;性能测试人员&lt;/strong>;确定是否存在证据来拒绝两个概率分布 &lt;em>;P&lt;/em>; 和 &lt;em>;Q&lt;/em>; 之间给定分歧的假设，受到预先指定的预算的限制，该预算由正在测试的 DP 保证确定。他们根据 &lt;em>;P&lt;/em>; 和 &lt;em>;Q 的样本计算下界，如果下界值超过预期偏差，则拒绝该属性。如果结果确实有界，则不提供任何保证。为了测试一系列隐私保证，DP-Auditorium 引入了三种新颖的测试仪：(1) HockeyStickPropertyTester、(2) RényiPropertyTester 和 (3) MMDPropertyTester。与其他方法不同，这些测试器不依赖于测试分布的显式直方图近似值。它们依赖于曲棍球棒散度、Rényi 散度和&lt;a href=&quot;https://jmlr.csail.mit.edu/papers/v13/gretton12a.html&quot;>;最大平均差异&lt;/a>;的变分表示（ MMD），可以通过函数空间的优化来估计散度。作为基线，我们实现了 &lt;a href=&quot;https://arxiv.org/abs/1806.06427&quot;>;HistogramPropertyTester&lt;/a>;，一种常用的近似 DP 测试器。虽然我们的三个测试仪遵循类似的方法，但为了简洁起见，我们在本文中重点关注 HockeyStickPropertyTester。 &lt;/p>; &lt;p>; 给定两个相邻数据集 &lt;em>;D&lt;/em>; 和 &lt;em>;D&#39;&lt;/em>;，HockeyStickPropertyTester 找到一个下限，&lt;i>;&lt;span style=&quot;bottom: 9px; left: 9px;position:relative;transfrom:scale(4,0.5);&quot;>;^&lt;/span>;δ&lt;/i>; &amp;nbsp;用于 &lt;em>;M&lt;/em>;(&lt;em>; D) &lt;/em>;和 &lt;em>;M&lt;/em>;(&lt;em>;D&#39;&lt;/em>;) 成立的概率很高。曲棍球棒散度强制两个分布 &lt;em>;M&lt;/em>;(&lt;em>;D) &lt;/em>; 和 &lt;em>;M&lt;/em>;(&lt;em>;D&#39;&lt;/em>;) 在近似的 DP 保证。因此，如果隐私保证声称曲棍球棒散度至多&lt;em>;δ&lt;/em>;，并且&lt;i>;&lt;span style=&quot;bottom: 9px; left: 9px;position:relative; transfrom:scale( 4,0.5);&quot;>;^&lt;/span>;δ&lt;/i>;&amp;nbsp; >; &lt;em>;δ&lt;/em>;，那么很有可能散度会高于 &lt;em>;D&lt;/em>; 和 &lt;em>;D&#39;&lt;/em>; 上的承诺，并且该机制无法满足给定的近似 DP 保证。下限&lt;i>;&lt;span style=&quot;bottom: 9px; left: 9px;position:relative; transfrom:scale(4,0.5);&quot;>;^&lt;/span>;δ&lt;/i>;&amp;nbsp;被计算为曲棍球棒散度变分公式的经验且易于处理的对应物（有关更多详细信息，请参阅&lt;a href=&quot;https://arxiv.org/pdf/2307.05608.pdf&quot;>;论文&lt;/a>;） 。精度&lt;i>;&lt;span style=&quot;bottom: 9px; left: 9px;position:relative; transfrom:scale(4,0.5);&quot;>;^&lt;/span>;δ&lt;/i>;&amp;nbsp;随着从机制中抽取的样本数量增加，但随着变分公式的简化而减少。我们平衡这些因素，以确保&lt;i>;&lt;span style=&quot;bottom: 9px; left: 9px;position:relative; transfrom:scale(4,0.5);&quot;>;^&lt;/span>;δ&lt;/i>; &amp;nbsp;既准确又易于计算。 &lt;/p>; &lt;p>; &lt;strong>;数据集查找器&lt;/strong>;使用&lt;a href=&quot;https://arxiv.org/pdf/2207.13676.pdf&quot;>;黑盒优化&lt;/a>;来查找数据集&lt;em >;D&lt;/em>; 和 &lt;em>;D&#39;&lt;/em>; 最大化&lt;i>;&lt;span style=&quot;bottom: 9px; left: 9px;position:relative; transfrom:scale(4,0.5);&quot;>;^ &lt;/span>;δ&lt;/i>;，散度值&lt;em>;δ&lt;/em>;的下限。请注意，黑盒优化技术是专门为导出目标函数的梯度可能不切实际甚至不可能的设置而设计的。这些优化技术在探索和开发阶段之间振荡，以估计目标函数的形状并预测目标可以具有最佳值的区域。相比之下，完整的探索算法，例如&lt;a href=&quot;https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search&quot;>;网格搜索方法&lt;/a>;，会搜索相邻数据集的整个空间&lt; em>;D&lt;/em>; 和 &lt;em>;D&#39;&lt;/em>;。 DP-Auditorium 通过开源黑盒优化库 &lt;a href=&quot;https://github.com/google/vizier&quot;>;Vizier&lt;/a>; 实现不同的数据集查找器。 &lt;/p>; &lt;p>; 在新机制上运行现有组件只需将该机制定义为 Python 函数，该函数采用数据数组 &lt;em>;D&lt;/em>; 和所需数量的样本 &lt;em>;n&lt;/em>; >; 由在&lt;em>;D&lt;/em>;上计算的机制输出。此外，我们为测试人员和数据集查找器提供灵活的包装器，允许从业者实现自己的测试和数据集搜索算法。 &lt;/p>; &lt;div style =“线路高：40％;”>; &lt;br />; &lt;/>; &lt;/>;具有不同输出空间的九种非私有机制。对于每个属性测试仪，我们使用&lt;em>;ε&lt;/em>;的不同值在固定数据集上重复测试，并报告每个测试仪标识隐私错误的次数。尽管没有测试仪始终胜过其他测试人员，但我们确定了以前技术（Histogroperpertytester）所遗漏的错误。请注意，组合植物的组织不适用于SVT机制。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlLYAUJ1cew8xCQNyNMvggKZ2c2bd5uHLzUdLx3xVdn_TW4ZBwd5tCI6zVVvVjmOWKJanJ4vP4swXOzNpZ4388x-iwISjqAzxnDAgM8F4-HL5gHLAGs3AIuqhns-gNJfA_AT9lmAMvItLRDEP5OjHPRFRA6OldJrY6Yost66LZ8Zsif8wIw6Uhkfa4PkN7/s785/image22.png “ style =”边距 - 左：自动;边缘右：自动;“>; &lt;img border =“ 0” data-Foriginal-height =“ 409” data-eriginal-width =“ 785” SRC =“ https：// blogger.googleusercontent.com/img/b/r29vz2xl/avvxsehllyauj1cew8xcqnynmvggkz2bd55uhlzudlxvdn_tw4zbdw4zbdw4 zbbbbbbbbbbbbbbbbbbbbb i6 zvvvvvvvvvvvvvpzjjjjjjjjquznj jjjjjjjjjjjjjjjjjpazxpaz x.4-swpzpazxpazxpazxpazxpazxpazxpazxpaZ 5GHLAGS3AIUQHNS-GNJFA_AT9LMAMVITLRDEP5OJHPRFRA6OLDJRY6YOST66LZ8Z8ZSSIF8WIWIW6UHKFA4PKN7/S16000/s16000/image22.png字幕“ style =”文本align：中心;“>;每个属性测试仪的次数违反了经过测试的非私有机制的隐私行为。 NonDPLaplaceMean and NonDPGaussianMean mechanisms are faulty implementations of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Additive_noise_differential_privacy_mechanisms#Laplace_Mechanism&quot;>;Laplace&lt;/a>; and &lt;a href=&quot;https://en.wikipedia. org/wiki/addistil_noise_differential_privacy_mechanisms＃gaussian_mechanism“>;高斯&lt;/a>;计算平均值的机制&lt;a href=&quot;https://github.com/tensorflow/privacy/blob/blob/master/tensorflow_privacy/privacy/privacy/privacy/pptimizers/dp_optimizer_keras.keras.keras.keras.py&quot;>; DP梯度渐变discent algorithM &lt;/gorithm &lt;/a>;（DP-GD）私人数据上的损失功能。为了保留隐私，DP-GD采用剪裁机制来绑定&lt;a href=&quot;https://mathworld.wolfram.com/l2-norm.html&quot;>; l2-norm &lt;/a>;梯度的价值&lt;/a>; em>; g &lt;/em>;，然后增加高斯噪声。该实现错误地假设添加的噪声具有&lt;em>; g &lt;/em>;的比例，而实际上，量表为&lt;em>; sg &lt;/em>;，其中&lt;em>; s &lt;/em>;是一个正面的标量。这种差异导致近似的DP保证，仅适用于大于或等于1的值，我们评估了属性测试人员在检测此错误中的有效性Hockeystickpropertytester和RényiPropertytester在识别侵犯隐私，表现优于MMDPropertytester和Histogroperpertytester方面表现出色。值得注意的是，这些测试人员即使在&lt;em>; s &lt;/em>;的值高达0.6的值中也检测到错误。 It is worth highlighting that &lt;em>;s &lt;/em>;= 0.5 corresponds to a &lt;a href=&quot;https://github.com/tensorflow/privacy/blob/308cbda4db6ccad5d1e7d56248727274e4c0c79e/tensorflow_privacy/privacy/analysis/compute_dp_sgd_privacy_lib.py#L445C1 -l446c1“>;常见错误&lt;/a>;在考虑隐私预算&lt;em>;ε&lt;/em>;的文献中涉及丢失两个因子。 DP原告成功捕获了此错误，如下所示。有关更多详细信息，请参见第5.6节&lt;a href=&quot;https://arxiv.org/pdf/2303.00654.pdf&quot;>;在这里&lt;/a>;。 &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container”样式=“ margin-left：auto; auto; margin-right：auto; auto;“>; &lt;tbody>; &lt;trody>; &lt;try>; &lt;tr>; &lt; td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-pnMcLqTWv1vSIZWncvObk3acW_SkBS3Lp_KuspJPbGBSjlepwW0hTLkCgLA7yTgU35y-Kj4HC_ddRX1fXS6T_HoF5Na87cSIcdiTBAwHnQ1sQZV3pdir_SI5PuwT7HAMEYmQohCd7wI84bNjKSt4sUVdnk9dOAXtkxCUDgzd3KZs5r2G2Z4jIZR0-FJH/s836/image21.jpg&quot; imageanchor=&quot; 1“ style =”保证金左：自动;边缘右：auto;“>; &lt;img border =“ 0” data-Original-height =“ 332” data-Original-width =“ 836” src =“ https：/ https：/ https：/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-pnMcLqTWv1vSIZWncvObk3acW_SkBS3Lp_KuspJPbGBSjlepwW0hTLkCgLA7yTgU35y-Kj4HC_ddRX1fXS6T_HoF5Na87cSIcdiTBAwHnQ1sQZV3pdir_SI5PuwT7HAMEYmQohCd7wI84bNjKSt4sUVdnk9dOAXtkxCUDgzd3KZs5r2G2Z4jIZR0-FJH/s16000/image21.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr -caption“ style =” text-align：center;“>;估计的差异和测试阈值&lt;em>; s &lt;/em>;的不同值&lt;em>; s &lt;/em>;使用Histogroperpertytester（&lt;strong>;左>; &lt;/strong>;）和Hockeystickpropertytester（&lt;strong>;右&lt;/strong>;）。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;br />; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” 0“” class =“ tr-caption-container”样式=“边距 - 左：auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibbce0TFnWcnJ4CoXPVVyuZrja_3JJTnBjsza7Ig-NibA14jHoh4TIuIhLRn9BgCdo_N4hSuft7Zpl3WgNjmteMUGkQ5xdjeFH2SzZlKmPR_PvXS-JeOIcwJO8J_h7SlR9_tknZ0fLbP2qOypalwVm-nZO118Oa67zgdi_VGc72tAzGKaYpGoWIl6p_ljD/s828/image20.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto;边缘权利：自动;“>; &lt;img border =“ 0” data-original-height =“ 333” data-eriginal-width =“ 828” src =“ https://blogger.googleusercontent.com/img/img/b/ R29VZ2XL/AVVXSEIBBCE0TFNWCNJ4COXPVVYUZRJA_3JJTNBJSZZA7IG-NIBA14JHOHHOHLN9BGCDO_N4HSUIHLRRN4HSU_N4HSU_N4HSU_HSU_HSU_HSU_HSU_HSU_HSU_HSU_HSU_HHSU_HSUFFFTEMN KNZ0FLBP2QOYPALWVM-NZO118OA67ZGDI_VGC72TAZGKAYPGOWIL6P_LJD/s16000/image20.jpg“ ;“>;用rényipropertytester（&lt;strong>; left &lt;/strong>;）和mmdpropertytester（&lt;strong>;右>; &lt;/strong>;右>; &lt;/strong>;） ）&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;b>;要测试数据集查找器，我们在发现隐私侵犯之前探索了探索的数据集数量。平均而言，大多数错误是在少于10个调用数据集查找器的电话中发现的。随机和探索/剥削方法比网格搜索更有效地查找数据集。有关更多详细信息，请参阅&lt;a href=&quot;https://arxiv.org/abs/2307.05608&quot;>;纸&lt;/a>;。 &lt;/p>; &lt;div style =“线路高：40％;”>; &lt;br />; &lt;/>; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; dp是数据保护最强大的框架之一。但是，正确实施DP机制可能具有挑战性，并且容易使用传统的单元测试方法来轻易检测到的错误。统一的测试框架可以帮助审计师，监管机构和学者确保私人机制确实是私人的。 &lt;/p>; &lt;p>; dp-auditorium是通过功能空间优化DP测试DP的一种新方法。我们的结果表明，这种基于功能的估计始终优于先前的黑盒访问测试仪。最后，我们证明这些基于函数的估计器与直方图估计相比，可以更好地发现隐私错误的发现率。由&lt;a href=&quot;https://github.com/google/differential-privacy/tree/main/main/python/dp_auditorium&quot;>;开放源&lt;/a>; DP-Auditorium，我们旨在为端到 - 最终测试新的差异私有算法。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>;确认&lt;/h2>; &lt;p>; &lt;em>;此处描述的工作是与AndrésMuñoz共同完成的麦地那，威廉·孔和乌马尔·赛义德。我们感谢Chris Dibak和Vadym Doroshenko为我们的图书馆提供了有益的工程支持和界面建议。&lt;/em>; &lt;/p>; &lt;/pents>; &lt;link href =“ http://blog.research.google/feeds/feeds/593333333333333333333333333333333333333333333333333333333460125094774/comments /默认值“ rel =”回复“ title =” post注释“ type =” application/atom+xml“/>; &lt;link href =” http://blog.research.google/2024/02/dp-auditorium-flexible- Library-for.html＃comment-form“ rel =” reply =“ title =” 0注释“ type =” text/html“/>; &lt;link href =” http://www.blogger.com/feeds/847492633145202626262626262626262626/posts /default/5933365460125094774&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5933365460125094774&quot; rel=&quot;self “ type =” application/atom+xml“/>; &lt;link href =” http://blog.research.google/2024/02/dp-auditorium-flexible-library-library-for.html“ rel =” re =“替代” title = “ DP-ADITORIUM：一个灵活的库库” &lt;/uri>; &lt;email>; noreply@blogger.com &lt;/email>; &lt;gd：image height =“ 16” rel =“ http://schemas.google.com/g/g/2005#thumbnail” src =“ https：/https：/ /img1.blogblog.com/img/b16-rounded.gif“ width =“ 16”>; &lt;/gd：image>; &lt;/furet>; &lt;媒体：thumbnail Height =“ 72” url =“ https：//blogger.googleusercorcercontent 。 9KrdyZQXN38JKVH6XCMLV6FZ1G0UFAXTKORHTTY0WUJEXLPQV6P2C9RPDG_W_W_W_5ZP/s72-c/hire.jpg“ /“>; &lt;/媒体：缩略图>; &lt;thr：thr>; 0 &lt;/thr：thr>; &lt;/entry>; &lt;/entry>; &lt;entry>; &lt;id>;标签：blogger.com，1999：blog-8474926331452026626.post-3264646469415710647310 &lt;/id>; &lt;发布>;2024-02-06T11:17:00.000-08:00&lt;/发布>;&lt;更新>;2024-02-06T11:17:53.968-08:00&lt;/更新>;&lt;category schema=&quot;http://www .blogger.com/atom/ns＃“ term =“图形挖掘”>; &lt;/category>; &lt;category scheme =“ http://www.blogger.com/atom/ns#” >; &lt;类别方案=“ http://www.blogger.com/atom/ns#” term =“机器学习”>; &lt;/category>; &lt;category>; &lt;类别spece =“ http://wwwww.blogger.com/atom/ns ＃“ term =” tensorflow“>; &lt;/category>; &lt;title type =“ text”>; tensorflow中的图形神经网络&lt;/stitle>; &lt;content type =“ html”>; &lt;span class =“ byline-author”>; dustin Zelle，软件工程师，Google Research和Arno Eigenwillig，软件工程师，Coreml &lt;/span>; &lt;img src =“ htttps://blogger.google.googleusercercercorcercontent.com/img/r29vz2x2xxl/r29vz2xl/ G4MUM5I-7T3ZDLWUWN5DCCUQI5FKQ-C3EIBPNUQFOLUKFUSX -i3ovim1teps_jkikzh7xqghupnsoa2y3peugwcpnyg4ziqa2_kqwxjpflo0wm6gnwm6gnw8txg5edndiwx_dkk _dkk/s1600/s1600/tfgnn％/tfgnn％20HERO.GIF />; &lt;p>;对象及其关系在我们周围的世界中无处不在，对于理解对象的关系与孤立观看的自己的属性一样重要 - 以运输网络，生产网络，知识图或社交网络为例。离散的数学和计算机科学在形式化&lt;em>; &lt;em>; &lt;a>; &lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/graph_(Discrete_mathematics fornation等网络方面有悠久的历史。由&lt;em>; nodes &lt;/em>;组成&lt;em>; edges &lt;/em>;以各种不规则方式连接。然而，大多数机器学习（ML）算法仅允许输入对象之间的常规和统一关系，例如像素的网格，一系列单词或根本没有关系。 &lt;/p>; &lt;a name=&#39;more&#39;>; &lt;/a>; &lt;p>; &lt;a href=&quot;https://distill.pub/2021/gnn-intro/&quot;>;图形神经网络&lt;/a>;简而言之，已经成为一种强大的技术来利用图形的连接性（如较旧的算法&lt;a href=&quot;http://perozzi.net/projects/projects/deepwalk/&quot;>; deepwalk &lt;/a>;和&lt;a href = a href = “ https://snap.stanford.edu/node2vec/&quot;>; node2vec &lt;/a>;）和各种节点和边缘上的输入功能。 GNNS可以对整个图表进行预测（该分子以某种方式反应？），单个节点（鉴于该文档的引用是什么主题？）或潜在的边缘（该产品是可能一起购买的，使用该产品？）。除了对图表进行预测外，GNN是一种强大的工具，用于桥接鸿沟，以弥补更典型的神经网络用例。他们用A &lt;em>;连续&lt;/em>;的方式编码图形的&lt;em>;离散&lt;/em>;，&lt;em>;关系&lt;/em>;信息，以便自然地将其包含在另一个深度学习系统中。 &lt;/p>; &lt;p>;我们很高兴宣布发布&lt;a href=&quot;https://github.com/tensorflow/tensorflow/gnn&quot;>; tensorflow gnn 1.0 &lt;/a>;（tf-gnn），一种生产测试的用于在大尺度上建造GNN的库。它支持Tensorflow中的建模和训练，以及从大型数据存储中提取输入图。 TF-gnn是从头开始构建的，以用于异质图，其中对象和关系的类型由不同的节点和边缘组表示。现实世界中的对象及其关系发生在不同的类型中，而TF-GNN的异质焦点使代表它们很自然。 &lt;/p>; &lt;p>;在TensorFlow中，此类图由类型&lt;code>; tfgnn.graphtensor &lt;/code>;的对象表示。这是一种复合张量类型（一个python类中的张量），被接受为&lt;a href=&quot;https://en.wikipedia.org/wiki/first-class_citizen&quot;>; &lt;code>; tf.data.dataset &lt;/code>;，&lt;code>; tf.function &lt;/code>;等。它同时存储图形结构及其附加到节点，边缘和整个图形的功能。图形传感器的可训练转换可以定义为高级&lt;a href=&quot;https://www.tensorflow.org/guide/keras&quot;>; keras api &lt;/a>;或直接使用&lt;code>; tfgnnn， .graphtensor &lt;/code>;原始。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>; gnns：在上下文中对对象进行预测&lt;/h2>; &lt;p>;用于插图，让我们看看在TF-GNN的一个典型应用中：预测通过巨大数据库的交叉引用表定义的图表中某种类型的节点的属性。例如，具有一对一引用的计算机科学（CS）ARXIV论文的引用数据库和多一的引用关系，我们想预测每篇论文的主题领域。 &lt;/p>; &lt;p>;像大多数神经网络一样，在许多标记示例的数据集（约百万）的数据集上，GNN受到培训，但每个培训步骤仅包含少量较小的培训示例（例如，数百个）。为了扩展到数百万，GNN在底层图的相当小子图表上进行了训练。每个子图都包含足够的原始数据来计算其中心标记节点的GNN结果并训练模型。这个过程（通常称为子图抽样）对于GNN培训非常重要。大多数现有的工具都以批处理方式完成采样，从而生成静态子图进行培训。 TF-GNN提供了通过动态和互动进行采样来改进这一点的工具。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhE36FVnslwVrX4LjLgpe5NOcVgJ2WSHCaw64LT9pMhjhHOFt-1pjp1AhaXqjxfEODX04Buw93D1G36HOStu5_mWUEdNs0gZTa1c7MXJ6ir9DYOp_HCYpFMT5NZiBbHxNwvUmF-dwhN2rgKQX0CeFY25X9aFnoD0W7bzL_xtkDJFdP0guocAJDSOgBHIiZm/s800/image2.gif&quot; style =“ Margin-Left：auto; Margin-Right：auto;”>; &lt;img border =“ 0” data-Original-height =“ 600” data-Original-width =“ 800” src =“ https：// blogger。 googleusercontent.com/img/b/R29vZ2xl/AVvXsEhE36FVnslwVrX4LjLgpe5NOcVgJ2WSHCaw64LT9pMhjhHOFt-1pjp1AhaXqjxfEODX04Buw93D1G36HOStu5_mWUEdNs0gZTa1c7MXJ6ir9DYOp_HCYpFMT5NZiBbHxNwvUmF-dwhN2rgKQX0CeFY25X9aFnoD0W7bzL_xtkDJFdP0guocAJDSOgBHIiZm/s16000/image2.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= “文本 -  align：中心;”>;如图所示，从较大的图形中对小的，可拖动的子图进行采样以创建用于GNN训练的输入示例。&lt;/td>; &lt;/td>; &lt;/tr>; &lt;/tr>; &lt;/tbody>; &lt;/tbody>; &lt;/tbody>; &lt;/tbody>; >; &lt;p>; TF-GNN 1.0首次亮相灵活的Python API，以在所有相关尺度上配置动态或批次子图抽样：在COLAB笔记本中进行互动性（例如&lt;a href =” https://colab.research.research.google.com/github.com/github.com/github.ghithub.com/github /tensorflow/gnn/blob/master/examples/notebooks/ogbn_mag_e2e.ipynb&quot;>; this One &lt;/a>;），用于有效地采样存储在单个训练主机的主要存储器中的小数据集=“ https://beam.apache.org/”>; apache beam &lt;/a>;用于存储在网络文件系统上的巨大数据集（最多数亿个节点和数十亿个边缘）。有关详细信息，请参阅我们的用户指南以获取&lt;a href=&quot;https://github.com/tensorflow/gnn/blob/main/main/main/tensorflow_gnn/docs/guide/guide/inmemory_sampler.md&quot;>; in-memory &lt;/a>; and-memory &lt;/a>; andmemory &lt;/a>; &lt;a href=&quot;https://github.com/tensorflow/gnn/blob/main/main/tensorflow_gnn/docs/guide/geide/beam_sampler.md&quot;>;基于beam的&lt;/a>;分别采样。 &lt;/p>; &lt;p>;在那些相同的采样子图上，GNN的任务是计算根节点处的隐藏状态（或潜在）状态；隐藏状态聚集并编码根节点邻域的相关信息。一种经典的方法是&lt;a href=&quot;https://research.google/pubs/neural-message-passing-for-quantum-chemistry/&quot;>; message-pass-passing神经网络&lt;/a>;。在每一轮消息传递中，节点都会从传入的边缘接收邻居的消息，并从他们那里更新自己的隐藏状态。在&lt;em>; n &lt;/em>;圆圈之后，根节点的隐藏状态反映了&lt;em>; n &lt;/em>;边缘中所有节点的汇总信息（如下图所示，用于&lt;em>; n &lt;/em>; = 2） 。消息和新的隐藏状态由神经网络的隐藏层计算。在异质图中，使用单独训练的隐藏层用于不同类型的节点和边缘&lt;/p>; &lt;table align =“ center” cellpadding =“ 0” cellSpacing =“ 0” class =“ traption -Container“ style =” Margin-Left：auto; Margin-Right：auto;“>; &lt;tbody>; &lt;try>; &lt;tr>; &lt;td style =” text-align：center;“>; &lt;a href =” https：//blogger。 googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMrCrQ1SCcwhZfE33X46EifocYAmKCPXMVe1d4na1V6flQavJ_f_FKtnlQbe2vnvzbSEtx5mxJHZ2OlQbO9rsiEhiPLY1PKQOT-EwahobMIVC92PZJs8RroEuYswHCpEjjpwqPrpqzKsDgrNaiY4lM_E8NVnxVRsYn0PNxe3TghByKJpW9V_YRD0RnNnm4/s573/image1.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height= &quot;511&quot; data-original-width=&quot;573&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMrCrQ1SCcwhZfE33X46EifocYAmKCPXMVe1d4na1V6flQavJ_f_FKtnlQbe2vnvzbSEtx5mxJHZ2OlQbO9rsiEhiPLY1PKQOT-EwahobMIVC92PZJs8RroEuYswHCpEjjpwqPrpqzKsDgrNaiY4lM_E8NVnxVRsYn0PNxe3TghByKJpW9V_YRD0RnNnm4/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td >; &lt;/tr>; &lt;tr>; &lt;td class =“ tr caption” style =“ text-align：center;”>;如图所示，一个简单的消息串起的神经网络，在每个步骤中，节点状态都从外部传播到将其合并以计算新节点状态的内部节点。一旦达到根节点，就可以做出最终预测。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;p>;训练设置是通过将输出层放在GNN隐藏状态的顶部来完成的对于标记的节点，计算&lt;em>;损失&lt;/em>;（以测量预测误差），并像往常一样通过反向传播来更新模型权重。 &lt;/p>; &lt;p>;除了有监督的培训之外（即最大程度地减少标签定义的损失），GNNS还可以以无监督的方式进行培训（即没有标签）。这使我们能够计算节点及其特征的&lt;em>;离散图结构的&lt;em>;连续&lt;/em>;表示（或&lt;em>;嵌入&lt;/em>;）。然后，这些表示通常在其他ML系统中使用。这样，图形编码的离散关系信息可以包含在更典型的神经网络用例中。 TF-GNN支持无与伦比图的无监督目标的细粒度规范。 &lt;/p>; &lt;div style =“线路高：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>;建筑物gnn Architectures &lt;/h2>; &lt;p>; TF-GNN库支持建筑和培训GNNS各种水平的抽象。 &lt;/p>; &lt;p>;在最高级别上，用户可以将任何预定义的模型与在keras层中表达的库捆绑在一起的任何预定义型号。除了从研究文献中收集的少量模型外，TF-GNN还配备了高度可配置的模型模板，该模型提供了精选的模型选择，我们发现这些选择可为许多内部问题提供强大的基线。这些模板实现了GNN层；用户只需要初始化KERAS层即可。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMfB8QoX14UU1GEAmFFOP0cAj__zxa_MKzVSiJoak9cVLNdbbhrSxbIWhqQM3OYKA5lo7zW8sWr6-9utm-rw0808rBOE4Cbw7NZxcmifenvF6DCH4opWhVQJHR-MLGcFoNu_WpET5h1PZRdXMhjcyKgBg3NchNTPq6gWVVluzcQNaO5qtonVp5KnJRgUaD/s1400/TFGNN%20code1 。 src =“ https://blogger.googleusercontent.com/img/b/r29vz2xl/avvxsejmfb8qox14uu1geamffop0ca__zxa_zxa_mkzvsvsvsvsvsvsijoo ZXCMIFENVF6DCH4OPWHVQJHR-MLGCFONU_WPET5H1PZRDXMHJCYKGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGBGWVVLUZCCQNAO5QTONVP5KNJRAD/s16000/s16000/tfgnn％20Code1.pode1.png &lt;/>; &lt;/>; &lt;/>; &lt;/tr /tbody>; &lt;/table>; &lt;p>;在最低级别上，用户可以根据围绕图形传递数据的原始内容来从头开始编写GNN模型，例如将数据从节点传播到所有传出的边缘或将数据汇总到来自其所有传入边缘的节点（例如，计算传入消息的总和）。当涉及功能或隐藏状态时，TF-GNN的图形数据模型平均处理节点，边缘和整个输入图，这使得不仅表达了以上讨论的MPNN等节点中心模型，还可以表达出更通用的&lt;a href = a href =的更通用形式。 “ https://arxiv.org/abs/1806.01261&quot;>; Graphnets &lt;/a>;。这可以（但不需要）用凯拉斯（Keras）作为核心张力量顶部的建模框架。有关建模的更多详细信息和中间级别，请参见TF-GNN &lt;a href=&quot;https://github.com/tensorflow/gnn/blob/main/main/main/tensorflow_gnn/docs/guide/guide/ghn_modeling.md&quot;>;用户指南&lt; /a>;和&lt;a href=&quot;https://github.com/tensorflow/gnn/tree/main/main/tensorflow_gnn/models&quot;>;模型集合&lt;/a>;。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/div>; &lt;h2>;训练编排&lt;/h2>; &lt;p>;虽然高级用户可以自由进行自定义模型培训，但&lt;a href=&quot;https://github.com/tensorflow/gnn/blob/main/main/tensorflow_gnn/docs/guide/runner.md&quot;>; tf-gnn Runner &lt;/a>;海角模型在常见情况下。一个简单的调用可能看起来像这样：&lt;/p>; &lt;table align =“中心” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container” style =“ margin-Left：auto; auto; margin-right; margin-right : auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxRRMrWL-AyxpHeyAhffhApAzlq-u7FoZaDnZFlwRsoYCljzZNi0LmRDDMwZ7mkXeBK0oUFujf_TDD -zltqccgnlghpedfrj2vs-d5-rpzfwxaarpojit-mh3n8tj7nzy-sfxtjxjdrhqy_hvua3-_c8_xqjffrwblo -LEFT：自动;边缘右：自动;“>; &lt;img border =” 0“数据原始高度=“508”数据原始宽度=“1400”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxRRMrWL-AyxpHeyAhffhApAzlq-u7FoZaDnZFlwRsoYCljzZNi0LmRDDMwZ7mkXeBK0oUF ujf_TDD-zlTQcgnLGhPedfrJ2vVs-D5-RPZFWXaaRpOJIt -MH3N8Tj7NZy-SFXTjxjDrhHQY_HVUA3-_C8_xQjfRWBlO-dzcFzgUL6wynMWJhUM7z_MYKvF/s16000/TFGNN%20code2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Runner 提供即用型针对 ML 难题的解决方案，例如分布式训练和 Cloud TPU 上固定形状的 tfgnn.GraphTensor 填充。除了对单个任务进行训练（如上所示）之外，它还支持对多个（两个或更多）任务进行联合训练。例如，无监督任务可以与有监督任务混合，以告知具有应用程序特定归纳偏差的最终连续表示（或嵌入）。调用者只需用任务映射替换任务参数： &lt;/p>; &lt;tablealign=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/ AVvXsEg4GGpfZib5MAUnX7BRLywJC4xMVt9Tz8kSMhgyDGN5A-aS9k-gna_t0Fo3uxMaAb8gK0ovrOO3XkeSNZ3i24leBCNsALR2NU_MWI7M_s47p2bx-aviaUKy_DxDEkzndNYMI_52jcEmNKyJrqDFye3_ PHaWJZz7MAQ1lVW-YpuWPOOYpSAfbrunU5q4M2ev/s1400/TFGNN%20code3.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; 数据原始-height =“392”数据原始宽度=“1400”src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4GGpfZib5MAUnX7BRLywJC4xMVt9Tz8kSMhgyDGN5A-aS9k-gna_t0Fo3uxMaAb8gK0ovrOO3XkeSNZ3i24leBC NsALR2NU_MWI7M_s47p2bx-aviaUKy_DxDEkzndNYMI_52jcEmNKyJrqDFye3_PHaWJZz7MAQ1lVW-YpuWPOOYpSAfbrunU5q4M2ev/s16000/TFGNN%20code3。 png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 此外，TF-GNN Runner 还包括 &lt;a href=&quot;https://www.gnn.png&quot; 的实现。 tensorflow.org/tutorials/interpretability/integrated_gradients&quot;>;用于模型归因的集成梯度&lt;/a>;。集成梯度输出是一个 GraphTensor，与观察到的 GraphTensor 具有相同的连接性，但其特征被梯度值取代，其中较大的值比较小的值在 GNN 预测中贡献更多。用户可以检查梯度值，以了解其 GNN 使用最多的特征。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 简而言之，我们希望 TF-GNN 能够有助于推进GNN 在 TensorFlow 中的大规模应用，并推动该领域的进一步创新。如果您想了解更多信息，请尝试我们的 &lt;a href=&quot;https://colab.sandbox.google.com/github/tensorflow/gnn/blob/master/examples/notebooks/ogbn_mag_e2e.ipynb&quot;>;Colab演示&lt;/a>;与流行的OGBN-MAG基准（在您的浏览器中，无需安装），浏览我们的其余部分&lt;a href=&quot;https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/ docs/guide/overview.md&quot;>;用户指南和 Colab&lt;/a>;，或者查看我们的&lt;a href=&quot;https://arxiv.org/abs/2207.03522&quot;>;论文&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;TF-GNN 版本 1.0 是由Google 研究部之间的合作：Sami Abu-El-Haija、Neslihan Bulut、Bahar Fatemi、Johannes Gasteiger、Pedro Gonnet、Jonathan Halcrow、Liangze Jiang、Silvio Lattanzi、Brandon Mayer、Vahab Mirrokni、Bryan Perozzi、Anton Tsitsulin、Dustin Zelle、Google Core ML：Arno Eigenwillig、Oleksandr Ferludin、Parth Kothari、Mihir Paradkar、Jan Pfeifer、Rachael Tamakloe 和 Google DeepMind：&lt;strong>; &lt;/strong>;Alvaro Sanchez-Gonzalez 和 Lisa Wang。&lt;/em>; &lt;/p>; &lt;/content >;&lt;link href=&quot;http://blog.research.google/feeds/3264694155710647310/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href= “http://blog.research.google/2024/02/graph-neural-networks-in-tensorflow.html#comment-form”rel =“replies”title =“0条评论”type =“text/html”/ >; &lt;link href =“ http://www.blogger.com/feeds/8474926331452026626/posts/posts/default/32646469415710647310” /www.blogger.com/feeds/8474926331452026626/posts/default/3264694155710647310&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/ 02/graph-neural-networks-in-tensorflow.html&quot; rel=&quot;alternate&quot; title=&quot;TensorFlow 中的图神经网络&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt; uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google .com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcnTwrjg8cyZhVY1c-qi2ZEenIrDlkmlKlX0GsAuiKiIoxUu6i-phANh8tsCG4mUm5i-7t3zdLwuwn5DCcuQI5FKq-C3eibPnuqfoLuKFUsx-I3Ovim1Teps_JKiKZH7XqgHupnsOa2Y3peUgWcPNYG4ZIqA2_KQwxJpflo0WM6gNW8tXg5eDndiWx_dKK/s72-c/TFGNN%20hero.gif&quot; width=&quot;72 &quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;标签： Blogger.com，1999年：Blog-8474926331452026626.POST-6956767920612914706 &lt;/id>; &lt;/id>; &lt;出版>; 2024-02-02-02T11：07：00.000-08：008：008：00：00.000-08：00 &lt;/00 08:00 &lt;/updated>; &lt;类别方案=“ http://www.blogger.com/atom/ns#” term =“ Google Cloud Platform”>; &lt;/category>; &lt;category>; &lt;category scheme =“ http：//www。 blogger.com/atom/ns#&quot; term=&quot;机器学习&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;用于时间序列预测的仅解码器基础模型&lt;/stitle>;&lt;content type=&quot;html&quot; >;&lt;span class=&quot;byline-author&quot;>;发布者：Rajat Sen 和 Yichen Zhou，Google 研究中心&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjLAVI4q3e6yNyTPTCFiLZVQfFm71GOX1TosHg_Sb8M6tVSO1hyphenhyphenZccOlufnqSuXP1rVWHm qHcely6fgW1vex4JdxenniJcaJ7TOomZolUFut8RUdxnOFZDrbt0hrIHkcrK7rl6cq5-kUuWGrOYqIirPAKtnf4vMDauPX4lFAz2PQjiqzqHxMna7eja9gOF/ s320/hero.jpg&quot; style=&quot;显示：无；&quot; />; &lt;p>; &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_series&quot;>;时间序列&lt;/a>;预测在零售、金融、制造、医疗保健和自然等各个领域无处不在科学。 In retail use cases, for example, it has been observed that &lt;a href=&quot;https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-applications-and- value-of-deep-learning&quot;>;提高需求预测准确性&lt;/a>;可以显着降低库存成本并增加收入。深度学习 (DL) 模型已成为预测丰富、多元、时间序列数据的流行方法，因为它们已被证明在各种设置中都表现良好（例如，DL 模型在 &lt;a href=&quot;https: //www.sciencedirect.com/science/article/pii/S0169207021001874&quot;>;M5 竞赛&lt;/a>;）。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 与此同时，用于自然语言处理（NLP）任务的大型基础语言模型也取得了快速进展，例如&lt;a href= “https://en.wikipedia.org/wiki/Machine_translation&quot;>;翻译&lt;/a>;，&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2023/09/retrieval-augmented- Generation-rag -in-ai/&quot;>;检索增强生成&lt;/a>;和&lt;a href=&quot;https://en.wikipedia.org/wiki/Intelligent_code_completion&quot;>;代码完成&lt;/a>;。这些模型经过大量&lt;em>; textual &lt;/em>;数据的培训，这些数据来自各种来源，例如&lt;a href=&quot;https://commoncrawl.org/&quot;>; Common Common Crawl &lt;/a>;这使他们能够识别语言中的模式。这使得它们非常强大的&lt;a href=&quot;https://en.wikipedia.org/wiki/Zero-shot_learning&quot;>;零样本&lt;/a>;工具；例如，&lt;a href=&quot;https://blog.google/products/bard/google-bard-try-gemini-ai/&quot;>;与检索配合使用时&lt;/a>;，它们可以回答有关当前事件的问题并进行总结。 &lt;/p>; &lt;p>; 尽管基于深度学习的预测器在很大程度上&lt;a href=&quot;https://arxiv.org/abs/1704.04110&quot;>;表现优于&lt;/a>;传统方法，并且在&lt;a href=&quot;https: //cloud.google.com/blog/products/ai-machine-learning/vertex-ai-forecasting&quot;>;降低训练和推理成本&lt;/a>;，他们面临挑战：大多数深度学习架构需要&lt;a href=&quot;https: //cloud.google.com/blog/products/ai-machine-learning/vertex-ai-forecasting&quot;>;在客户可以在新的时间序列上测试模型之前，需要经过漫长而复杂的培训和验证周期&lt;/a>;。相比之下，时间序列预测的基础模型可以对未见的时间序列数据提供良好的开箱即用的预测，无需额外的训练，使用户能够专注于对实际下游任务的细化预测，例如&lt;a href =&quot;https://en.wikipedia.org/wiki/Customer_demand_planning&quot;>;零售需求规划&lt;/a>;。 &lt;/p>; &lt;p>; 为此，在“&lt;a href=&quot;https://arxiv.org/pdf/2310.10688.pdf&quot;>;用于时间序列预测的仅解码器基础模型&lt;/a>;”中，我们引入了 TimesFM，这是一个在包含 1000 亿个现实世界时间点的大型时间序列语料库上进行预训练的单一预测模型。与最新的大型语言模型（LLM）相比，TimesFM 要小得多（2 亿个参数），但我们表明，即使在这样的规模下，它在不同领域和时间粒度的各种未见过的数据集上的零样本性能也接近在这些数据集上明确训练的最先进的监督方法。今年晚些时候，我们计划在 &lt;a href=&quot;https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/train-model#aiplatform_create_training_pipeline_tabular_forecasting_sample-python&quot;>; 中向外部客户提供此模型Google Cloud Vertex AI&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;用于时间序列预测的仅解码器基础模型&lt;/h2>; &lt;p>; 法学硕士通常是以&lt;a href=&quot;https://arxiv.org/pdf/1801.10198.pdf&quot;>;仅解码器&lt;/a>;方式进行训练，涉及三个步骤。首先，文本被分解为称为令牌的子字。然后，这些令牌被送入堆叠的因果层，这些层产生与每个输入令牌相对应的输出（它无法处理未来的令牌） 。最后，对应于&lt;em>; i &lt;/em>; th代币的输出总结了以前令牌的所有信息，并预测了（&lt;em>; i &lt;/em>; +1）-th令牌。在推理过程中，LLM 一次生成一个令牌的输出。例如，当提示“法国的首都是什么？”时，它可能会生成标记“The”，然后以“法国的首都是什么？”为条件。 ”生成下一个标记“资本”，依此类推，直到生成完整的答案：“法国的首都是巴黎”。时间序列预测的基础模型应该适应可变的上下文（我们观察到的内容）和范围（我们查询模型预测的内容）长度，同时具有足够的能力来编码大型预训练中的所有模式数据集。与 LLM 类似，我们使用堆叠变压器层（自注意力和&lt;a href=&quot;https://en.wikipedia.org/wiki/Feedforward_neural_network&quot;>;前馈&lt;/a>;层）作为 TimesFM 模型的主要构建块。在时间序列预测的背景下，我们将补丁（一组连续的时间点）视为由最近的&lt;a href=&quot;https://arxiv.org/abs/2211.14730&quot;>;长-地平线预测工作&lt;/a>;。然后，任务是根据堆叠变压器层末尾的第 (&lt;em>;i&lt;/em>;) 个输出来预测第 (&lt;em>;i&lt;/em>;+1) 个时间点补丁。 &lt;/p>; &lt;p>; 然而，它与语言模型有几个关键的区别。首先，我们需要一个具有残差连接的&lt;a href=&quot;https://en.wikipedia.org/wiki/Multilayer_perceptron&quot;>;多层感知器&lt;/a>;块，将时间序列补丁转换为可以输入的令牌到变压器层以及&lt;a href=&quot;https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/&quot;>;位置编码&lt;/a>;（体育）。为此，我们使用类似于我们之前在&lt;a href=&quot;https://arxiv.org/abs/2304.08424&quot;>;长期预测&lt;/a>;中的工作的残差块。其次，在另一端，来自堆叠变压器的输出令牌可以用于预测比输入补丁长度更长的后续时间点的长度，即，输出补丁长度可以大于输入补丁长度。 &lt;/p>; &lt;p>; 考虑使用长度为 512 个时间点的时间序列来训练输入补丁长度为 32 和输出补丁长度为 128 的 TimesFM 模型。在训练期间，模型同时被训练为使用前 32 个时间点- 点预测接下来的128个时间点，前64个时间点预测第65至192个时间点，前96个时间点预测第97至224个时间点，依此类推。在推理过程中，假设给模型一个长度为 256 的新时间序列，并负责预测未来的接下来 256 个时间点。该模型将首先生成时间点 257 到 384 的未来预测，然后以初始 256 长度输入加上生成的输出为条件，生成时间点 385 到 512。另一方面，如果在我们的模型中，输出补丁长度等于输入补丁长度 32，那么对于相同的任务，我们将必须经历八个生成步骤，而不仅仅是上面的两个。这增加了累积更多错误的机会，因此，在实践中，我们发现较长的输出补丁长度可以为长范围预测带来更好的性能&lt;/p>; &lt;tablealign=&quot;center&quot;cellpadding=&quot;0&quot;cellspacing=&quot;0 “ class =“ tr-caption-container” style =“边距 - 左：auto; margin-right：auto;”>; &lt;tbody>; &lt;tbody>; &lt;tr>; &lt;td style =“ text-align：center; center;”>; &lt;a href = “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4G0lBOLUqlPIXJ3R68kjS984MBIKBPDBrCWtgmjVVTyQRqY6-rn3aHJjgxCbG-8csyBLsp0POILdeJ2VcsRy8lrip0k5DWsUpuL9LU1qOPXLW99mra Ndd6HVU791NYqJeTyY7LjuMnOIo6RGmkxBQqqaPrSsC0dELrwy21QUs1Jgwxr8flmdNkDV2tZsT/s1084/image3.jpg&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border= “0”数据原始高度=“674”数据原始宽度=“1084”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4G0lBOLUqlPIXJ3R68kjS984MBIKBPDBrCWtgmjVVTyQRqY6-rn3aHJjgxCbG-8csyBLsp0PO ILdeJ2VcsRy8lrip0k5DWsUpuL9LU1qOPXLW99mraNdd6HVU791NYqJeTyY7LjuMnOIo6RGmkxBQqqaPrSsC0dELrwy21QUs1Jgwxr8flmdNkDV2tZsT/s16000/image3。 jpg“/>; &lt;/a>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td class =“ tr-caption” style =“ text-align：center;”>; timesfm架构。&lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;预训练数据&lt;/h2>; &lt;p>; 就像LLM一样代币越多越好，TimesFM 需要大量合法的时间序列数据来学习和改进。我们花费了大量的时间来创建和评估我们的训练数据集，以下是我们发现效果最好的数据集：&lt;/p>; &lt;div style=&quot;margin-left: 40px;&quot;>; &lt;p>; &lt;strong>;合成数据有助于基础知识。&lt;/strong>;可以使用统计模型或物理模拟生成有意义的合成时间序列数据。这些基本的时间模式可以教会模型时间序列预测的语法。 &lt;/p>;&lt;/div>; &lt;div style=&quot;margin-left: 40px;&quot;>; &lt;p>; &lt;strong>;真实世界的数据增添了真实世界的味道。&lt;/strong>;我们梳理了可用的公共时间序列数据集，并有选择地汇集了1000亿个时间点的大型语料库。这些数据集包括 &lt;a href=&quot;https://trends.google.com/trends/&quot;>;Google 趋势&lt;/a>; 和 &lt;a href=&quot;https://meta.wikimedia.org/wiki/Research： Page_view&quot;>;维基百科页面浏览量&lt;/a>;，跟踪人们感兴趣的内容，并且很好地反映了许多其他现实世界时间序列的趋势和模式。这有助于 TimesFM 了解更大的情况，并在提供训练期间未见的特定领域上下文时更好地进行概括。 &lt;/p>;&lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;零样本评估结果&lt;/h2>; &lt;p>; 我们评估 TimesFM 零样本使用流行的时间序列基准对训练期间未见过的数据进行拍摄。我们观察到，TimesFM 的表现优于大多数统计方法，例如 &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average&quot;>;ARIMA&lt;/a>;、&lt;a href=&quot;https://en.wikipedia. org/wiki/Exponential_smoothing&quot;>;ETS&lt;/a>;，并且可以匹配或超越强大的深度学习模型，例如 &lt;a href=&quot;https://arxiv.org/abs/1704.04110&quot;>;DeepAR&lt;/a>;、&lt;a href=&quot; https://arxiv.org/abs/2211.14730&quot;>;PatchTST&lt;/a>; 已在目标时间序列上&lt;em>;显式训练&lt;/em>;。 &lt;/p>; &lt;p>;我们使用&lt;a href=&quot;https://huggingface.co/datasets/monash_tsf&quot;>; Monash预测存档&lt;/a>;来评估TimesFM的开箱即用绩效。该档案包含来自交通、天气和需求预测等各个领域的数万个时间序列，覆盖频率从几分钟到每年的数据。根据现有文献，我们检查&lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;>;平均绝对误差&lt;/a>; (MAE) &lt;a href=&quot;https://arxiv.org/ abs/2310.07820&quot;>;适当缩放&lt;/a>;，以便可以在数据集中进行平均。我们发现零样本（ZS）TimesFM 优于大多数监督方法，包括最近的深度学习模型。我们还将 TimesFM 与 &lt;a href=&quot;https://platform.openai.com/docs/models/gpt-3-5&quot;>;GPT-3.5&lt;/a>; 进行比较，以使用 &lt;a href 提出的特定提示技术进行预测=&quot;https://arxiv.org/abs/2310.07820&quot;>;llmtime(ZS)&lt;/a>;。我们证明 TimesFM 的性能优于 llmtime(ZS)，尽管其数量级要小一些。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIeNF6GcmbUvVvYpKxNSvwlm_swz6M3G7nTDl0INa2zq8AlvjTBCVuvwOw0dx48JCk4H3S0aBUcsvqj2BypV3340cbl qgD6yktoLBXzpxA2fwoM4n_KU8m0TfaESjihc3nx29RYVTpO4g09RCK-rucPulH3gqEOU9jO7EZ_VbDcFnfB_RHXmdpuZO_T_-g/s1476/image2.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;876&quot; data-original-width=&quot;1476&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIeNF6GcmbUvVvYpKxNSvwlm_swz6M3G7nTDl0INa2zq8AlvjTBCVuvwOw0dx48JCk4H3S0aBUcsvqj2BypV3340cblqgD6yktoLBXzpxA2fwoM4n_KU8m0 TfaESjihc3nx29RYVTpO4g09RCK-rucPulH3gqEOU9jO7EZ_VbDcFnfB_RHXmdpuZO_T_-g/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;TimesFM(ZS) 与 Monash 数据集上的其他监督和零样本方法相比的缩放 MAE（越低越好）。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br>; &lt;p>; 大多数 Monash 数据集都是短或中水平的，即预测长度不会太长。我们还根据最近最先进的基线 &lt;a href=&quot;https://arxiv.org/abs/2211.14730&quot;>;PatchTST&lt;/a>;（以及其他长期预测）在流行的长期预测基准上测试了 TimesFM。地平线预测基线）。在下图中，我们在 &lt;a href=&quot;https://paperswithcode.com/dataset/ett&quot;>;ETT&lt;/a>; 数据集上绘制了预测未来 96 和 192 个时间点任务的 MAE。该指标是在每个数据集的最后一个测试窗口上计算的（如 &lt;a href=&quot;https://arxiv.org/abs/2310.07820&quot;>;llmtime&lt;/a>; 论文所做的那样）。我们看到 TimesFM 不仅超越了 llmtime(ZS) 的性能，而且还与在各自数据集上显式训练的监督 PatchTST 模型的性能相匹配。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0DDM32GPO6zkmnIrObEP2OA92g45b-zSMHgCf-uNoj6Ed0M0zVsN7vmFmfgXT6Sh5p-W0xI1qj6YwXcqi3T6a D5hI9ZOJqT8Sobp43FGrtSsLUkI2poHnGml7Za4BMObSd6nEKUVL8wj7nHJDFYHbWaQOXOcfxvqXUcMxUZ3WVQW8Z5sabfFsi7M85_7I/s735/image1.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;433&quot; data-original-width=&quot;735&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0DDM32GPO6zkmnIrObEP2OA92g45b-zSMHgCf-uNoj6Ed0M0zVsN7vmFmfgXT6Sh5p-W0xI1qj6YwXcqi3T6aD5hI9ZOJqT8Sobp43FGrtSsLU kI2poHnGml7Za4BMObSd6nEKUVL8wj7nHJDFYHbWaQOXOcfxvqXUcMxUZ3WVQW8Z5sabfFsi7M85_7I/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;TimesFM(ZS) 相对于 llmtime(ZS) 和 ETT 数据集上的长期预测基线的最后一个窗口 MAE（越低越好）。&lt;/td>;&lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 我们训练一个解码器 -使用 100B 个现实世界时间点的大型预训练语料库进行时间序列预测的唯一基础模型，其中大部分是来自 Google 趋势的搜索兴趣时间序列数据和来自维基百科的页面浏览量。我们表明，即使是使用我们的 TimesFM 架构的相对较小的 200M 参数预训练模型，在来自不同领域和粒度的各种公共基准测试中也显示出令人印象深刻的零样本性能。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;这项工作是多个团队合作的结果Google 研究院和 Google Cloud 的个人，包括（按字母顺序排列）：Abhimanyu Das、Weihao Kong、Andrew Leach、Mike Lawrence、Alex Martin、Rajat Sen、Yang Yang、Skander Hannachi、Ivan Kuznetsov 和 Yichen Zhou。&lt;/em>; &lt; /p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6956767920612914706/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot; />;&lt;link href=&quot;http://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6956767920612914706&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>; &lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6956767920612914706&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http:// blog.research.google/2024/02/a-decoder-only-foundation-model-for.html&quot; rel=&quot;alternate&quot; title=&quot;用于时间序列预测的仅解码器基础模型&quot; type=&quot;text/html &quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:图片高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=“16” &quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjLAVI4q3e6yNyTPTCFiLZVQfFm71GOX1TosHg_Sb8M6tVSO1hyphenhyphenZccOlufnqSuXP1rVWHmqHcely6fgW1 vex4JdxenniJcaJ7TOomZolUFut8RUdxnOFZDrbt0hrIHkcrK7rl6cq5-kUuWGrOYqIirPAKtnf4vMDauPX4lFAz2PQjiqzqHxMna7eja9gOF/s72-c/英雄。 jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry >;&lt;id>;标签：blogger.com，1999：blog-8474926331452026626.post-2254287928040727502&lt;/id>;&lt;发布>;2024-02-02T09:49:00.000-08:00&lt;/发布>;&lt;更新>;2024-02- 02T09:49:36.211-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;深度学习&quot;>;&lt;/category>;&lt;category schema=&quot;http ://www.blogger.com/atom/ns#&quot; term=&quot;ICML&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;ML 公平性&quot; >;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Supervised Learning&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;干预早期读数以缓解虚假特征和简单性偏见&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Google Research 博士前研究员 Rishabh Tiwari 和研究科学家 Pradeep Shenoy&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdBd5rMRA2U1nd8fetuEweTgmHncn49ASMQtPlm6dfsr5V29RwsoUR8UtK4B7oSE1eiIdW-vD-gjCUK4tGZTbsY4XdO0adL2YtAjpgbF1S 3mL_Jw3f31SwLKYUtCOLJ807gdXdRmD5iVsrtc_Ii-BiqQacv89vbtRbNAIINa9PhKAF_sDAZu09FLs4599T/s1600/SiFer%20Hero.png&quot; style=&quot;显示：无；&quot; />; &lt;p>; 现实世界中的机器学习模型通常是根据有限的数据进行训练的，这些数据可能包含意外的&lt;a href=&quot;https://en.wikipedia.org/wiki/Bias_(statistics)&quot;>;统计偏差&lt;/a >;。例如，在 &lt;a href=&quot;https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html&quot;>;CELEBA&lt;/a>; 名人图像数据集中，金发碧眼的女性名人比例不成比例，导致分类器错误地预测“金发”为大多数女性面孔的头发颜色——在这里，性别是预测头发颜色的虚假特征。这种不公平的偏见可能会在&lt;a href=&quot;https://www.researchgate.net/publication/362524426_Addressing_fairness_in_artificial_intelligence_for_medical_imaging&quot;>;医疗诊断&lt;/a>;等关键应用中产生严重后果。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 令人惊讶的是，最近的工作还发现了深层网络通过所谓的“放大”这种统计偏差的固有趋势。深度学习的&lt;a href=&quot;https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf&quot;>;简单性偏差&lt;/a>;。这种偏差是深度网络在训练早期识别弱预测特征的倾向，并继续锚定这些特征，而无法识别更复杂和可能更准确的特征。考虑到上述情况，我们提出了简单而有效的解决方案，通过应用&lt;em>;早期读出&lt;/em>;和&lt;em>;特征遗忘&lt;/em>;来解决虚假特征和简单性偏差的双重挑战。 。首先，在“&lt;a href=&quot;https://arxiv.org/abs/2310.18590&quot;>;使用早期读数调节蒸馏中的特征偏差&lt;/a>;”中，我们展示了从深层网络的早期层进行预测（称为“早期读数”）可以自动发出有关所学习表示的质量问题的信号。特别是，当网络依赖于虚假特征时，这些预测更经常是错误的，而且更肯定是错误的。我们利用这种错误的信心来改善&lt;a href=&quot;https://arxiv.org/pdf/1503.02531.pdf&quot;>;模型蒸馏&lt;/a>;的结果，在这种情况下，更大的“老师”模型指导训练较小的“学生”模型。然后在“&lt;a href=&quot;https://arxiv.org/abs/2301.13293&quot;>;使用特征筛克服深度网络中的简单性偏差&lt;/a>;”中，我们通过让网络“忘记”来直接干预这些指标信号” 有问题的特征，从而寻找更好、更具预测性的特征。与以前的方法相比，这大大提高了模型泛化到未见过的领域的能力。我们的&lt;a href=&quot;https://ai.google/responsibility/principles&quot;>;人工智能原则&lt;/a>;和我们的&lt;a href=&quot;https://ai.google/responsibility/responsible-ai-practices/&quot;>;负责任的人工智能实践&lt;/a>;指导我们如何研究和开发这些先进的应用程序，并帮助我们应对统计偏差带来的挑战。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzG_p8Re7HHeTp_Qg_GwjX5LcHsE-TZDmHr3azTSOLKl4f1J4xcL9vxo46zicAl6QoIKIrTJaI2Z51iFq2oIC jeb6Ut4-W1W74bytv87pH3hKVJOotWWWDk0gwB-ak_YZRmtZyimw8b9lSJ1DRzh6uIpvIBN2pbIw-6MuN47rUjTK_RzLLfYXPrIjtpjRz/s1080/image3 .gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;540&quot; data-original-width=&quot;1080&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzG_p8Re7HHeTp_Qg_GwjX5LcHsE-TZDmHr3azTSOLKl4f1J4xcL9vxo46zicAl6QoIKIrTJaI2Z51iFq2oICjeb6Ut4-W1W74bytv87pH3h KVJOotWWWDk0gwB-ak_YZRmtZyimw8b9lSJ1DRzh6uIpvIBN2pbIw-6MuN47rUjTK_RzLLfYXPrIjtpjRz/s16000/image3.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;动画比较使用和不使用特征筛训练的两个模型的假设响应。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;用于去偏蒸馏的早期读数&lt;/h2>; &lt;p>;我们首先说明&lt;em>;早期读数的诊断价值&lt;/em >; 以及它们在去偏差蒸馏中的应用，即确保学生模型通过蒸馏继承教师模型对特征偏差的弹性。我们从一个标准的蒸馏框架开始，在该框架中，学生接受混合标签匹配的训练（最小化&lt;a href=&quot;https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e&quot;>;交叉熵损失&lt; /a>; 学生输出和真实标签之间）和教师匹配（最小化 &lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&quot;>;KL 散度&lt;/a >; 对于任何给定的输入，学生和教师输出之间的损失）。 &lt;/p>; &lt;p>; 假设有人在学生模型的中间表示之上训练一个线性解码器，即一个名为 &lt;em>;Aux&lt;/em>; 的小型辅助神经网络。我们将该线性解码器的输出称为网络表示的早期读出。我们的发现是，早期读数在包含虚假特征的实例上会产生更多错误，而且，这些错误的置信度高于与其他错误相关的置信度。这表明对早期读数错误的置信度是模型对潜在虚假特征依赖性的相当强的自动指标。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixpq4OhPGxL9gGW30-0kqQ_CieDj3PJcqw8L4_7fBDZOFKuQpI67ljqIItOoJ3U9-dpPd1CpofAG_ld689r0H cPTrzFeTd1ceMQ42C3CRPWWJMYknydHpJhFjQUjb-M6mx8ILQbWEBIOv-NSgTauMGgDZ8t3EMGHE3j6UN9HIF3BJmB63GhOzFwOVmswlc/s1128/image5 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;796&quot; data-original-width=&quot;1128&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixpq4OhPGxL9gGW30-0kqQ_CieDj3PJcqw8L4_7fBDZOFKuQpI67ljqIItOoJ3U9-dpPd1CpofAG_ld689r0HcPTrzFeTd1ceMQ42C3CRPWWJMYk nydHpJhFjQUjb-M6mx8ILQbWEBIOv-NSgTauMGgDZ8t3EMGHE3j6UN9HIF3BJmB63GhOzFwOVmswlc/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;说明早期读数（即辅助层的输出）在去偏蒸馏中的用法。在早期读数中自信错误预测的实例在蒸馏损失中的权重会增加。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;我们使用此信号来调节教师在蒸馏损失中的贡献在每个实例的基础上，结果发现训练有素的学生模型有显着改进。 &lt;/p>; &lt;p>; 我们在已知包含虚假相关性的标准基准数据集上评估了我们的方法（&lt;a href=&quot;https://arxiv.org/pdf/1911.08731.pdf&quot;>;Waterbirds&lt;/a>;、&lt;a href =“ https://mmlab.ie.cuhk.edu.hk/projects/celeba.html”>; celeba &lt;/a>;，&lt;a href =“ https://wwwww.tensorflow.org.org.org/datasets/datasets/catalog/catalog/catalog/civil_cymments >;公民评论&lt;/a>;，&lt;a href=&quot;https://cims.nyu.edu/~sbowman/multinli/&quot;>;MNLI&lt;/a>;）。每个数据集都包含数据分组，这些数据分组共享一个可能以虚假方式与标签相关的属性。例如，上面提到的 CelebA 数据集包括 {blondmale, blondfemale, non-blondmale,non-blondfemale} 等组，模型在预测头发颜色时通常在 {non-blondfemale} 组上表现最差。因此，模型性能的衡量标准是其&lt;em>;最差组准确度&lt;/em>;，即数据集中存在的所有已知组中准确度最低的。我们改进了所有数据集上学生模型的最差组准确度；此外，我们还提高了四个数据集中三个数据集的整体准确性，这表明我们对任何一组的改进都不会以牺牲其他组的准确性为代价。更多详细信息请参阅我们的&lt;a href=&quot;https://arxiv.org/pdf/2310.18590.pdf&quot;>;论文&lt;/a>;。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpQiz04rM3DMtDiusAWyWl92FMUKbafR0l2dGvrj17fX3nuvPDnyXMQaumsxDvch3ScnOCL4Duq5_O32dWbv_CTsIu5aNc -c3xrVAIXjQ3kmn0jZ_TZ5SJ7C2lq1oxLZ33-VKXSSPRa_oGUB5jJlsBTZupsHMeUtSVXLh414e1NVEgI1IamqhTA1dqU0s5/s1270/image4.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1014&quot; data-original-width=&quot;1270&quot; height=&quot;511&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpQiz04rM3DMtDiusAWyWl92FMUKbafR0l2dGvrj17fX3nuvPDnyXMQaumsxDvch3ScnOCL4Duq5_O32dWbv_CTsIu5aNc-c3xrVAIXjQ3kmn0jZ_TZ5 SJ7C2lq1oxLZ33-VKXSSPRa_oGUB5jJlsBTZupsHMeUtSVXLh414e1NVEgI1IamqhTA1dqU0s5/w640-h511/image4.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;不同蒸馏技术相对于 Teacher 模型的最差组精度的比较。我们的方法在所有数据集上都优于其他方法。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;使用特征筛克服简单性偏差&lt;/h2>; &lt;p>;在第二个密切相关的项目中，我们直接干预早期读数提供的信息，以改进&lt;a href=&quot;https://en.wikipedia.org/ wiki/Feature_learning&quot;>;特征学习&lt;/a>;和&lt;a href=&quot;https://developers.google.com/machine-learning/crash-course/generalization/video-lecture&quot;>;泛化&lt;/a>;。工作流程在&lt;em>;识别&lt;/em>;有问题的特征和&lt;em>;从网络中删除&lt;/em>;已识别的特征之间交替。我们的主要假设是，早期的特征更容易出现简单性偏差，并且通过擦除（“筛选”）这些特征，我们可以学习更丰富的特征表示。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghN4NJ5vZ6jESH3koLTfGa3DpSenk5liLEg2awv2cOo1blDwwuDjLGVGxyeHSAzkLWTBUwO_swf4uGC2oShnD0WTNrebCL9KLAMO BIxR3ZZnw9eVS8g16s_lgP5kCbhZmVoTctASyDVvb3wtzIlzju01m4ADr7G21NpOWpac55hBllzYBaQVAXCjq8BIca/s1098/image6.png&quot; style=&quot;margin-左：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;604&quot; data-original-width=&quot;1098&quot; src=&quot;https://blogger.googleusercontent.com/ img/b/R29vZ2xl/AVvXsEghN4NJ5vZ6jESH3koLTfGa3DpSenk5liLEg2awv2coo1blDwwuDjLGVGxyeHSAzkLWTBUwO_swf4uGC2oShnD0WTNrebCL9KLAMOBIxR3ZZnw9eVS8g16s_lgP5kCbhZmVoTctAS yDVvb3wtzIlzju01m4ADr7G21NpOWpac55hBllzYBaQVAXCjq8BIca/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;使用特征筛训练工作流程。我们交替识别有问题的特征（使用训练迭代）和从网络中删除它们（使用遗忘迭代）。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;我们在更多细节：&lt;/p>; &lt;ul>; &lt;li>;&lt;b>;识别简单特征&lt;/b>;：我们通过前向和反向传播以传统方式训练主要模型和读出模型（上面的 AUX）。请注意，来自辅助层的反馈不会反向传播到主网络。这是为了迫使辅助层从已有的特征中学习，而不是在主网络中创建或强化它们。 &lt;/li>;&lt;li>;&lt;b>;应用特征筛&lt;/b>;：我们的目标是使用一种新颖的&lt;em>;遗忘损失&lt;/em>;来消除神经网络早期层中已识别的特征， &lt;em>; L&lt;sub>;f &lt;/sub>;&lt;/em>;，它只是读数与标签上均匀分布之间的交叉熵。本质上，所有导致重要读数的信息都会从主网络中删除。本步骤中，辅助网络和主网络上层保持不变。 &lt;/li>; &lt;/ul>; &lt;p>; 我们可以通过少量的配置参数来具体控制特征筛选如何应用于给定的数据集。通过改变辅助网络的位置和复杂性，我们控制了识别和擦除特征的复杂性。通过修改学习和遗忘步骤的混合，我们控制模型学习更复杂特征的挑战程度。这些依赖于数据集的选择是通过&lt;a href=&quot;https://en.wikipedia.org/wiki/Hyperparameter_optimization&quot;>;超参数搜索&lt;/a>;做出的，以最大限度地提高验证准确性，这是泛化的标准衡量标准。由于我们在搜索空间中包含“不遗忘”（即基线模型），因此我们期望找到至少与基线一样好的设置。 &lt;/p>; &lt;p>; 下面我们展示了基线模型（中行）和我们的模型（底行）在两个基准数据集上学习的特征 - 偏差活动识别（&lt;a href=&quot;https://github.com/alinlab /BAR&quot;>;BAR&lt;/a>;）和动物分类（&lt;a href=&quot;https://arxiv.org/pdf/1906.02899v3.pdf&quot;>;NICO&lt;/a>;）。使用事后基于梯度的重要性评分（​​&lt;a href=&quot;https://arxiv.org/abs/1610.02391&quot;>;GRAD-CAM&lt;/a>;）估计特征重要性，光谱的橙红色端表示高重要性，而绿蓝色表示低重要性。如下所示，我们训练的模型侧重于主要感兴趣的对象，而基线模型往往侧重于更简单且与标签虚假相关的背景特征。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgumwu2DQ-nPeTLxt_uS6q6tIR6oQZdlWOoM4_I5kUmYfyJi8xyWIpw7WusdRAsA_YthYgO2Zz8sj7V1Id3JOTs ljM9zpK2vwhokMfnZQOxbAIWtaFvFN4sfN6qF0rkOklj10y-_rLfL-WQS4zf6AWCub7aUTS7a8LyEsZ5uhQmXjTai7neuWElZBbP_5UI/s1616/image2.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;850&quot; data-original-width=&quot;1616&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgumwu2DQ-nPeTLxt_uS6q6tIR6oQZdlWOoM4_I5kUmYfyJi8xyWIpw7WusdRAsA_YthYgO2Zz8sj7V1Id3JOTsljM9zpK2vwhokMfnZQOxbAIW taFvFN4sfN6qF0rkOklj10y-_rLfL-WQS4zf6AWCub7aUTS7a8LyEsZ5uhQmXjTai7neuWElZBbP_5UI/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;使用 GRAD-CAM 在活动识别 (BAR) 和动物分类 (NICO) 泛化基准上进行特征重要性评分。我们的方法（最后一行）关注图像中的相关对象，而基线（ERM；中间行）依赖于与标签虚假相关的背景特征。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/表>; &lt;p>; 通过这种学习更好的、可概括的特征的能力，我们在现实世界的虚假特征基准数据集上的一系列相关基线上显示出了巨大的进步：&lt;a href=&quot;https://github.com/alinlab/BAR &quot;>;酒吧&lt;/a>;，&lt;a href=&quot;https://arxiv.org/pdf/2104.06885.pdf&quot;>;CelebA Hair&lt;/a>;，&lt;a href=&quot;https://nico.thumedialab.com/ &quot;>;NICO&lt;/a>; 和 &lt;a href=&quot;https://www.tensorflow.org/datasets/catalog/imagenet_a&quot;>;ImagenetA&lt;/a>;，利润率高达 11%（见下图）。更多详细信息请参阅&lt;a href=&quot;https://arxiv.org/abs/2301.13293&quot;>;我们的论文&lt;/a>;。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjjuXHls8mwfL2u-TVZlDlu5UMPrank9F2ODbf6h12q9oMLNrIYyfyv4OuQriS0XzI-z0BrQOs2xUiXt53lGLQtdz mKQDtGXFtv6TZEGg4pKua8JD9AkQn0J92mTjlQAlZTUPgqIYRAFpnsRTU0szE5J90_LeGNj3PTUKrsgq3WAMAjWSy30HQtMnNzevvY/s1082/image1.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1082&quot; data-original-width=&quot;844&quot; height=&quot;640&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjjuXHls8mwfL2u-TVZlDlu5UMPrank9F2ODbf6h12q9oMLNrIYyfyv4OuQriS0XzI-z0BrQOs2xUiXt53lGLQtdzmKQDtGXFtv6TZEGg4pKua8 JD9AkQn0J92mTjlQAlZTUPgqIYRAFpnsRTU0szE5J90_LeGNj3PTUKrsgq3WAMAjWSy30HQtMnNzevvY/w501-h640/image1.png&quot; width=&quot;501&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;我们的特征筛选方法相对于一系列特征泛化基准数据集的最近基线，显着提高了准确性。&lt;/td>;&lt;/td>;&lt;/ tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 我们希望我们的工作能够早日实现读数及其在泛化特征筛选中的使用将刺激新型对抗性特征学习方法的开发，并有助于提高深度学习系统的泛化能力和鲁棒性。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;将早期读数应用于去偏蒸馏的工作是与我们的学术伙伴 Durga Sivasubramanian、Anmol Reddy 和 Ganesh Ramakrishnan 教授在 &lt;a href=&quot;https://www.iitb.ac.in/&quot;>;IIT Bombay&lt;/a>; 合作进行。我们衷心感谢 Praneeth Netrapalli 和 Anshul Nasery 的反馈和建议。我们还感谢 Nishant Jain、Shreyas Havaldar、Rachit Bansal、Kartikeya Badola、Amandeep Kaur 以及 Google 印度研究院的全体博士前研究人员参与研究讨论。特别感谢 Tom Small 创建本文中使用的动画。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/2254287928040727502/comments/default&quot; rel =&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/02/intervening-on-early-readouts-for. html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/2254287928040727502 “ rel =“编辑”类型=“application/atom+xml”/>;&lt;link href =“http://www.blogger.com/feeds/8474926331452026626/posts/default/2254287928040727502”rel =“self”类型=“ application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/02/intervening-on-early-readouts-for.html&quot; rel=&quot;alternate&quot; title=&quot;早期干预用于减轻虚假功能和简单性偏差的读数” type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>; &lt;电子邮件>;noreply@blogger.com&lt;/电子邮件>;&lt;gd：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog” .com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img /b/R29vZ2xl/AVvXsEgdBd5rMRA2U1nd8fetuEweTgmHncn49ASMQtPlm6dfsr5V29RwsoUR8UtK4B7oSE1eiIdW-vD-gjCUK4tGZTbsY4XdO0adL2YtAjpgbF1S3mL_Jw3f31SwLKYUtCOLJ80 7gdXdRmD5iVsrtc_Ii-BiqQacv89vbtRbNAIINa9PhKAF_sDAZu09FLs4599T/s72-c/SiFer%20Hero.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media :thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;标签:blogger.com,1999:blog-8474926331452026626.post-5966553114967673984&lt;/id>;&lt;发布>;2024-01 -31T13:59:00.000-08:00&lt;/已发布>;&lt;更新>;2024-01-31T13:59:36.056-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom /ns#&quot; term=&quot;计算机视觉&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;机器学习&quot;>;&lt;/category>;&lt;category schema= &quot;http://www.blogger.com/atom/ns#&quot; term=&quot;On-device Learning&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;MobileDiffusion：在设备上快速生成文本到图像&lt; /stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Core ML 高级软件工程师赵阳和高级软件工程师侯廷波&lt;/span>; &lt;img src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOndf55Pc7tkXJektbVBEYRsOlxbUVui2uwOdXvuHj9cNpoNw2One4-68fqFNl2_fvv11CcgYfoI1XVQIkpjA9DosaOeqdkIRj9aZZJNoDy8Kq B_XCVDtDd_EvT5UGL2ZhXvL2PU3RjN8XBjI0eQe8VIJCKI0-20AG0TKGK58mO9tBZa80P58KSjTU_liK/s1600/InstantTIGO%20hero.png&quot; style=&quot;显示：无；&quot; />; &lt;p>; 文本到图像&lt;a href=&quot;https://arxiv.org/abs/2006.11239&quot;>;扩散模型&lt;/a>;在根据文本提示生成高质量图像方面表现出了卓越的能力。然而，领先的模型具有数十亿个参数，因此运行成本昂贵，需要强大的桌面或服务器（例如，&lt;a href=&quot;https://stability.ai/news/stable-diffusion-public-release&quot;>;稳定扩散&lt; /a>;、&lt;a href=&quot;https://openai.com/research/dall-e&quot;>;DALL·E&lt;/a>; 和 &lt;a href=&quot;https://imagen.research.google/&quot;>;图像&lt;/a>;）。虽然最近通过 MediaPipe 在 &lt;a href=&quot;https://blog.research.google/2023/06/speed-is-all-you-need-on-device.html&quot;>;Android&lt;/a>; 上的推理解决方案取得了进展和通过 Core ML 的 &lt;a href=&quot;https://github.com/apple/ml-stable-diffusion&quot;>;iOS&lt;/a>; 已经在过去一年中实现了快速（亚秒级）文本到图像的转换移动设备上的一代仍然遥不可及。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 为此，在“&lt;a href=&quot;https://arxiv.org/abs/2311.16567&quot;>;MobileDiffusion：亚秒文本到-移动设备上的图像生成&lt;/a>;”，我们介绍了一种新颖的方法，具有在设备上快速生成文本到图像的潜力。 MobileDiffusion 是专为移动设备设计的高效潜在扩散模型。我们还采用 &lt;a href=&quot;https://arxiv.org/abs/2311.09257&quot;>;DiffusionGAN&lt;/a>; 来实现推理过程中的一步采样，从而微调预训练的扩散模型，同时利用 GAN对去噪步骤进行建模。我们在 iOS 和 Android 高级设备上测试了 MobileDiffusion，它可以在半秒内运行生成 512x512 的高质量图像。其相对较小的模型尺寸（仅 520M 参数）使其特别适合移动部署。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgc9IegNp6IHze1sPewUyoR_WouBi8jMhiThcaavD0SXFld3788eA89uyOP6gpmdCXSZMMuacrgQMJ61ygVJsLfE51tqTmm YS0C-GI9SaF_hEGlhTp_zTFXdW_AgXIP5CLCejKQVCsPrhycF8p_Rj9qQHR0J_kTO8Md7VT5R47IMJHinO6dkHn23lUlU7rf/s800/image2.gif&quot;样式=&quot;左边距：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;369&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEgc9IegNp6IHze1sPewUyoR_WouBi8jMhiThcaavD0SXFld3788eA89uyOP6gpmdCXSZMMuacrgQMJ61ygVJsLfE51tqTmmYS0C-GI9SaF_hEGlhTp_zTFXdW_AgXIP5 CLCejKQVCsPrhycF8p_Rj9qQHR0J_kTO8Md7VT5R47IMJHinO6dkHn23lUlU7rf/s16000/image2.gif&quot;/>;&lt;/a>;&lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>; &lt;td 样式=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpz0XGSpMH9OVTd865uusar0AeXtu_26HD3tHzJHm2iEVeLYynBhi6pl0tidIYOoJVamc-NplnsNPCNl3vMX-qjqEZCYtndsl-9YjulMpLi DbP3Uws9cZ5ITjb0C3MNaVNC5mh-kbyKZYXn5rxBAuPLaHg_56ZAJfPOrkBfh44goI3CnEW-XZFDUvJgWAV/s800/image5.gif&quot;样式=“左边距：自动”； margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;369&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEhpz0XGSpMH9OVTd865uusar0AeXtu_26HD3tHzJHm2iEVeLYynBhi6pl0tidIYOoJVamc-NplnsNPCNl3vMX-qjqEZCYtndsl-9YjulMpLiDbP3Uws9cZ5ITjb0C3MNaVNC5mh-kbyKZ YXn5rxBAuPLaHg_56ZAJfPOrkBfh44goI3CnEW-XZFDUvJgWAV/s16000/image5.gif&quot;/>;&lt;/a>;&lt;/td>; &lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;tablealign=&quot;center&quot;cellpadding =&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;在设备上快速生成文本到图像。&lt;/td>;&lt; /tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;背景&lt;/h2>; &lt;p>; 文本相对效率低下-图像扩散模型面临两个主要挑战。首先，扩散模型的固有设计需要&lt;a href=&quot;https://blog.research.google/2023/06/on-device-diffusion-plugins-for.html &quot;>;迭代去噪&lt;/a>;来生成图像，需要对模型进行多次评估。其次，文本到图像扩散模型中网络架构的复杂性涉及大量参数，通常达到数十亿，从而导致因此，尽管在移动设备上部署生成模型具有潜在的好处，例如增强用户体验和解决新出现的隐私问题，但在当前的文献中仍然相对未经探索。 &lt;/p>; &lt;p>; 文本到图像扩散模型中推理效率的优化一直是一个活跃的研究领域。先前的研究主要集中于解决第一个挑战，寻求减少功能评估（NFE）的数量。利用先进的数值求解器（例如，&lt;a href=&quot;https://arxiv.org/abs/2206.00927&quot;>;DPM&lt;/a>;）或蒸馏技术（例如，&lt;a href=&quot;https://arxiv.org/ abs/2202.00512&quot;>;渐进式蒸馏&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2303.01469&quot;>;浓稠蒸馏&lt;/a>;），必要的采样步骤数量已从数百次显着减少到个位数。一些最近的技术，例如 &lt;a href=&quot;https://arxiv.org/abs/2311.09257&quot;>;DiffusionGAN&lt;/a>; 和 &lt;a href=&quot;https://arxiv.org/abs/2311.17042#:~:text =我们%20引入%20Adversarial%20Diffusion%20Distillation，同时%20保持%20high%20image%20quality。&quot;>;对抗性扩散蒸馏&lt;/a>;，甚至减少到单个必要步骤。 &lt;/p>; &lt;p>; 然而，在移动设备上，由于模型架构的复杂性，即使少量的评估步骤也可能很慢。到目前为止，文本到图像扩散模型的架构效率受到的关注相对较少。一些早期的作品简要地涉及了这个问题，涉及删除冗余的神经网络块（例如，&lt;a href=&quot;https://snap-research.github.io/SnapFusion/&quot;>;SnapFusion&lt;/a>;）。然而，这些工作缺乏对模型架构中每个组件的全面分析，从而无法为设计高效架构提供整体指导。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;MobileDiffusion&lt;/h2>; &lt;p>; 有效克服移动设备计算能力有限带来的挑战需要对模型的架构效率进行深入、整体的探索。为了实现这一目标，我们的研究对稳定扩散的 &lt;a href=&quot;https://arxiv.org/abs/2112.10752&quot;>;UNet 架构&lt;/a>;中的每个组成部分和计算操作进行了详细检查。我们提供了一个全面的指南，用于制作高效的文本到图像扩散模型，最终形成 MobileDiffusion。 &lt;/p>; &lt;p>; MobileDiffusion 的设计遵循&lt;a href=&quot;https://arxiv.org/abs/2112.10752&quot;>;潜在扩散模型&lt;/a>;。它包含三个组件：文本编码器、扩散 UNet 和图像解码器。对于文本编码器，我们使用 &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;CLIP-ViT/L14&lt;/a>;，这是一个适合移动设备的小型模型（125M 参数）。然后我们将重点转向扩散 UNet 和图像解码器。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;扩散UNet&lt;/h3>; &lt;p>; 如下图所示，扩散UNet通常交错变压器块和卷积块。我们对这两个基本组成部分进行了全面调查。在整个研究过程中，我们控制训练管道（例如数据、优化器）来研究不同架构的效果。 &lt;/p>; &lt;p>; 在经典的文本到图像扩散模型中，变压器块由用于建模视觉特征之间的远程依赖性的自注意力层（SA）和用于捕获的交叉注意力层（CA）组成。文本条件和视觉特征之间的相互作用，以及前馈层（FF）来对注意力层的输出进行后处理。这些转换器块在文本到图像的扩散模型中起着关键作用，是负责文本理解的主要组件。然而，考虑到注意力操作的计算费用是序列长度的二次方，它们也带来了重大的效率挑战。我们遵循&lt;a href=&quot;https://arxiv.org/abs/2301.11093&quot;>;UViT&lt;/a>;架构的思想，它将更多的变压器块放置在UNet的瓶颈处。这种设计选择的动机是，由于注意力计算的维度较低，因此在瓶颈处的资源密集程度较低。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsshK53k6noqIbabpGMBzYIBCdviXisDoBsD3Houk-lXzN8pZQcusKYBvjWwcwA1Aq5DnWyk01YM9B2RyRZx6HcGgTP -LrW-tnwFwByzlBACN3WggyPYM0Mpyr2OVGVLFhx1uN48aR1g9P4o0joN2STli9VpA_tFMdQ-ikRXVrNpawzB793-unSENR-PIV /s915/image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;249&quot; data-original-width=&quot;915&quot; src =&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsshK53k6noqIbabpGMBzYIBCdviXisDoBsD3Houk-lXzN8pZQcusKYBvjWwcwA1Aq5DnWyk01YM9B2RyRZx6HcGgTP-LrW-tnwFwByzlBACN3W ggyPYM0Mpyr2OVGVLFhx1uN48aR1g9P4o0joN2STli9VpA_tFMdQ-ikRXVrNpawzB793-unSENR-PIV/s16000/image4.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;我们的 UNet 架构在中间包含更多变压器，并在更高分辨率下跳过自注意力 (SA) 层。&lt;/ td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 卷积块，特别是 &lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;>;ResNet&lt;/a>; 块部署在UNet 的各个级别。虽然这些块对于特征提取和信息流很有帮助，但相关的计算成本，尤其是在高分辨率水平上，可能会很大。在这种情况下，一种经过验证的方法是&lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot;>;可分离卷积&lt;/a>;。我们观察到，在 UNet 的较深层部分中用轻量级可分离卷积层替换常规卷积层会产生类似的性能。 &lt;/p>; &lt;p>; 下图中，我们比较了几种扩散模型的UNet。我们的 MobileDiffusion 在 &lt;a href=&quot;https://arxiv.org/pdf/2110.12894.pdf&quot;>;FLOPs&lt;/a>;（浮点运算）和参数数量方面表现出卓越的效率。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjXYleITSssbZnLffeh3BzG3tX2qNQNeB__xc-ySks0SPnXsMb2kTLZ0PcE2KWJ4I9FX_QMP32pXd06IuV1kJJSlgp7 CuV6dqkXJsiFqo_6xqWXZ1-65p_EPU9gk7G9B4-L2TaKGiD5cahwg428CTmV1dcuQQ_vBTVmP8543IJigIF0qHo8_JaB8h5EuVvl/s1200/image3.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjXYleITSssbZnLffeh3BzG3tX2qNQNeB__xc-ySks0SPnXsMb2kTLZ0PcE2KWJ4I9FX_QMP32pXd06IuV1kJJSlgp7CuV6dqkXJsiFqo_6xqWXZ1- 65p_EPU9gk7G9B4-L2TaKGiD5cahwg428CTmV1dcuQQ_vBTVmP8543IJigIF0qHo8_JaB8h5EuVvl/s16000/image3.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- title&quot; style=&quot;text-align: center;&quot;>;一些扩散UNet的比较。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt; br />; &lt;/div>; &lt;h3>;图像解码器&lt;/h3>; &lt;p>; 除了UNet之外，我们还对图像解码器进行了优化。我们训练了一个&lt;a href=&quot;https://arxiv.org/abs/2012.03715&quot;>;变分自动编码器&lt;/a>; (VAE)来编码&lt;a href=&quot;https://en.wikipedia.org/wiki/ RGB_color_model&quot;>;RGB&lt;/a>; 图像转换为 8 通道潜在变量，图像空间尺寸缩小 8 倍。潜在变量可以被解码为图像，并且大小增大 8 倍。为了进一步提高效率，我们通过修剪原始的宽度和深度来设计轻量级解码器架构。由此产生的轻量级解码器可显着提高性能，延迟降低近 50%，质量也更好。有关更多详细信息，请参阅我们的&lt;a href=&quot;https://arxiv.org/abs/2311.16567&quot;>;论文&lt;/a>;。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjT2Nmo7GjGdN0_2dqevJB52RogqnWFDVmFsrusHHxnVf9YQYsdbVkAQvBI3h9SzKZ0TqOQOmnxaZ6z2kdix12 tei5oMpD17SY1LoBWqxD1EHgV0ygTb9TV0IFZQtv4dAix378lb8WGv5GGPQIuyStX3gWqn0pjTTXbpIlA0VzYSeiGpkO5bsHhZfjbkR07/s1124/image6.png&quot; style=&quot;margin-左：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;789&quot; data-original-width=&quot;1124&quot; src=&quot;https://blogger.googleusercontent.com/ img/b/R29vZ2xl/AVvXsEjT2Nmo7GjGdN0_2dqevJB52RogqnWFDVmFsrusHHxnVf9YQYsdbVkAQvBI3h9SzKZ0TqOQOmnxaZ6z2kdix12tei5oMpD17SY1LoBWqxD1EHgV0ygTb9TV0 IFZQtv4dAix378lb8WGv5GGPQIuyStX3gWqn0pjTTXbpIlA0VzYSeiGpkO5bsHhZfjbkR07/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;VAE重建。我们的 VAE 解码器具有比 SD（稳定扩散）更好的视觉质量。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;tablealign=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0 &quot; class=&quot;tr-caption-container&quot; style=&quot;text-align: center;&quot;>; &lt;tbody>;&lt;tr>; &lt;td style=&quot;text-align: left;&quot;>;&lt;b>;解码器&lt;/b>; &lt;/ td>; &lt;td>;&lt;b>;&amp;nbsp;&amp;nbsp;#Params (M)&lt;/b>; &lt;/td>; &lt;td>;&lt;b>;&amp;nbsp;&amp;nbsp;PSNR↑&amp;nbsp;&amp;nbsp;&lt;/b>; &lt; /td>; &lt;td>;&lt;b>;&amp;nbsp;&amp;nbsp;SSIM↑&amp;nbsp;&amp;nbsp;&lt;/b>; &lt;/td>; &lt;td>;&lt;b>;&amp;nbsp;&amp;nbsp;LPIPS↓&amp;nbsp;&amp;nbsp;&lt;/b>; &lt;/td >; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left;&quot;>;&lt;b>;SD&lt;/b>; &lt;/td>; &lt;td>;49.5 &lt;/td>; &lt;td>;26.7 &lt;/td>; &lt; td>;0.76 &lt;/td>; &lt;td>;0.037 &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left;&quot;>;&lt;b>;我们的&lt;/b>; &lt;/td>; &lt;td>; 39.3 &lt;/td>; &lt;td>;30.0 &lt;/td>; &lt;td>;0.83 &lt;/td>; &lt;td>;0.032 &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left;&quot;>;&lt; b>;我们的精简版&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/b>; &lt;/td>; &lt;td>;9.8 &lt;/td>; &lt;td>;30.2 &lt;/td>; &lt;td>;0.84 &lt;/td>; &lt;td>;0.032 &lt;/ td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;br />; &lt;tablealign=“center”cellpadding=“0”cellspacing=“0”class=“tr-caption-container”style=“margin-left” : auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;VAE解码器的质量评估。我们的精简版解码器比标清小得多，具有更好的质量指标，包括&lt;a href=&quot;https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio&quot;>;峰值信噪比&lt;/a>; (PSNR)、&lt;a href=&quot;https://en.wikipedia.org/wiki/Structural_similarity&quot;>;结构相似性指数测量&lt;/a>; (SSIM) 和&lt;a href=&quot;https://arxiv.org/ abs/1801.03924&quot;>;学习感知图像块相似度&lt;/a>; (LPIPS)。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;一步采样&lt;/h3>; &lt;p>;除了优化模型架构之外，我们还采用了&lt;a href=&quot;https://arxiv.org/abs/2311.09257&quot;>;DiffusionGAN混合&lt;/a>;实现一步采样。训练用于文本到图像生成的 DiffusionGAN 混合模型会遇到一些复杂的问题。值得注意的是，鉴别器（区分真实数据和生成数据的分类器）必须基于纹理和语义进行判断。此外，训练文本到图像模型的成本可能非常高，特别是在基于 GAN 的模型中，其中鉴别器引入了额外的参数。纯基于 GAN 的文本到图像模型（例如，&lt;a href=&quot;https://arxiv.org/abs/2301.09515&quot;>;StyleGAN-T&lt;/a>;、&lt;a href=&quot;https://arxiv. org/abs/2303.05511&quot;>;GigaGAN&lt;/a>;）面临类似的复杂性，导致训练高度复杂且昂贵。 &lt;/p>; &lt;p>; 为了克服这些挑战，我们使用预训练的扩散 UNet 来初始化生成器和鉴别器。这种设计可以使用预先训练的扩散模型进行无缝初始化。我们假设扩散模型中的内部特征包含文本和视觉数据之间复杂相互作用的丰富信息。这种初始化策略显着简化了训练。 &lt;/p>; &lt;p>; 下图说明了训练过程。初始化后，噪声图像被发送到生成器进行一步扩散。结果根据具有重建损失的地面实况进行评估，类似于扩散模型训练。然后，我们向输出添加噪声并将其发送到鉴别器，鉴别器的结果使用 GAN 损失进行评估，从而有效地采用 GAN 来建模去噪步骤。通过使用预训练的权重来初始化生成器和判别器，训练变成了一个微调过程，在不到 10K 次迭代内收敛。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnK7SE2-cHSlP-PDmkl_xfjp3sP-kB41r6OvC8Wg6miXnYwdES0INwN19BHWQ_uyXtcBT-872U5J6jLY8yX VtA_W96qkRRPh6Pjvw0n-ZJvjJK91kYTh7H1n4nzy8z1TyrQZlZoZrQUDTo5Qm-6a_2vIVye3aqm7o32qOOXiWXwxDzw_J6cQsOrJ -UILKw/s960/image7.jpg&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;576&quot; data-original-width=&quot;960 “ src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnK7SE2-cHSlP-PDmkl_xfjp3sP-kB41r6OvC8Wg6miXnYwdES0INwN19BHWQ_uyXtcBT-872U5J6jLY8yXVtA_W96qkRRPh6Pj vw0n-ZJvjJK91kYTh7H1n4nzy8z1TyrQZlZoZrQUDTo5Qm-6a_2vIVye3aqm7o32qOOXiWXwxDzw_J6cQsOrJ-UILKw/s16000/image7.jpg&quot;/>;&lt;/a>;&lt;/ td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;DiffusionGAN 微调说明。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/ table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结果&lt;/h2>; &lt;p>; 下面我们展示了 MobileDiffusion 与 DiffusionGAN 一步采样生成的示例图像。凭借如此紧凑的模型（总共 5.2 亿参数），MobileDiffusion 可以为各个领域生成高质量的多样化图像。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyDLq1NW7Qvy4_oEqg1pHAMzeBfuei3VadIKZRNkv6ZHnzewVWQU5x76e0bm-QqWVr-_q1W4axBJeyqyCbdRFoUFBYxR xDj3qo7I4-Du6TS2Bez_-mmXzYoHLJk7y5fiKl9PPkHNk_dsvy7ezuAFavW4sYIeYTxhAPAH35FYP5YOceS8NfJey0gpvHUwza/s1728/image1 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1296&quot; data-original-width=&quot;1728&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyDLq1NW7Qvy4_oEqg1pHAMzeBfuei3VadIKZRNkv6ZHnzewVWQU5x76e0bm-QqWVr-_q1W4axBJeyqyCbdRFoUFBYxRxDj3qo7I4-Du6TS2Bez_-mmX zYoHLJk7y5fiKl9PPkHNk_dsvy7ezuAFavW4sYIeYTxhAPAH35FYP5YOceS8NfJey0gpvHUwza/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;由我们的 MobileDiffusion 生成的图像&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 我们在两个设备上测量了 MobileDiffusion 的性能iOS 和 Android 设备，使用不同的运行时优化器。下面报告了延迟数字。我们看到MobileDiffusion非常高效，可以在半秒内运行生成512x512的图像。这种闪电般的速度可能会在移动设备上实现许多有趣的用例。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFkcI7kibwRFhpxTsVmUkAzK38MCeBoTR6fOWyhjnqwPm7x8TwrVn_O0OipsXCbgS4qTtcbtm41Fxi7U_IJjpe uZadWO7cBKkcdrXHniAJgQP4Qk-wOBfnhtwNPxDbzxtM0uxVba3BjwzLa3Lw13-03FoRQbWwf_25KR9GLLkSqIFpnU5aE-6hnomY5IuK/s1184/image8.png “ imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1184&quot; src= “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFkcI7kibwRFhpxTsVmUkAzK38MCeBoTR6fOWyhjnqwPm7x8TwrVn_O0OipsXCbgS4qTtcbtm41Fxi7U_IJjpeuZadWO7cBKkcdrXHniAJgQ P4Qk-wOBfnhtwNPxDbzxtM0uxVba3BjwzLa3Lw13-03FoRQbWwf_25KR9GLLkSqIFpnU5aE-6hnomY5IuK/s16000/image8.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;移动设备上的延迟测量 (&lt;b>;s&lt;/b>;)。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 凭借在延迟和大小方面卓越的效率，MobileDiffusion 有潜力成为对于移动部署来说，这是非常友好的选择，因为它能够在输入文本提示时实现快速图像生成体验。我们将确保该技术的任何应用都符合 Google 的&lt;a href=&quot;https://ai.google/responsibility/responsible-ai-practices/&quot;>;负责任的 AI 实践&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;我们要感谢为我们提供帮助的合作者和贡献者将 MobileDiffusion 引入设备：Zhisheng Shaw、Yanwu Xu、Jiuqiang Tang、Haolin Jia、Lutz Justen、Daniel Fenner、Ronald Wotzlaw、Jianing Wei、Raman Sarokin、Juhyun Lee、Andrei Kulik、Chuo-Ling Chang 和 Matthias Grundmann。&lt; /em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/5966553114967673984/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/ atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/mobileiffusion-rapid-text-to-image.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5966553114967673984&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot; />;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5966553114967673984&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http: //blog.research.google/2024/01/mobilediffusion-rapid-text-to-image.html&quot; rel=&quot;alternate&quot; title=&quot;MobileDiffusion：在设备上快速生成文本到图像&quot; type=&quot;text/ html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd ：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=“ 16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOndf55Pc7tkXJektbVBEYRsOlxbUVui2uwOdXvuHj9cNpoNw2One4-68fqFNl2_fvv11CcgYfoI 1XVQIkpjA9DosaOeqdkIRj9aZZJNoDy8KqB_XCVDtDd_EvT5UGL2ZhXvL2PU3RjN8XBjI0eQe8VIJCKI0-20AG0TKGK58mO9tBZa80P58KSjTU_liK/s72-c /InstantTIGO%20hero.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt; /entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-5144906729109253495&lt;/id>;&lt;已发布>;2024-01-26T11:56:00.000-08:00&lt;/已发布>;&lt;已更新>;2024-01-26T11:56:23.553-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Algorithms&quot;>;&lt;/category>;&lt;category方案=“http://www.blogger.com/atom/ns#”术语=“深度学习”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=&quot;optimization&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;混合输入矩阵乘法性能优化&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Manish Gupta ，Google 研究部高级软件工程师&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEKJJf1R773hab0veY6zffF2Nf_yfV2mk8YU9yRnuBDD3ak1o0iXecWlJw2x7bL-Ez2MX1c21MXk65VMK5IsoLp J1H6BTC6k7BvVWl_gHJpJIOG2cm3BwP4V-HCScGHYIynuskbhvu1uorQGprHGbOFmfGI7E5UWemJcZ0xSC3tC5DolBYgyBwugl6OOLr/s1180/matrixhero.png&quot; style=&quot;显示: 无;” />; &lt;p>; 人工智能驱动的技术正在融入我们的日常生活，有可能增强我们获取知识的能力并提高我们的整体生产力。这些应用程序的支柱在于大型语言模型（LLM）。 LLM 需要占用大量内存，通常需要专门的硬件加速器来高效交付&lt;a href=&quot;https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on -tpu-v5e&quot;>;数十亿亿次浮点运算&lt;/a>;的计算能力。这篇博文展示了我们如何通过更有效地利用内存来开始解决计算挑战。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; LLM 的大部分内存和计算均由 &lt;a href=&quot;https://arxiv.org/pdf/2005.14165.pdf&quot;>; 消耗&lt;a href=&quot;https://arxiv.org/pdf/2006.16668.pdf&quot;>;矩阵乘法&lt;/a>;运算中的权重&lt;/a>;。使用较窄的&lt;em>;&lt;a href=&quot;https://en.wikipedia.org/wiki/Primitive_data_type&quot;>;数据类型&lt;/a>;&lt;/em>;可以减少内存消耗。例如，以 8 位&lt;a href=&quot;https://en.wikipedia.org/wiki/Integer_(computer_science)&quot;>;整数&lt;/a>;（即 U8 或 S8）数据类型存储权重会减少内存相对于&lt;a href=&quot;https://en.wikipedia.org/wiki/Single- precision_floating-point_format&quot;>;单精度&lt;/a>; (F32) 占用空间为 4 倍，相对于 &lt;a href=&quot; 占用空间为 2 倍https://en.wikipedia.org/wiki/Half- precision_floating-point_format&quot;>;半精度&lt;/a>; (F16) 或 &lt;a href=&quot;https://en.wikipedia.org/wiki/Bfloat16_floating-point_format &quot;>;bfloat16&lt;/a>; (BF16)。此外，&lt;a href=&quot;https://arxiv.org/pdf/2206.01861.pdf&quot;>;之前的工作&lt;/a>;表明，LLM 模型在 S8 和 &lt;em>; 中运行带有&lt;em>;权重&lt;/em>;的矩阵乘法>;F16 中的输入（保留用户输入的较高精度）是一种提高效率的有效方法，同时在精度方面进行了可接受的权衡。这种技术被称为&lt;em>;仅权量化&lt;/em>;，并且需要有效地实现与&lt;em>;混合输入&lt;/em>;的矩阵乘法，例如，半精度输入乘以8位整数。包括 GPU 在内的硬件加速器支持一组固定的数据类型，因此混合输入矩阵乘法需要软件转换来映射到硬件运算。 &lt;/p>; &lt;p>; 为此，在本博客中，我们重点关注将混合输入矩阵乘法映射到 &lt;a href=&quot;https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-深度/&quot;>;NVIDIA Ampere 架构&lt;/a>;。我们提出了解决数据类型转换和布局一致性的软件技术，以将混合输入矩阵乘法有效地映射到硬件支持的数据类型和布局上。我们的结果表明，软件中额外工作的开销是最小的，并且使性能接近峰值硬件能力。此处描述的软件技术已在开源 &lt;a href=&quot;https://github.com/NVIDIA/cutlass/pull/1084&quot;>;NVIDIA/CUTLASS&lt;/a>; 存储库中发布。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgaLaSxuLbV_5ifXLyJsTGs0WLa23prrxrhX4IKSLZw5l3oSd2SPk5AgZtNgvUY_j-IbOyjttva-XIfkRr1cDBwCXgh Ez-3Q0G-6236m7_TIgTrm_K2UejYnTnhAEmZtKHq1mN9HKP0xxV8nqSxzTNHG1U0j-cVj236efpR7lSgmt082QEYNwKsGMTRiWZb/s1999 /image3.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1159&quot; data-original-width=&quot;1999&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgaLaSxuLbV_5ifXLyJsTGs0WLa23prrxrhX4IKSLZw5l3oSd2SPk5AgZtNgvUY_j-IbOyjttva-XIfkRr1cDBwCXghEz-3Q0G-6236m7_TIgTrm _K2UejYnTnhAEmZtKHq1mN9HKP0xxV8nqSxzTNHG1U0j-cVj236efpR7lSgmt082QEYNwKsGMTRiWZb/s16000/image3.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;具有各种数据类型格式的 175B 参数 LLM 模型的内存占用。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table >; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;矩阵乘法累加运算&lt;/h2>; &lt;p>; 现代人工智能硬件加速器，例如&lt;a href= &quot;https://cloud.google.com/tpu/docs/intro-to-tpu#how_a_tpu_works&quot;>;Google 的 TPU&lt;/a>; 和 &lt;a href=&quot;https://www.nvidia.com/en-us/ data-center/tensor-cores/&quot;>;NVIDIA 的 GPU&lt;/a>; 通过针对 Tensor Core 在硬件中本地乘法矩阵，Tensor Core 是用于加速矩阵运算的专用处理元素，特别是对于 AI 工作负载。在本博客中，我们重点关注 NVIDIA Ampere Tensor Core，它提供&lt;em>;矩阵乘法累加&lt;/em>; (&lt;code>;&lt;a href=&quot;https://docs.nvidia.com/cuda/parallel- thread-execution/index.html#warp-level-matrix-instructions-mma&quot;>;mma&lt;/a>;&lt;/code>;）操作。在博客的其余部分中，对 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 的引用适用于 Ampere Tensor Core。 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 运算的两个输入矩阵（称为操作数）支持的数据类型、形状和数据布局在硬件中是固定的。这意味着通过将问题平铺到硬件支持的数据类型、形状和布局上，可以在软件中实现各种数据类型和更大形状的矩阵乘法。 &lt;/p>; &lt;p>; Tensor Core &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 运算通过指定两个输入矩阵来定义（例如，&lt;em>;A&lt; /em>; &amp;amp; &lt;em>;B&lt;/em>;，如下所示）以生成结果矩阵 &lt;em>;C&lt;/em>;。 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 操作本身支持混合精度。 &lt;em>;&lt;a href=&quot;https://developer.nvidia.com/blog/programming-tensor-cores-cuda-9/&quot;>;混合精度张量核心&lt;/a>;&lt;/em>;允许混合输入（&lt; em>;A&lt;/em>; 和 &lt;em>;B&lt;/em>;）数据类型与结果（&lt;em>;C&lt;/em>;）数据类型。相比之下，混合输入矩阵乘法涉及混合输入数据类型，硬件不支持，因此需要在软件中实现。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiS_vu1tTxHo9Gy6Mywfx1xbQ0G6XTpOOQ04-l-Nw_rM7qOAM9kXg_qDjIakIpx-IclRmfR96cTGGExo2k9fxn VdltW4I9nb7RHloRtqWFMFeOtZ68Yr5wve9uLTISZKA3GxB_VaNo98Gfsa7zGGP0dCrjebZ0Fq1dutfoxoy25eByHXorHCwTTiqsFzw6M/s1039/image5.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;668&quot; data-original-width=&quot;1039&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiS_vu1tTxHo9Gy6Mywfx1xbQ0G6XTpOOQ04-l-Nw_rM7qOAM9kXg_qDjIakIpx-IclRmfR96cTGGExo2k9fxnVdltW4I9nb7RHloRtqWFMFeOtZ 68Yr5wve9uLTISZKA3GxB_VaNo98Gfsa7zGGP0dCrjebZ0Fq1dutfoxoy25eByHXorHCwTTiqsFzw6M/s16000/image5.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- title&quot; style=&quot;text-align: center;&quot;>;M×N-by-K 对 M×K 的输入矩阵 A 和 K×N 的矩阵 B 进行张量核心运算，产生输出矩阵 C M-by-N。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;混合的挑战-输入矩阵乘法&lt;/h2>; &lt;p>; 为了简化讨论，我们只讨论混合输入矩阵乘法的一个具体示例：F16 表示用户输入，U8 表示模型权重（写为 F16 * U8）。这里描述的技术适用于混合输入数据类型的各种组合。 &lt;/p>; &lt;p>; GPU 程序员可以访问&lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy&quot;>;内存层次结构&lt;/a>;，包括全局内存、共享内存、寄存器，按照容量递减、速度递增的顺序排列。 NVIDIA Ampere Tensor Core &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 运算消耗寄存器中的输入矩阵。此外，需要输入和输出矩阵来符合32个线程中的数据布局，称为A &lt;em>; warp &lt;/em>;。对于 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 操作，扭曲中支持的数据类型&lt;em>;和&lt;/em>;布局是固定的，因此要实现混合-高效输入乘法，需要解决软件中数据类型转换和布局一致性的挑战。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;数据类型转换&lt;/h3>; &lt;p>; &lt;span style=&quot;color: #54863f; &quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 运算需要两个具有相同数据类型的输入矩阵。因此，混合输入矩阵乘法（其中一个操作数存储在全局内存中的 U8 中，其他操作数存储在 F16 中）需要从 U8 到 F16 的数据类型转换。该转换将为 F16 带来两个操作数，将&lt;em>;混合输入&lt;/em>;矩阵乘法映射到硬件支持的&lt;em>;混合精度&lt;/em>;张量核心。鉴于权重数量很大，因此存在大量此类操作，我们的技术展示了如何减少其延迟并提高性能。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;布局一致性&lt;/h3>; &lt;p>; &lt;span style=&quot;color: #54863f;&quot; >;&lt;code>;mma&lt;/code>;&lt;/span>; 操作还要求扭曲寄存器内的两个输入矩阵的布局符合硬件规范。混合输入矩阵乘法（F16 * U8）中U8数据类型的输入矩阵&lt;em>;B&lt;/em>;的布局需要符合转换后的F16数据类型。这称为布局一致性，需要在软件中实现。 &lt;/p>; &lt;p>; 下图显示了一个 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 运算，消耗了矩阵 &lt;em>;A&lt;/em>; 和矩阵 &lt; em>;B&lt;/em>; 从寄存器生成寄存器中的矩阵 &lt;em>;C&lt;/em>;，分布在一个扭曲上。线程 &lt;em>;T0&lt;/em>; 突出显示并放大，以显示权重矩阵 &lt;em>;B&lt;/em>; 经过数据类型转换，并且需要布局一致性才能映射到硬件支持的 Tensor Core手术。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMMvieW8Uyta8c4afsNM7SgyZtlB2ra7G7aBG4z7D73rn-T7NHge0J1zfK7A_edL9tsQIthWVtEd0hZmwAjfO5C-X M6d5hNkv8IEBlpRxHilOxFgjYi27qauWFAQTl5wV8ixQ9MrfvqpuEQrdFuqDtjPJESG795s6cH3FlPJIVS4TuvKo0gmd8L1HwOJ_6/s1999/image4.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1240&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMMvieW8Uyta8c4afsNM7SgyZtlB2ra7G7aBG4z7D73rn-T7NHge0J1zfK7A_edL9tsQIthWVtEd0hZmwAjfO5C-XM6d5hNkv8IEBlpRxHilOxFgjYi 27qauWFAQTl5wV8ixQ9MrfvqpuEQrdFuqDtjPJESG795s6cH3FlPJIVS4TuvKo0gmd8L1HwOJ_6/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;软件中的混合输入 (F32 = F16 * U8) 操作到硬件中原生支持的扭曲级张量核心 (F32 = F16 * F16) 的映射。 （原始图来源&lt;a href=&quot;https://www.nvidia.com/en-us/on-demand/session/gtcsj20-s21745/&quot;>;开发 CUDA 内核以将 Tensor Core 推向 NVIDIA A100 的绝对极限&lt; /a>;.)&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;应对挑战的软件策略&lt;/h2>; &lt;p>; 典型的数据类型转换涉及 32 位寄存器上的一系列操作，如下所示。每个矩形块代表一个寄存器，相邻的文本是操作。整个序列显示了从 4xU8 到 2x(2xF16) 的转换。该序列大约涉及 10 个操作。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyJ4C214tiBhdjds0fWCV9EWh8X_UEDQlFqkpeoo6CZR3QMMrWyqi5mfRjvHLtbHH55J4hM5oRxe0HouGnbE3 KuPbmh8MKk-TtDMMZv1YMKPv-Q4gYAr5l3ZXdTIPUHKs7f8wfCgr3XPe6_jUO7u12pGEmZVFiAGn_LCOlUlQQRSF7_r7jlOrPJW9Oc4V1/s947/image1.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;836&quot; data-original-width=&quot;947&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyJ4C214tiBhdjds0fWCV9EWh8X_UEDQlFqkpeoo6CZR3QMMrWyqi5mfRjvHLtbHH55J4hM5oRxe0HouGnbE3KuPbmh8MKk-TtDMMZv1YMKPv-Q 4gYAr5l3ZXdTIPUHKs7f8wfCgr3XPe6_jUO7u12pGEmZVFiAGn_LCOlUlQQRSF7_r7jlOrPJW9Oc4V1/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L760&quot;>;NumericArrayConvertor&lt;/a>;&lt; /code>; 在 32 位寄存器中从 4xU8 到 2x(2xF16)。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 实现布局一致性的方法有很多。现有的两个解决方案是： &lt;/p>; &lt;ol>; &lt;li>;&lt;em>;窄位宽共享内存加载&lt;/em>;：在这种方法中，线程发出窄位宽内存加载，将 U8 数据从共享内存移动到寄存器。这会产生&lt;em>;两个&lt;/em>; 32 位寄存器，每个寄存器包含 2xF16 值（如上所示矩阵 &lt;em>;B&lt;/em>; 的线程 &lt;em>;T0&lt;/em>;）。较窄的共享内存负载直接实现寄存器的布局一致性，而不需要任何洗牌；但是，它没有利用全部共享内存带宽。 &lt;/li>;&lt;li>;&lt;em>;全局内存中的预处理&lt;/em>;：&lt;a href=&quot;https://arxiv.org/pdf/2211.10017.pdf&quot;>;替代策略&lt;/a>;涉及重新排列全局内存中的数据（内存层次结构中共享内存的上一级） &lt;/a>;），允许更广泛的共享内存负载。这种方法最大限度地提高了共享内存带宽利用率，并确保数据以一致的布局直接加载到寄存器中。虽然重新排列过程可以在 LLM 部署之前离线执行，确保不会影响应用程序性能，但它引入了一个额外的、重要的特定于硬件的预处理步骤，需要额外的程序来重新排列数据。 &lt;a href=&quot;https://github.com/NVIDIA/FasterTransformer&quot;>;NVIDIA/FasterTransformer&lt;/a>; 采用这种方法来有效解决布局一致性挑战。 &lt;/li>; &lt;/ol>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;优化软件策略&lt;/h2>; &lt;p>;进一步优化并降低开销为了实现数据类型转换和布局一致性，我们实现了 &lt;code>;&lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L2514&quot;>;FastNumericArrayConvertor&lt;/a >;&lt;/code>; 和 &lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/gemm/warp/mma_mixed_input_tensor_op.h#L120&quot;>;FragmentShuffler&lt;/a>;分别。 &lt;/p>;&lt;p>; &lt;code>;FastNumericArrayConvertor&lt;/code>; 在 32 位寄存器中的 4xU8 上运行，无需解包各个 1xU8 值。此外，它使用成本较低的算术运算，从而减少了指令数量并提高了转换速度。 &lt;/p>; &lt;p>; &lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L2514&quot;>;U8-to-F16&lt;/的转换顺序a>; 如下所示。这些操作使用打包的 32b 寄存器，避免显式解包和打包。 &lt;code>;FastNumericArrayConvertor&lt;/code>; 使用 &lt;code>;&lt;a href=&quot;https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions- prmt&quot;>;permute byte&lt;/a>;&lt;/code>; 将 4xU8 的字节重新排列到两个寄存器中。此外，&lt;code>;FastNumericArrayConvertor&lt;/code>; 不使用昂贵的整数到浮点转换指令，而是采用向量化运算来获取包含 2x(2xF16) 值的&lt;em>;两个&lt;/em>; 32 位寄存器中的打包结果。 U8 到 F16 的 &lt;code>;FastNumericArrayConvertor&lt;/code>; 大约使用六次操作，相对于上面所示的方法减少了 1.6 倍。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRhtLljZ8wfnfnyXQsYZlNMDZ-cUqCV7wPvGimtPtU3JcKJLv6lCDT_PfBBmyp0TuHRgFIZ2cbgEDeL5bqke4FGU cpGMbAhcIBJxQcpcuWZIlqG1yXOHPf5BivF26_qlDnR9W2Y3RVE36ZB7rEGZO3x2Xva7-rqBZkoI7l4gnzBWLYfIrmhFBNN8DpaoEA/s1392/image201.png&quot; imageanchor =&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;733&quot; data-original-width=&quot;1392&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRhtLljZ8wfnfnyXQsYZlNMDZ-cUqCV7wPvGimtPtU3JcKJLv6lCDT_PfBBmyp0TuHRgFIZ2cbgEDeL5bqke4FGUcpGMbAhcIBJxQcpcuWZIlqG1 yXOHPf5BivF26_qlDnR9W2Y3RVE36ZB7rEGZO3x2Xva7-rqBZkoI7l4gnzBWLYfIrmhFBNN8DpaoEA/s16000/image201.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr -caption&quot; style=&quot;text-align: center;&quot;>;&lt;code>;FastNumericArrayConvertor&lt;/code>; 利用 &lt;code>;&lt;a href=&quot;https://docs.nvidia.com/cuda/parallel-thread-execution/index .html#data-movement-and-conversion-instructions-prmt&quot;>;置换字节&lt;/a>;&lt;/code>;和压缩算术，减少数据类型转换中的指令数量。&lt;/td>;&lt;/tr>;&lt; /tbody>;&lt;/table>; &lt;p>; &lt;code>;FragmentShuffler&lt;/code>; 通过以允​​许使用更宽位宽的加载操作的方式混洗数据来处理布局一致性，从而提高共享内存带宽利用率并减少操作总数。 &lt;/p>; &lt;p>; NVIDIA Ampere 架构提供加载矩阵指令 (&lt;code>;&lt;a href=&quot;https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-矩阵指令-ldmatrix&quot;>;ldmatrix&lt;/a>;&lt;/code>;）。 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;ldmatrix&lt;/code>;&lt;/span>; 是一个 warp 级别的操作，其中一个 warp 的 32 个线程将数据从共享内存移动到 &lt;em >;形状&lt;/em>;和&lt;em>;布局&lt;/em>;，&lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>;矩阵&lt;em>;A&lt;/em>;和&lt;em>;B&lt;/em>;消耗。使用&lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;ldmatrix&lt;/code>;&lt;/span>;&lt;em>;减少&lt;/em>;加载指令的数量并&lt;em>;增加&lt;/em>;内存带宽利用率。由于 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;ldmatrix&lt;/code>;&lt;/span>; 指令将 U8 数据移至寄存器，因此加载后的布局符合 U8*U8 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 操作，而不是 F16*F16 &lt;span style=&quot;color: #54863f;&quot;>;&lt;code>;mma&lt;/code>;&lt;/span>; 操作。我们实现了 FragmentShuffler，以使用 shuffle 重新排列寄存器内的数据（&lt;code>;&lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html #warp-shuffle-functions&quot;>;shfl.sync&lt;/a>;)&lt;/code>; 操作以实现布局一致性。 &lt;/p>;&lt;p>; 这项工作最重要的贡献是通过寄存器洗牌实现布局一致性，避免全局内存中的离线预处理或较窄位宽的共享内存负载。此外，我们还提供了 &lt;code>;FastNumericArrayConvertor&lt;/code>; 的实现，涵盖了 &lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L2514&quot; 的数据类型转换>;U8 到 F16&lt;/a>;、&lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L2448&quot;>;S8 到 F16&lt;/ a>;、&lt;a href=&quot;https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L2546&quot;>;U8 到 BF16&lt;/a>; 和 &lt;a href= “https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L2588&quot;>;S8 到 BF16&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;性能结果&lt;/h2>; &lt;p>; 我们测量了 &lt; 的八种混合输入变体的性能em>;我们的方法&lt;/em>;（如下图蓝色和红色所示；改变矩阵&lt;em>;A&lt;/em>;和&lt;em>;B&lt;/em>;的数据类型）和两个&lt;em>;混合精度&lt;/em>; em>; NVIDIA A100 SXM 芯片上的数据类型（以绿色显示）。性能结果以 &lt;a href=&quot;https://en.wikipedia.org/wiki/FLOPS&quot;>;FLOPS&lt;/a>; 为单位（越高越好）。值得注意的是，前八个矩阵乘法相对于后两个矩阵乘法需要额外的操作，因为混合精度变体直接针对硬件加速的 Tensor Core 操作，不需要数据类型转换和布局一致性。即便如此，我们的方法证明了混合输入矩阵乘法性能仅略低于或与混合精度相当。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-Dq_2LmFUlg0KlNIJvFufCUMZujNc9LcoMnSURpGQwGbM75vXuS-Nm9ZH-7ItgWmZaBSUS3yawN0u3K21tbWTdijU4 fVNgEyS33jOztyGfvNvLEw6IBiJO3JSmpctQtN8tvZmagEYQNSP3mmBQnXJ8GeNlQymbeqrKjFycjkKnHL_5FC8V6WR858byfm_/s1999/image2.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1180&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-Dq_2LmFUlg0KlNIJvFufCUMZujNc9LcoMnSURpGQwGbM75vXuS-Nm9ZH-7ItgWmZaBSUS3yawN0u3K21tbWTdijU4fVNgEyS33jOztyGfvNvLEw6 IBiJO3JSmpctQtN8tvZmagEYQNSP3mmBQnXJ8GeNlQymbeqrKjFycjkKnHL_5FC8V6WR858byfm_/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;NVIDIA A100 40GB SMX4 芯片上计算受限矩阵问题形状的混合输入矩阵乘法性能&lt;code>;m=3456, n=4096, k=2048。&lt;/ code>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p >; &lt;em>;我们想提及几位通过技术头脑风暴和改进博客文章做出贡献的人，包括 Quentin Colombet、Jacques Pienaar、Allie Culp、Calin Cascaval、Ashish Gondimalla、Matt Walsh、Marek Kolodziej 和 Aman Bhatia。我们要感谢 NVIDIA 合作伙伴 Rawn Henry、Pradeep Ramani、Vijay Thakkar、Hai Cheng Wu、Andrew Kerr、Matthew Nicely 和 Vartika Singh。&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http:// /blog.research.google/feeds/5144906729109253495/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research. google/2024/01/mixed-input-matrix-multiplication.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www .blogger.com/feeds/8474926331452026626/posts/default/5144906729109253495&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/ posts/default/5144906729109253495&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/mixed-input-matrix-multiplication.html &quot; rel=&quot;alternate&quot; title=&quot;混合输入矩阵乘法性能优化&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com /profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src= &quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https:// /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEKJJf1R773hab0veY6zffF2Nf_yfV2mk8YU9yRnuBDD3ak1o0iXecWlJw2x7bL-Ez2MX1c21MXk65VMK5IsoLpJ1H6BTC6k7BvVWl_gHJpJIOG 2cm3BwP4V-HCScGHYIynuskbhvu1uorQGprHGbOFmfGI7E5UWemJcZ0xSC3tC5DolBYgyBwugl6OOLr/s72-c/matrixhero.png”宽度=“72”xmlns：媒体=“http://search.yahoo.com/mrss/” >;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-1418736582601940076&lt;/id>;&lt;已发布>;2024-01-23T14:27:00.000-08:00&lt;/已发布>;&lt;更新>;2024-01-23T14:27:09.785-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger .com/atom/ns#&quot; term=&quot;深度学习&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Graphs&quot;>;&lt;/category>;&lt; title type=&quot;text&quot;>;Exphormer：图结构数据的缩放转换器&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Ameya Velingker，Google 研究院研究科学家Balaji Venkatachalam，Google 软件工程师&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbovKreBr7RlKc4L36E6rLqiZBZzJSq5GLijCkomHREon5tYXd-7C2pppMXnL5Mj2d82kZGnPlarrrMzQOfRn N8kVvqDh1GnadIJ-hbaaS8VjYzCpaD-DgYor5cKx-OhTGZk9iCy5MjtwG2Q9eTyQiipDr5ViMdl2vkxfbLzWnB3wmLb8YfvVsTJ1FnOmw/s1600/EXPHORMER%2005large.gif&quot;样式=“显示：无；” />; &lt;p>; &lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)&quot;>;图&lt;/a>;，其中对象及其关系表示为节点（或顶点）和边节点对之间的连接（或链接）在计算和机器学习 (ML) 中无处不在。例如，社交网络、道路网络以及分子结构和相互作用都是底层数据集具有自然图结构的领域。机器学习可用于学习节点、边或整个图的属性。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 图学习的常见方法是&lt;a href=&quot;https://distill.pub/2021/gnn-intro/&quot;>;图神经网络网络（GNN），通过对节点、边缘和全局属性应用可优化的转换来对图数据进行操作。最典型的 GNN 类别通过 &lt;a href=&quot;https://wandb.ai/graph-neural-networks/spatial/reports/An-Introduction-to-Message-Passing-Graph-Neural-Networks--VmlldzoyMDI2NTg2 进行操作&quot;>;消息传递框架，其中每一层将节点的表示与其直接邻居的表示聚合。 &lt;/p>; &lt;p>; 最近，&lt;a href=&quot;https://arxiv.org/abs/2012.09699&quot;>;图转换器模型&lt;/a>;已成为消息传递 GNN 的流行替代方案。这些模型建立在自然语言处理 (NLP) 领域&lt;a href=&quot;https://en.wikipedia.org/wiki/Transformer_(machine-learning_model)&quot;>;Transformer 架构&lt;/a>;的成功之上，使它们适应图形- 结构化数据。图转换器中的注意力机制可以通过交互图来建模，其中边代表相互关注的节点对。与消息传递架构不同，图转换器具有与输入图分离的交互图。典型的交互图是一个完整的图，这意味着一个完整的注意力机制，可以模拟所有节点对之间的直接交互。&lt;em>; &lt;/em>;然而，这会产生二次计算和内存瓶颈，限制了图转换器对最多具有数千个节点的小图上的数据集的适用性。使图转换器可扩展被认为是该领域最重要的研究方向之一（参见&lt;a href=&quot;https://towardsdatascience.com/graph-ml-in-2022-where-are-we-now-f7f8242599e0&quot; >;这里是第一个开放问题&lt;/a>;）。 &lt;/p>; &lt;p>; 一种自然的补救措施是使用边数较少的&lt;em>;稀疏&lt;/em>;交互图。 &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3530811&quot;>;人们提出了许多稀疏且高效的变换器&lt;/a>;来消除序列的二次瓶颈，但是，它们通常不会扩展到有原则地绘制图表。 &lt;/p>; &lt;p>; 在“&lt;a href=&quot;https://arxiv.org/abs/2303.06147&quot;>;Exphormer：图的稀疏变换器&lt;/a>;”中，介绍于 &lt;a href=&quot;https:// icml.cc/Conferences/2023/Dates&quot;>;ICML 2023&lt;/a>;，我们通过引入专为图数据设计的变压器稀疏注意力框架来解决可扩展性挑战。 Exphormer 框架利用扩展图，这是&lt;a href=&quot;https://en.wikipedia.org/wiki/Spectral_graph_theory&quot;>;谱图理论&lt;/a>;的强大工具，并且能够在以下方面取得强有力的实证结果：各种各样的数据集。我们的 Exphormer 实现现已在 &lt;a href=&quot;https://github.com/hamed1375/Exphormer&quot;>;GitHub&lt;/a>; 上提供。 &lt;/p>; &lt;br />; &lt;h2>;扩展图&lt;/h2>; &lt;p>; Exphormer 核心的一个关键思想是使用 &lt;a href=&quot;https://en.wikipedia.org/wiki/Expander_graph &quot;>;扩展图&lt;/a>;，它们是稀疏但连接良好的图，具有一些有用的属性 - 1）图的矩阵表示具有与完整图类似的线性代数属性，2）它们表现出快速混合随机游走，即从任何起始节点开始的随机游走中的少量步骤足以确保收敛到图的节点上的“稳定”分布。扩展器已应用于不同领域，例如算法、伪随机性、复杂性理论和纠错码。 &lt;/p>; &lt;p>; 扩展器图的常见类别是 &lt;em>;d&lt;/em>; 正则扩展器，其中每个节点都有 &lt;em>;d&lt;/em>; 条边（即每个节点的度数 &lt; em>;d&lt;/em>;）。扩展图的质量是通过其&lt;em>;谱间隙&lt;/em>;来衡量的，这是其&lt;a href=&quot;https://en.wikipedia.org/wiki/Adjacency_matrix&quot;>;邻接矩阵&lt;/a的代数属性>;（图形的矩阵表示，其中行和列由节点索引，条目指示节点对是否由边连接）。那些最大化光谱间隙的被称为&lt;a href=&quot;https://en.wikipedia.org/wiki/Ramanujan_graph&quot;>;拉马努扬图&lt;/a>; - 它们实现了&lt;em>;d&lt;/em>;的间隙 - 2*√(&lt;em>;d&lt;/em>;-1)，这本质上是&lt;em>;d&lt;/em>;正则图中最好的。多年来，针对各种 &lt;em>;d&lt;/em>; 值，人们提出了拉马努金图的许多确定性和随机构造。我们使用弗里德曼的随机扩展器构造，它生成近拉马努金图。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg495FZQZ12yMiNhU8C7XUKEJ88H5_v2PPrzhwcDOVnSaVEtdCXaL7py-LzwZZkybKwIaePLHKpdmD6qALfskdjeaA8ML 9QYHMwWkxz2ZnhWYqoV1PpnNgbRRfm0pSVYJVrtUpONyyF5PfswJ_QoxD-9vI9F3rF6VQbIRDDIbgvOFc35vTEF9uxizKNpli9/s843/image1.gif&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;843&quot; data-original-width=&quot;800&quot; height=&quot;320&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg495FZQZ12yMiNhU8C7XUKEJ88H5_v2PPrzhwcDOVnSaVEtdCXaL7py-LzwZZkybKwIaePLHKpdmD6qALfskdjeaA8ML9QYHMwWkxz2ZnhWYqoV1P pnNgbRRfm0pSVYJVrtUpONyyF5PfswJ_QoxD-9vI9F3rF6VQbIRDDIbgvOFc35vTEF9uxizKNpli9/s320/image1.gif&quot; width=&quot;304&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt; td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;span id=&quot;docs-internal-guid-2920b38b-7fff-2fa8-a3cd-06dfd3ba9968&quot;>;&lt;spanface=&quot;Arial, sans-衬线&quot; style=&quot;font-size: 10pt;字体样式：斜体；字体变体替代：正常；字体变体东亚：正常；字体变体数字：正常；字体变体位置：正常；垂直对齐：基线； white-space-collapse:preserve;&quot;>;扩展图是 Exphormer 的核心。一个好的扩展器是稀疏的，但表现出随机游走的快速混合，使其全局连接适合图转换器模型中的交互图。&lt;/span >;&lt;/span>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;Exphormer 用稀疏 &lt;em>;d&lt;/em 的边缘替换标准 Transformer 的密集、全连接交互图>;-正则扩展图。直观上，扩展图的谱近似和混合属性允许在图转换器架构中堆叠多个关注层后，远处的节点能够相互通信，即使节点可能不直接相互关注。此外，通过确保&lt;em>;d&lt;/em>;恒定（与节点数量的大小无关），我们在生成的交互图中获得了线性数量的边。&lt;/p>; &lt;br />; &lt;h2 >;Exphormer：构建稀疏交互图&lt;/h2>; &lt;p>; Exphormer 将扩展边与输入图和虚拟节点结合起来。更具体地说，Exphormer 的稀疏注意力机制构建了一个由三种类型的边组成的交互图：&lt;/p>; &lt;ul>; &lt;li>;来自输入图的边（&lt;em>;局部注意力&lt;/em>;）&lt;/li>; &lt;li>;来自恒定度扩展图的边（&lt;em>;扩展注意力&lt;/em>;）&lt;/li>;&lt;li>;从每个节点到一小组虚拟节点的边（&lt;em>;全局注意力&lt;/em>; ) &lt;/li>; &lt;/ul>; &lt;tablealign=“center”cellpadding=“0”cellspacing=“0”class=“tr-caption-container”style=“margin-left：auto；margin-right：auto； &quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiS7VdL6OcWCmXd-wTtx-qs_nA7qTYZFJOTHS7RZNS3Io_w4km3NM4opPsQBXu1u50KjDA43CsG0hoi 1l7I9gq_KGBMvwKEjlWQKBzCeytLQHujF-4K4r9E4F4Q0APvw7le4twjGbDyEiVfEzhbsovhzk2_g4Xd4jwCo66HW7xbnLvm3WPBsHaoq- hDAYX8/s800/image1.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;430&quot; data-original-width=&quot;800&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiS7VdL6OcWCmXd-wTtx-qs_nA7qTYZFJOTHS7RZNS3Io_w4km3NM4opPsQBXu1u50KjDA43CsG0hoi1l7I9gq_KGBMvwKEjlWQKBzC eytLQHujF-4K4r9E4F4Q0APvw7le4twjGbDyEiVfEzhbsovhzk2_g4Xd4jwCo66HW7xbnLvm3WPBsHaoq-hDAYX8/s16000/image1.gif&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt; tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;span id=&quot;docs-internal-guid-ac11d16d-7fff-62da-cf18-7ba830f677d3&quot;>;&lt;spanface=&quot;Arial , 无衬线&quot; style=&quot;font-size: 10pt;字体样式：斜体；字体变体替代：正常；字体变体东亚：正常；字体变体数字：正常；字体变体位置：正常；垂直对齐：基线； white-space-collapse:preserve;&quot;>;Exphormer 通过组合三种类型的边来构建交互图。生成的图具有良好的连通性，并保留输入数据集图的归纳偏差，同时仍然保持稀疏。&lt;/span>;&lt;/ span>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 每个组件都有特定的用途：输入图的边保留输入图结构的归纳偏差（通常会在全连接注意力模块）。同时，扩展器边缘允许良好的全局连接性和随机游走混合属性（在光谱上近似于具有更少边缘的完整图）。最后，虚拟节点充当全局“内存接收器”，可以直接与每个节点通信节点。虽然这会导致每个虚拟节点的附加边等于输入图中的节点数，但生成的图仍然稀疏。扩展器图的度和虚拟节点的数量是用于调整以提高质量的超参数指标。 &lt;/p>; &lt;p>; 此外，由于我们使用恒定度的扩展图和少量恒定数量的虚拟节点来进行全局注意力，因此得到的稀疏注意力机制与原始输入图的大小是线性的，即根据节点和边总数的顺序对许多直接交互进行建模。 &lt;/p>; &lt;p>; 我们还表明，Exphormer 与密集变压器一样具有表现力，并且遵循通用逼近属性。特别是，当 Exphormer 的稀疏注意力图通过自循环（将节点连接到自身的边）进行增强时，它可以普遍逼近连续函数 [&lt;a href=&quot;https://arxiv.org/abs/1912.10077&quot;>;1 &lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2006.04862&quot;>;2&lt;/a>;]。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;与序列的稀疏 Transformer 的关系&lt;/h3>; &lt;p>; 将 Exphormer 与稀疏进行比较很有趣序列的注意方法。也许在概念上与我们的方法最相似的架构是 &lt;a href=&quot;https://blog.research.google/2021/03/constructing-transformers-for-longer.html&quot;>;BigBird&lt;/a>;，它构建了一个交互通过组合不同的组件来绘制图形。 BigBird 也使用虚拟节点，但与 Exphormer 不同，它使用来自 &lt;a href=&quot;https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3 的窗口注意力和随机注意力%A9nyi_model&quot;>;Erdős-Rényi&lt;/a>; 其余组件的随机图模型。 &lt;/p>; &lt;p>; BigBird 中的窗口注意力着眼于序列中标记周围的标记——Exphormer 中的局部邻域注意力可以被视为窗口注意力对图的概括。 &lt;/p>; &lt;p>; &lt;em>;n&lt;/em>; 个节点上的 Erdős-Rényi 图，&lt;em>;G(n, p)&lt;/em>;，以概率 &lt;em>;p 独立连接每对节点&lt;/em>;，还可以用作适当高&lt;em>;p&lt;/em>;的扩展图。然而，需要超线性边数 (Ω(&lt;em>;n&lt;/em>; log &lt;em>;n&lt;/em>;)) 来确保 Erdős-Rényi 图是连通的，更不用说良好的扩展器了。另一方面，Exphormer 中使用的扩展器只有&lt;em>;线性&lt;/em>;数量的边。 &lt;/p>; &lt;br />; &lt;h2>;实验结果&lt;/h2>; &lt;p>; 早期的工作已经展示了在图大小高达 5,000 个节点的数据集上使用基于全图 Transformer 的模型。为了评估 Exphormer 的性能，我们基于著名的 &lt;a href=&quot;https://github.com/rampasek/GraphGPS&quot;>;GraphGPS 框架&lt;/a>; [&lt;a href=&quot;https://arxiv.org/ abs/2205.12454&quot;>;3&lt;/a>;]，它结合了消息传递和图形转换器，并在许多数据集上实现了最先进的性能。我们证明，用 Exphormer 代替 GraphGPS 框架中的图注意力组件的密集注意力可以实现具有可比或更好性能的模型，并且通常具有更少的可训练参数。 &lt;/p>; &lt;p>; 此外，Exphormer 还特别允许图形转换器架构的扩展远远超出上述通常的图形大小限制。 Exphormer 可以扩展到包含 10,000 多个节点图的数据集，例如 &lt;a href=&quot;https://arxiv.org/abs/1811.05868&quot;>;Coauthor 数据集&lt;/a>;，甚至可以扩展到更大的图，例如井-已知&lt;a href=&quot;https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv&quot;>;ogbn-arxiv数据集&lt;/a>;，一个引文网络，由17万个节点和110万条边组成。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-HJWH6mqX6N9ytZPbz6wawfMLzF2ey50Ot2BcowvPbQ3FaNwhlEZ3htvDbhq1C6ckLykf0yk3A1sIG0aPGaT 8G_aSLj_A-AOfl8NIZdygdkn0C26RzZS9d-9KjyP1f_Zy7suN-iqvYR4zSCgqCXrhP8hVIirUgi6VGEBGx9I_AZikzc_ACKskBMBMPoSw/s1600/ExphormerPerformance .png&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;&quot;>;&lt;img alt=&quot;&quot; border=&quot;0&quot; data-original-高度=“190”数据原始宽度=“1522”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-HJWH6mqX6N9ytZPbz6wawfMLzF2ey50Ot2BcowvPbQ3FaNwhlEZ3htvDbhq1C6ckLykf0yk3A1sIG0 aPGaT8G_aSLj_A-AOfl8NIZdygdkn0C26RzZS9d-9KjyP1f_Zy7suN-iqvYR4zSCgqCXrhP8hVIirUgi6VGEBGx9I_AZikzc_ACKskBMBMPoSw/s1600/ExphormerPerformance.png&quot; / >;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;在五个 &lt;a href=&quot; 上比较 Exphormer 与标准 GraphGPS 的结果https://arxiv.org/abs/2206.08164&quot;>;长期图基准&lt;/a>;数据集。我们注意到，在论文发表时，Exphormer 在五个数据集（PascalVOC-SP、COCO-SP、Peptides-Struct、PCQM-Contact）中的四个上取得了最先进的结果。&lt;/td>;&lt;/td>;&lt;/ tr>;&lt;/tbody>;&lt;/table>; &lt;!--&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin -right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDbVRMNKr2z64PowKGcaM4NDeiIfzrpfyXe02tRD8tpr_DS99oIjewDwOZZJkNgOr7ZSYwsE5jVqpwO z0Tj2z68SkQzCWtZrhC3cXf2WWfJEZmSfOq3xlGIjdfx-9V0CkbYYv6LU63i1B -suztAyK0Dx8udq2SYSX4TEeP5Erw021KZY8L4FEVNV3BOXaL/s1600/ExphormerPerformance.png&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;&quot;>;&lt;img alt=&quot;&quot; border=&quot; 0&quot; data-original-height=&quot;202&quot; data-original-width=&quot;1655&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDbVRMNKr2z64PowKGcaM4NDeiIfzrpfyXe02tRD8tpr_DS99oIjewDwOZZJkNgOr7ZSYwsE5jV qpwOz0Tj2z68SkQzCWtZrhC3cXf2WWfJEZmSfOq3xlGIjdfx-9V0CkbYYv6LU63i1B-suztAyK0Dx8udq2SYSX4TEeP5Erw021KZY8L4FEVNV3BOXaL/s1600/ExphormerPerformance.png &quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;在五个&lt;a href 上比较 Exphormer 与标准 GraphGPS 的结果=&quot;https://arxiv.org/abs/2206.08164&quot;>;长期图基准&lt;/a>;数据集。我们注意到，截至发布时，Exphormer 在五个数据集（PascalVOC-SP、COCO-SP、Peptides-Struct、PCQM-Contact）中的四个上取得了最先进的结果。&lt;/td>;&lt;/tr>; &lt;/tbody>;&lt;/table>;-->; &lt;!--&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>; &lt;tbody>;&lt;tr>; &lt;tdalign=&quot;left&quot;>;&lt;strong>;型号&lt;/strong>; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;PascalVOC- SP&amp;nbsp;&lt;/strong>; &lt;br>; &amp;nbsp;&lt;font size=&quot;-1&quot;>;F1 得分 &lt;/font>;&lt;strong>;↑&lt;/strong>;&amp;nbsp; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;&amp;nbsp;COCO-SP&amp;nbsp;&lt;/strong>;&lt;br>;&amp;nbsp;&lt;font size=&quot;-1&quot;>;F1分数&lt;/font>;&lt;strong>;↑&lt; /strong>;&amp;nbsp; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;肽功能&lt;/strong>;&lt;br>;&lt;font size=&quot;-1&quot;>;AP &lt;/font>;&lt;strong>;↑&lt;/强>;&amp;nbsp; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;肽结构&lt;/strong>;&lt;br>;&lt;font size=&quot;-1&quot;>;MAE&lt;/font>;&lt;strong>;↓&lt;/强>;&amp;nbsp; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;PCQM-联系方式&lt;/strong>;&lt;br>;&amp;nbsp;&lt;font size=&quot;-1&quot;>;MRR&lt;/font>;&lt;strong>;↑&lt;/strong >; &lt;/td>; &lt;/tr>; &lt;tr>;&lt;td colspan=&quot;6&quot;>;&lt;div style=&quot;line-height: 40%;&quot;>;&lt;br />;&lt;/div>;&lt;/td>;&lt;/tr>; &lt;tr>; &lt;td>;标准图形GPS &lt;/td>; &lt;tdalign=&quot;center&quot;>;0.375 ± 0.011 &lt;/td>; &lt;tdalign=&quot;center&quot;>;0.341 ± 0.004 &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;0.654 ± 0.004&lt;/strong>; &amp;nbsp; &lt;/td>; &lt;tdalign=&quot;center&quot;>;0.250 ± 0.001 &lt;/td>; &lt;tdalign=&quot;center&quot;>;&amp;nbsp;0.334 ± 0.001&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;&lt;em>;Exphormer（我们的）&lt;/em>; &lt;/td>; &lt;td align=&quot;center&quot;>;&lt;strong>;&lt;em>;0.398 ± 0.004&lt;/em>;&lt;/strong>; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;&lt;em>;0.346 ± 0.001 &lt;/em>;&lt;/strong>; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;em>;0.653 ± 0.004&lt;/em>; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong >;&lt;em>;&amp;nbsp;0.248 ± 0.001&lt;/em>;&lt;/strong>; &lt;/td>; &lt;tdalign=&quot;center&quot;>;&lt;strong>;&lt;em>;&amp;nbsp;0.364 ± 0.002&lt;/em>;&lt;/strong>; &lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>;-->; &lt;p>; 最后，我们观察到Exphormer通过扩展器创建小直径的覆盖图，表现出有效学习远程依赖关系的能力。 &lt;a href=&quot;https://arxiv.org/abs/2206.08164&quot;>;远程图基准&lt;/a>; 是一套由五个图学习数据集组成的套件，旨在衡量模型捕获远程交互的能力。结果表明，基于 Exphormer 的模型优于标准 GraphGPS 模型（在发布时，该模型在五分之四的数据集上是最先进的）。 &lt;/p>; &lt;br />; &lt;h2>;结论&lt;/h2>; &lt;p>; 图转换器已成为 ML 的重要架构，它将 NLP 中使用的非常成功的基于序列的转换器适应图结构数据。然而，可扩展性已被证明是在具有大型图的数据集上使用图转换器的主要挑战。在这篇文章中，我们介绍了 Exphormer，一个稀疏注意力框架，它使用扩展图来提高图转换器的可扩展性。 Exphormer 被证明具有重要的理论特性，并表现出强大的经验性能，特别是在学习长期依赖性至关重要的数据集上。如需了解更多信息，我们建议读者观看 ICML 2023 的简短演示&lt;a href=&quot;https://icml.cc/virtual/2023/poster/23782&quot;>;视频&lt;/a>;。&lt;/p>; &lt;br / >; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;我们感谢不列颠哥伦比亚大学的研究合作者 Hamed Shirzad 和 Danica J. Sutherland 以及 Google Research 的 Ali Kemal Sinop。特别感谢 Tom Small 创建本文中使用的动画。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/1418736582601940076/comments/default&quot; rel =&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/exphormer-scaling-transformers-for.html# comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1418736582601940076&quot; rel =&quot;编辑&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1418736582601940076&quot; rel=&quot;self&quot; type=&quot;application/ atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/exphormer-scaling-transformers-for.html&quot; rel=&quot;alternate&quot; title=&quot;Exphormer：图的缩放转换器结构化数据” type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger .com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16 -rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbovKreBr7RlKc4L36E6rLqiZBZzJSq5GLijCkomHREon5tYXd -7C2pppMXnL5Mj2d82kZGnPlarrrMzQOfRnN8kVvqDh1GnadIJ-hbaaS8VjYzCpaD-DgYor5cKx-OhTGZk9iCy5MjtwG2Q9eTyQiipDr5ViMdl2vkxfbLzWnB3wmLb8YfvVsTJ1FnOmw/ s72-c/EXPHORMER%2005large.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt; thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-220849549986709693&lt;/id>;&lt;已发布>;2024-01-18T10:03 ：00.000-08:00&lt;/已发布>;&lt;已更新>;2024-01-18T10:03:43.608-08:00&lt;/已更新>;&lt;类别方案=“http://www.blogger.com/atom/ns#” term=&quot;大型语言模型&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;引入 ASPIRE 在法学硕士中进行选择性预测&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;已发布作者：Jiefeng Chen（学生研究员）和 Jinsung Yoon（云 AI 团队研究科学家）&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMaqP9dd9YDXh04PEWHSFquEToz6U5M4YUxzfExokjfteUfuGAKhqs1LV5DUMJOBoiF3GjGxg7Nq ezNazuTeWePMsuH_OW7NM4z4ooMPhWnR22iyzENgpmG2-xJDbRbeeyyLbG-3dIdgYjl2IxX0K-bFvpbrAJsQA7Mu70MqxEuVFJXvwnP_- o4sPK8wYe/s320/ASPIRE%20hero.jpg&quot; style=&quot;显示：无；&quot; />; &lt;p>; 在快速发展的人工智能领域，大型语言模型 (LLM) 彻底改变了我们与机器交互的方式，将自然语言理解和生成的界限推向了前所未有的高度。然而，进入高风险决策应用仍然是一个巨大的鸿沟，这主要是由于模型预测固有的不确定性。传统的法学硕士递归地生成响应，但它们缺乏为这些响应分配置信度分数的内在机制。尽管可以通过总结序列中各个标记的概率来得出置信度分数，但传统方法通常无法可靠地区分正确答案和错误答案。但是，如果法学硕士能够衡量自己的信心并仅在有把握时才做出预测，结果会怎样呢？ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; &lt;a href=&quot;https://papers.nips.cc/paper_files/paper/2017/hash/4a8423d5e91fda00bb7e46540e2b0cf1-Abstract.html&quot;>;选择性预测&lt;/a>;旨在通过使法学硕士能够输出答案和选择分数来实现这一点，选择分数表明答案正确的概率。通过选择性预测，人们可以更好地了解在各种应用中部署的法学硕士的可靠性。先前的研究，例如&lt;a href=&quot;https://openreview.net/pdf?id=VD-AYtP0dve&quot;>;语义不确定性&lt;/a>;和&lt;a href=&quot;https://arxiv.org/pdf/2207.05221 .pdf&quot;>;自我评估&lt;/a>;，试图在法学硕士中实现选择性预测。典型的方法是使用启发式提示，例如“建议的答案是对还是错？”触发法学硕士的自我评估。但是，这种方法可能不适用于具有挑战性的&lt;a href=&quot;https://en.wikipedia.org/wiki/Question_answering&quot;>;问答&lt;/a>; (QA) 任务。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIwlr34r2t085uhaOx2IbBulTJX2FB2g8LkhTgrKgycgb8cDZaRuht0cFPqmlgSkT5jHOx-rrWywmYAEEfJ0FxlC 7ammU8ewrZaVo_My7cCpBNYlfgERRKgFYnF-8LhsWhcyS3KTFdBnhyphenhyphencrenwQxBkbjM8UriPKzji8zDkXYv-5rhRXiE0SlvGmXUV-jt/s1999/image2 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1534&quot; data-original-width=&quot;1999&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIwlr34r2t085uhaOx2IbBulTJX2FB2g8LkhTgrKgycgb8cDZaRuht0cFPqmlgSkT5jHOx-rrWywmYAEEfJ0FxlC7ammU8ewrZaVo_My7cCpBNYlf gERRKgFYnF-8LhsWhcyS3KTFdBnhyphenhyphencrenwQxBkbjM8UriPKzji8zDkXYv-5rhRXiE0SlvGmXUV-jt/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://arxiv.org/abs/2205.01068&quot;>;OPT-2.7B&lt;/a>; 模型错误地回答了来自&lt;a href=&quot;https://aclanthology.org/P17-1147/&quot;>;TriviaQA&lt;/a>; 数据集：“哪种维生素有助于调节血液凝固？”与“维生素C”。如果没有选择性预测，法学硕士可能会输出错误的答案，在这种情况下，可能会导致用户服用错误的维生素。通过选择性预测，法学硕士将输出答案以及选择分数。如果选择分数较低（0.1），LLM会进一步输出“我不知道！”警告用户不要信任它或使用其他来源验证它。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; 在“&lt;a href=&quot;https://aclanthology. org/2023.findings-emnlp.345.pdf&quot;>;适应自我评估以提高法学硕士的选择性预测&lt;/a>;”，发表于 &lt;a href=&quot;https://2023.emnlp.org/program/accepted_findings /&quot;>;EMNLP 2023的研究结果&lt;/a>;，我们引入了ASPIRE——一个精心设计的新颖框架，旨在增强法学硕士的选择性预测能力。 ASPIRE 通过参数高效的微调对 QA 任务上的法学硕士进行微调，并训练他们评估生成的答案是否正确。 ASPIRE 允许法学硕士输出答案以及该答案的置信度分数。我们的实验结果表明，ASPIRE 在各种 QA 数据集上的性能显着优于最先进的选择性预测方法，例如 CoQA 基准&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ASPIRE 的机制&lt;/h2>; &lt;p>; 想象一下，教授法学硕士不仅要回答问题，还要还要评估这些答案——类似于学生在课本后面验证他们的答案。这就是 ASPIRE 的本质，它涉及三个阶段：(1) 针对特定任务的调优，(2) 答案采样，(3) 自我评估学习。 &lt;/p>; &lt;p>; &lt;strong>;特定于任务的调整&lt;/strong>;：ASPIRE 执行特定于任务的调整以训练适应性参数 (θ&lt;sub>;p&lt;/sub>;)，同时冻结 LLM。给定生成任务的训练数据集，它会对预训练的 LLM 进行微调以提高其预测性能。为此，参数高效的调整技术（例如，&lt;a href=&quot;https://aclanthology.org/2021.emnlp-main.243/&quot;>;软提示调整&lt;/a>;和&lt;a href=&quot;https: //openreview.net/forum?id=nZeVKeeFYf9&quot;>;LoRA&lt;/a>;）可用于调整任务上的预训练 LLM，因为它们可以有效地利用少量目标任务数据获得强泛化能力。具体来说，LLM 参数 (θ) 被冻结，并添加自适应参数 (θ&lt;sub>;p&lt;/sub>;) 进行微调。仅更新 θ&lt;sub>;p&lt;/sub>; 以最小化标准 LLM 训练损失（例如，&lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-entropy#Cross-entropy_minimization&quot;>;交叉-熵&lt;/a>;）。这种微调可以提高选择性预测性能，因为它不仅提高了预测精度，而且还提高了正确输出序列的可能性。 &lt;/p>; &lt;p>; &lt;strong>;答案采样&lt;/strong>;：在针对特定任务进行调整后，ASPIRE 使用 LLM 和学习到的 θ&lt;sub>;p&lt;/sub>; 为每个训练问题生成不同的答案，并创建一个用于自我评估学习的数据集。我们的目标是生成具有高可能性的输出序列。我们使用&lt;a href=&quot;https://en.wikipedia.org/wiki/Beam_search&quot;>;束搜索&lt;/a>;作为解码算法来生成高似然输出序列和&lt;a href=&quot;https:// aclanthology.org/P04-1077/&quot;>;Rouge-L&lt;/a>; 度量来确定生成的输出序列是否正确。 &lt;/p>; &lt;p>; &lt;strong>;自评估学习&lt;/strong>;：在对每个查询的高似然输出进行采样后，ASPIRE 添加自适应参数 (θ&lt;sub>;s&lt;/sub>;)，并且仅微调 θ &lt;sub>;s&lt;/sub>; 用于学习自我评估。由于输出序列的生成仅取决于θ和θ&lt;sub>;p&lt;/sub>;，因此冻结θ和学习到的θ&lt;sub>;p&lt;/sub>;可以避免在学习自我评估时改变LLM的预测行为。我们优化了 θ&lt;sub>;s&lt;/sub>;，使得适应后的 LLM 可以自己区分正确和错误的答案。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjKSO3s9PgcBr1MpkJR_PYI-ogQ79JD4A4-fJ_OgT8reSKEqIWSUPD7QUVSqIUuAhNfbgEA-XVrOne8S1oJSFaE6YIH4 z43bn8jzsfG768qynW-G6lG7dwOvu15UCH6tdlIXEoe2dCUAHmT2bmNijwUvigF50W8vBCsCrjBA_FGYlnsmizHiyutHYZ1A-A2/s1999 /image5.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;933&quot; data-original-width=&quot;1999&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjKSO3s9PgcBr1MpkJR_PYI-ogQ79JD4A4-fJ_OgT8reSKEqIWSUPD7QUVSqIUuAhNfbgEA-XVrOne8S1oJSFaE6YIH4z43bn8jzsfG768qynW-G6 LG7dwOvu15UCH6tdlIXEoe2dCUAHmT2bmNijwUvigF50W8vBCsCrjBA_FGYlnsmizHiyutHYZ1A-A2/s16000/image5.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;ASPIRE 框架的三个阶段。 &lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; 在所提出的框架中，可以训练 θ&lt;sub>;p&lt;/sub>; 和 θ&lt;sub>;s&lt;/sub>;使用任何参数有效的调整方法。在这项工作中，我们使用&lt;a href=&quot;https://aclanthology.org/2021.emnlp-main.243/&quot;>;软提示调整&lt;/a>;，这是一种简单而有效的学习“&lt;a href=&quot; https://blog.research.google/2022/02/guiding-frozen-language-models-with.html&quot;>;软提示&lt;/a>;”来调节冻结语言模型，以比传统离散文本更有效地执行特定的下游任务提示。这种方法背后的驱动力在于认识到，如果我们能够开发出有效激发自我评价的提示，那么应该可以通过结合有针对性的培训目标的软提示调整来发现这些提示。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhCX9MjJ_KqSauAvXOvcXCDWR1H-hoD3e6EaSCEbG5-EJoJYLmekytCRSXaXrhNGS5BH7DfwbZW7FWzUaTERsGxKSWWM8 lLAOxxDX3M5U4Zv8gERXBk_uCY7OVshLexrKt5GTswrkRdFW0dAcMaALHvrLIosv7Tn4pRd7Rh35-HGWQ13SAeHtJ5-wsNgMNt/s800/image1 .gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;466&quot; data-original-width=&quot;800&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhCX9MjJ_KqSauAvXOvcXCDWR1H-hoD3e6EaSCEbG5-EJoJYLmekytCRSXaXrhNGS5BH7DfwbZW7FWzUaTERsGxKSWWM8lLAOxxDX3M5U4Zv8gERXBk_u CY7OVshLexrKt5GTSwrkRdFW0dAcMaALHvrLIosv7Tn4pRd7Rh35-HGWQ13SAeHtJ5-wsNgMNt/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;通过软提示调优实现ASPIRE框架。我们首先使用第一个软提示生成问题的答案，然后使用第二个软提示计算学习到的自我评估分数。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p >; 在训练 θ&lt;sub>;p&lt;/sub>; 和 θ&lt;sub>;s&lt;/sub>; 后，我们通过波束搜索解码获得查询的预测。然后，我们定义一个选择分数，将生成的答案的可能性与学习的自我评估分数（即，预测对于查询正确的可能性）相结合，以做出选择性预测。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结果&lt;/h2>; &lt;p>; 为了证明 ASPIRE 的功效，我们通过三个问答来评估它数据集 - &lt;a href=&quot;https://aclanthology.org/Q19-1016/&quot;>;CoQA&lt;/a>;、&lt;a href=&quot;https://aclanthology.org/P17-1147/&quot;>;TriviaQA&lt;/a>; >; 和 &lt;a href=&quot;https://aclanthology.org/D16-1264/&quot;>;SQuAD&lt;/a>; — 使用各种&lt;a href=&quot;https://arxiv.org/abs/2205.01068&quot;>;开放预-训练有素的变压器（OPT）模型。通过使用软提示调整训练 θ&lt;sub>;p&lt;/sub>;，我们观察到法学硕士的准确性大幅提高。例如，采用 ASPIRE 的 &lt;a href=&quot;https://arxiv.org/abs/2205.01068&quot;>;OPT-2.7B&lt;/a>; 模型表现出比使用CoQA 和 SQuAD 数据集。这些结果表明，通过适当的调整，较小的法学硕士可能有能力在某些情况下匹配或可能超越较大模型的准确性。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiT3H50FS2Ml9VoWJCuNnInzRQqtNEpyUXuwRnogIG-pDIlRduV0DmvyI9iQIHTziGdqkugV9SDjIcV8WPfnb8QyzQ3ACcus D7O1FQvyVe9U9C5iCbX-us8xHNhbvg2uv_CPwe4UJASF_dPe8s-c-xz-1hplqXYYxw4wsLOw9dJ-vWrLz -Ei4BrrW-e9Wzc/s1999/image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1500&quot; data-original-width= “1999” src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiT3H50FS2Ml9VoWJCuNnInzRQqtNEpyUXuwRnogIG-pDIlRduV0DmvyI9iQIHTziGdqkugV9SDjIcV8WPfnb8QyzQ3ACcusD7O1FQvyVe 9U9C5iCbX-uS8xHNhbvg2uv_CPwe4UJASF_dPe8s-c-xz-1hplqXYYxw4wsLOw9dJ-vWrLz-Ei4BrrW-e9Wzc/s16000/image4.png&quot;/>;&lt;/ a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 在深入研究固定模型预测的选择分数计算时，ASPIRE 获得了更高的&lt;a href=&quot;https://openreview.net /pdf?id=VD-AYtP0dve&quot;>;AUROC&lt;/a>; 分数（随机选择的正确输出序列比随机选择的不正确输出序列具有更高选择分数的概率）高于所有数据集的基线方法。例如，在 CoQA 基准上，与基线相比，ASPIRE 将 AUROC 从 51.3% 提高到 80.3%。 &lt;/p>; &lt;p>; TriviaQA 数据集评估中出现了一个有趣的模式。虽然预训练的 OPT-30B 模型表现出更高的基线精度，但与传统的自我评估方法相比，其选择性预测的性能并没有显着提高 - &lt;a href=&quot;https://arxiv.org/abs/2207.05221&quot;>;自我评估eval 和 P(True)&lt;/a>; — 已应用。相比之下，较小的 OPT-2.7B 模型在使用 ASPIRE 进行增强后，在这方面表现优于其他模型。这种差异强调了一个重要的见解：利用传统自我评估技术的较大法学硕士在选择性预测方面可能不如较小的 ASPIRE 增强模型有效。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbQLSLnyNPe8LW9W3KLt7Tkp3gmLSLHkTbICIi5j__yWNt7aG9PmWyW5bE4vSs8q2iFqE5dlb0KOdtKzcmg1JuKd zZWFUxYXiatDPB7N-q1NhkkH9hEcgqlw33BFUh_v_8DQJnY5lMrXexv0HUvTPYRS_Gb-M75Rx_TBhxyvLrI-AhZJV243sUzo2gIPoh/s1999/image3.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1599&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbQLSLnyNPe8LW9W3KLt7Tkp3gmLSLHkTbICIi5j__yWNt7aG9PmWyW5bE4vSs8q2iFqE5dlb0KOdtKzcmg1JuKdzZWFUxYXiatDPB7N-q1NhkkH9 hEcgqlw33BFUh_v_8DQJnY5lMrXexv0HUvTPYRS_Gb-M75Rx_TBhxyvLrI-AhZJV243sUzo2gIPoh/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 我们与 ASPIRE 的实验之旅强调了法学硕士格局的关键转变：语言模型并不是其性能的全部和最终目的。相反，模型的有效性可以通过策略调整来大幅提高，即使在较小的模型中也可以进行更精确、更自信的预测。因此，ASPIRE 证明了法学硕士的潜力，他们可以明智地确定自己的确定性，并在选择性预测任务中果断地超越更大的同行。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 总之，ASPIRE 不仅仅是另一个框架；它是一个框架。这是一个未来的愿景，法学硕士可以成为决策中值得信赖的合作伙伴。通过磨练选择性预测性能，我们距离充分发挥人工智能在关键应用中的潜力又近了一步。 &lt;/p>; &lt;p>; 我们的研究打开了新的大门，我们邀请社区在此基础上继续发展。我们很高兴看到 ASPIRE 将如何激励下一代法学硕士及其他人。要了解更多关于我们的发现，我们鼓励您阅读我们的论文，并加入我们这个激动人心的旅程，以创建更可靠和具有自我意识的人工智能。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;我们衷心感谢 Sercan Sayna Ebrahimi 的贡献O Arik、Tomas Pfister 和 Somesh Jha。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/220849549986709693/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/introducing-aspire-for-selective.html#comment-form&quot; rel=&quot;回复&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/220849549986709693&quot; rel=&quot;编辑&quot;类型=“application/atom+xml”/>;&lt;link href=“http://www.blogger.com/feeds/8474926331452026626/posts/default/220849549986709693”rel=“self”类型=“application/atom+xml” />;&lt;link href=&quot;http://blog.research.google/2024/01/introducing-aspire-for-selective.html&quot; rel=&quot;alternate&quot; title=&quot;引入 ASPIRE 在法学硕士中进行选择性预测&quot; type=&quot; text/html&quot;/>;&lt;作者>;&lt;名称>;Google AI&lt;/名称>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>; &lt;gd：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMaqP9dd9YDXh04PEWHSFquEToz6U5M4YUxzfExokjfteUfuGAKhqs1LV5DUMJOBoiF3GjGxg7NqezNazuTeWePMsu H_OW7NM4z4ooMPhWnR22iyzENgpmG2-xJDbRbeeyyLbG-3dIdgYjl2IxX0K-bFvpbrAJsQA7Mu70MqxEuVFJXvwnP_ -o4sPK8wYe/s72-c/ASPIRE%20hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt; /thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-1800430129205268706&lt;/id>;&lt;发布>;2024-01-12T09:04:00.000-08:00 &lt;/已发布>;&lt;更新>;2024-01-16T10：55：15.626-08：00&lt;/更新>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=“生成人工智能” >;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=“健康”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/” atom/ns#&quot; term=&quot;大语言模型&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;AMIE：用于诊断医学推理和对话的研究人工智能系统&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt; span class=&quot;byline-author&quot;>;发布者：Google 研究主管 Alan Karthikesalingam 和 Vivek Natarajan&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgr_wfWpw2CVBYDc3Mlk879CUecv4uGlq36Fxe0GENVcK2kJnzAyRkPRb 8vO5jJVqrd_zvQ6W8suHyp1xhFhNFJuUj8nTNRp3TsZP7Z5uWlqw22hZZKVJJ33X5NWmT0UTkOdC4raONlnSbR8E616Mi_lJVE3DvbWYB-19eR2wpCgwAaykkquUV3DOLRY6c /s16000/AMIE.gif&quot; style=&quot;显示：无；&quot; />; &lt;p>; 医患对话是医学的基石，熟练且有意的沟通可以推动诊断、管理、同理心和信任。能够进行此类诊断对话的人工智能系统可以通过成为临床医生和患者等有用的对话伙伴来提高护理的可用性、可及性、质量和一致性。但接近临床医生丰富的专业知识是一项重大挑战。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 医学领域之外的大型语言模型 (LLM) 的最新进展表明，它们可以计划、推理并使用相关上下文来进行丰富的对话。然而，良好的诊断对话有许多方面是医学领域独有的。一位高效的临床医生会获取完整的“临床病史”，并提出有助于得出鉴别诊断的明智问题。他们运用相当多的技能来建立有效的关系，清楚地提供信息，与患者共同做出明智的决定，对他们的情绪做出同理心的反应，并在下一步的护理中支持他们。虽然法学硕士可以准确地执行医学总结或回答医学问题等任务，但很少有专门针对开发此类对话诊断能力的工作。 &lt;/p>; &lt;p>; 受这一挑战的启发，我们开发了&lt;a href=&quot;https://arxiv.org/abs/2401.05654&quot;>;Articulate Medical Intelligence Explorer (AMIE)&lt;/a>;，这是一个基于法学硕士，并针对诊断推理和对话进行了优化。我们从临床医生和患者的角度从反映现实世界临床咨询质量的多个维度对 AMIE 进行了培训和评估。为了将 AMIE 扩展到多种疾病状况、专业和场景，我们开发了一种新颖的基于自我游戏的模拟诊断对话环境，具有自动反馈机制，以丰富和加速其学习过程。我们还引入了推理时间链推理策略，以提高 AMIE 的诊断准确性和对话质量。最后，我们通过模拟与训练有素的演员的协商，在多轮对话的真实例子中前瞻性地测试了 AMIE。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1TB1GjBHpX7Kazzao7l_ysdB7rXdxZQG7CodkfM4A7cYSJRKUEfhZL4iFJ4BI0ipp9o4rPam4ARcp0v98V_1CtcY Pb9fCalxW3Y_vekZl1iDtkdfshLbAi_OSbwuaecYtMosCRUtgvAMYWSoASj7A7OgAPfzVEQbwMOmkfzNnWKot2dtyAmQmFDtYKy4/s1200/AMIE%20GIF%201%20v2.gif &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;512&quot; data-original-width=&quot;1200&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1TB1GjBHpX7Kazzao7l_ysdB7rXdxZQG7CodkfM4A7cYSJRKUEfhZL4iFJ4BI0ipp9o4rPam4ARcp0v98V_1CtcYPb9fCalxW3Y_vekZl1iDtkd fshLbAi_OSbwuaecYtMosCRUtgvAMYWSoASj7A7OgAPfzVEQbwMOmkfzNnWKot2dtyAmQmFDtYKy4/s16000/AMIE%20GIF%201%20v2.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;AMIE 针对诊断对话进行了优化，提出有助于减少不确定性并提高诊断准确性的问题，同时还平衡了有效临床沟通的其他要求，例如同理心、培养&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;对话式诊断AI的评估&lt;/h2>; &lt;p>;除了开发和优化AI系统本身对于诊断对话，如何评估此类系统也是一个悬而未决的问题。受到用于衡量现实环境中咨询质量和临床沟通技巧的公认工具的启发，我们构建了一个试点评估标准，以评估与病史采集、诊断准确性、临床管理、临床沟通技巧、关系培养和共情。 &lt;/p>; &lt;p>; 然后，我们设计了一项基于文本的咨询的随机、双盲交叉研究，其中经过验证的患者参与者与经过委员会认证的初级保健医生 (PCP) 或针对诊断对话优化的人工智能系统进行交互。我们以&lt;a href=&quot;https://en.wikipedia.org/wiki/Objective_structed_clinical_examination&quot;>;客观结构化临床检查&lt;/a>; (OSCE) 的方式进行咨询，这是一种实际评估中常用的方法世界以标准化和客观的方式检查临床医生的技能和能力。在典型的 OSCE 中，临床医生可能会在多个工作站之间轮换，每个工作站都模拟现实生活中的临床场景，在这些场景中，他们执行诸如与标准化患者演员（经过仔细培训以模拟患有特定病症的患者）进行咨询等任务。咨询是使用同步文本聊天工具进行的，模仿了当今大多数使用法学硕士的消费者所熟悉的界面。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBTzb4Nx-dNLSwgDjJka4tYA29gFEnPna3N68cdriUmaybI1IGhqxPMLzObLg1nRh3S7pd21G7CHczMvy7tUHyETCl VRu8Hv3J9gQRd_WGYwORLiylKUgNViILvFO068daetL3MzJAa2rGU7Yzjg2BkfUas0hQgP9yBwmH_Wx3wmCpGfuZ-75yejQTAg8/s1350/image4.gif&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1350&quot; height=&quot;568&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBTzb4Nx-dNLSwgDjJka4tYA29gFEnPna3N68cdriUmaybI1IGhqxPMLzObLg1nRh3S7pd21G7CHczMvy7tUHyETClVru8Hv3J9gQRd_WGYwORLiyl KUgNViILvFO068daetL3MzJAa2rGU7Yzjg2BkfUas0hQgP9yBwmH_Wx3wmCpGfuZ-75yejQTAg8/w640-h568/image4.gif&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;AMIE 是一个基于法学硕士的研究人工智能系统，用于诊断推理和对话。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/ table>; &lt;br />; &lt;h2>;AMIE：基于法学硕士的会话诊断研究人工智能系统&lt;/h2>; &lt;p>; 我们在真实世界数据集上训练 AMIE，其中包括医学推理、医学总结和真实世界临床对话。 &lt;/p>; &lt;p>; 使用通过被动收集和转录现场临床就诊而开发的真实对话来培训法学硕士是可行的，但是，两个重大挑战限制了他们在培训法学硕士进行医学对话方面的有效性。首先，现有的现实世界数据往往无法捕捉广泛的医疗状况和场景，阻碍了可扩展性和全面性。其次，来自现实世界对话记录的数据往往很嘈杂，包含模棱两可的语言（包括俚语、行话、幽默和讽刺）、中断、不合语法的话语和隐含的引用。 &lt;/p>; &lt;p>; 为了解决这些限制，我们设计了一个基于自我游戏的模拟学习环境，具有自动反馈机制，可在虚拟护理环境中进行诊断医学对话，使我们能够在许多医疗条件和环境中扩展 AMIE 的知识和能力。除了所描述的真实世界数据的静态语料库之外，我们还使用此环境通过一组不断发展的模拟对话来迭代微调 AMIE。 &lt;/p>; &lt;p>; 这个过程由两个自我对弈循环组成：（1）一个“内部”自我对弈循环，其中 AMIE 利用上下文中的评论家反馈来改进其在与人工智能患者模拟器的模拟对话中的行为； （2）“外部”自我播放循环，其中一组经过改进的模拟对话被纳入后续的微调迭代中。由此产生的新版本的 AMIE 可以再次参与内部循环，从而创建一个良性的持续学习循环。 &lt;/p>; &lt;p>; 此外，我们还采用了推理时间链推理策略，使 AMIE 能够根据当前对话逐步完善其响应，以得出知情且有依据的答复。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiASnZ5p1olZNNL1e-bzqA6s1WprbenNRebHvq2sXuRhYHtHBMw5s1sgAR6SXS4lSDkBD_WgsY6mepBCoLojtes3GOU3yCoOPRG LoGpkMV99TM1Ru0xpNSNWee-5xfkUGBeE9fnp_rY8t_0Dv3NIxVnj9iGPNSyoGtJ6N9MSsjFsIqDpJVhsAQbCBoyJ1-N/s1400/image1.gif &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;1400&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiASnZ5p1olZNNL1e-bzqA6s1WprbenNRebHvq2sXuRhYHtHBMw5s1sgAR6SXS4lSDkBD_WgsY6mepBCoLojtes3GOU3yCoOPRGLoGpkMV99TM1Ru0xpNSNWee-5xf kUGBeE9fnp_rY8t_0Dv3NIxVnj9iGPNSyoGtJ6N9MSsjFsIqDpJVhsAQbCBoyJ1-N/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;AMIE 使用一种新颖的基于自我游戏的模拟对话学习环境来提高多种疾病状况、专业和患者背景下的诊断对话质量。&lt;/td>;&lt;/ tr>;&lt;/tbody>;&lt;/table>; &lt;!--&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDZCFvlZe9612iZ0gY2ov193z0iDcGQI0I9I1o0KRullBPhVIxyHerVflj5dm24vxyRqlNiPyL nfHW1yc9gE88KNekb_WQ4as6qO5BExL9K_aDXc9Ypx6DYNqWmvP5QoJ2sVitVVfVMvyLY2DJ7Ck92fwFAaHEeF2JmSMnftbXpAAUjS6ADM4F3dctOz4/ s1834/image4.png&quot; style=&quot;margin-left: 自动; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1284&quot; data-original-width=&quot;1834&quot; height=&quot;448&quot; src=&quot;https://blogger.googleusercontent.com /img/b/R29vZ2xl/AVvXsEiDZCFvlZe9612iZ0gY2ov193z0iDcGQI0I9I1o0KRullBPhVIxyHerVflj5dm24vxyRqlNiPyLnfHW1yc9gE88KNekb_WQ4as6qO5BExL9K_aDXc9Ypx6DYN qWmvP5QoJ2sVitVVfVMvyLY2DJ7Ck92fwFAaHEeF2JmSMnftbXpAAUjS6ADM4F3dctOz4/w640-h448/image4.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;AMIE 使用一种新颖的基于自我游戏的模拟对话学习环境来提高多种疾病状况、专业和患者背景下的诊断对话的质量。&lt;/td>;&lt;/tr>;&lt;/ tbody>;&lt;/table>;-->; &lt;br />; &lt;p>; 我们测试了与模拟患者（由训练有素的演员扮演）会诊时的表现，并与使用上述随机方法的 20 名真实 PCP 的表现进行比较。AMIE 和 PCP在一项随机、盲法交叉研究中，从专科主治医生和模拟患者的角度进行了评估，该研究包括来自加拿大、英国和印度的 OSCE 提供者的 149 个案例场景，涉及不同的专业和疾病。值得注意的是，我们的研究并不是为了模仿传统的面对面 OSCE 评估或临床医生通常使用文本、电子邮件、聊天或远程医疗的方式。相反，我们的实验反映了当今消费者与法学硕士互动的最常见方式，这是人工智能系统参与远程诊断对话的一种潜在可扩展且熟悉的机制。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSuFcXXr8lxIA1-p428y31PqVkpEMlQAdKj-vdTmtVYqeuogSQAjWFM3Gj8akNVG-6Cyd9xZKbLKz0jUFABDU_Jjw CM35qLVsSi5zlB3frgei5NAwhTQ7PyEbipXJK8gPvb0vY_VKGrZ-GFAmwtDf-pcJbKtY5DCEBb43N5rtnSa8gYdLxl5aQxpAZ1qo/s1999 /image8.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1296&quot; data-original-width=&quot;1999&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSuFcXXr8lxIA1-p428y31PqVkpEMlQAdKj-vdTmtVYqeuogSQAjWFM3Gj8akNVG-6Cyd9xZKbLKz0jUFABDU_JjwcM35qLVsSi5zlB3frgei5NAwh TQ7PyEbipXJK8gPvb0vY_VKGrZ-GFAmwtDf-pcJbKtY5DCEBb43N5rtnSa8gYdLxl5aQxpAZ1qo/s16000/image8.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;通过在线多轮同步文本聊天与模拟患者进行虚拟远程 OSCE 的随机研究设计概述。&lt;/td>;&lt; /tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;AMIE 的性能&lt;/h2>; &lt;p>; 在此设置中，我们观察到，在对两者进行评估时，AMIE 执行模拟诊断对话的效果至少与 PCP 一样好沿着多个具有临床意义的咨询质量轴。从专科医生的角度来看，AMIE 在 32 个轴中的 28 个轴上具有更高的诊断准确性和卓越的性能，从患者参与者的角度来看，在 26 个轴中的 24 个轴上，AMIE 具有更高的诊断准确性和卓越的性能。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvP4CCxNKLIBLIBfPnJZ-7mRYZqxINGJ8_Uos8K3Gd8PJrFURwBYYjJePGqHpa63nFQR2aahi3HcwPos9NCV-fknrdVR srwJCI6qFub84f5g5gNo_SvuosZt7Rjm5LXOQuVvG0n_GmzL6jNhihROxls9ZQBA5aVPod_onwurffiTI12F6d4wwfbeNMdxQ/s1834/image4.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1284&quot; data-original-width=&quot;1834&quot; height=&quot;448&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvP4CCxNKLIBLIBfPnJZ-7mRYZqxINGJ8_Uos8K3Gd8PJrFURwBYYjJePGqHpa63nFQR2aahi3HcwPos9NCV-fknrdVRsrwJCI6qFub84f5g5gNo_S vuosZt7Rjm5LXOQuVvG0n_GmzL6jNhihROxls9ZQBA5aVPod_onwurffiTI12F6d4wwfbeNMdxQ/w640-h448/image4.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;在我们的评估中，AMIE 在诊断对话的多个评估轴上均优于 PCP。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table >; &lt;tablealign=“center”cellpadding=“0”cellspacing=“0”class=“tr-caption-container”style=“margin-left：auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZvkY54tqvLCbfTrEFR5e_T1eEXJZvn3V__lBts2bukKDwuJkLmDo5w- ilA8B44JwDPUv5v5hzCN9WRWttPEZ2qN1wQaGQR0SRjjVhapLDxg6Te5YLjPqgUwoDCot2sBujGLVHgIrKFXUkT3bKzL1MLHCMxEMs0pC5ZMoi-PTAhPFLgW7bsjsi5jy3pL0/s1999/image9.png&quot;样式=“左边距：自动”； margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;752&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEhZvkY54tqvLCbfTrEFR5e_T1eEXJZvn3V__lBts2bukKDwuJkLmDo5w-ilA8B44JwDPUv5v5hzCN9WRWttPEZ2qN1wQaGQR0SRjjVhapLDxg6Te5YLjPqgUwoDCot2sBujGLV HgIrKFXUkT3bKzL1MLHCMxEMs0pC5ZMoi-PTAhPFLgW7bsjsi5jy3pL0/s16000/image9.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;专家评级的 top-k 诊断准确性。AMIE 和 PCP Top-k 鉴别诊断 (DDx) 准确性在 149 个场景中与地面真实诊断 (a) 和可接受的鉴别诊断 (b) 中列出的所有诊断进行比较。 Bootstrapping (n=10,000) 确认 AMIE 和 PCP DDx 准确度之间的所有前 k 个差异均显着，在&lt;a href=&quot;https://en.wikipedia.org/wiki/False_discovery_rate&quot;>;错误发现率之后 p &lt;0.05 &lt;/a>;&amp;nbsp;(FDR) 修正。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;tablealign=&quot;center&quot;cellpadding=&quot;0&quot;cellspacing=&quot;0&quot;class=&quot;tr-caption -container&quot; style=&quot;margin-left: 自动; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3FLScvpxSucelwHpfxEC_pMR4cXG3ioiw1lRJs1XgWbuGM8mLS635ryiJJOF7ZOuuA4t0rkj1OXWXB 57GW- FQcNcYq_TKfTPyCLm-EV3Ivk5yPgYdjYKxT8-yxQnDz4mNJwKop4yS3XvyNpcUzVOrhm0MrJKs5DVfl-u8hgwhwkI6kZAvCto4Z4JGcnTb/s1999/image2.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1864&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEi3FLScvpxSucelwHpfxEC_pMR4cXG3ioiw1lRJs1XgWbuGM8mlLS635ryiJJOF7ZOuuA4t0rkj1OXWXB57GW-FQcNcYq_TKfTPyCLm-EV3Ivk5yPgYdjYKxT8-yxQnDz4mN JwKop4yS3XvyNpcUzVOrhm0MrJKs5DVfl-u8hgwhwkI6kZAvCto4Z4JGcnTb/s16000/image2.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align&quot; : center;&quot;>;由专科医生评估的诊断对话和推理质量。在 32 个轴中的 28 个轴上，AMIE 的表现优于 PCP，而在其他轴上则具有可比性。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt; !--&lt;tablealign=“center”cellpadding=“0”cellspacing=“0”class=“tr-caption-container”style=“margin-left：auto； margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNa2OOpTrDPJWdNMWqfl0Mp3Yjn6d0DbFLTTwnpcAmjxddEt6rr6ryOBE_KNWbtce0bRFRYJYOVqdA9eetE ptfRWgoWJ4- 4LEka8RJMZ7p3qcjqGWtA2PKRxyMZKzbtRXCfvQqMQrpVgGrefJB0QwzO1GxTkNAPwhrQ1HXHFbUMZpR7fFhhBKUylktESg/s1892/image6.png&quot; style=&quot;margin-left: 自动; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1714&quot; data-original-width=&quot;1892&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEjNa2OOpTrDPJWdNMWqfl0Mp3Yjn6d0DbFLTTwnpcAmjxddEt6rr6ryOBE_KNWbtce0bRFRYJYOVqdA9eetEptfRWgoWJ4-4LEka8RJMZ7p3qcjqGWtA2PKRxyMZKzbtRXCfvQqMQrpV gGrefJB0QwzO1GxTkNAPwhrQ1HXHFbUMZpR7fFhhBKUylktESg/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;诊断由专科医生评估的对话和推理能力。在 32 个轴中的 28 个轴上，AMIE 的表现优于 PCP，而在其他轴上则相当。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>;-->; &lt;br />; &lt;h2>;局限性&lt;/h2>; &lt;p>;我们的研究有几个局限性，应该谨慎解释。首先，我们的评估技术可能低估了人类对话的现实价值，因为我们研究中的临床医生仅限于不熟悉的文本聊天界面，允许大规模的法学硕士与患者互动，但并不代表通常的临床实践。其次，任何此类研究都必须被视为漫长旅程中探索性的第一步。从我们在本研究中评估的法学硕士研究原型过渡到可供人们和为其提供护理的人使用的安全而强大的工具，将需要大量的额外研究。有许多重要的限制需要解决，包括现实世界约束下的实验性能，以及对健康公平、隐私、鲁棒性等重要主题的专门探索，以确保技术的安全性和可靠性。 &lt;/p>; &lt;br />; &lt;h2>;AMIE 对临床医生的帮助&lt;/h2>; &lt;p>; 在&lt;a href=&quot;https://arxiv.org/abs/2312.00164&quot;>;最近发布的预印本&lt;/a >;，我们评估了 AMIE 系统早期迭代单独生成 DDx 或作为临床医生辅助的能力。二十 (20) 名全科临床医生评估了来自&lt;em>;&lt;a href=&quot;https://www.nejm.org/&quot;>;新英格兰医学杂志&lt;/a>;&lt;/em>;的 303 个具有挑战性的真实医疗案例>; (NEJM) &lt;a href=&quot;https://www.nejm.org/case-challenges&quot;>;临床病理学会议&lt;/a>; (CPC)。每份病例报告均由两名随机接受两种辅助条件之一的临床医生阅读：搜索引擎和标准医疗资源的帮助，或除这些工具外的 AMIE 帮助。所有临床医生在使用相应的辅助工具之前都提供了基线、无协助的 DDx。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEia-nKW28SyAk0DHT21L2CsB18JKUmmt2sPtafGvRtJWrOEgfn1v_hXDtSIJsFP2m66tBA33MwMHXKQSL-nGKfv MTKASXUVZ5n_I4VytKfa0S3EN5vf2TeMHfmOtMLCJtfD3PCvMMc8PJsbIYu-iikFu4atfCOBa-a5yHTM2Tok1wjZpkmBbvioUhXz4Dc/s1999/image5 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1022&quot; data-original-width=&quot;1999&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEia-nKW28SyAk0DHT21L2CsB18JKUmmt2sPtafGvRtJWrOEgfn1v_hXDtSIJsFP2m66tBA33MwMHXKQSL-nGKfvMTKASXUVZ5n_I4VytKfa0S3EN5 vf2TeMHfmOtMLCJtfD3PCvMMc8PJsbIYu-iikFu4atfCOBa-a5yHTM2Tok1wjZpkmBbvioUhXz4Dc/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;协助随机读者研究设置，以调查 AMIE 对临床医生解决新英格兰医学杂志复杂诊断病例挑战的辅助效果。&lt;/td>;&lt; /tr>;&lt;/tbody>;&lt;/table>; &lt;p>; AMIE 表现出的独立性能超过了无人协助的临床医生（前 10 名准确率分别为 59.1% 和 33.6%，p= 0.04）。比较两个辅助研究组，与没有 AMIE 协助的临床医生 (24.6%，p&lt;0.01) 和有搜索的临床医生 (5.45%，p=0.02) 相比，受 AMIE 协助的临床医生的前 10 名准确率更高。此外，与没有 AMIE 协助的临床医生相比，得到 AMIE 协助的临床医生得出了更全面的鉴别列表。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiO1YlFJdQMCt1ZMTQN5neWeYoljjA7Y13FP_2c7q85hSKbLCdNLJtUt1VtBFlCUBlGTIviqdr4XWnnandULaKfGlyPh89Qzza HXmb-wFxYfkwbRv5OO9Wni6Hr04jVO_W1w2cs7RQcCRWCWrW9lxM3t61BI3ZPK6hdsv7RAQAn8TN6s80nP9nwjia0xig/s1999/image7.png&quot;样式=&quot;左边距：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1424&quot; data-original-width=&quot;1999&quot; height=&quot;456&quot; src=&quot;https:// /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiO1YlFJdQMCt1ZMTQN5neWeYoljjA7Y13FP_2c7q85hSKbLCdNLJtUt1VtBFlCUBlGTIviqdr4XWnnandULaKfGlyPh89QzzaHXmb-wFxYfkwbRv5OO9Wni6 Hr04jVO_W1w2cs7RQcCRWCWrW9lxM3t61BI3ZPK6hdsv7RAQAn8TN6s80nP9nwjia0xig/w640-h456/image7.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;除了强大的独立性能之外，使用AMIE系统还为临床医生解决这些复杂病例挑战带来了显着的辅助效果和诊断准确性的提高。&lt;/ td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 值得注意的是，NEJM CPC 并不代表日常临床实践。它们是仅针对数百人的不寻常病例报告，因此为探讨公平或公平等重要问题提供了有限的范围。 &lt;/p>; &lt;br />; &lt;h2>;医疗保健领域大胆而负责任的研究——可能性的艺术&lt;/h2>; &lt;p>; 在世界各地，获得临床专业知识的机会仍然很少。虽然人工智能在特定的临床应用中显示出了巨大的前景，但参与临床实践的动态、对话式诊断过程需要人工智能系统尚未展示的许多功能。医生不仅拥有知识和技能，还致力于遵守无数原则，包括安全和质量、沟通、伙伴关系和团队合作、信任和专业精神。在人工智能系统中实现这些属性是一项鼓舞人心的挑战，应该负责任地、谨慎地对待。 AMIE 是我们对“可能性的艺术”的探索，这是一个仅供研究的系统，用于安全地探索未来的愿景，其中人工智能系统可能会更好地与委托我们护理的熟练临床医生的属性保持一致。它只是早期的实验工作，而不是产品，并且有一些局限性，我们认为值得进行严格和广泛的进一步科学研究，以设想一个对话式、同理心和诊断式人工智能系统可能变得安全、有用和易于使用的未来。 &lt;/p>; &lt;br />; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;此处描述的研究是 Google Research 和 Google Deepmind 多个团队的共同工作。我们感谢所有的合著者——Tao Tu、Mike Schaekermann、Anil Palepu、Daniel McDuff、Jake Sunshine、Khaled Saab、Jan Freyberg、Ryutaro Tanno、Amy Wang、Brenna Li、Mohamed Amin、Sara Mahdavi、Karan Sighal、Shekoofeh阿齐兹、内纳德·托马塞夫、刘云、程勇、侯乐、阿尔伯特·韦伯森、杰克·加里森、亚什·夏尔马、阿努潘·帕塔克、苏珊特·普拉卡什、菲利普·曼斯菲尔德、施韦塔克·帕特尔、布拉德利·格林、埃娃·多米诺斯卡、蕾妮·王、尤拉吉·戈特维斯、戴尔·韦伯斯特、凯瑟琳·周、克里斯托弗·塞姆图斯、乔尔·巴拉尔、格雷格·科拉多和约西·马蒂亚斯。我们还要感谢萨米·拉赫加尔、劳伦·维纳和约翰·吉利亚德对叙事和视觉效果的支持。最后，我们感谢 Michael Howell、James Manyika、Jeff Dean、Karen DeSalvo、Zoubin Ghahramani 和 Demis Hassabis 在本项目过程中的支持&lt;/em>;。 &lt;/p>;&lt;br />;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/1800430129205268706/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application /atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/amie-research-ai-system-for-diagnostic_12.html#comment-form&quot; rel=&quot;replies&quot; 标题=&quot;0条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1800430129205268706&quot; rel=&quot;edit&quot; type=&quot;application/atom +xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1800430129205268706&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href= &quot;http://blog.research.google/2024/01/amie-research-ai-system-for-diagnostic_12.html&quot; rel=&quot;alternate&quot; title=&quot;AMIE：用于诊断医学推理和对话的研究人工智能系统&quot; type=&quot;text/html&quot;/>;&lt;作者>;&lt;名称>;Google AI&lt;/名称>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;电子邮件>;noreply@blogger.com&lt; /email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded. gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgr_wfWpw2CVBYDc3Mlk879CUecv4uGlq36Fxe0GEnVcK2kJnzAyRkPRb8vO5jJVqrd_zvQ6 W8suHyp1xhFhNFJuUj8nTNRp3TsZP7Z5uWlqw22hZZKVJJ33X5NWmT0UTkOdC4raONlnSbR8E616Mi_lJVE3DvbWYB-19eR2wpCgwAaykkquUV3DOLRY6c/ s72-c/AMIE.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>; &lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-7998118785777164574&lt;/id>;&lt;已发布>;2024-01-11T14:42:00.000-08:00&lt;/已发布>;&lt;更新>;2024-01-11T14:42:51.944-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;大型语言模型&quot;>;&lt;/category >;&lt;类别方案=“http://www.blogger.com/atom/ns#”term=“ML”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom/ns#” &quot; term=&quot;自然语言理解&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;大型语言模型能否识别并纠正错误？&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-作者&quot;>;作者：Gladys Tyen，Google 研究实习生&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaRCK2QC8HmH0lzm2lPjqVOxFPZDoyTAPq9icazR1vrsFUTDr5OJdTIZNMDgut_ylOOmeZmA4n0BTIgFCsksZ_xATb JDnQegxWMpdqv2kyGBWKMTV9E2k3WybhBzhL3-oQnpNUWWTKURxt5y8f7gGwUkPTExml1QD2U-UqW0hglZ-cXXCkznmufJIfyPAR/s1600/Backtracking.jpg “样式=“显示：无；” />; &lt;p>; LLM 在推理任务中越来越受欢迎，例如&lt;a href=&quot;https://hotpotqa.github.io/&quot;>;多轮 QA&lt;/a>;、&lt;a href=&quot;https:// arxiv.org/abs/2207.01206&quot;>;任务完成&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/2304.05128&quot;>;代码生成&lt;/a>;或&lt;a href=&quot;https:// /github.com/openai/grade-school-math&quot;>;数学&lt;/a>;。然而，就像人类一样，他们并不总是在第一次尝试时就正确解决问题，尤其是在他们没有接受过培训的任务上。因此，为了使此类系统最有用，它们应该能够 1) 确定其推理出错的地方，以及 2) 回溯以找到另一个解决方案。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 这导致了与自我纠正相关的方法激增，其中法学硕士用于识别其自身的问题。自己的输出，然后根据反馈产生改进的结果。自我纠正通常被认为是一个单一的过程，但我们决定将其分为两个部分：&lt;em>;错误查找&lt;strong>;&lt;/strong>;&lt;/em>;和&lt;em>;输出纠正&lt;/em>;。 &lt;/p>; &lt;p>; 在“&lt;a href=&quot;https://arxiv.org/abs/2311.08516#:~:text=While%20self%2D Correction%20has%20shown,et%20al.%2C%202023) .&quot;>;LLM 无法发现推理错误，但可以纠正它们！&lt;/a>;”，我们分别测试最先进的 LLM 的错误发现和输出纠正。我们提出了 &lt;a href=&quot;https://github.com/WHGTyen/BIG-Bench-Mistake&quot;>;BIG-Bench Mistake&lt;/a>;，这是一个用于错误识别的评估基准数据集，我们用它来解决以下问题： &lt;/p>; &lt;ol>; &lt;li>;法学硕士能否发现&lt;a href=&quot;https://arxiv.org/abs/2201.11903&quot;>;思想链&lt;/a>; (CoT) 风格推理中的逻辑错误？ &lt;/li>;&lt;li>;发现错误可以用来衡量正确性吗？ &lt;/li>;&lt;li>;知道错误在哪里，是否可以提示法学硕士回溯并得出正确答案？ &lt;/li>;&lt;li>;错误发现作为一种技能可以推广到法学硕士从未见过的任务吗？ &lt;/li>; &lt;/ol>; &lt;br />; &lt;h2>;关于我们的数据集&lt;/h2>; &lt;p>; 错误查找是自然语言处理中一个尚未充分研究的问题，该领域特别缺乏评估任务。为了最好地评估法学硕士发现错误的能力，评估任务应该显示明确的错误。据我们所知，由于这个原因，当前大多数错误查找数据集并未超出&lt;a href=&quot;https://github.com/openai/grade-school-math&quot;>;数学&lt;/a>;领域。 &lt;/p>; &lt;p>; 为了评估法学硕士推理数学领域之外的错误的能力，我们生成了一个供研究界使用的新数据集，称为&lt;strong>; &lt;/strong>;&lt;a href=&quot;https: //github.com/WHGTyen/BIG-Bench-Mistake&quot;>;大基准错误&lt;/a>;。该数据集由使用 &lt;a href=&quot;https://ai.google/discover/palm2/&quot;>;PaLM 2&lt;/a>; 针对 &lt;a href=&quot;https:// 中的五个任务生成的思想链轨迹组成github.com/suzgunmirac/BIG-Bench-Hard&quot;>;BIG-Bench&lt;/a>;。每个跟踪都标有第一个逻辑错误的位置。 &lt;/p>; &lt;p>; 为了最大限度地增加数据集中的错误数量，我们对答案不正确的 255 个迹线进行了采样（因此我们知道肯定存在错误），对答案正确的迹线进行了 45 个采样（因此可能存在或可能不是一个错误）。然后，我们要求人工贴标员检查每条痕迹并识别第一个错误步骤。每条迹线均由至少三位标注者进行注释，其答案的&lt;a href=&quot;https://en.wikipedia.org/wiki/Inter-rater_reliability&quot;>;评分者间可靠性&lt;/a>;水平>;0.98（使用 &lt;a href=&quot;https://en.wikipedia.org/wiki/Krippendorff%27s_alpha&quot;>;Krippendorff 的 α&lt;/a>;）。除 &lt;a href=&quot;https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/dyck_languages&quot;>;Dyck Languages 任务&lt;/a>;（涉及预测）之外的所有任务均已完成标记给定输入序列的右括号序列。我们通过算法标记了该任务。 &lt;/p>; &lt;p>; 该数据集中出现的逻辑错误简单且明确，为测试法学硕士在将其用于更困难、更模糊的任务之前发现自己的错误的能力提供了一个良好的基准。&lt;/p>; &lt;div class =&quot;separator&quot; style=&quot;clear: Both; text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvk5zKLBvc2Ou6RpJc9l-lLqwHW6nWARuc2IAckSQ2SPYX6-UQj9Z8FyOB5emaBvXPta4MWqR1gis9FMEXeafffprNpy PmF_XaBOQ7tQpRpEylbnSlbwytNv1BFXlz5I-ulNM0ZBC7kBhx2KkdCT5MIejwdsHKpHu6rrJ4LBVd-Na_XUn5DCy0EKtj1Uy6/ s1354/BBMistakes2.png&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;410&quot; data-original-width=&quot;1354&quot; src= “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvk5zKLBvc2Ou6RpJc9l-lLqwHW6nWARuc2IAckSQ2SPYX6-UQj9Z8FyOB5emaBvXPta4MWqR1gis9FMEXeafffprNpyPmF_XaBOQ7tQpRpEylbnSlbwyt Nv1BFXlz5I-ulNM0ZBC7kBhx2KkdCT5MIejwdsHKpHu6rrJ4LBVd-Na_XUn5DCy0EKtj1Uy6/s16000/BBMistakes2.png&quot; />;&lt;/a>;&lt;/div>; &lt;br />; &lt;h2>;错误识别核心问题&lt;/h2>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;1.法学硕士能否发现思想链式推理中的逻辑错误？&lt;/h3>; &lt;p>; 首先，我们想知道法学硕士是否能够独立于其纠正错误的能力来识别错误。我们尝试多种提示方式来测试&lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_pre-trained_transformer&quot;>;GPT&lt;/a>;系列模型定位错误的能力（提示&lt;a href=&quot;https ://github.com/WHGTyen/BIG-Bench-Mistake/tree/main/mistake_finding_prompts&quot;>;此处&lt;/a>;）假设它们通常代表现代法学硕士的表现。 &lt;/p>; &lt;p>; 一般来说，我们发现这些最先进的模型表现不佳，最好的模型总体准确率达到 52.9%。因此，需要提高法学硕士在这方面的推理能力。 &lt;/p>; &lt;p>; 在我们的实验中，我们尝试了三种不同的提示方法：直接（trace）、直接（step）和CoT（step）。在直接（跟踪）中，我们向法学硕士提供跟踪并询问错误的位置步骤或&lt;em>;没有错误&lt;/em>;。在直接（步骤）中，我们提示法学硕士针对其采取的每一步问自己这个问题。在CoT（步骤）中，我们提示LLM给出每个步骤是否错误的推理。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYeNEXWh6vhy4SvTgSE5kOYYdRV3vFdUGs9zorH7bI010gD4gFziPwtig3bvlJFnzEpOgcQZZbn_2_KDEiqwFgdt imB-IYhhROTmtTKoxmmWF0jzI1IKfU3ZSeAhqEDJgLBwkmdUrbMDd9uYo3kLvK5uhygNRU2mkuRhnW3ZofDkYw-CsjKzFUQdplpFfe/s1061/image2.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;466&quot; data-original-width=&quot;1061&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYeNEXWh6vhy4SvTgSE5kOYYdRV3vFdUGs9zorH7bI010gD4gFziPwtig3bvlJFnzEpOgcQZZbn_2_KDEiqwFgdtimB-IYhhROTmtTKoxmmWF0jzI1IKfU 3ZSeAhqEDJgLBwkmdUrbMDd9uYo3kLvK5uhygNRU2mkuRhnW3ZofDkYw-CsjKzFUQdplpFfe/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;直接（trace）、直接（step）和CoT（step）三种提示方式的示意图。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;我们的发现是一致的，并且建立在&lt;a href=&quot;https://arxiv.org/abs/2310.01798&quot;>;之前的结果&lt;/a>;的基础上，但进一步表明，法学硕士即使是简单且明确的错误也难以避免（作为比较） ，我们的人类评估者在没有事先专业知识的情况下以高度一致的方式解决了问题）。我们假设这是法学硕士无法自我纠正推理错误的一个重要原因。有关完整结果，请参阅&lt;a href=&quot;https://arxiv.org/abs/2311.08516&quot;>;论文&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;2.发现错误可以用来衡量答案的正确性吗？&lt;/h3>; &lt;p>;当人们遇到我们不确定答案的问题时，我们可以逐步解决我们的解决方案。如果没有发现错误，我们可以假设我们做了正确的事情。 &lt;/p>; &lt;p>; 虽然我们假设这对于法学硕士也有类似的作用，但我们发现这是一个糟糕的策略。在我们包含 85% 错误轨迹和 15% 正确轨迹的数据集中，使用此方法并不比始终将轨迹标记为不正确的幼稚策略好多少，后者给出加权平均值 &lt;a href=&quot;https://en.wikipedia. org/wiki/F-score&quot;>;F1&lt;/a>; 为 78。&lt;/p>; &lt;tablealign=&quot;center&quot;cellpadding=&quot;0&quot;cellspacing=&quot;0&quot;class=&quot;tr-caption-container&quot;style=&quot;左边距：自动；右边距：自动；&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/ b/R29vZ2xl/AVvXsEi07Eh2ZJrPHzVPJkom0V-tc51me104pXKoAmHrVaNwNgL8CW4QCIv4js4_aZzabllySdTx5vpHv_5T0NwKDB7nDcfHaNpx7C-fkoWKArltSWSWoXSTB5_4IPr2uOdjpsZKVMBf qVJUejyEuvy5SFC0y8933eBb6hxuvtbyoa-CcWfyQdDtBwBdMadk04JU/s698/Self- Correcting-LLMs-Tasks.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-原始高度=“427”数据原始宽度=“698”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi07Eh2ZJrPHzVPJkom0V-tc51me104pXKoAmHrVaNwNgL8CW4QCIv4js4_aZzablySdTx5vpHv_5T0NwK DB7nDcfHaNpx7C-fkoWKArltSWSWoXSTB5_4IPr2uOdjpsZKVMBfqVJUejyEuvy5SFC0y8933eBb6hxuvtbyoa-CcWfyQdDtBwBdMadk04JU/s16000/自校正-LLM -Tasks.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;显示错误查找效果的图表法学硕士可以用作每个数据集答案正确性的代理。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br / >; &lt;/div>; &lt;h3>;3. LLM 可以回溯知道错误在哪里吗？&lt;/h3>; &lt;p>; 由于我们已经证明 LLM 在查找 CoT 跟踪中的推理错误方面表现不佳，我们想知道 LLM 是否能够纠正错误&lt;em>;&lt; /em>;，即使他们知道错误在哪里。 &lt;/p>; &lt;p>; 请注意，了解&lt;em>;错误位置&lt;/em>;与了解&lt;em>;正确答案&lt;/em>;不同：即使最终答案是正确的，CoT 跟踪也可能包含逻辑错误，或者反之亦然。在大多数现实情况下，我们不知道正确的答案是什么，但我们也许能够识别中间步骤中的逻辑错误。 &lt;/p>; &lt;p>; 我们提出以下回溯方法：&lt;/p>; &lt;ol>; &lt;li>;在温度 = 0 时照常生成 CoT 迹线。（温度是控制生成响应的随机性的参数，温度越高，值产生更多样化和创造性的输出，通常以牺牲质量为代价。）&lt;/li>;&lt;li>;识别第一个逻辑错误的位置（例如使用分类器，或者在这里我们只使用数据集中的标签）。 &lt;/li>;&lt;li>;在温度 = 1 时重新生成错误步骤并产生一组八个输出。由于已知原始输出会导致不正确的结果，因此目标是在此步骤中找到与原始输出显着不同的替代生成。 &lt;/li>;&lt;li>;从这八个输出中，选择一个与原始错误步骤不同的输出。 （我们在这里只是使用精确匹配，但将来这可能会更加复杂。）&lt;/li>;&lt;li>;使用新步骤，在温度 = 0 时正常生成迹线的其余部分。&lt;/li>; &lt; /ol>; &lt;p>; 这是一种非常简单的方法，不需要任何额外的提示制作，并且避免了重新生成整个跟踪。我们使用 BIG-Bench Mistake 的错误位置数据对其进行测试，发现它可以纠正 CoT 错误。 &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/abs/2310.01798&quot;>;最近的工作&lt;/a>;表明自我纠正方法，例如&lt;a href=&quot;https://arxiv. org/abs/2303.11366&quot;>;反射&lt;/a>;和&lt;a href=&quot;https://arxiv.org/abs/2303.17491&quot;>;RCI&lt;/a>;，导致准确性分数下降，因为有更多的正确答案变得不正确反之亦然。另一方面，我们的方法产生的收益（通过纠正错误答案）多于损失（通过将正确答案更改为错误答案）。 &lt;/p>; &lt;p>; 我们还将我们的方法与随机基线进行比较，其中我们随机假设一个步骤是错误的。我们的结果表明，这个随机基线确实产生了一些收益，但不如使用正确的错误位置回溯那么多，并且损失更多。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4CQ3amwJgMJ7OZToizp04vYIOj7F4kTdVO5DgthHi_HQQNa2FrkKjBA7LB249yN44kXFs0lZVuX1W4n3GLQI51Fy 95ls-gK_rMLQQETYNmvqI7OS7U6xHgXx2cUnhTcwmZrpFWrS1vd01G14gWOexxZDTcpOIbGTHfXRgLWj22OteqMh_iTK2Rg_fC7xt/s744/image4.png&quot;样式=&quot;左边距：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;480&quot; data-original-width=&quot;744&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEi4CQ3amwJgMJ7OZToizp04vYIOj7F4kTdVO5DgthHi_HQQNa2FrkKjBA7LB249yN44kXFs0lZVuX1W4n3GLQI51Fy95ls-gK_rMLQQETYNmvqI7OS7U6xHgXx 2cUnhTcwmZrpFWrS1vd01G14gWOexxZDTcpOIbGTHfXRgLWj22OteqMh_iTK2Rg_fC7xt/s16000/image4.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;该图表显示了我们的方法的准确性的增益和损失以及每个数据集的随机基线。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-高度：40%；&quot;>; &lt;br />; &lt;/div>; &lt;h3>;4.错误发现可以推广到法学硕士从未见过的任务吗？&lt;/h3>; &lt;p>;为了回答这个问题，我们在四个 BIG-Bench 任务上微调了一个小模型，并在第五个保留任务上对其进行了测试。我们对每项任务都这样做，总共生成了五个经过微调的模型。然后我们将结果与零样本提示进行比较 &lt;a href=&quot;https://blog.google/technology/ai/google-palm-2-ai-large-language-model/&quot;>;PaLM 2-L-Unicorn &lt;/a>;，一个更大的模型。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi0wDD7i6x7jVZpzCE3jQDkun0ros6zlSxrHP9wMEZAky3WiWaVB1U8ffguLlcl1vIrDy-8AxyZhxPlymeUas4FJaCqDQ dQFW7YAXTGH6MaXwZs9SyrkE4Q4h1zlgFgblXwDmxTTR0uQugbOXK93s7uAE-Q4GbOBO5z94uby9KtOgc0rMBEU1qq4hQVYmuV/s759/image5.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;281&quot; data-original-width=&quot;759&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEi0wDD7i6x7jVZpzCE3jQDkun0ros6zlSxrHP9wMEZAky3WiWaVB1U8ffguLlcl1vIrDy-8AxyZhxPlymeUas4FJaCqDQdQFW7YAXTGH6MaXwZs9SyrkE4Q4 h1zlgFgblXwDmxTTR0uQugbOXK93s7uAE-Q4GbOBO5z94uby9KtOgc0rMBEU1qq4hQVYmuV/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;span style=&quot;text-align: left;&quot;>;条形图显示了与 PaLM 2-L-Unicorn 的零样本提示相比，经过微调的小模型的准确性改进。&lt; /span>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 我们的结果表明，较小的微调奖励模型通常比零样本提示大模型表现更好，即使奖励模型模型从未见过测试集中任务的数据。唯一的例外是逻辑演绎，它的表现与零样本提示相当。 &lt;/p>; &lt;p>; 这是一个非常有希望的结果，因为我们可以使用一个小的微调奖励模型来执行回溯并提高任何任务的准确性，即使我们没有相关数据。这个较小的奖励模型完全独立于生成器 LLM，并且可以针对个别用例进行更新和进一步微调。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiC2HmNdzNKjZYLC_aPbRVHZmFs6_ko4Bs5CjljgTEeXipJsW0_H3HlbE-8TLCQK9GtYuUBT-liCpaZ5zi2dcbF1G kvhjouJbJBE9mVl1yUCJEZAVY8Gk8d-P_HlmeqxcPIpsKwSQeSE93LV1aimd_GuLA5VrWOYtfeLkLpEXXkrgJW5R6fV06_OBxJi6CI/s867/image3.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;446&quot; data-original-width=&quot;867&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiC2HmNdzNKjZYLC_aPbRVHZmFs6_ko4Bs5CjljgTEeXipJsW0_H3HlbE-8TLCQK9GtYuUBT-liCpaZ5zi2dcbF1GkvhjouJbJBE9mVl1yUCJEZAVY 8Gk8d-P_HlmeqxcPIpsKwSQeSE93LV1aimd_GuLA5VrWOYtfeLkLpEXXkrgJW5R6fV06_OBxJi6CI/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;展示我们的回溯方法如何工作的插图。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;结论&lt;/h2>; &lt;p>; 在这项工作中，我们创建了一个评估基准数据集，更广泛的学术界可以使用它来评估未来的法学硕士。我们进一步表明，法学硕士目前很难发现逻辑错误。然而，如果可以的话，我们将展示回溯作为一种可以为任务带来收益的策略的有效性。最后，可以在一般错误查找任务上训练较小的奖励模型，并用于改进域外错误查找，这表明错误查找可以泛化。 &lt;/p>; &lt;br />; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;感谢 Peter Chen、Tony Mak、Hassan Mansoor 和 Victor Cărbune 提供的想法以及帮助进行实验和数据收集。我们还要感谢 Sian Gooding 和 Vicky Zayats 对本文的评论和建议。&lt;/em>; &lt;/p>;&lt;br />;&lt;/content>;&lt;link href=&quot;http://blog.research.google /feeds/7998118785777164574/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/ can-large-language-models-identify-and.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger .com/feeds/8474926331452026626/posts/default/7998118785777164574&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/默认/7998118785777164574&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/can-large-language-models-identify-and .html&quot; rel=&quot;alternate&quot; title=&quot;大型语言模型可以识别并纠正错误吗？&quot; type=&quot;text/html&quot;/>;&lt;作者>;&lt;名称>;Google AI&lt;/名称>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;电子邮件>;noreply@blogger.com&lt; /email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded. gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaRCK2QC8HmH0lzm2lPjqVOxFPZDoyTAPq9icazR1vrsFUTDr5OJdTIZNMDgut_ylOOmeZmA4n0BTIgFCsks Z_xATbJDnQegxWMpdqv2kyGBWKMTV9E2k3WybhBzhL3-oQnpNUWWTKURxt5y8f7gGwUkPTExml1QD2U- UqW0hglZ-cXXCkznmufJIfyPAR/s72-c/Backtracking.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/ thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-7197275876457161088&lt;/id>;&lt;发布>;2024-01-08T14:07:00.000-08:00&lt; /published>;&lt;更新>;2024-01-19T09:59:57.076-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;RAI-HCT 亮点&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Responsible AI&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Google 研究院的负责任 AI ：用户体验团队&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Ayça Çakmakli，Google 研究部负责任的 AI 和以人为本的技术团队用户体验主管&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhssQETGEGXjqvZARNVbKQATaocb0RDAkEOzrkJXtbqiJhZ0_hAAeb8zgOqbiGutvlvU1BTaE96y-0Mc6xXX-bP1-xyVa6xPsmmSwqxZlk_nn6Ugmy cZGYztCOgV1G3IKT9YCnmKFggXUmrEKFW1Y9NtfXNOHmSfaLoIxk8UxQked-9QDeDkSOCZMBaIYrL/s16000/hero.jpg&quot; style=&quot;显示：无；&quot; />; &lt;p>; Google 的负责任的 AI 用户体验（Responsible AI UX）团队是一个嵌入 Google Research 的以产品为导向的团队。这种独特的定位要求我们将负责任的人工智能开发实践应用于以用户为中心的用户体验 (UX) 设计流程。在这篇文章中，我们描述了用户体验设计和负责任的人工智能在产品开发中的重要性，并分享了一些示例，说明我们团队的能力和跨职能协作如何在整个 Google 中实现负责任的开发。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 首先是用户体验部分。我们是一个由产品设计专家组成的多学科团队：设计师、工程师、研究人员和策略师，他们管理以用户为中心的用户体验设计流程，从早期构思和问题框架到后期用户界面 (UI) 设计、原型设计和细化。我们相信，当未满足的重要用户需求与产品的主要价值主张之间存在明确的一致性时，就会出现有效的产品开发，并且这种一致性可以通过彻底的以用户为中心的用户体验设计流程可靠地实现。 &lt;/p>; &lt;p>; 其次，认识到生成式人工智能 (GenAI) 对社会产生重大影响的潜力，我们接受我们作为主要用户倡导者的角色，同时我们继续发展我们的用户体验设计流程，以应对人工智能带来的独特挑战，最大限度地发挥利益并最大限度地降低风险。当我们经历人工智能驱动的产品设计过程的每个阶段时，我们高度重视我们的决策的道德、社会和长期影响。我们致力于持续开发全面的&lt;a href=&quot;https://ai.google/responsibility/ai-governance-operations&quot;>;安全性和包容性协议&lt;/a>;，围绕内容管理等关键问题定义设计和部署护栏、安全性、隐私、模型功能、模型访问、公平性和公平性，有助于减轻 GenAI 风险。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgF6fWFT9CPcFgDfbPhNuCcrNiTCCSUlP1c0Dnr_sSYCnFt3J-7j3axB8sgk34-jdo6L7Xsp9XpNSz7_xp6uEZD5_ GumzOt491oPcnWsbI74tkmBNh5QQ07ra2R-1CrgcnbhVexR48bt_YVRriqIGhF_qgO_PIDseseNvOYISz6bPHjYg5zBkS5FxeM08m-/s1920/image4。 png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1080&quot; data-original-width=&quot;1920&quot; src=&quot;https:// /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgF6fWFT9CPcFgDfbPhNuCcrNiTCCSUlP1c0Dnr_sSYCnFt3J-7j3axB8sgk34-jdo6L7Xsp9XpNSz7_xp6uEZD5_GumzOt491oPcnWsbI74tkmBN h5QQ07ra2R-1CrgcnbhVexR48bt_YVRriqIGhF_qgO_PIDseseNvOYISz6bPHjYg5zBkS5FxeM08m-/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot; tr-caption&quot; style=&quot;text-align: center;&quot;>;Responsible AI UX 不断发展其以用户为中心的产品设计流程，以满足 GenAI 驱动的产品格局的需求，对用户和社会的需求更加敏感，强调道德、社会和长期影响。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 产品设计中的责任也体现在我们选择解决和解决的用户和社会问题上。我们提供资源的计划。因此，我们鼓励&lt;a href=&quot;https://blog.research.google/2023/11/emerging-practices-for-society-centered.html&quot;>;优先考虑规模和严重程度较高的用户问题&lt;/a>;帮助最大限度地发挥 GenAI 技术的积极影响。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrU1niTXyrjzqlRSA8w6qyV4zKtquz0QP8faCIfMp9oPYYZjNCWe0pjW3z3AE9dLMHIR8OKVmzbUlU3oRW9POZnEpmlVGK 8hws3E5sgNhj9cR7bY78gGteQN1ekl9LDz61s-WQjxTcPYnxfqO6RXs-Ax-dCOIe9vn-xdX-K9Hjta1PIFDHjlvrxbXeQSk9/s1920 /image3.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1080&quot; data-original-width=&quot;1920&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrU1niTXyrjzqlRSA8w6qyV4zKtquz0QP8faCIfMp9oPYYZjNCWe0pjW3z3AE9dLMHIR8OKVmzbUlU3oRW9POZnEpmlVGK8hws3E5sgNhj9cR7bY7 8gGteQN1ekl9LDz61s-WQjxTcPYnxfqO6RXs-Ax-dCOIe9vn-xdX-K9Hjta1PIFDHjlvrxbXeQSk9/s16000/image3.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/ tbody>;&lt;/table>; &lt;p>; 跨团队和学科的沟通对于负责任的产品设计至关重要。从用户研究团队到产品设计和工程团队（反之亦然）的信息和见解的无缝流动对于良好的产品开发至关重要。我们团队的核心目标之一是通过弥合我们工程师的广泛技术专业知识与我们学术、研究的用户/社会专业知识之间的沟通差距，确保将深入的用户洞察力实际应用到谷歌人工智能驱动的产品设计决策中。科学家和以用户为中心的设计研究专家。我们建立了一支在这些领域拥有专业知识的多学科团队，加深了我们对受众沟通需求的同理心，并使我们能够更好地在用户和用户之间建立联系。社会专家和我们的技术专家。我们创建框架、指南、原型、备忘单和多媒体工具，帮助在正确的时间为正确的人带来生活洞察。&lt;/p>; &lt;tablealign=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class =&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQrlbUi_jNRom8l7asIw8JHH12fjthtD_iPFDrWhxlItMd3L01hZpxdMx3bGEoRa3QUzHBcal0wvd3eLOKMyDZscFoIgfI4IHYdKkyaLxNhifdcl2ODH5 nOV3VyYFtpCZaeze-zhCghpHY72da-OSdhvuTYrkqrYC0887_rVckCCTPCzOL-ZugV5oqHtlX/s1920/image5.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border= “0”数据原始高度=“1080”数据原始宽度=“1920”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQrlbUi_jNRom8l7asIw8JHH12fjthtD_iPFDrWhxlItMd3L01hZpxdMx3bGEoRa3QUzHBcal0w vd3eLOKMyDZscFoIgfI4IHYdKkyaLxNhifdcl2ODH5nOV3VyYFtpCZaeze-zhCghpHY72da-OSdhvuTYrkqrYC0887_rVckCCTPCzOL-ZugV5oqHtlX/s16000/ image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt; /tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;促进负责任的 GenAI 原型设计和开发 &lt;/h2>; &lt;p>; 期间Responsible AI UX、&lt;a href=&quot;https://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html&quot;>;人员 + AI 研究&lt;/a>;之间的合作（ PAIR）倡议和&lt;a href=&quot;https://labs.google/&quot;>;实验室&lt;/a>;，我们发现&lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3491101.3503564 &quot;>;原型设计&lt;/a>;可以提供参与大型语言模型 (LLM) 的创造性机会，并且通常是 GenAI 产品开发的第一步。为了满足将法学硕士引入原型制作过程的需求，我们探索了一系列不同的提示设计。然后，我们深入该领域，采用各种外部的第一人称用户体验设计研究方法来获取洞察力并获得对用户观点的同理心。通过用户/设计师共同创建会议、迭代和原型设计，我们能够让内部利益相关者、产品经理、工程师、作家、销售和营销团队一起参与，以确保用户的观点得到充分理解并加强一致性跨团队。 &lt;/p>; &lt;p>; 这项工作的成果是 &lt;a href=&quot;https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html&quot;>;MakerSuite&lt;/a>; ，一个在 &lt;a href=&quot;https://blog.research.google/2023/05/google-research-at-io-2023.html&quot;>;Google I/O 2023&lt;/a>; 上推出的生成式 AI 平台，可实现人们，即使是那些没有任何机器学习经验的人，也可以使用法学硕士创造性地进行原型设计。该团队对用户的第一手经验以及对他们所面临挑战的了解使我们能够将&lt;a href=&quot;https://ai.google/responsibility/principles/&quot;>;AI 原则&lt;/a>;融入到 MakerSuite 产品设计中。例如，&lt;a href=&quot;https://developers.generativeai.google/guide/safety_setting&quot;>;安全过滤器&lt;/a>;等产品功能使用户能够管理结果，从而利用 MakerSuite 实现更轻松、更负责任的产品开发。 &lt;/p>; &lt;p>; 由于我们与产品团队密切合作，我们能够调整纯文本原型以支持与 &lt;a href=&quot;https://makersuite.google.com/app/prompts/new_freeform 的多模式交互&quot;>;Google AI Studio&lt;/a>;，MakerSuite 的演变。现在，Google AI Studio 使开发者和非开发者能够无缝利用 Google 最新的 &lt;a href=&quot;https://ai.google.dev/&quot;>;Gemini&lt;/a>; 模型来合并多种模态输入，例如文本和图像，在产品探索中。以这种方式促进产品开发使我们有机会更好地利用人工智能来识别&lt;a href=&quot;https://arxiv.org/pdf/2310.15428.pdf&quot;>;结果的适当性&lt;/a>;，并为开发人员和开发人员释放机会非开发人员可以玩 AI 沙箱。我们与合作伙伴一起，继续在我们支持的产品中积极推动这一努力。&lt;/p>; &lt;tablealign=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style= “左边距：自动；右边距：自动；&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img /b/R29vZ2xl/AVvXsEht40iWgBGeov03IQ-OXhPgLMF8vC9NPSZag-3PyHJMRKHRoTKOAShqTJCueqijS_jdyd7kOMQa-PjmZBQg-EqyAn3f56tucPSLjvFEmaVTuS3Eo9YYq9gIV22MqFeL0qiU4Abl FB46S46Y-czdfct-2dfPCh_NaH9zMHJwUlGWRYb37XLHj6_tvqAQrsV3/s1999/image6.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; 数据-original-height=&quot;1406&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht40iWgBGeov03IQ-OXhPgLMF8vC9NPSZag-3PyHJMRKHRoTKOAShqTJCueqijS_jdyd7kOMQa-PjmZBQ g-EqyAn3f56tucPSLjvFEmaVTuS3Eo9YYq9gIV22MqFeL0qiU4AblFB46S46Y-czdfct-2dfPCh_NaH9zMHJwUlGWRYb37XLHj6_tvqAQrsV3/ s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https: //makersuite.google.com/app/prompts/new_freeform&quot;>;Google AI studio&lt;/a>; 使开发者和非开发者能够利用 Google Cloud 基础架构并在产品探索中合并多种模式输入。&lt;/td>;&lt;/tr >;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;公平语音识别&lt;/h2>; &lt;p>; 多个&lt; a href=&quot;https://www.pnas.org/doi/10.1073/pnas.1915768117&quot;>;外部研究&lt;/a>;，以及 Google 的&lt;a href=&quot;https://www.frontiersin.org/articles /10.3389/frai.2021.725911/full&quot;>;自己的研究&lt;/a>;发现，相对于白人说话者，当前语音识别技术平均理解黑人说话者的能力存在缺陷。随着多模式人工智能工具开始更加依赖语音提示，这个问题将会加剧并继续疏远用户。为了解决这个问题，Responsible AI UX 团队&lt;a href=&quot;https://blog.google/technology/research/project-elevate-black-voices-google-research/&quot;>;与世界知名的语言学家和科学家合作在霍华德大学&lt;/a>;，著名的&lt;a href=&quot;https://en.wikipedia.org/wiki/Historically_black_colleges_and_universities&quot; target=&quot;_blank&quot;>;HBCU&lt;/a>;，致力于打造高品质的非裔美式英语数据集，用于改进我们的语音技术产品的设计，使其更易于使用。这项名为“提升黑人之声项目”的工作将使霍华德大学能够与那些希望改进语音技术的人共享数据集，同时建立负责任的数据收集框架，确保数据造福黑人社区。霍华德大学将保留该数据集的所有权和许可，并作为其负责任使用的管理者。在 Google，我们正在提供资金支持，并与霍华德大学的合作伙伴密切合作，以确保该计划取得成功。 &lt;/p>; &lt;br />; &lt;div class=&quot;separator&quot; style=&quot;clear: Both; text-align: center;&quot;>; &lt;iframe allowedfullscreen=&quot;&quot; class=&quot;BLOG_video_class&quot;frameborder=&quot;0&quot; height=&quot;360 &quot; src=&quot;https://www.youtube.com/embed/t_pdlrU8qhs?si=5xY1AoGc_d2HTzQf&quot; width=&quot;640&quot; youtube-src-id=&quot;5xY1AoGc_d2HTzQf&quot;>;&lt;/iframe>; &lt;/div>; &lt;br />; &lt; div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;公平计算机视觉&lt;/h2>; &lt;p>; &lt;a href=&quot;http://gendershades.org/&quot;>;性别阴影&lt;/a>;项目强调，计算机视觉系统很难检测肤色较深的人，对于肤色较深的女性表现尤其差。这主要是因为用于训练这些模型的数据集不包含广泛的肤色。为了解决这一限制，Responsible AI UX 团队一直与社会学家 &lt;a href=&quot;https://www.ellismonk.com/&quot;>;Dr. Ellis Monk&lt;/a>; 发布&lt;a href=&quot;https://blog.google/products/search/monk-skin-tone-scale/&quot;>;Monk 肤色等级&lt;/a>; (MST)，这是一款皮肤色调等级旨在更包容世界各地的肤色范围。它提供了一个工具来评估数据集的包容性和模型在各种肤色范围内的性能，从而产生更适合每个人的功能和产品。 &lt;/p>; &lt;p>; 我们已将 MST 集成到一系列 &lt;a href=&quot;https://blog.google/products/search/monk-skin-tone-scale/&quot;>;Google 产品&lt;/a>;中，例如如搜索、Google 相册等。我们还开源了 MST，&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3632120&quot;>;发表了我们的研究&lt;/a>;，&lt;a href=&quot;https://blog.research .google/2023/05/consensus-and-subjectivity-of-skin-tone_15.html&quot;>;描述了我们的注释实践&lt;/a>;，以及&lt;a href=&quot;https://skintone.google/mste-dataset&quot;>;分享了一个示例数据集&lt;/a>;，以鼓励其他人轻松地将其集成到他们的产品中。 Responsible AI UX 团队继续与 Monk 博士合作，在多个产品应用程序中利用 MST，并继续进行国际研究，以确保其具有全球包容性。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;咨询与咨询指导&lt;/h2>; &lt;p>; 随着 Google 各团队不断开发利用 GenAI 模型功能的产品，我们的团队认识到他们面临的挑战各不相同，而且市场竞争也很激烈。为了支持团队，我们开发了可操作的资产，以促进考虑可用资源的更加简化和负责任的产品设计流程。我们作为一家以产品为中心的设计咨询公司，寻找扩展服务、分享专业知识并更广泛地应用我们的设计原则的方法。我们的目标是通过负责任的产品设计，帮助 Google 的所有产品团队将未满足的重要用户需求与技术优势联系起来。 &lt;/p>; &lt;p>; 我们实现这一目标的方法之一是创建&lt;a href=&quot;https://pair.withgoogle.com/guidebook/&quot;>;People + AI Guidebook&lt;/a>;，这是一本不断发展的我们学到的许多负责任的设计经验以及我们为内部和外部利益相关者提出的建议的总结性资源。即将推出的滚动&lt;a href=&quot;https://medium.com/people-ai-research/updating-the-people-ai-guidebook-in-the-age-of-generative-ai-cace6c846db4&quot;>;更新&lt;/a>; 特别关注如何利用 GenAI 进行最佳设计和考虑用户需求，我们希望我们的内部团队、外部利益相关者和更大的社区能够在产品开发过程中最关键的里程碑上获得有用且可操作的指导。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOMslkRaMAkYwAUCOHS5tWTuCBQJ7sPNjkDbopWKKl21XD_1Q_VrK3tCctspa72hY63uOMZKipV5flHTW69S5bVjCVBvE8 oMKmEax3VWNj7Wx20UlYRPZABdJhq0DJlegrtSIbQBxtkf18ygJtSxk2kY5f8L82WKEw9vLmiRDgrZiIXtsJ5RtbgvmISRw4/s1100/image1.png&quot; style=&quot;margin-左：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;622&quot; data-original-width=&quot;1100&quot; src=&quot;https://blogger.googleusercontent.com/ img/b/R29vZ2xl/AVvXsEjOMslkRaMAkywAUCOHS5tWTuCBQJ7sPNjkDbopWKKl21XD_1Q_VrK3tCctspa72hY63uOMZKipV5flHTW69S5bVjCVBvE8oMKmEax3VWNj7Wx20UlYRPZABdJhq0DJlegrtSI bQBxtkf18ygJtSxk2kY5f8L82WKEw9vLmiRDgrZiIXtsJ5RtbgvmISRw4/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;《人+人工智能指南》共有六章，旨在涵盖产品生命周期的不同方面。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;如果您有兴趣阅读有关 Responsible AI 的更多信息用户体验以及我们如何具体考虑使用生成式 AI 进行负责任的设计，请查看此 &lt;a href=&quot;https://medium.com/people-ai-research/meet-ay%C3%A7a-%C3%A7akmakli- googles-new-head-of-responsible-ai-ux-d8f2700df95b&quot;>;问答&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;向我们负责任的 AI UX 团队成员致谢： Aaron Donsbach、Alejandra Molina、Courtney Heldreth、Diana Akrong、Ellis Monk、Femi Olanubi、Hope Neveux、Kafayat Abdul、Key Lee、Mahima Pushkarna、Sally Limb、Sarah Post、Sures Kumar Thoddu Srinivasan、Tesh Goyal、Ursula Lauriston 和 Zion门格沙。特别感谢 Michelle Cohn 对这项工作的贡献。 &lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/7197275876457161088/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application /atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2024/01/responsible-ai-at-google-research-user.html#comment-form&quot; rel=&quot;replies&quot; 标题=&quot;0条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/7197275876457161088&quot; rel=&quot;edit&quot; type=&quot;application/atom +xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/7197275876457161088&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href= &quot;http://blog.research.google/2024/01/responsible-ai-at-google-research-user.html&quot; rel=&quot;alternate&quot; title=&quot;Google Research 的负责任的人工智能：用户体验团队&quot; type=&quot; text/html&quot;/>;&lt;作者>;&lt;名称>;Google AI&lt;/名称>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>; &lt;gd：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhssQETGEGXjqvZARNVbKQATaocb0RDAkEOzrkJXtbqiJhZ0_hAAeb8zgOqbiGutvlvU1BTaE96y-0Mc6xXX- bP1-xyVa6xPsmmSwqxZlk_nn6UgmycZGYztCOgV1G3IKT9YCnmKFggXUmrEKFW1Y9NtfXNOHmSfaLoIxk8UxQked -9QDeDkSOCZMBaIYrL/s72-c/hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr ：总计>;&lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-8816183473385638131&lt;/id>;&lt;发布>;2023-12-22T10:37:00.000-08:00&lt;/已发布>;&lt;updated>;2024-01-11T16:01:33.313-08:00&lt;/updated>;&lt;title type=&quot;text&quot;>;2023：人工智能和计算领域取得突破性进展的一年&lt;/stitle>;&lt;content type=&quot; html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布人：Google DeepMind 首席科学家 Jeff Dean谷歌研究部、谷歌 DeepMind 首席执行官 Demis Hassabis 和谷歌研究部技术与高级副总裁 James Manyika社会&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiU12G_p2DZO4gQ-P95aP2IFvtKRHRG5Oik9VzJ4WtT_VznggjUrL4tTzqto-C8yx6ULgvugKgH9usiZxnKGk97pOFyH Wnu-1S4sSbR2Jjq5T36tQRbZucTAP7gmXkGw77xN6s39IKxPaxbo5tw_Cq52ZfPWOCBkWL-2XTuzsIh6viRIqgGcdUdNq-pHjzl/s1100/year_in_review-hero.jpg&quot; style=&quot;display ： 没有任何;” />; &lt;p>; 今年是人工智能 (AI) 研究及其实际应用领域取得令人难以置信进展的一年。 &lt;/p>; &lt;p>; 随着正在进行的研究将人工智能推得更远，我们回顾一下我们的&lt;a href=&quot;https://ai.google/static/documents/google-why-we-focus-on-ai.pdf &quot;>;今年 1 月发表的观点&lt;/a>;，题为“我们为什么关注人工智能（以及目的）”，我们在其中指出：&lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt; div style=&quot;margin-left: 40px;&quot;>; &lt;p>; 我们致力于在开发和交付有用且有益的应用程序方面领导和设定标准，应用基于人类价值观的道德原则，并在从研究中学习的过程中不断改进我们的方法、经验、用户和更广泛的社区。 &lt;/p>; &lt;p>; 我们还相信，让人工智能正确发展——对我们来说，这涉及创新并为人们和社会提供广泛的利益，同时降低其风险——必须是我们和其他人的共同努力，包括研究人员、开发人员、用户（个人、企业和其他组织）、政府、监管机构和公民。 &lt;/p>; &lt;p>; 我们坚信，我们专注于大胆、负责任地开发和交付的人工智能创新是有用的、引人注目的，并且有潜力帮助和改善世界各地人们的生活——这就是我们的动力。 &lt;/p>; &lt;/div>; &lt;p>; 在这篇年度回顾文章中，我们将回顾 Google Research 和 Google DeepMind 在 2023 年安全地将这些段落付诸实践的一些努力。&lt;/p>; &lt;br />; &lt; h2>;产品的进步和发展&lt;/h2>; &lt;p>; 今年，生成式人工智能吸引了全世界的注意力，它创造图像、音乐、故事，并就一切可以想象到的事物进行引人入胜的对话，其创造力水平和速度在几年前几乎令人难以置信。 &lt;/p>; &lt;p>; 二月份，我们&lt;a href=&quot;https://blog.google/technology/ai/bard-google-ai-search-updates/&quot;>;首次推出&lt;/a>; &lt;a href= “https://bard.google.com&quot;>;Bard&lt;/a>;，一个可用于探索创意并简单解释事物的工具。它可以生成文本、翻译语言、编写不同类型的创意内容等等。 &lt;/p>; &lt;p>; 五月份，我们观看了台上公布的数月乃至数年的基础和应用工作成果&lt;a href=&quot;https://blog.research.google/2023/05/google-research- at-io-2023.html&quot;>;Google I/O&lt;/a>;。主要包括 &lt;a href=&quot;https://ai.google/discover/palm2/&quot;>;PaLM 2&lt;/a>;，这是一种大型语言模型 (LLM)，它将计算优化扩展、改进的数据集混合、和模型架构，以擅长高级推理任务。 &lt;/p>; &lt;div class=&quot;separator&quot; style=&quot;clear: Both; text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5R7E2f0BQIsiLZm25kxfR_Ix_Bvm6HlQQCXI12sB42siKUAf8eZvVEDU5bi8EQc22BoG6SV_H8NbC -PKd2pPv7FhC -uBR43ZWpbrgvaGJ7699j-uUctPbFBO9Bf-u81gkfU1OP4oGZhs6KKkub2znNsvcElREn5kwKh2npPJxFJdSVZZUIPZhyphenhyphen3B_jCq4/s1920/lockup_ic_PaLM-2_H_4297x745px_clr_@1x .jpg&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;555&quot;数据原始宽度=“1920”高度=“116”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5R7E2f0BQIsiLZm25kxfR_Ix_Bvm6HlQQCXI12sB42siKUAf8eZvVEDU5bi8EQc22BoG6SV_H8NbC-PKd2pP v7FhC-uBR43ZWpbrgvaGJ7699j-uUctPbFBO9Bf-u81gkfU1OP4oGZhs6KKkub2znNsvcElREn5kwKh2npPJxFJdSVZZUIPZhyphenhyphen3B_jCq4/w400-h116/lockup_ic_PaLM-2_H_4297x745 px_clr_ @1x.jpg&quot; width=&quot;400&quot; />;&lt;/a>;&lt;/div>; &lt;p>;通过针对不同目的对 PaLM 2 进行微调和指令调整，我们能够将其集成到众多 Google 产品和功能中，包括：&lt;/p>; &lt;ul>; &lt;li>;Bard 的更新，启用了多语言功能。自首次推出以来，Bard 现已支持 &lt;a href=&quot;https://support.google.com/bard/answer/13575153?hl=en&quot;>;40 多种语言和 230 多个国家和地区&lt;/a>;和&lt;a href=&quot;https://blog.google/products/bard/google-bard-new-features-update-sept-2023/&quot;>;使用扩展程序&lt;/a>;，Bard 可以查找并显示相关信息每天使用的 Google 工具，例如 Gmail、Google 地图、YouTube 等。 &lt;/li>; &lt;li>;&lt;a href=&quot;https://blog.google/products/search/generative-ai-search/&quot;>;搜索生成体验&lt;/a>; (SGE)，它使用法学硕士重新构想如何组织信息以及如何帮助人们浏览信息，为我们的核心搜索产品创建更流畅的对话交互模型。这项工作将搜索引擎体验从主要关注信息检索扩展到更多功能——能够检索、综合、创造性生成和延续先前的搜索——同时继续充当用户和他们所寻求的网络内容之间的连接点。 &lt;/li>; &lt;li>;&lt;a href=&quot;https://google-research.github.io/seanet/musiclm/examples/&quot;>;MusicLM&lt;/a>;，由 &lt;a href 提供支持的文本到音乐模型=&quot;https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html&quot;>;AudioLM&lt;/a>; 和 &lt;a href=&quot;https://arxiv.org/abs/ 2208.12415&quot;>;木兰&lt;/a>;，可以将文字、哼唱、图像或视频以及音乐伴奏制作成音乐。 &lt;/li>; &lt;li>;Duet AI，我们的人工智能协作者，可在用户使用 Google Workspace 和 Google Cloud 时为他们提供帮助。例如，&lt;a href=&quot;https://workspace.google.com/blog/product-announcements/duet-ai&quot;>;Google Workspace 中的 Duet AI&lt;/a>; 可以帮助用户写作、创建图像、分析电子表格、草稿并总结电子邮件和聊天消息，以及总结会议。 &lt;a href=&quot;https://cloud.google.com/blog/products/application-modernization/introducing-duet-ai-for-google-cloud&quot;>;Google Cloud 中的 Duet AI&lt;/a>; 帮助用户编码、部署、扩展和监控应用程序，以及识别和加速解决网络安全威胁。 &lt;/li>; &lt;li>;还有许多&lt;a href=&quot;https://blog.google/technology/developers/google-io-2023-100-announcements/&quot;>;其他进展&lt;/a>;。 &lt;/li>; &lt;/ul>; &lt;p>; 继去年发布文本到图像生成模型 &lt;a href=&quot;https://imagen.research.google/&quot;>;Imagen&lt;/a>; 之后，六月，我们发布了 &lt;a href=&quot;https://blog.research.google/2023/06/imagen-editor-and-editbench-advancing.html&quot;>;Imagen Editor&lt;/a>;，它提供了使用区域遮罩和自然语言提示交互式编辑生成图像，以提供对模型输出更精确的控制。 &lt;/p>; &lt;div style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfNnxCCKKLZgjajw30Ml1CiPruUIScAPwpa77LQ8Auqkf_KJh9rlJWhYRnQf1g4L0qhVDUJNHabkpL_ZW60FJs8X UWV1kT5M32YU-6oYBC5383noYqno-cYzUboAAOgXvDlWtqwu-zl94M2r02Fsid0jjgLBJl3JCVR4lc8ZVw7-c7q9OlHjzmrRXz5i5H/s1261/ image4.png&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;306&quot; data-original-width=&quot;1261&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfNnxCCKKLZgjajw30Ml1CiPruUIScAPwpa77LQ8Auqkf_KJh9rlJWhYRnQf1g 4L0qhVDUJNHabkpL_ZW60FJs8XUWV1kT5M32YU -6oYBC5383noYqno-cYzUboAAOgXvDlWtqwu-zl94M2r02Fsid0jjgLBJl3JCVR4lc8ZVw7-c7q9OlHjzmrRXz5i5H/s16000/image4.png&quot; />;&lt;/a>;&lt;/div>; &lt;p>; 今年晚些时候，我们发布了 Imagen 2，它通过专门的图像美学改进了输出以人体为基础的模型对良好照明、取景、曝光和清晰度等品质的偏好。 &lt;/p>; &lt;p>; 10 月份，我们推出了一项功能，&lt;a href=&quot;https://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking- Practice.html&quot;>;帮助人们练习口语并提高语言技能&lt;/a>;。实现此功能的关键技术是与 Google 翻译团队合作开发的一种新颖的深度学习模型，称为 Deep Aligner。与基于 &lt;a href=&quot;https://aclanthology.org/C96- 2141/&quot;>;隐马尔可夫模型&lt;/a>;（HMM）。 &lt;/p>; &lt;p>; 11 月，我们与 &lt;a href=&quot;https://blog.youtube/inside-youtube/ai-and-music-experiment/&quot;>;YouTube&lt;/a>; 合作，宣布&lt;a href=&quot;https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/&quot;>;Lyria&lt;/a>;，我们迄今为止最先进的人工智能音乐生成模型。我们与 &lt;a href=&quot;https://blog.youtube/inside-youtube/partnering-with-the-music-industry-on 合作发布了两项旨在为创造力、DreamTrack 和音乐 AI 工具开辟新游乐场的实验-ai/&quot;>;YouTube 在人工智能技术方面与音乐行业合作的原则&lt;/a>;。 &lt;/p>; &lt;p>; 然后在 12 月，我们推出了 &lt;a href=&quot;https://blog.google/technology/ai/google-gemini-ai/&quot;>;Gemini&lt;/a>;，我们最强大、最通用的人工智能模型。 Gemini 从一开始就被构建为跨文本、音频、图像和视频的多模式。我们最初的 Gemini 型号系列提供三种不同尺寸：Nano、Pro 和 Ultra。 Nano 模型是我们最小、最高效的模型，用于为 Pixel 等产品提供设备端体验。 Pro 模型功能强大，最适合跨多种任务进行扩展。 Ultra 模型是我们最大、最有能力完成高度复杂任务的模型。 &lt;/p>; &lt;br />; &lt;div class=&quot;separator&quot; style=&quot;clear: Both; text-align: center;&quot;>;&lt;a href=&quot;https://www.youtube.com/watch?v=jV1vkHv4zq8 &quot;>;&lt;iframe allowedfullscreen=&quot;&quot; class=&quot;BLOG_video_class&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/jV1vkHv4zq8&quot; width=&quot;640&quot; youtube-src-id=&quot;jV1vkHv4zq8&quot;>; &lt;/iframe>;&lt;/a>;&lt;/div>; &lt;br />; &lt;p>;在&lt;a href=&quot;https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf&quot;>;技术报告中&lt; /a>;关于&lt;a href=&quot;https://deepmind.google/technologies/gemini&quot;>;Gemini 模型&lt;/a>;，我们发现 Gemini Ultra 的性能在 32 个模型中的 30 个上超过了当前最先进的结果LLM 研究和开发中广泛使用的学术基准。 Gemini Ultra 的得分为 90.04%，是第一个在 &lt;a href=&quot;https://arxiv.org/abs/2009.03300&quot;>;MMLU&lt;/a>; 上超越人类专家的模型，并取得了最佳成绩- 在新的 &lt;a href=&quot;https://arxiv.org/abs/2009.03300&quot;>;MMMU&lt;/a>; 基准上艺术得分为 59.4%。 &lt;/p>; &lt;p>; 基于 &lt;a href=&quot;https://deepmind.google/discover/blog/competitive-programming-with-alphacode/&quot;>;AlphaCode&lt;/a>; 构建，这是第一个在为了达到竞争性编程中中等水平的水平，我们&lt;a href=&quot;https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf&quot;>;推出了由专门版本的 Gemini 提供支持的 AlphaCode 2&lt;/a>; 。当在与原始 AlphaCode 相同的平台上进行评估时，我们发现 AlphaCode 2 解决的问题多了 1.7 倍，并且表现优于 85% 的参赛者&lt;/p>; &lt;p>; 同时，&lt;a href=&quot;https: //blog.google/products/bard/google-bard-try-gemini-ai/&quot;>;巴德通过使用 Gemini Pro 模型获得了最大的升级&lt;/a>;，使其在理解、理解、总结、推理、编码和计划。在八项基准测试中的六项中，Gemini Pro 的表现优于 GPT-3.5，包括在 MMLU（衡量大型 AI 模型的关键标准之一）和 &lt;a href=&quot;https://huggingface.co/datasets/gsm8k&quot;>;GSM8K&lt; /a>;，衡量小学数学推理能力。 Gemini Ultra 将于明年初通过巴德高级 (Bard Advanced) 登陆巴德，这是一种全新的尖端人工智能体验。 &lt;/p>; &lt;p>; Gemini Pro 还可在 &lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/gemini-support-on-vertex-ai&quot;>;Vertex 上使用AI&lt;/a>;，Google Cloud 的端到端 AI 平台，使开发者能够构建能够跨文本、代码、图像和视频处理信息的应用。 &lt;a href=&quot;https://blog.google/technology/ai/gemini-api-developers-cloud/&quot;>;Gemini Pro 也于 12 月在 AI Studio 中推出&lt;/a>;。 &lt;/p>; &lt;p>; 为了最好地展示 Gemini 的一些功能，我们制作了&lt;a href=&quot;https://deepmind.google/technologies/gemini/#hands-on&quot;>;一系列短视频&lt;/a>;双子座如何做到的解释：&lt;/p>; &lt;ul>; &lt;li>;&lt;a href=&quot;https://www.youtube.com/watch?v=sPiOP_CB54A&quot;>;解锁科学文献中的见解&lt;/a>; &lt;/li >;&lt;li>;&lt;a href=&quot;https://www.youtube.com/watch?v=LvGmVmHv69s&amp;amp;t=1s&quot;>;擅长竞技性节目&lt;/a>; &lt;/li>;&lt;li>;&lt;a href=&quot; https://www.youtube.com/watch?v=D64QD7Swr3s&quot;>;处理和理解原始音频&lt;/a>; &lt;/li>;&lt;li>;&lt;a href=&quot;https://www.youtube.com/watch? v=K4pX1VAxaAI&quot;>;解释数学和物理推理&lt;/a>; &lt;/li>;&lt;li>;&lt;a href=&quot;https://www.youtube.com/watch?v=v5tRc_5-8G4&quot;>;关于用户意图的原因生成定制体验&lt;/a>; &lt;/li>; &lt;/ul>; &lt;br />; &lt;h2>;机器学习/人工智能研究&lt;/h2>; &lt;p>; 除了我们在产品和技术方面的进步，我们还做出了机器学习和人工智能研究更广泛领域取得了许多重要进展。 &lt;/p>; &lt;p>; 最先进的 ML 模型的核心是 Transformer 模型架构，&lt;a href=&quot;https://blog.research.google/2017/08/transformer-novel-neural-network.html &quot;>;由 Google 研究人员于 2017 年开发&lt;/a>;。它最初是为语言开发的，事实证明它在&lt;a href=&quot;https://blog.research.google/2020/12/transformers-for-image-recognition-at.html&quot;>;计算机视觉&lt;/ a>;、&lt;a href=&quot;https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/&quot;>;音频&lt;/a>;、&lt;a href=&quot;https://deepmind .google/discover/blog/a-catalogue-of-genic-mutations-to-help-pinpoint-the-cause-of-diseases/&quot;>;基因组学&lt;/a>;，&lt;a href=&quot;https://deepmind. google/technologies/alphafold/&quot;>;蛋白质折叠&lt;/a>;等。今年，我们在&lt;a href=&quot;https://blog.research.google/2023/03/scaling-vision-transformers-to-22.html&quot;>;缩放视觉转换器&lt;/a>;方面的工作展示了以下状态：在各种视觉任务中取得了最先进的成果，并且在构建 &lt;a href=&quot;https://blog.research.google/2023/03/palm-e-embodied-multimodal-language.html&quot; 方面也很有用>;能力更强的机器人&lt;/a>;。 &lt;/p>; &lt;p>; &lt;/p>; &lt;p>; 扩展模型的多功能性需要执行更高级别和多步骤推理的能力。今年，我们通过多项研究路线实现了这一目标。例如，&lt;a href=&quot;https://blog.research.google/2023/08/teaching-language-models-to-reason.html&quot;>;算法提示&lt;/a>;是一种教授语言模型推理的新方法通过演示一系列算法步骤，然后模型可以将其应用到新的上下文中。这种方法将一项中学数学基准的准确率从 25.9% 提高到 61.1%。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqMgWRH7DtSwqbAImqRRsW26oyKnDiinTNvtkUuvASZJSaChsNXG1-4EeDkTr22E7xjRzwcFdWCZSKFuuBoLfsZiH27pZ 1d6XMef8ns6RGx619oZnHdeCVZb7EOPWigNqbGsmu4FrU2Xgampr0HIASv7ks8ha9DE8L3hmAhKU8_Aps8L_1evceD2MKyG23/s1200/image5.gif&quot;样式=&quot;左边距：自动；右边距：自动；&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;166&quot; data-original-width=&quot;1200&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEhqMgWRH7DtSwqbAImqRRsW26oyKnDiinTNvtkUuvASZJSaChsNXG1-4EeDkTr22E7xjRzwcFdWCZSKFuuBoLfsZiH27pZ1d6XMef8ns6RGx619oZnHdeCVZb7EOPWigN qbGsmu4FrU2Xgampr0HIASv7ks8ha9DE8L3hmAhKU8_Aps8L_1evceD2MKyG23/s16000/image5.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;通过提供算法提示，我们可以通过情境学习向模型传授算术规则。&lt;/em>;&lt;/td>;&lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;p>; 在视觉问答领域，我们与加州大学伯克利分校的研究人员合作，展示了如何&lt;a href=&quot;https://blog.research.google/2023/07 /modular-visual-question-answering-via.html&quot;>;通过将视觉模型与经过训练来回答视觉问题的语言模型相结合，更好地回答复杂的视觉问题&lt;/a>;（“马车在马的右边吗？”）通过综合程序来执行多步骤推理来提出问题。 &lt;/p>; &lt;p>; 我们现在使用&lt;a href=&quot;https://blog.research.google/2023/05/large-sequence-models-for-software.html&quot;>;理解许多方面的通用模型软件开发生命周期的自动化生成代码审查意见，响应代码审查意见，为代码片段提出性能改进建议（通过学习过去在其他上下文中的此类更改），修复代码以响应编译错误等等。 &lt;/p>; &lt;p>; 在与 Google 地图团队的多年研究合作中，我们能够扩展逆强化学习并将其应用到&lt;a href=&quot;https://blog.research.google/2023/ 09/world-scale-inverse-reinforcement.html&quot;>;为超过 10 亿用户改进路线建议的世界级问题&lt;/a>;。我们的工作最终使全球路线匹配率相对提高了 16-24%，有助于确保路线更好地符合用户偏好。 &lt;/p>; &lt;p>; 我们还继续致力于改进机器学习模型的推理性能的技术。在&lt;a href=&quot;https://blog.research.google/2023/08/neural-network-pruning-with.html&quot;>;计算友好的神经网络连接修剪方法&lt;/a>;的研究中，我们能够针对计算上难以处理的最佳子集选择问题设计一种近似算法，该算法能够从图像分类模型中修剪 70% 的边缘，并且仍然保留几乎所有原始精度。 &lt;/p>; &lt;p>; 致力于&lt;a href=&quot;https://blog.research.google/2023/06/speed-is-all-you-need-on-device.html&quot;>;在设备上加速扩散模型&lt;/a>;，我们还能够对注意力机制、卷积核和运算融合应用各种优化，使在设备上运行高质量图像生成模型变得可行；例如，只需 12 秒即可在智能手机上生成“可爱小狗和周围鲜花的逼真高分辨率图像”。 &lt;/p>; &lt;br />; &lt;div class=&quot;separator&quot; style=&quot;clear: Both; text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl /AVvXsEhM5NuphyphenhyphenlH7_H5PfABZrn1a-CuFJm8XyEpAlodQqpcrTvYj3XNWarRULjbSgKqY1trCsC0hbVvHTU9l4pUyn3vFupsfyLDVgdMgsTYHtE1b8AWQwZWUgXGAAJ_F12rcOqVDjbe1q5 OX0TdYEQBOt-FpKIqvfYivuAcPU3bVTZcYxUdFOdtaW5JE6Fii7ej/s522/image7.gif&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;522&quot; data-original-宽度=“270”高度=“400”src=“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhM5NuphyphenhyphenlH7_H5PfABZrn1a-CuFJm8XyEpAlodQqpcrTvYj3XNWarRULjbSgKqY1trCsC0hbVvHTU9l4pUyn3vFupsf yLDVgdMgsTYHtE1b8AWQwZWUgXGAAJ_F12rcOqVDjbe1q5OX0TdYEQBOt-FpKIqvfYivuAcPU3bVTZcYxUdFOdtaW5JE6Fii7ej/w208-h400/image7.gif&quot; width=&quot;208&quot; />; &lt;/a>;&lt;/div>; &lt;br />; &lt;p>;功能语言和多模态模型的进步也使我们的机器人研究工作受益。我们将单独训练的语言、视觉和机器人控制模型组合到 &lt;a href=&quot;https://blog.research.google/2023/03/palm-e-embodied-multimodal-language.html&quot;>;PaLM-E&lt;/ a>;，一种具体的机器人多模态模型，以及 &lt;a href=&quot;https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/ &quot;>;Robotic Transformer 2&lt;/a>; (RT-2)，一种新颖的视觉语言动作 (VLA) 模型，&lt;a href=&quot;https://deepmind.google/discover/blog/robocat-a-self- Improve-robotic-agent/&quot;>;从网络和机器人数据中学习&lt;/a>;，并将这些知识转化为机器人控制的通用指令。&lt;/p>; &lt;p>; &lt;/p>;&lt;tablealign=&quot;center&quot;cellpadding =&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijJL6HUJ6swdYZlAdRsPttHH9EmdE7TpGlK92U9hxHu29ANiHMQLC3QB1PX8HFWwatiJ6V-rjeImQ67oRUGtQMR4TDXB7mOVqsz-BouN1 y29vbUU7rc-nTkj2H-V0V3VNCTMujhLSyNM3duUEVOYhm0nf8wBVrIghfEdpRsKtHn_gg2dWVxzzSXTk6ROTb/s616/image8.jpg&quot; style=&quot;margin-left: 自动; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;559&quot; data-original-width=&quot;616&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEijJL6HUJ6swdYZlAdRsPttHH9EmdE7TpGlK92U9hxHu29ANiHMQLC3QB1PX8HFWwatiJ6V-rjeImQ67oRUGtQMR4TDXB7mOVqsz-BouN1y29vbUU7rc-nTkj2H-V0V3VNC TMujhLSyNM3duUEVOYhm0nf8wBVrIghfEdpRsKtHn_gg2dWVxzzSXTk6ROTb/s16000/image8.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;RT-2 架构和训练：我们在机器人和网络数据上共同微调预训练的视觉语言模型。最终的模型吸收了机器人摄像头图像并直接预测机器人要执行的动作。&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;此外，我们还展示了如何&lt;a href=&quot;https:// blog.research.google/2023/08/saytap-language-to-quadrupedal.html&quot;>;语言也可用于控制四足机器人的步态&lt;/a>;并探索了&lt;a href=&quot;https://blog .research.google/2023/08/language-to-rewards-for-robotic-skill.html&quot;>;使用语言帮助制定更明确的奖励函数&lt;/a>;，以弥合人类语言和机器人动作之间的差距。然后，在 &lt;a href=&quot;https://blog.research.google/2023/05/barkour-benchmarking-animal-level.html&quot;>;Barkour&lt;/a>; 中，我们对四足机器人的敏捷极限进行了基准测试。&lt;/p >; &lt;br />; &lt;h2>;算法&amp;amp;优化&lt;/h2>; &lt;p>; 设计高效、稳健且可扩展的算法仍然是重中之重。今年，我们的工作包括：应用和可扩展算法、市场算法、系统效率和优化以及隐私。 &lt;/p>; &lt;p>; 我们推出了 &lt;a href=&quot;https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/&quot;>;AlphaDev&lt;/a>;，一个使用强化的 AI 系统学习发现增强的计算机科学算法。 AlphaDev 发现了一种更快的排序算法，一种对数据进行排序的方法，这导致了 LLVM libc++ 排序库的改进，对于较短的序列，速度提高了 70%；对于超过 250,000 个元素的序列，速度提高了约 1.7%。 &lt;/p>; &lt;p>; 我们开发了一种新颖的模型来&lt;a href=&quot;https://arxiv.org/abs/2305.12322&quot;>;预测大型图的属性&lt;/a>;，从而能够估计大型程序的性能。我们发布了一个新的数据集 &lt;a href=&quot;https://arxiv.org/abs/2308.13490&quot;>;TPUGraphs&lt;/a>;，以加速&lt;a href=&quot;https://www.kaggle.com/competitions/predict -ai-model-runtime&quot;>;该领域的开放研究&lt;/a>;，并展示了我们如何使用&lt;a href=&quot;https://blog.research.google/2023/12/advancements-in-machine-learning -for.html&quot;>;现代机器学习提高机器学习效率&lt;/a>;。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjC00uLmFXRBzNXoaXirQMkAV7j91dBVwgvY4BEFuOLP4V9MquLuKt9imKFHBHsc7laEKUIuXUe_-v0DJyCauIQMrOzUaSOKl1 5hxBeAbgLGPWNYehM7Z8seK3P9JcjyMmeSZNyXWMYNME84KZwIygF1deRSpaZ1oBeK-uFnxEqCJcm6M0z4hA18JVGew-H/s1223/image11.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1042&quot; data-original-width=&quot;1223&quot; height=&quot;341&quot; src= “https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjC00uLmFXRBzNXoaXirQMkAV7j91dBVwgvY4BEFuOLP4V9MquLuKt9imKFHBHsc7laEKUIuXUe_-v0DJyCauIQMrOzUaSOKl15hxBeAbgLGPWNYehM7Z8seK 3P9JcjyMmeSZNyXWMYNME84KZwIygF1deRSpaZ1oBeK-uFnxEqCJcm6M0z4hA18JVGew-H/w400-h341/image11.png“宽度=“400”/>;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;TPUGraphs 数据集拥有 4400 万张用于 ML 程序优化的图表。 &lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;我们开发了一个新的&lt;a href=&quot;https://en.wikipedia.org/wiki/Load_balancing_(computing)&quot;>;用于将查询分发到服务器的负载平衡&lt;/a>;算法，称为&lt;a href=&quot;https://arxiv.org/abs/2312.10172&quot;>;Prequal&lt;/a>;，它最大限度地减少了请求中的请求和请求的组合估计延迟。跨多个系统的部署显着节省了 CPU、延迟和 RAM。我们还为容量预留的经典缓存问题设计了一个新的&lt;a href=&quot;https://arxiv.org/abs/2305.02508&quot;>;分析框架&lt;/a>;。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRpdeenR8s32zMYfc6hmCq1OKu_Fk8NnhymDBWweQky1o9OIqARGqtzA-SUPAX1UZVQsrvPDXXbr20ZBz70RNBS3njSwC tkGYmBbWYOV7J87xFTMXCDRoiOh4EtGqf_aKBtegTJrbyru3ompVpfYzMx6EKWX26xHs_POZJ2dd3lbvDX-JggUoXFDn-HDJa/s1896/image12.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;422&quot; data-original-width=&quot;1896&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRpdeenR8s32zMYfc6hmCq1OKu_Fk8NnhymDBWweQky1o9OIqARGqtzA-SUPAX1UZVQsrvPDXXbr20ZBz70RNBS3njSwCtkGYmBbWYOV7J87xFTMXCDRoiOh 4EtGqf_aKBtegTJrbyru3ompVpfYzMx6EKWX26xHs_POZJ2dd3lbvDX-JggUoXFDn-HDJa/s16000/image12.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;标准化 CPU 使用率热图过渡到&lt;a href=&quot;Prequal&quot;>;Prequal&lt;/a>; 08:00。&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 我们改进了集群和 &lt;a href=&quot;https://en.08:00&quot; 方面的最新技术。 wikipedia.org/wiki/Graph_neural_network&quot;>;图算法&lt;/a>;，通过开发新技术&lt;a href=&quot;https://arxiv.org/abs/2106.05513&quot;>;计算最小割&lt;/a>;，&lt;a href =&quot;https://arxiv.org/abs/2309.17243&quot;>;近似相关聚类&lt;/a>;和&lt;a href=&quot;https://arxiv.org/abs/2308.00503&quot;>;大规模并行图聚类&lt;/a>; 。此外，我们还引入了&lt;a href=&quot;https://arxiv.org/abs/2308.03578&quot;>;TeraHAC&lt;/a>;，这是一种针对万亿边图的新型层次聚类算法，设计了一个&lt;a href=&quot;https:// blog.research.google/2023/11/best-of-both-worlds-achieving.html&quot;>;文本聚类算法&lt;/a>;在保持质量的同时实现了更好的可扩展性，并设计了最高效的&lt;a href=&quot;https:// /arxiv.org/abs/2307.03043&quot;>;用于近似倒角距离的算法&lt;/a>;，多重嵌入模型的标准相似性函数，与高度优化的精确算法相比，速度提高了 50 倍以上，并可扩展到数十亿个点。 &lt;/p>;&lt;p>;&lt;/p>; &lt;p>; 我们继续优化 Google 的大型嵌入模型 (LEM)，该模型为我们的许多核心产品和推荐系统提供支持。一些新技术包括用于网络规模机器学习系统中经过实战检验的特征表示的&lt;a href=&quot;https://arxiv.org/abs/2305.12102&quot;>;统一嵌入&lt;/a>;以及&lt;a href=&quot;https:// arxiv.org/abs/2209.14881&quot;>;顺序注意力&lt;/a>;，使用注意力机制在训练过程中发现高质量的稀疏模型架构。 &lt;/p>; &lt;!--&lt;p>; 今年，我们还继续研究市场算法，以设计计算高效的市场和因果推理。首先，我们仍然致力于推动人们对广告自动化快速增长的兴趣，我们最近的工作&lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3543507.3583416&quot;>;解释了自动出价机制的采用&lt; /a>; 和&lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3580507.3597725&quot;>;研究了不同拍卖形式对广告商激励的影响&lt;/a>;。在多通道设置中，我们的研究结果揭示了局部优化和全局优化之间的选择如何影响多通道的设计&lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3580507.3597707&quot; >;拍卖系统&lt;/a>;和&lt;a href=&quot;https://dl.acm.org/doi/10.5555/3618408.3618709&quot;>;出价系统&lt;/a>;。 &lt;/p>;-->; &lt;p>; 除了自动出价系统之外，我们还研究了其他复杂环境中的拍卖设计，例如&lt;a href=&quot;https://arxiv.org/abs/2204.01962&quot;>;买多机制&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2207.09429&quot;>;异构投标人拍卖&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2309.10766&quot;>;合约设计&lt;/a>;，并创新了&lt;a href=&quot;https://dl.acm.org/doi/10.5555/3618408.3618478&quot;>;强大的在线竞价算法&lt;/a>;。受生成式人工智能在协作创作中应用（例如，广告商的联合广告）的推动，我们提出了&lt;a href=&quot;https://arxiv.org/abs/2310.10826&quot;>;一种新颖的代币拍卖模型&lt;/a>;，其中法学硕士争取在协作人工智能创造中的影响力。最后，我们展示了如何&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3580507.3597702&quot;>;减轻实验设计中的个性化影响&lt;/a>;，例如，这可能会导致建议随着时间的推移而漂移。 &lt;/p>; &lt;p>; Chrome Privacy Sandbox 是 Google Research 和 Chrome 之间的多年合作项目，已公开推出多个 API，包括用于 &lt;a href=&quot;https://privacysandbox.com/intl/en_us/learning- hub/#protected-audience&quot;>;受保护受众&lt;/a>;、&lt;a href=&quot;https://privacysandbox.com/intl/en_us/learning-hub/#topics&quot;>;主题&lt;/a>;和&lt;a href =&quot;https://privacysandbox.com/intl/en_us/learning-hub/#attribution-reporting&quot;>;归因报告&lt;/a>;。这是保护用户隐私同时支持开放和自由的网络生态系统的重要一步。关于&lt;a href=&quot;https://arxiv.org/abs/2304.07210&quot;>;重新识别风险&lt;/a>;的基础研究促进了这些努力，&lt;a href=&quot;https://arxiv.org/abs /2301.05605&quot;>;私有流计算&lt;/a>;，&lt;a href=&quot;https://blog.research.google/2023/12/summary-report-optimization-in-privacy.html&quot;>;优化&lt;/a>;隐私上限和预算、&lt;a href=&quot;https://arxiv.org/pdf/2308.13510.pdf&quot;>;分层聚合&lt;/a>;以及使用&lt;a href=&quot;https://arxiv.org/pdf进行训练的模型/2312.05659.pdf&quot;>;标记隐私&lt;/a>;。 &lt;/p>; &lt;br />; &lt;h2>;科学与社会&lt;/h2>; &lt;p>; 在不远的将来，人工智能应用于科学问题很有可能通过以下方式加快某些领域的发现速度： 10×或100×，或更多，并导致包括生物工程在内的各个领域的重大进步，&lt;a href=&quot;https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep -learning&quot;>;材料科学&lt;/a>;，&lt;a href=&quot;https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/ &quot;>;天气预报&lt;/a>;、&lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/google-ai-climate-change-solutions/&quot;>;气候预报&lt;/a>;、&lt;a href =&quot;https://blog.research.google/2023/09/google-research-embarks-on-effort-to.html&quot;>;神经科学&lt;/a>;，&lt;a href=&quot;https://blog.research. google/2023/04/an-ml-based-approach-to-better.html&quot;>;基因医学&lt;/a>;和&lt;a href=&quot;https://health.google/health-research/publications/&quot;>;医疗保健&lt;/a>;。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;可持续性和气候变化&lt;/h3>; &lt;p>; In &lt;a href=&quot;https:// blog.google/outreach-initiatives/sustainability/google-ai-reduce-greenhouse-emissions-project-greenlight/&quot;>;绿灯计划&lt;/a>;，我们与全球 13 个城市合作，帮助改善十字路口和减少走走停停的排放。这些合作伙伴关系的早期数据表明，停靠次数最多可减少 30%，排放量最多可减少 10%。 &lt;/p>; &lt;p>; 在我们的&lt;a href=&quot;https://sites.research.google/contrails/&quot;>;轨迹工作&lt;/a>;中，我们分析了大规模天气数据、历史卫星图像和过去的航班。我们&lt;a href=&quot;https://blog.google/technology/ai/ai-airlines-contrails-climate-change/&quot;>;训练了一个 AI 模型&lt;/a>;来预测凝结尾迹的形成位置并相应地重新调整飞机航线。我们与美国航空和 Breakthrough Energy 合作，使用该系统证明凝结尾迹减少了 54%。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnU7wUIVSDG3HicS_tHszwAD_RlhU_SXJO0quz5CUJ0RLT03erljh8ckLW8NLAlYtOPpX6lzsohacC7x2X-_2abBGDGWG PIN0KZpYJ0YH3FOZRDhq-zVTeXne4LjpKGPoDtNtljKkee2R4hE3ju3wYhltF5q8oaPZ1I9R39eB2uYBnFfRxjka1vCg8H5Vv/s957/image14.gif&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;400&quot; data-original-width=&quot;957&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnU7wUIVSDG3HicS_tHszwAD_RlhU_SXJO0quz5CUJ0RLT03erljh8ckLW8NLAlYtOPpX6lzsohacC7x2X-_2abBGDGWGpIN0KZpYJ0YH3FOzRDhq-zVTeXne 4LjpKGPoDtNtljKkee2R4hE3ju3wYhltF5q8oaPZ1I9R39eB2uYBnFfRxjka1vCg8H5Vv/s16000/image14.gif&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;使用 AI 和 GOES-16 卫星图像检测到美国上空的轨迹。&lt;/em>;&lt;/td>;&lt;/tr>;&lt; /tbody>;&lt;/table>; &lt;p>; 我们还在开发新颖的技术驱动方法来&lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/google-ai-climate-change-solutions/&quot; >;帮助社区应对气候变化的影响&lt;/a>;。例如，我们&lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/&quot;>;将洪水预报覆盖范围扩大到 80 个国家&lt;/ a>;，直接影响超过4.6亿人。我们发起了&lt;a href=&quot;https://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html&quot;>;多项研究工作&lt;/a>;，以帮助缓解野火的危险日益增加，包括使用&lt;a href=&quot;https://blog.research.google/2023/02/real-time-tracking-of-wildfire.html&quot;>;实时跟踪野火边界&lt;/a>;卫星图像，以及为面临风险的社区&lt;a href=&quot;https://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html&quot;>;改进紧急疏散计划&lt;/a>;的工作迅速蔓延的野火。我们的&lt;a href=&quot;https://www.americanforests.org/article/american-forests-unveils-updates-for-tree-equity-score-tool-to-address-climate-justice/&quot;>;合作伙伴&lt;/a >; American Forests 将我们的 &lt;a href=&quot;https://insights.sustainability.google/places/ChIJVTPokywQkFQRmtVEaUZlJRA/trees?hl=en-US&quot;>;Tree Canopy&lt;/a>; 项目中的数据应用于他们的&lt;a href =&quot;https://treeequityscore.org/&quot;>;树木公平评分&lt;/a>;平台，帮助社区识别和解决树木获取不平等问题。&lt;/p>; &lt;p>;最后，我们继续开发更好的天气预报模型更长的时间范围。改进 &lt;a href=&quot;https://blog.research.google/2020/03/a-neural-weather-model-for-eight-hour.html&quot;>;MetNet&lt;/a>; 和 &lt;a href=&quot;https ://blog.research.google/2021/11/metnet-2-deep-learning-for-12-hour.html&quot;>;MetNet-2&lt;/a>;，今年的工作&lt;a href=&quot;https: //blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html&quot;>;MetNet-3&lt;/a>;，我们现在在长达二十四小时的时间里优于传统的数值天气模拟。在中期全球天气预报领域，我们的工作&lt;a href=&quot;https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-与 &lt;a href=&quot;https://en.wikipedia.org/wiki/Integrated_Forecast_System&quot;>;HRES&lt;/a>;（最准确的业务确定性预报，由&lt;a href=&quot;https://www.ecmwf.int/&quot;>;欧洲中期天气预报中心&lt;/a>; (ECMWF) 制作。我们与 ECMWF 合作发布了 &lt;a href=&quot;https://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html&quot;>;WeatherBench-2&lt;/a>;，这是一个基准在通用框架中评估天气预报的准确性。 &lt;/p>; &lt;br />; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot; >;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;iframe allowedfullscreen=&quot;&quot; class=&quot;BLOG_video_class&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed /Q6fOlW-Y_Ss&quot; width=&quot;640&quot; youtube-src-id=&quot;Q6fOlW-Y_Ss&quot;>;&lt;/iframe>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text -align: center;&quot;>;GraphCast 在 10 天内的预测精选，显示 700 百帕斯卡（距地表约 3 公里）的比湿度、地表温度和地表风速。&lt;/td>;&lt;/tr>;&lt;/tbody>; &lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;健康和生命科学&lt;/h3>; &lt;p>;人工智能显着改善流程的潜力医疗保健意义重大。我们最初的 &lt;a href=&quot;https://www.nature.com/articles/s41586-023-06291-2&quot;>;Med-PaLM&lt;/a>; 模型是第一个能够在美国医学考试中取得及格分数的模型执照考试。我们最新的 &lt;a href=&quot;https://blog.google/technology/health/ai-llm-medpalm-research-thecheckup/&quot;>;Med-PaLM 2 模型&lt;/a>;进一步改进了 19%，实现了专家级准确率达86.5%。这些 &lt;a href=&quot;https://sites.research.google/med-palm/&quot;>;Med-PaLM 模型&lt;/a>;基于语言，使临床医生能够就复杂的医疗状况提出问题并进行对话，并且作为以下内容的一部分&lt;a href=&quot;https://cloud.google.com/blog/topics/healthcare-life-sciences/introducing-medlm-for-the-healthcare-industry&quot;>;可供&lt;/a>;医疗保健组织使用通过 Google Cloud &lt;a href=&quot;https://cloud.google.com/vertex-ai/docs/generative-ai/medlm/overview&quot;>;MedLM&lt;/a>;。 &lt;/p>; &lt;p>; 就像我们的通用语言模型不断发展以处理多种模态一样，我们最近展示了关于 &lt;a href=&quot;https://blog.research.google/2023/08/multimodal- Medical-ai.html&quot;>;Med-PaLM 的多模态版本&lt;/a>;能够解释医学图像、文本数据和其他模态，&lt;a href=&quot;https://arxiv.org/abs/2307.14334&quot;>;描述路径&lt;/a>;我们如何实现人工智能模型的令人兴奋的潜力，以帮助推进现实世界的临床护理。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgIHNosDcouStVqnHjoNr_b7YQQGCEXsxlCOy1ltKotOv5GQfl6JA9We90L6Ej3TZ2tiutOASoon-BPt__Fh9jN2NiXY1W6z5em CW63JkkS7sS1LrsMz7mINkzvSuD_i4NR3GdRbsQFlVrNrC3cv1bNHETISJ_Ml0n7ddXbtHmO_AzfSd8EPq7-ud7iBNH/s1600/image2.gif&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1600&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEgIHNosDcouStVqnHjoNr_b7YQQGCEXsxlCOy1ltKotOv5GQfl6JA9We90L6Ej3TZ2tiutOASoon-BPt__Fh9jN2NiXY1W6z5emcW63JkkS7sS1LrsMz7mINkzvSuD _i4NR3GdRbsQFlVrNrC3cv1bNHETISJ_Ml0n7ddXbtHmO_AzfSd8EPq7-ud7iBNH/s16000/image2.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Med-PaLM M 是一个大型多模态生成模型，可以灵活地编码和解释生物医学数据，包括临床语言、成像和基因组学，并且具有相同的模型模型权重。&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;我们还一直致力于&lt;a href=&quot;https://deepmind.google/discover/blog/codoc -developing-reliable-ai-tools-for-healthcare/&quot;>;如何在临床工作流程中最好地利用人工智能模型&lt;/a>;。我们已经证明，&lt;a href=&quot;https://blog.research.google/2023/03/learning-from-deep-learning-case-study.html&quot;>;将深度学习与可解释性方法结合起来&lt;/a>;可以产生为临床医生带来新的见解。我们还表明，认真考虑隐私、安全、公平和道德的自我监督学习，&lt;a href=&quot;https://blog.research.google/2023/04/robust-and-efficient-medical-imaging .html&quot;>;可以将训练临床相关医学成像模型所需的去识别化数据量减少 3×–100×，从而减少在实际临床环境中采用模型的障碍。我们还为人们发布了&lt;a href=&quot;https://blog.research.google/2023/11/enabling-large-scale-health-studies-for.html&quot;>;开源移动数据收集平台&lt;/a>;人工智能系统还可以在现有形式的医疗数据中发现全新的信号和生物标记。在&lt;a href=&quot;https://blog.research.google/2023/03/detecting-novel-systemic-biomarkers-in.html&quot;>;在视网膜图像中发现的新型生物标记&lt;/a>;的研究中，我们证明了可以从外眼照片预测跨越多个器官系统（例如肾脏、血液、肝脏）的全身生物标志物的数量。在其他工作中，我们表明，结合&lt;a href=&quot;https://blog.research.google/2023/04/developing-aging-clock-using-deep.html&quot;>;视网膜图像和基因组信息&lt;/a>;有助于确定衰老的一些潜在因素。 &lt;/p>; &lt;p>; 在基因组学领域，我们与 60 个机构的 119 名科学家合作，创建了一个&lt;a href=&quot;https://blog.research.google/2023/05/building-better-pangenomes-to- Improve.html&quot;>;人类基因组的新图谱&lt;/a>;，或称泛基因组。这种更公平的泛基因组更好地代表了全球人群的基因组多样性。在我们突破性的 &lt;a href=&quot;https://www.nature.com/articles/s41586-021-03819-2&quot;>;AlphaFold&lt;/a>; 工作的基础上，我们在 &lt;a href=&quot;https:// /deepmind.google/discover/blog/a-catalogue-of-genic-mutations-to-help-pinpoint-the-cause-of-diseases/&quot;>;AlphaMissense&lt;/a>; 今年提供了 89% 的预测目录在所有 7100 万个可能的&lt;a href=&quot;https://en.wikipedia.org/wiki/Missense_mutation&quot;>;错义变异&lt;/a>;中，可能是致病的，也可能是良性的。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHNPYsNIjVTRyfPZODcVpp-XnQAtz2b0HcKsa8F9GyJXoKfp-9PH8N_IcXO_lJ7WfuTZ2ezeAVYCDPnqeyu-qeXahqu 1lwJXb6Zq00Mt7M-WMyFff9eUL67L_QZBwK95DNlVAcFpd9cr1GW5gxqNb0mOJszQphyphenhyphen6Yi_QelNzeYnvZ1XNKZqNU2EP_x8MjW/s1070/image1 .jpg&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;491&quot; data-original-width=&quot;1070&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHNPYsNIjVTRyfPZODcVpp-XnQAtz2b0HcKsa8F9GyJXoKfp-9PH8N_IcXO_lJ7WfuTZ2ezeAVYCDPnqeyu-qeXahqu1lwJXb6Zq00Mt7M-WMyFff 9eUL67L_QZBwK95DNlVAcFpd9cr1GW5gxqNb0mOJszQphyphenhyphen6Yi_QelNzeYnvZ1XNKZqNU2EP_x8MjW/s16000/image1.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;覆盖在 AlphaFold 预测结构上的 AlphaMissense 预测示例（红色 – 预测为致病性；蓝色——预测为良性；灰色——不确定）。红点代表已知的致病性错义变异，蓝点代表已知的良性变异。&lt;strong>;左：&lt;/strong>;&amp;nbsp;HBB 蛋白。该蛋白的变异体可导致镰状细胞性贫血。&lt;strong>;右：&lt;/strong>;CFTR 蛋白。这种蛋白质的变体可导致囊性纤维化。&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;我们还分享了&lt;a href=&quot;https://deepmind.google/discover/ blog/a-glimpse-of-the-next- Generation-of-alphafold/&quot;>;下一代 AlphaFold 进展的更新&lt;/a>;。我们最新的模型现在可以对&lt;a href=&quot;https://www.wwpdb.org/&quot;>;蛋白质数据库&lt;/a>; (PDB) 中的几乎所有分子生成预测，通常达到原子精度。这开启了新的认识并显着提高了多个关键生物分子类别的准确性，包括配体（小分子）、蛋白质、核酸（DNA 和 RNA）以及含有翻译后修饰 (PTM) 的分子。&lt;/p>;&lt;p>;&lt; /p>; &lt;p>; 在神经科学方面，我们&lt;a href=&quot;https://blog.research.google/2023/09/google-research-embarks-on-effort-to.html&quot;>;宣布了一项新的合作&lt;/a>; 与哈佛大学、普林斯顿大学、美国国立卫生研究院和其他机构合作，以突触分辨率绘制整个小鼠大脑图谱，第一阶段将重点关注&lt;a href=&quot;https://en.wikipedia.org/wiki /Hippocampal_formation&quot;>;海马结构&lt;/a>; — 大脑中负责记忆形成、空间导航和其他重要功能的区域。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;量子计算&lt;/h3>; &lt;p>; 量子计算机有潜力解决大型现实世界问题科学和工业领域的问题。但要实现这一潜力，它们必须比现在大得多，并且必须可靠地执行传统计算机无法执行的任务。 &lt;/p>; &lt;p>; 今年，我们在开发大规模、实用的量子计算机方面迈出了重要一步。我们的突破是首次演示&lt;a href=&quot;https://blog.research.google/2023/02/suppressing-quantum-errors-by-scaling.html&quot;>;量子纠错&lt;/a>;，表明它可以减少错误，同时增加量子位的数量。为了实现实际应用，这些量子位构建块必须执行更可靠，将错误率从目前常见的约十分之一&lt;sup>;3&lt;/sup>;降低到约十分之一&lt;sup>;8&lt;/sup>; 。 &lt;/p>; &lt;br />; &lt;h2>;负责任的人工智能研究&lt;/h2>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;责任设计&lt;/h3>; &lt;p>; 生成式人工智能正在医疗保健、教育、安全、能源、交通、制造和娱乐等广泛领域产生变革性影响。鉴于这些进步，设计符合我们的&lt;a href=&quot;https://ai.google/responsibility/principles/&quot;>;人工智能原则&lt;/a>;的技术仍然是重中之重。我们最近还发布了&lt;a href=&quot;https://blog.research.google/2023/11/emerging-practices-for-society-centered.html&quot;>;以社会为中心的人工智能新兴实践&lt;/a>;的案例研究。在我们的年度 &lt;a href=&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf&quot; target=&quot;_blank&quot;>;AI 原则进展更新&lt;/a>;中，我们提供了详细介绍了我们的 Responsible AI 研究如何集成到产品和风险管理流程中。 &lt;/p>; &lt;p>; 负责任的人工智能的主动设计从识别和记录潜在危害开始。例如，我们最近&lt;a href=&quot;https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/&quot;>;推出&lt;/a>;&lt;a href= “https://arxiv.org/abs/2310.11986”>;基于上下文的三层框架，用于全面评估人工智能系统的社会和道德风险。在模型设计过程中，可以通过使用&lt;a href=&quot;https://blog.research.google/2023/11/responsible-ai-at-google-research_16.html&quot;>;负责任的数据集&lt;/a>;来减轻危害。 &lt;/p>; &lt;p>; 我们&lt;a href=&quot;https://blog.google/technology/research/project-elevate-black-voices-google-research/&quot;>;与霍华德大学合作&lt;/a>;高质量的非裔美国英语 (AAE) 数据集，以改进我们的产品并使其为更多人服务。我们对&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3593013.3594016&quot;>;全球包容性文化表征&lt;/a>;的研究以及我们发布的&lt;a href=&quot;https://skintone.google /&quot;>;僧侣肤色等级&lt;/a>;进一步推动了我们对所有人的公平代表性的承诺。我们获得的见解和开发的技术不仅帮助我们改进自己的模型，还为 &lt;a href=&quot;https://blog.google/intl/en-in/company-news/using-ai-to-study -demographic-representation-in-in-indian-tv/&quot;>;对大众媒体的代表性进行大规模研究&lt;/a>;，以告知和激发世界各地更具包容性的内容创作。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEirYAo6ClPM9zD8ctnoTvdyhnwW1VdVT2p677EMKGrN0oULjyK9TdS05z1OzhTTuyxp0kfuUUbHEieZXYRW6hUe3XlJM6 HYOS68rXneSGQeLTy_Bo_SCvbxnjHdG2CB_8aLCz5pP-B_dciLKZYlIo9j8bEyUdKtZQhg7DukG9pJudJKU-o0DRuM5XrbvkBI/s1196/image9.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;158&quot; data-original-width=&quot;1196&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEirYAo6ClPM9zD8ctnoTvdyhnwW1VdVT2p677EMKGrN0oULjyK9TdS05z1OzhTTuyxp0kfuUUbHEieZXYRW6hUe3XlJM6HYOS68rXneSGQeLTy_Bo_SCvbxnjHd G2CB_8aLCz5pP-B_dciLKZYlIo9j8bEyUdKtZQhg7DukG9pJudJKU-o0DRuM5XrbvkBI/s16000/image9.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;僧侣肤色 (MST) 等级。如需了解更多信息，请访问&lt;a href=&quot;http://skintone.google/&quot;>;skintone.google&lt;/a>;。&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;随着生成图像模型的进步，&lt;a href=&quot;https://blog.research.google/2023/08/responsible-ai-at-google-research.html&quot;>;对人的公平和包容性代表性&lt;/a>;仍然存在是重中之重。在开发过程中，我们正在努力&lt;a href=&quot;https://blog.research.google/2023/07/using-societal-context-knowledge-to.html&quot;>;扩大代表性不足的声音并更好地整合社会背景知识&lt;/a>;。我们使用&lt;a href=&quot;https://arxiv.org/pdf/2306.06135.pdf&quot;>;分类器和过滤器&lt;/a>;主动解决潜在的危害和偏见，&lt;a href=&quot;https://arxiv.org/pdf /2311.17259.pdf&quot;>;仔细的数据集分析&lt;/a>;，以及模型内缓解措施，例如微调、&lt;a href=&quot;https://arxiv.org/abs/2310.16523&quot;>;推理&lt;/a>;、&lt; a href=&quot;https://arxiv.org/abs/2306.14308&quot;>;少量提示&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2310.16959&quot;>;数据增强&lt;/a>;和&lt;a href=&quot;https://arxiv.org/abs/2310.17022&quot;>;受控解码&lt;/a>;，我们的研究表明生成式人工智能能够&lt;a href=&quot;https://arxiv.org/abs/2302.06541 ”用更少的数据开发更高质量的安全分类器&lt;/a>;。我们还发布了&lt;a href=&quot;https://developers.googleblog.com/2023/10/make-with-makersuite-part-2-tuning-llms.html&quot;>;一种强大的方法，可以用更少的数据更好地调整模型&lt; /a>; 使开发人员能够更好地控制生成人工智能中的责任挑战。&lt;/p>; &lt;p>; 我们开发了新的&lt;a href=&quot;https://arxiv.org/abs/2303.08114&quot;>;最先进的技术可解释性方法&lt;/a>;来识别训练数据对模型行为的作用。通过&lt;a href=&quot;https://arxiv.org/abs/2302.06598&quot;>;将训练数据归因方法与敏捷分类器相结合&lt;/a>;，我们发现我们可以识别错误标记的训练示例。这使得减少训练数据中的噪声成为可能，从而显着提高模型准确性。 &lt;/p>; &lt;p>; 我们发起了多项努力来提高在线内容的安全性和透明度。例如，我们推出了 &lt;a href=&quot;https://deepmind.google/discover/blog/identifying-ai- generated-images-with-synthid/&quot;>;SynthID&lt;/a>;，这是一种用于添加水印和识别 AI 的工具生成的图像。 SynthID 人眼无法察觉，不会影响图像质量，并且即使在添加滤镜、更改颜色以及使用各种有损压缩方案保存等修改之后，水印仍然可检测到。 &lt;/p>; &lt;p>; 我们还推出了&lt;a href=&quot;https://blog.google/products/search/google-search-new-fact-checking-features/&quot;>;关于此图片&lt;/a>;来提供帮助人们评估图像的可信度，显示图像的历史记录、图像在其他页面上的使用方式以及图像的可用元数据等信息。我们&lt;a href=&quot;https://arxiv.org/abs/2210.03535&quot;>;探索了其他领域已开发的安全方法&lt;/a>;，从低风险容忍度的既定情况中学习。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBYUNXlxnFiBnnB_-EFKhdc-1W8MwG-VZKrhyKtWFmfAcqlrbSdPl7TAslOAMaH1Zon0TvGKpj23nlO7XZyg2ovFu NHpgXbsyUUPrxzf1RtJFlBPzR5Hh9KAus1l79qrBFP5JJDScQgn_5cq3ZVf7T0VuPiNLLJ-PsENlba_BA0nORQkofZYY7K1DhJGXt/s616/image6 .gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;346&quot; data-original-width=&quot;616&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBYUNXlxnFiBnnB_-EFKhdc-1W8MwG-VZKrhyKtWFmfAcqlrbSdPl7TAslOAMaH1Zon0TvGKpj23nlO7XZyg2ovFuNHpgXbsyUUPrxzf1RtJFlBPzR 5Hh9KAus1l79qrBFP5JJDScQgn_5cq3ZVf7T0VuPiNLLJ-PsENlba_BA0nORQkofZYY7K1DhJGXt/s16000/image6.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;SynthID 为 AI 生成的图像生成难以察觉的数字水印。&lt;/em>;&lt;/td>; &lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 隐私仍然是我们对 Responsible AI 承诺的一个重要方面。我们继续改进最先进的隐私保护学习算法&lt;a href=&quot;https://arxiv.org/abs/2103.00039&quot;>;DP-FTRL&lt;/a>;，开发了DP-Alternating Minimization算法（&lt; a href=&quot;https://arxiv.org/pdf/2310.15454.pdf&quot;>;DP-AM&lt;/a>;），通过严格的隐私保护实现个性化推荐，并定义了新的&lt;a href=&quot;https://blog .research.google/2023/09/ Differentially-private-median-and-more.html&quot;>;一般范例&lt;/a>;，用于降低许多聚合和学习任务的隐私成本。我们还提出了一种&lt;a href=&quot;https://openreview.net/pdf?id=q15zG9CHi8&quot;>;审核差分隐私机器学习系统&lt;/a>;的方案。&lt;/p>; &lt;p>;在应用程序方面，我们演示了&lt;a href=&quot;https://arxiv.org/pdf/2308.10888.pdf&quot;>;DP-SGD 在大型模型微调机制中提供了实用的解决方案&lt;/a>;，并表明 DP 扩散模型生成的图像是&lt;a href=&quot;https://arxiv.org/pdf/2302.13861.pdf&quot;>;对于一系列下游任务很有用&lt;/a>;。我们&lt;a href=&quot;https://blog.research.google/2023/12/sparsity-preserving- Differentially.html&quot;>;提出&lt;/a>;一种用于大型嵌入模型的 DP 训练的新算法，该算法可以在 TPU 上提供高效的训练不影响准确性。 &lt;/p>; &lt;p>; 我们还与众多学术和工业研究人员合作组织了&lt;a href=&quot;https://unlearning-challenge.github.io/&quot;>;首届机器学习挑战&lt;/a>;解决忘记训练图像的情况，以保护个人的隐私或权利。我们分享了一种&lt;a href=&quot;https://arxiv.org/pdf/2311.17035.pdf&quot;>;可提取记忆&lt;/a>;的机制，以及&lt;a href=&quot;https://arxiv.org/abs/2302.03874&quot; >;参与式系统&lt;/a>;让用户能够更好地控制他们的敏感数据。 &lt;/p>; &lt;p>;我们继续将世界上最大的非典型语音录音语料库扩展到&lt;a href=&quot;https://sites.research.google/euphonia/euphonia/about/&quot;>; Project euphonia &lt;/>; a>;，它使我们能够训练&lt;a href=&quot;https://blog.research.google/2023/03/universal-speech-model-usm-state-model-usm-state-ort-art.html&quot;>;通用语音模型&lt;/ a>; to &lt;a href=&quot;https://blog.research.google/2023/06/responsible-ai-ai-at--google-google-research-ai.html&quot;>;更好地识别37％的非典型演讲&lt;/a>; - 世界基准。 &lt;/p>; &lt;p>;我们还构建了一个&lt;a href=&quot;https://blog.research.google/2023/08/study-socacely-aware-ware-temorporally-causal.html&quot;>;有声读物推荐系统&lt;/a>;适用于阅读障碍的学生，例如阅读障碍。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h3>;对抗测试&lt;/h3>; &lt;p>;我们在对抗测试中的工作&lt;a href =“ https：https：https：https： //blog.research.google/2023/03/responsible-ai-at-google-research.html&quot;>;从历史上被边缘化的社区发出的社区声音&lt;/a>;。我们与&lt;a href=&quot;https://arxiv.org/abs/2303.08177&quot;>;公平的AI研究圆桌会议等团体合作a href =“ https://dynabench.org/tasks/adversarial-nibbler”>;与外部用户互动&lt;/a>;，以识别生成模型输出中的潜在危害。 &lt;/p>; &lt;p>;我们&lt;a href=&quot;https://blog.research.google/2023/11/responsible-ai-ai-at-google-research_16.html&quot;>;建立了一个专用的Google Ai Red Team &lt;/a >;专注于测试AI模型和产品的安全性，隐私和滥用风险。我们表明，诸如“ &lt;a href=&quot;https://arxiv.org/pdf/2302.10149.pdf？isapp = 1&quot;>;中毒&lt;/a>;”或&lt;a href =“ https://arxiv.org.org.org.org /pdf/2306.15447.pdf&quot;>; verversarial示例&lt;/a>;可以应用于生产模型，并表现出其他风险，例如在&lt;a href =“ https://wwwwwwww.usenix.org/seenix.org/syples/files/files/files/files/files/usenixsecurity23---- carlini.pdf“>;图像&lt;/a>;和&lt;a href=&quot;https://arxiv.org/pdf/2311.17035.pdf&quot;>;文本生成模型&lt;/a>;。我们还证明，防御此类攻击可能具有挑战性，因为仅应用防御可能会导致其他&lt;a href=&quot;https://arxiv.org/pdf/pdf/2309.05610.pdf&quot;>;安全和隐私泄漏&lt;/a>;。我们还引入了&lt;a href=&quot;https://arxiv.org/abs/2305.15324&quot;>;极端风险&lt;/a>;的模型评估&lt;/a>;，例如进攻性网络能力或强大的操纵技巧。 &lt;/p>; &lt;div style =“线路高：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h3>;在我们推进最新状态时，工具和教育&lt;/h3>; &lt;p>;使AI民主化在ML和AI中，我们还希望确保人们能够理解并将AI应用于特定问题。我们发行了&lt;a href=&quot;https://makersuite.google.com/&quot;>; makerSuite &lt;/a>;（现在&lt;a href=&quot;https://makersuite.google.google.com&quot;>; google ai ai stutio &lt;/a>;） ，一种基于Web的工具，使AI开发人员能够快速迭代并构建轻巧的AI驱动应用程序。为了帮助AI工程师更好地理解和调试AI，我们发布了&lt;a href=&quot;https://pair-code.github.io/lit/&quot;>; lit 1.0 &lt;/a>;，一个state-of-the-the-art，打开 - 机器学习模型的源调试器。 &lt;/p>; &lt;p>; &lt;a href=&quot;https://colab.google/&quot;>; colab &lt;/a>;，我们的工具可帮助开发人员和学生在其Web浏览器中访问强大的计算资源，并吸引了超过1000万用户。我们刚刚添加了&lt;a href=&quot;https://blog.google/technology/ai/democratizing-access-access-to-oai-enabled-coding-with-colab/&quot;>; ai-powered代码帮助&lt;/a>;所有用户都免费 - 使COLAB成为数据和ML工作流程中的更有用和集成的经验。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhy5OhqeP7Rf5gTbCP-gYsmTFyc9ztUMXrcv_M8Lya5zLPzzRVrHmldGiR-rf1PnggxP_rlG2mo6YJ9NhnNnFHEbtn8f-FJk_cxOTtO9hL0ZhxV9hSGd0LW0-RymxkPVBbqXKDk4nRV7mJE6heVnn-6tYcLdpofuhqKPHnqxDTZf1hjifTg3k7K4VNcS2S6/s844 /image10.gif“ style =”边距 - 左：自动; margin-right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 470” data-Original-width =“ 844” src =“ src =” https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhy5OhqeP7Rf5gTbCP-gYsmTFyc9ztUMXrcv_M8Lya5zLPzzRVrHmldGiR-rf1PnggxP_rlG2mo6YJ9NhnNnFHEbtn8f-FJk_cxOTtO9hL0ZhxV9hSGd0LW0-RymxkPVBbqXKDk4nRV7mJE6heVnn-6tYcLdpofuhqKPHnqxDTZf1hjifTg3k7K4VNcS2S6/s16000/image10.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =“ tr-caption” style =“ text-align：center;”>; &lt;em style =“ text-align：left;”>;最常用的功能之一是“解释错误”  - 每当用户遇到COLAB中的执行错误，代码辅助模型提供了一个解释以及潜在的修复。&lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;p>;确保AI在放置时产生准确的知识要使用，我们最近还引入了&lt;a href=&quot;https://deepmind.google/discover/discover/blog/funsearch-making-making-new-discoveries-in-mathematical-sciences-sciences-ingematical-sciences-using-large-lange-lange-models/&quot;>; funsearch &lt;>; funsearch &lt;>; /a>;，一种新方法，使用进化方法和大语言模型在数学科学中可见真实的知识。&lt;/p>; &lt;p>;对于AI工程师和产品设计师，我们正在更新&lt;a href =&#39;https：/https：/ /pair.withgoogle.com/guidebook/&quot;>; people + AI指南&lt;/a>;具有生成的AI最佳实践，我们继续设计&lt;a href=&quot;https://pair.withgoogle.com/explorable Explorables &lt;/a>;，其中包括&lt;a href=&quot;https://pair.withgoogle.com/explorables/explorables/uncternity-ood/od/&quot;>;如何以及为什么模型有时会自信地做出错误的预测&lt;/a>;。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h3>;社区参与&lt;/h3>; &lt;p>;我们继续通过发表我们的大部分工作，参加和组织会议。我们今年迄今已发表了500多篇论文，并在ICML等会议上有很强的论文（请参阅&lt;a a href =“ https://blog.research.google/2023/07/google-at------icml-2023。 html“>; Google Research &lt;/a>;和&lt;a href=&quot;https://deepmind.google/discover/discover/google/google-deepmind-research-atresearch-at-icml-2023/&quot;>; Google DeepMind ICLR（&lt;a href=&quot;https://blog.research.google/2023/04/google-at-iclr-2023.html&quot;>; Google Research &lt;/a>;，&lt;a href =“ https：// deepmind。 Google/discover/blog/deepminds-latest-ratesk-at-iclr-2023/“>; google deepmind &lt;/a>;），neurips（&lt;a href =“ https://blog.research.google/2023/2023/12/google -at-neurips-2023.html“>; Google Research &lt;/a>;，&lt;a href=&quot;https://deepmind.google/discover/discover/blog/google-deepmind-deepmind-at-at-neurips-2023/&quot;>; Google DeepMind &lt;/>; a>;），&lt;a href=&quot;https://blog.research.google/2023/10/google-at-iccv-2023.html&quot;>; iccv &lt;/a>;，&lt;a href =“ 。 -2023.html“>; acl &lt;/a>;，&lt;a href=&quot;https://blog.research.google/2023/04/google-at-chi-2023.html&quot;>; chi &lt;/a>;，和&lt; a href =“ https://blog.research.google/2023/08/google-at-interspeech-2023.html”>; interspeech &lt;/a>;。我们还在努力支持世界各地的研究人员，参加诸如&lt;a href=&quot;https://deeplearningningindaba.com/2023/google-outreach-mentoreach-mentorship-programme/&quot;>;深度学习Indaba &lt;/a>;，&lt;a href=&quot;https://deeplearningningindaba.com/2023/deplearningningindaba.com/a>; a href =“ https://khipu.ai/khipu2023/khipu-2023-speakers2023/”>; khipu &lt;/a>;，支持&lt;a href =“拉丁美洲的拉丁美洲/博士学位研究 - 拉丁 - 美国“>;在拉丁美洲的博士学位奖学金&lt;/a>;等等。我们还与来自33个学术实验室的合作伙伴合作，汇总22种不同机器人类型的数据，并创建&lt;a href =“ https://deepmind.google/discover/discover/blog/scaling-up-up-learning-learning-learning-across-many-different-robot--robot -Types/“>;打开X-Embodiment数据集和RT-X模型&lt;/a>;更好地推进负责任的AI开发。 &lt;/p>; &lt;p>; Google率先开发了&lt;a href=&quot;https://mlcommons.org/working-groups/ai-safety/ai-safety/&quot;>; ai安全基准&lt;/a >;在&lt;a href=&quot;https://mlcommons.org/&quot;>; mlCommons &lt;/a>;标准组织中，来自生成AI空间中的几位主要参与者的标准组织，包括Openai，Anthropic，Microsoft，Microsoft，Meta，Hugging Face等。与行业中的其他人一起，我们还&lt;a href=&quot;https://blog.google/outreach-initiatives/public-policy/google-microsoft-openai-apenai-anthropic-frontier-model-model-model-model-model-model-forum/&quot;>; a>; &lt;a href=&quot;https://www.frontiermodelforum.org/&quot;>; Frontier模型论坛&lt;/a>;（FMF），该论坛的重点是确保Frontier AI模型的安全和负责任的开发。 With our FMF partners and other philanthropic organizations, we launched a $10 million &lt;a href=&quot;https://blog.google/outreach-initiatives/public-policy/google-microsoft-anthropic-open-ai-frontier-model-forum - 执行导演/“>; AI安全基金&lt;/a>;促进对社会工具持续开发的研究，以有效测试和评估最有能力的AI模型。 &lt;/p>; &lt;p>;与&lt;a href=&quot;http://google.org&quot;>; Google.org &lt;/a>;，我们&lt;a href =“ https://blog.google/technology/technology/technology/ai /google-ai-data-un-global-goals/“>;与联合国合作&lt;/a>;建造&lt;a href=&quot;https://unstats.un.org/unsdwebsite/unsdwebsite/undatacommons/undatacommons/sdgs&quot;>; un可持续发展目标的数据共享&lt;/a>;，该工具可以跟踪17 &lt;a href=&quot;https://sdgs.un.org/goals&quot;>;可持续发展目标&lt;/a>;和&lt;href &lt;a href =“ https://globalgoals.withgoogle.com/globalgoals/supported-organizations”>;支持的项目&lt;/a>;来自非政府组织，学术机构和社会企业，&lt;a href =“ Initiatives/google-org/httpsbloggoogleoutreach-initiativesgoogle-orgunited-nations-global-goals-google-ai-/&quot;>;利用人工智能加速实现可持续发展目标&lt;/a>;。 &lt;/p>; &lt;p>;这篇文章中突出的项目是我们在过去一年所做的研究工作的一小部分。在&lt;a href=&quot;https://blog.research.google/&quot;>; Google Research &lt;/a>;和&lt;a href=&quot;https://deepmind.google/discover/discover/blog/&quot;>; Google DeepMind上找到更多信息。 &lt;/a>;博客，以及我们的&lt;a href=&quot;https://research.google/pubs/&quot;>;出版物列表&lt;/a>;。 &lt;/p>; &lt;br />; &lt;h2>;未来愿景&lt;/h2>; &lt;p>;随着多模型模型变得更加有能力，他们将使人们能够在从科学到教育到全新知识领域的领域取得令人难以置信的进步。 &lt;/p>; &lt;p>;进步持续发展，随着年的进步，我们的产品和研究进步也将为AI找到更多有趣的创意用途。 &lt;/p>; &lt;p>;结束今年的审视，我们从&lt;em>; &lt;a href =“ https://ai.google/static/documents/google-why-we-we-focus-- on-ai.pdf“>;我们为什么要专注于AI（以及到底）&lt;/a>; &lt;/em>;：&lt;/p>; &lt;div style =“ margin-left：40px;”>; &lt;p>;如果要大胆地负责任地，我们认为AI可以成为改变各地人民生活的基础技术 - 这就是激动我们的！态;“”>;今年审视在&lt;a href=&quot;https://blog.creachearch.google/2023/2023 Yar.2023 are-of-of-groundbreaking-adbreaking-Advances-in.html&quot;>; Google Research blo &lt;/a>; g和&lt;a href=&quot;https://deepmind.google/discover/blog/2023-a arear of-of-of-of-of-groundbreaking-Advances-invances-in-ai-and-computing/&quot;>; google DeepMind Blog &lt;/a>;。&lt;/span>; &lt;/p>; &lt;/content>; &lt;link href =“ http://blog.research.google/feeds/881618347347347385638131/comments/comments/comments/default/default”发表注释“ type =”应用程序/atom+xml”/>; &lt;link href =” http://blog.research.google/2023/2023 Yarial-of-ground-groundbreaking-rakearking-abrbreaking-advances-in.html#comment-form “ rel =”回复“ title =” 0注释“ type =” text/html“/>; &lt;link href =” http://www.blogger.com/feeds/8474926331452026626/posts/posts/default/88161618161834733855638563813813813131&#39;REL =“” “ type =”应用程序/ATOM+XML“/>; &lt;link href =” http://www.blogger.com/feeds/8474926333145202626/posts/posts/posts/default/88161618161816183473434338563856381381381381381381381381381381381 rel =“ “/>; &lt;link href =” http://blog.research.google/2023/2023 Yar.-of-groundbreaking-andvances-in.html” AI和计算中的进步“ type =” text/html“/>; &lt;unal>; &lt;name>; google ai &lt;/name>; &lt;uri>; http://www.blogger.com/profile.com/profile/1209862651477775266161 &lt;/uri>; noreply@blogger.com &lt;/email>; &lt;gd：image height =“ 16” rel =“ http://schemas.google.com/g/g/2005#thumbnail” src =“ https://img1.blog1.blogblog.com/ img/b16-rounded.gif“ width =“ 16”>; &lt;/gd：image>; &lt;/wustr>; &lt;媒体：缩略图高度=“ 72” url =“ https://blogger.googger.googleusercontent.com/img/img/b/ R29vZ2xl/AVvXsEiU12G_p2DZO4gQ-P95aP2IFvtKRHRG5Oik9VzJ4WtT_VznggjUrL4tTzqto-C8yx6ULgvugKgH9usiZxnKGk97pOFyHWnu-1S4sSbR2Jjq5T36tQRbZucTAP7gmXkGw77xN6s39IKxPaxbo5tw_Cq52ZfPWOCBkWL-2XTuzsIh6viRIqgGcdUdNq-pHjzl/s72-c/year_in_review-hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/媒体：缩略图>; &lt;thr：THR>; 0 &lt;/thr：Total>; &lt;/entry>; &lt;entry>; &lt;ID>;标签：Blogger.com，1999年：Blog-8474926331452026626.POST-5516200707034946636207 12-19T13：08：00.000-08：00 &lt;/publined>; &lt;更新>; 2024-01-12T11：04：04：04.629-08：00 &lt;/updateed>; &lt;category scheme =“ http：///www.blogger.com/ atom/ns＃“ term =“大语言模型”>; &lt;/category>; &lt;category scheme =“ http://www.blogger.com/atom/ns#” term =“ Machine Learning”>; &lt;/category>; &lt;类别scheme =“ http://www.blogger.com/atom/ns#” term =“ video”>; &lt;/category>; &lt;category scheme =“ http://www.blogger.com/atom/ns#” term = “视觉研究”>; &lt;/category>; &lt;title type =“ text”>; videopoet：零摄影视频生成的大语言模型&lt;/stitle>; &lt;content type =“ html”>; &lt;span class =“ byline-author” >;Posted by Dan Kondratyuk and David Ross, Software Engineers, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFG8pxLk-uvJVPesDUxU7Ox7Tb0VR4lB4jNygxiiIl9gyeX-rgtCb5jhWbPDKGad4d5GkPFr7-uzdZOngFtnPbmV6IurKEd5vHTiLesCvx8RDzBy_5u31e6C93kuirOG8pKcwEBkBrw4TBTzh3WIoX1TZYzYM3M4aj4zYD2r_p5FflI7ntpqoD9fsGQhwO/s1600/videopoetpreview .gif“ style =” display：none;” />; &lt;p>;最近的视频生成模型已经突破了现场，在许多情况下，展示了令人惊叹的风景如画的质量。视频生成中当前的瓶颈之一是能够产生连贯的大动作。在许多情况下，即使是当前的领先模型也会产生小运动，或者在产生较大动作时也会表现出明显的人工制品。 &lt;/p>; &lt;a name=&#39;more&#39;>; &lt;/a>; &lt;p>; &lt;p>;要探索语言模型在视频生成中的应用，我们介绍Videopoet（&lt;a href =“ http://sites.research.google/videopoet “>;网站&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2312.14125&quot;>;研究论文&lt;/a>;），一种大型语言模型（LLM），能够使用各种视频生成任务，包括文本到视频，图像到视频，视频风格，视频&lt;a href=&quot;https://en.wikipedia.org/wiki/inpainting&quot;>; Inpainting &lt;/a>;和&lt;a href = a href = “ https://paperswithcode.com/task/image-ustpainting&quot;>; outpainting &lt;/a>;和Video-to-to-to-audio。一个值得注意的观察是，领先的视频生成模型几乎完全基于扩散（例如，请参见&lt;a href=&quot;https://imagen.research.google/video/video/&quot;>; Imagen Video &lt;/a>;）。另一方面，由于其在各种模式中的出色学习能力，包括语言，代码和音频（例如，&lt;a href =&#39;https：// https：// Google-Research.github.io/seanet/audiopalm/examples/&quot;>; audiopalm &lt;/a>;）。与该空间中的替代模型相反，我们的方法无缝地将许多视频生成功能集成到单个LLM中，而不是依靠专门从事每个任务的单独训练的组件。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/div>; &lt;h2>;概述&lt;/h2>; &lt;p>;下图显示了Videopoet的功能。输入图像可以动画以产生运动，并且（可选的裁剪或掩盖）可以编辑用于介绍或支出的视频。为了进行样式化，该模型采用代表代表运动的深度和光流的视频，并在顶部绘制内容以产生文本引导的样式。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfgEjHPIukR1pHUT7VBU8DecJaayp8sIV1WC4HM6EOW-K1-E_Xu9-qE2hrTBrtgrks3awr8IiT9NhxVMDOR0qoFZ8nDQT_Si3LY60CWKySkaybXRW5Uf6EwZIiDRy7qkQGuoLUxoysR-fjEr0NTMqAGP2Cm8cyUQHVOOlS7MysnwHwqhdM-eA63PXy5XsV/s1999 /Image7.png“ style =”左右左右：自动; margin-right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 682” data-Original-width =“ 1999” src =“ src =” https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfgEjHPIukR1pHUT7VBU8DecJaayp8sIV1WC4HM6EOW-K1-E_Xu9-qE2hrTBrtgrks3awr8IiT9NhxVMDOR0qoFZ8nDQT_Si3LY60CWKySkaybXRW5Uf6EwZIiDRy7qkQGuoLUxoysR-fjEr0NTMqAGP2Cm8cyUQHVOOlS7MysnwHwqhdM-eA63PXy5XsV/s16000/image7.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =“ tr-caption” style =“ text-align：center;”>; videopoet的概述，能够在各种以视频为中心的输入和输出上进行多任务处理。 LLM可以选择将文本作为输入，以指导文本到视频，图像到视频，视频对审计，风格化和支出任务的生成。使用的资源：&lt;a href=&quot;https://commons.wikimedia.org/wiki/main_page&quot;>; wikimedia commons &lt;/a>;和&lt;a href=&quot;https://davischallenge.org/davis &lt;/a>; 。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>;语言模型作为视频生成器&lt;/h2 >; &lt;p>;使用LLM进行培训的一个主要优点是，可以重用现有LLM培训基础设施中引入的许多可扩展效率提高。但是，LLMS在离散令牌上运行，这可能会使视频发电具有挑战性。幸运的是，存在&lt;a href=&quot;https://magvit.cs.cmu.edu/v2/&quot;>;视频&lt;/a>;和&lt;a href=&quot;https://arxiv.org/abs/2107.03312&quot;>; audio &lt;/a>;用于编码视频和音频剪辑的Tokenizers作为离散令牌的序列（即，整数索引），并且也可以将其转换回原始表示形式。 &lt;/p>; &lt;p>; videopoet训练&lt;a href=&quot;https://en.wikipedia.org/wiki/autoregresceression_model&quot;>;自动性语言模型&lt;/a>;以通过视频，图像，音频和文本方式学习使用多个tokenizer（&lt;a href=&quot;https://magvit.cs.cmu.edu/v2/&quot;>; magvit v2 &lt;/a>;用于视频和图像，&lt;a href =“ https://arxiv.org.org.org.org.org.org.org /abs/2107.03312&quot;>; soundstream &lt;/a>;用于音频）。一旦模型生成在某些上下文中的代币，这些代币便可以通过令牌解码器转换为可见的表示形式。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxFblHaHRJNH7Oi2_oOTosGN9XrjgjhWmnfADchMT8WR0XAo6SxiUfpUmn5R6akciiRduaKIMdgwHZzK3xW8mErarQ_ugx41ctQAMK08O9UMVevgkk-AgFI1xYFWAomd16OcOh0R-XpyZVLQXncpk2SHf-RmPzrqBbIWZc-nUG2TH6nC2R7qyHXn8eTC-u/s2680 /Image21.png“ style =” Margin-Left：auto; Margin-Right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 824” data-Original-width =“ 2680” src =“ src =” https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxFblHaHRJNH7Oi2_oOTosGN9XrjgjhWmnfADchMT8WR0XAo6SxiUfpUmn5R6akciiRduaKIMdgwHZzK3xW8mErarQ_ugx41ctQAMK08O9UMVevgkk-AgFI1xYFWAomd16OcOh0R-XpyZVLQXncpk2SHf-RmPzrqBbIWZc-nUG2TH6nC2R7qyHXn8eTC-u/s16000/image21.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =“ tr-caption”样式=“ text-align：center;”>;详细介绍了Videopoet任务设计，显示了各种任务的培训和推理输入和输出。使用令牌编码器和解码器将模态转换为代币。每种方式都被边界令牌包围，任务令牌表示要执行的任务类型。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/div>; &lt;h2>; videopoet生成的示例&lt;/h2>; &lt;p>;我们的模型生成的一些示例如下所示。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgoUJFpPd377ceVnh3Yi0Y1oM6pVPL_FSEwugxBVKfEwHV8VA-1ZPmddz1VRBtqESjjEP83EJ4HOLLSBmXOVLEODZVFZYUuDiCRyMUIvSaRsxieR-58iAwHPBf7SNeSBU2a3Pm80JOFivTSjZsqlerHxAGg_Ko_8gCDLWWtNAQffyGCNJrw2G5PPG-vSYtz/s1100/image18.gif “样式=” Margin-Left：Auto; Margin-Right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 963” data-Original-width =“ 1100” 1100“ src =” https：/// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgoUJFpPd377ceVnh3Yi0Y1oM6pVPL_FSEwugxBVKfEwHV8VA-1ZPmddz1VRBtqESjjEP83EJ4HOLLSBmXOVLEODZVFZYUuDiCRyMUIvSaRsxieR-58iAwHPBf7SNeSBU2a3Pm80JOFivTSjZsqlerHxAGg_Ko_8gCDLWWtNAQffyGCNJrw2G5PPG-vSYtz/s16000/image18.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-字幕“ style =” text-align：center;“>;视频中从各种文本提示中生成的视频。有关特定的文本提示，请参阅&lt;a href=&quot;http://sites.research.google/videopoet&quot;>;网站&lt;/a>;。&lt;/td>; &lt;/td>; &lt;/tr>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br/ >; &lt;p>;对于文本到视频，视频输出是可变的长度，可以根据文本内容应用一系列动作和样式。为了确保负责任的做法，我们参考公共领域中的艺术品和样式-container“>; &lt;tbody>; &lt;tr>; &lt;td style =” text-align：right;“>; &lt;b>; text Input &lt;/b>; &lt;/td>; &lt;td>; &lt;td>;＆nbsp;＆nbsp;＆nbsp; &lt;/td>; &lt;td>; &lt;td>; &lt;td>; =“ center” width =“ 20％”>; &lt;em>;“时代广场上的浣熊跳舞” &lt;/em>; &lt;/td>; &lt;td>;＆nbsp;＆nbsp; &lt;/td>; &lt;td>; &lt;td align =“中心” width =“ “ 20％”>; &lt;em>;“一匹马在van-gogh的&#39;starry Night&#39;&#39;&#39; 20％“>; &lt;em>;”“两个熊猫扑克牌” &lt;/em>; &lt;/td>; &lt;td>;＆nbsp;＆nbsp; &lt;/td>; &lt;td align =“中心” width =“ 20％”>; &lt;em>;“大量的爆炸式飞溅彩虹油漆，带有苹果出现的8k” &lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tr>; &lt;tr>; &lt;td style =“ text-align：right; comight;”>; &lt;b>; &lt;b>;视频输出&lt; /b>; &lt;/td>; &lt;td>;＆nbsp;＆nbsp; &lt;/td>; &lt;td style =“ text-align：center;”>; &lt;a href =“ https://blogger.googleusercontent.com/img/img/b/ r29vz2xl/avvxsehfnvzu_hzvgt7xcva4adbprfzwpov_b8xs6q54no72b88fgthfk7ehfr3uj9acnac0txnac0txnac0txxi6vxi6vxi6vxi6vxi6vxi6c2i8hqwznwws2 vernmiabi yia yiarybiia yiarybiia yia ia y.bhiia和2WQZMTTOBSKIHB0RJIFSK_C7VZBQ685OPUY_UQPC5NJGXQKS3AWJOG-GQGK0V/s448/image6.gif“ style =” Margin-Left：auto;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 256” r29vz2xl/avvxsehfnvzu_hzvgt7xcva4adbprfzwpov_b8xs6q54no72b88fgthfk7ehfr3uj9acnac0txnac0txnac0txxi6vxi6vxi6vxi6vxi6vxi6c2i8hqwznwws2 vernmiabi yia yiarybiia yiarybiia yia ia y.bhiia和2WQZMTTOBSKIHB0RJIFSK_C7VZBQ685OPUY_UQPC5NJGXQKS3AWJOG-GQGK0V/S16000/IMAGE6.GIF“/>; &lt;/a>; &lt;/a>; &lt;/a>; &lt;/a>; &lt;/>; &lt;/>; &lt;/>; &lt;/td>; &lt;td>; &lt;td>; &lt;td>; &lt;td>; &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0FAaXVgkTSmoK90XYZq3sbW1fgRUmvOLZUpZ4dubLjJOFYID6w_q5GGIU1hy1E8B4J7hF01OOAupDxJWyD2OBMJEs6AIAbJEzH0qrx7TovnikAUXZyN_MQBu33QYe17CTtI95oI6x91qJhSSPyXNGlmkFKbWX8xwd6nT7Esd9RNE8tjiSbWwWQTKoAfjg/s448/image11.gif&quot; style=&quot;margin-left: auto;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 256” R29vZ2xl/AVvXsEj0FAaXVgkTSmoK90XYZq3sbW1fgRUmvOLZUpZ4dubLjJOFYID6w_q5GGIU1hy1E8B4J7hF01OOAupDxJWyD2OBMJEs6AIAbJEzH0qrx7TovnikAUXZyN_MQBu33QYe17CTtI95oI6x91qJhSSPyXNGlmkFKbWX8xwd6nT7Esd9RNE8tjiSbWwWQTKoAfjg/s16000/image11.gif&quot; />;&lt;/a>;&lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&lt;/td>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https ：//blogger.googleusercontent.com/img/b/r29vz2xl/avvxsei4yqm_nd4mtu-3d_adfxkkax453hyphenhyphenxe9e9e9e7ehbzz9rvbozzfboizwxfboboizwxfboboizwxf_5flw4xacu3xacu3x1autw4wrck.pkwrcwrcwrcwrc.phig>; k.->; k.->; k.->; yk yk yk yk yk yk yk yk yk yk yk yk yk yk yk yk yk yk yk yk>; yk>; yk>;>; TXDWIWSMIQ59NDH3AXWD0UOIFA8C2AQ0XNSGCV1NSGCV1FC9MXFVISZTG8Z7GPCAKGQTN5HOBBJ-PKS8II1TOUDAR8/s448/s448/image12.gif&#39;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 256” R29vZ2xl/AVvXsEi4yqm_nd4mtu-3d_AdfxkKAX453hyphenhyphenXE9e7ohBzZC9RvboIZWxF_5fLw4XaCU3x1aUtW4WRckKzfqB-yzHdV_uzPiCAAwv6zgv__7MZtxdwiWsMiQ59NDH3axwd0UOIFA8C2aq0XNSgcV1ieCN1fc9MXFVIszTG8z7gpcAkgqTn5HOBBJ-pks8I1tOudAR8/s16000/image12.gif&quot; />;&lt;/a>;&lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&lt;/td>; &lt;td style=&quot;text-align: center;&quot;>; &lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2huAujTA8vjmb5rlgj6vXF7uIHr0N7KrnLFiTXyjuN0l6kxSp7gQRPES5hD30ZzN-XTzUZSC-ROT19x0wE5cjQA_FOovY-Zox_68e0Dl4Dxanqvyuos3S1TExRdg3WZANucc-DXtKUsnim9Kh0GwU6LyFhpCJgHal0bI0UbpBYrXtlNGBYWuT8XVNIt6u/s448/image17.gif&quot; style=&quot;margin-left: auto;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 256” R29vZ2xl/AVvXsEg2huAujTA8vjmb5rlgj6vXF7uIHr0N7KrnLFiTXyjuN0l6kxSp7gQRPES5hD30ZzN-XTzUZSC-ROT19x0wE5cjQA_FOovY-Zox_68e0Dl4Dxanqvyuos3S1TExRdg3WZANucc-DXtKUsnim9Kh0GwU6LyFhpCJgHal0bI0UbpBYrXtlNGBYWuT8XVNIt6u/s16000/image17.gif&quot; />;&lt;/a>;&lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;p>;For image-to-video, VideOpoet可以获取输入映像并使用提示。&lt;/p>; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container” style =“ margin-left：margin-left：” margin-left：汽车; Margin-Right：auto;“>; &lt;tbody>; &lt;tr>; &lt;td style =” text-align：center;“>; &lt;a href =” https：//blogger.googleuserercercontent.com/img/img/r29vz2xxl/r29vz2xl/avvz2xl/avvxsej5kaqccs7gjojr0m_8hmm_8hmm_8hmsysq- Wd-KsjuF782YuV5D33BlPE8f3-AU1iTKwOVrpxnnBDHa-5AXgkXNBNil61r5eVhXa2v16VUraEt6DAa-4_v-xHJq6lJfwkJ9ATQZTGdxKsbvnfielzv_6iJyLrubPyrGhle_BUecTVJkGo_7S8sM-3yl6vVVtqNNg4nf0mw/s1536/image13.gif&quot; style=&quot;margin-left: auto;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 1536” src =“ https://blogger.googleusercontent.com/img/img/b/b/ R29vZ2xl/AVvXsEj5kAQCs7GJoJR0m_8hmYsq-Wd-KsjuF782YuV5D33BlPE8f3-AU1iTKwOVrpxnnBDHa-5AXgkXNBNil61r5eVhXa2v16VUraEt6DAa-4_v-xHJq6lJfwkJ9ATQZTGdxKsbvnfielzv_6iJyLrubPyrGhle_BUecTVJkGo_7S8sM-3yl6vVVtqNNg4nf0mw/s16000/image13.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style =“ text-align：center;”>;带有文本提示的图像到视频的一个示例，以指导运动。每个视频都与左图配对。&lt;strong>;左>;左>;：“船在帆布上浏览海洋，雷暴和闪电，动画油”。甘蔗在大风天下俯视下面的漩涡状海雾”。 。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;p>;用于视频样式化，我们在用一些附加的输入文本中进食videopoet之前预测了光流和深度信息。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQ2eDU0pNOfQJF8cKPOV5QkKthIO3-98jbqyZJ7lFLk7cckq8Gg4FXrro6oikQRxDVDKKz8rg9CU6wihsfU68RnnLkHGxJUeFNGBobjsbJ4VHGFtUg-nerlt2rPiJ9bu8i2VkkXX5yEK650t4ay8F7K2zSW5-TjjkbR61TskVhsaQCw1-8lkP1gMDg96i1/s1536/image16 。 //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQ2eDU0pNOfQJF8cKPOV5QkKthIO3-98jbqyZJ7lFLk7cckq8Gg4FXrro6oikQRxDVDKKz8rg9CU6wihsfU68RnnLkHGxJUeFNGBobjsbJ4VHGFtUg-nerlt2rPiJ9bu8i2VkkXX5yEK650t4ay8F7K2zSW5-TjjkbR61TskVhsaQCw1-8lkP1gMDg96i1/s16000/image16.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =“ tr-caption”样式=“ text-align：center;”>;视频风格化的示例在视频上，文本到视频生成的视频，带有文本提示，深度和光流作为调节。每对中的左视频是输入视频，右侧是程式化的输出。 &lt;b>;左&lt;/b>;：“袋鼠戴着太阳镜在阳光明媚的海滩上拿着沙滩球。” &lt;b>;中间&lt;/b>;：“泰迪熊在水晶透明的冷冻湖上滑冰。” &lt;b>;右&lt;/b>;：“在伪造的光中咆哮的金属狮子。” &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;p>; videopoet也能够生成音频。在这里，我们首先从模型中生成2秒的剪辑，然后尝试在没有任何文本指导的情况下预测音频。这使您可以从单个模型中生成视频和音频。&lt; /p>; &lt;br />; &lt;br />; &lt;br />; &lt;table align =“中心” cellpadding =“ 0” cellspacing =“ 0” class =“ tr caption-container” >; &lt;tbody>; &lt;tr>; &lt;td>; &lt;video Controls =“ controls” playSinline =“” width =“ 100％”>; &lt;source src =“ https://storage.googleapis.com/videopoet/videopoet/videot/videos/105_drums_drums_with_with_with_with_with_with_with_mp4 “ type =“ video/mp4”>; &lt;/source>; &lt;/video>; &lt;/td>; &lt;td>;＆nbsp;＆nbsp;＆nbsp; &lt;/td>; &lt;td>; &lt;video Controls =“ controls” playSinline =“ width =” 100 ％“>; &lt;source src =” https://storage.googleapis.com/videopoet/videos/107_cat_piano_with_with_audio.mp4“ type =“ video/mp4”>; &lt;/source>; &lt;/source>; &lt;/source>; &lt;/source>; &lt;/source>; &lt;/tive ;＆nbsp; &lt;/td>; &lt;td>; &lt;video Controls =“ controls” playSinline =“” width =“ 100％”>; &lt;source src =“ https：//storage.googleapis.com/videopoet/videopoet/videoet/videos/108_train_train_train_train_train_train_train_train_with_with_mp4 “ type =“ video/mp4”>; &lt;/source>; &lt;/video>; &lt;/td>; &lt;td>;＆nbsp;＆nbsp;＆nbsp; &lt;/td>; &lt;td>; &lt;video Controls =“ controls” playSinline =“ width =” 100 %&quot;>; &lt;source src=&quot;https://storage.googleapis.com/videopoet/videos/104_dog_popcorn_with_audio.mp4&quot; type=&quot;video/mp4&quot;>;&lt;/source>; &lt;/video>;&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container” style =“ margin-Left：auto;边缘权利：自动;“>; &lt;tbody>; &lt;try>; &lt;td class =“ tr-caption” style =“ text-align：center;”>;视频对审计的示例，从没有视频示例中生成音频任何文本输入。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;p>;默认情况下，Videopoet模型在肖像方向上生成视频，以将其输出定制为短形式内容。为了展示其功能，我们，我们制作了一部简短的电影，由Videopoet生成的许多简短片段组成。对于剧本，我们问&lt;a href=&quot;https://bard.google.com/&quot;>; bard &lt;/a>;写一个关于旅行的短篇小说浣熊带有场景分解和随附的提示列表。然后，我们为每个提示生成了视频剪辑，并将所有结果拼接在一起，以制作下面的最终视频。&lt; /p>; &lt;br />; &lt;br />; &lt;div class =“ saparator” style =“ clear：两者; text-align：center;“>; &lt;iframe allayfullscreen =” class =“ blog_video_class” frameborder =“ 0” heptiv =“ 360” src =“ https：//wwwww.youtube.com/embed.com/embed/70wzkfx6ylk “ youtube-src-id =” 70wzkfx6ylk“>; &lt;/iframe>; &lt;/div>; &lt;br />; &lt;p>;当我们开发videopoet时，我们注意到模型功能的一些不错的属性，我们在下面突出显示。&lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/div>; &lt;h3>;长视频&lt;/h3>; &lt;p>;我们能够仅通过在最后1秒的条件下生成更长的视频视频并预测接下来的1秒。通过反复链接它，我们表明该模型不仅可以很好地扩展视频，而且还可以忠实地保留所有物体的外观，即使在几个迭代中也可以保留所有对象的外观。&lt;/p>; &lt;p>;这是两个示例videopoet从文本输入中生成长视频：&lt;br />; &lt;br />; &lt;br />; &lt; /p>; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr caption-container”>; &lt;tbody >; &lt;tr>; &lt;td style =“ text-align：right;”>; &lt;b>; text Input &lt;/b>; &lt;/td>; &lt;td>; &lt;td>;＆nbsp;＆nbsp;＆nbsp; &lt;/td>; &lt;td>; &lt;td align =“ center” width =“ width =” “ 35％”>; &lt;em>;“宇航员开始在火星上跳舞。然后在背景中爆炸五颜六色丛林中非常尖锐的精灵城市，有一条灿烂的蓝河，瀑布和陡峭的垂直悬崖面。 ＆nbsp;＆nbsp;＆nbsp; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style =“ text-align：recright;”>; &lt;b>;视频输出&lt;/b>; &lt;/td>; &lt;td>; &lt;td>; &lt;td>;＆nbsp;＆nbsp;＆nbsp;＆nbsp; &lt;/td>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaT8uErAOI-bKPCwsVpEQ_SSxqdgjVB9ai-Db3M9YXhGM3X9N0Jwt-UcDb6X8n2V_4-Tf76xkwlSS4ftV8TvAIV6ZbjeXK5JPtQr8Mb_ZcPKiIvOdwFXJOBEfDk1Gp1hzRBkoYwmoH3bAu6NVNBo-ficSneXgvhDF7fwMGVqMik0KWGwv_GLf7clQ2l5e5/ s448/image14.gif“ style =”边距 - 左：自动; margin-right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 448” data-Original-width =“ 256” src = &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaT8uErAOI-bKPCwsVpEQ_SSxqdgjVB9ai-Db3M9YXhGM3X9N0Jwt-UcDb6X8n2V_4-Tf76xkwlSS4ftV8TvAIV6ZbjeXK5JPtQr8Mb_ZcPKiIvOdwFXJOBEfDk1Gp1hzRBkoYwmoH3bAu6NVNBo-ficSneXgvhDF7fwMGVqMik0KWGwv_GLf7clQ2l5e5/s16000/image14.gif&quot; />;&lt;/a>;&lt;/td>; &lt;td>;&amp;nbsp; &amp;nbsp;&lt;/td>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgDbroT8i5N-AdcRsTLjkLWoqzif1nJj-z1bRxcZwM_-1213gK6Or85VxKIFBMsnvAF_KLAmXWWLeDPxA5ZqWtNI5nqfp_6wzgKnqACckJMjBU2eNy8ySgvWjuFOPNarVcBwx9ZlrAdyMrWCdt29xDE7dPHhlwcxbRSyO7-ZllKs1SRGDgVm5XUc21I3Ddv/ s448/image9.gif“ style =”边距 - 左：auto;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 256” R29vZ2xl/AVvXsEgDbroT8i5N-AdcRsTLjkLWoqzif1nJj-z1bRxcZwM_-1213gK6Or85VxKIFBMsnvAF_KLAmXWWLeDPxA5ZqWtNI5nqfp_6wzgKnqACckJMjBU2eNy8ySgvWjuFOPNarVcBwx9ZlrAdyMrWCdt29xDE7dPHhlwcxbRSyO7-ZllKs1SRGDgVm5XUc21I3Ddv/s16000/image9.gif&quot; />;&lt;/a>;&lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp ; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;p>;也可以交互编辑Videopoet生成的现有视频剪辑。如果我们提供输入视频，我们可以更改运动对象执行不同动作的对象。对象操作可以在第一帧或中间框架中居中，这允许高度编辑控制。&lt;/p>; &lt;p>;输入视频，然后选择所需的下一个剪辑。&lt;/p>; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container”样式=“ margin-left：auto; auto; Margin-Right：auto;“>; &lt;tbody>; &lt;tr>; &lt;td style =” text-align：center;“>; &lt;a href =” https://blogger.googleusercentent.com/img/img/r29vz2xxl/r29vz2xl/ 8v2ShkxFaqage2MkmSopCm17wtoYnVCFufD5GKZHzM9ZUeL4EvCtVLZGMJYiUA1NVJhplymInJr4_K-G9s9263JAVRMxPb9_15zipLZIwHcmYpwyZmGRwgtbFwpONB9CrOqnDmG9bJBvr7pXNbEqLtms_7QNMbSYSspRefkisKLzeWXAIW9/s1280/image10.gif&quot; style=&quot;margin-left: auto;边缘权利：自动;”>; &lt;img border =“ 0” data-original-height =“ 448” data-eriginal-width =“ 1280” src =“ https://blogger.googleusercontent.com/img/img/b/ R29vZ2xl/AVvXsEg2NFzPadmS-8v2ShkxFaqage2MkmSopCm17wtoYnVCFufD5GKZHzM9ZUeL4EvCtVLZGMJYiUA1NVJhplymInJr4_K-G9s9263JAVRMxPb9_15zipLZIwHcmYpwyZmGRwgtbFwpONB9CrOqnDmG9bJBvr7pXNbEqLtms_7QNMbSYSspRefkisKLzeWXAIW9/s16000/image10.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;左侧的输入视频被用作调节，以产生四个选择，并在初步提示下：“可爱的生锈的破碎蒸汽朋克机器人被苔藓潮湿和崭露头角的植被覆盖，被高大的草包围。”我们展示了未提倡动议的情况。对于下面的列表中的最后一个视频，我们添加到提示：“在后台上用烟雾供电”以指导动作。&lt;/td>; &lt;/tr>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>;要编辑其对所需状态的内容，以文本提示为条件。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjlvHv0EU7YHj88knDA8pnCs5VDEsHI8OQeWDx8-dhNXcVKteNqMMrMczg9k0j-T8kevUiQua-Eet5BzT9xJ5CR-lpmFjMYyOQFZcAfXu-rlgTmes9_4-GONo7NFHYAw1q -IVK6MVJ34IYJJ6KGPQ8DP6OWJH1SKGYXA2BDPVVEUUIJB6UBKKVU1C1ILCGDR/S512/image5.gif&#39;gif“ style =” Margin-Left：Margin-Left：Auto; Auto; Auto; Auto; Margin-Right; Margin-Right：Margin-Right：Auto：auto; auto; auto; &quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjlvHv0EU7YHj88knDA8pnCs5VDEsHI8OQeWDx8-dhNXcVKteNqMMrMczg9k0j-T8kevUiQua-Eet5BzT9xJ5CR-lpmFjMYyOQFZcAfXu-rlgTmes9_4-GONo7NFHYAw1q-Ivk6MVj34iyjj6KGpQ8dp6OwJH1SKGyxA2BDPvvEUUIJB6UBkvu1c1ILCgdr/s16000/image5.gif&quot; />;&lt;/a>;&lt;/ td>; &lt;/tr>; &lt;tr>; &lt;td class =“ tr-caption” style =“ text-align：center;”>;用不同的提示来动画绘画。 &lt;b>;左&lt;/b>;：“一个女人转身看着相机。” &lt;b>;右&lt;/b>;：“一个女人打哈欠。” ** &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/div>; &lt;h3>;相机运动&lt;/h3>; &lt;/h3>; &lt;/h3>; &lt;/h3>; &lt;/h3>; p>;我们还可以通过将所需的相机运动的类型附加到文本提示中来准确地控制相机运动。例如，我们用模型生成了一个图像，并提示了“冒险游戏概念艺术”在水晶透明河上的雪山上的日出” &lt;/em>;。下面的示例附加了给定的文本后缀以应用所需的运动。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4w_RIRlokn88vR5u6GdRE32zOr5wKLUphlx4BwiZDQL0J6i-yhyphenhyphensc4wCsJ07izsk_MkLVT-TAfRIqU9sJ4E_cYVRszJ1bw-Ha4jYsv1oBgSMjAENhCPHIvg2aXBIULeH4UzR-0K5AHPixzxBYD7rP11xf4m2s7e1WFUyRHLv-RkKhAC9whQvwUovphkgy/s1536 /image2.gif“ style =”边距左左右：自动; margin-right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 448” data-eriginal-width =“ 1536” src =“ src =” https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4w_RIRlokn88vR5u6GdRE32zOr5wKLUphlx4BwiZDQL0J6i-yhyphenhyphensc4wCsJ07izsk_MkLVT-TAfRIqU9sJ4E_cYVRszJ1bw-Ha4jYsv1oBgSMjAENhCPHIvg2aXBIULeH4UzR-0K5AHPixzxBYD7rP11xf4m2s7e1WFUyRHLv-RkKhAC9whQvwUovphkgy/s16000/image2.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =“ tr-caption” style =“ text-align：center;”>;从左到右提示：“缩放”，“ dolly Zoom”，“ Pan左”，“左右”，“ ARC Shot”，“ Crane Shot Shot ”，“ FPV无人机射击”。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/div>; &lt;h2>;评估结果&lt;/h2>; &lt;p>;我们通过各种基准评估了文本到视频生成的Videopoet，以将结果与其他方法进行比较。为了确保中立的评估，我们在没有樱桃的示例的情况下以各种提示进行了所有模型，并要求人们对自己的偏好进行评分。下图突出显示了Videopoet的时间百分比作为绿色的首选选项，以进行以下问题。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h3>;文本保真度&lt;/h3>; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0“ class =” tr-caption-container“ style =” Margin-Left：auto; Margin-Right：auto;“>; &lt;tbody>; &lt;try>; &lt;tr>; &lt;td style =” text-align：center; center;“>; &lt;a href =&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjotT5lhyphenhyphenreDLFlq_hZRSAKKI2jWx9Pp2y1xvBTQflO-H7EQ3VZYmsRTiaTV1creTpMo0It1-IfiFh313zzhhjDPeSxSW3nnRWsQC1toPBSsRlQD0T6UmzFqSNGaeQ0CGBKmn6xyAJXTG3NaF9o0icxag6f_eRzjTvu71gNRB3lOLN4xK8iQWA7dT5FKo2F/s1999/image1.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border =&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjotT5lhyphenhyphenreDLFlq_hZRSAKKI2jWx9Pp2y1xvBTQflO-H7EQ3VZYmsRTiaTV1creTpMo0It1-IfiFh313zzhhjDPeSxSW3nnRWsQC1toPBSsRlQD0T6UmzFqSNGaeQ0CGBKmn6xyAJXTG3NaF9o0icxag6f_eRzjTvu71gNRB3lOLN4xK8iQWA7dT5FKo2F/s16000/image1 。视频的百分比是准确遵循提示的优选。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;br />; &lt;/div >; &lt;h3>;运动趣味性&lt;/h3>; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container”样式=“ margin-Left：auto;利润率：自动; OFr2gqCUC33D3J6aLCS9sE4LKuoXhA89YNZE9yg_VmvUwJg2N1_nKt9m5z2NJgWiM2Ylqs2_Y2nAULojUuwpNmLv7LhYv4aGs4WgffyECcQtKM3Z83bmosuuXvHw4DeekkzAIpCkF2LlN6jExQysy68Ovgmgk1/s1999/image15.png&quot; style=&quot;margin-left: auto;边缘权利：自动;“>; &lt;img border =“ 0” data-original-height =“ 797” data-eriginal-width =“ 1999” R29vZ2xl/AVvXsEjIWoXGSpe80GopYbQLJcyISxwM7DVtB-OFr2gqCUC33D3J6aLCS9sE4LKuoXhA89YNZE9yg_VmvUwJg2N1_nKt9m5z2NJgWiM2Ylqs2_Y2nAULojUuwpNmLv7LhYv4aGs4WgffyECcQtKM3Z83bmosuuXvHw4DeekkzAIpCkF2LlN6jExQysy68Ovgmgk1/s16000/image15.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;User运动兴趣的偏好评分，即，在产生有趣的运动方面，首选视频的百分比是什么。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;p>;基于上述内容，平均而言选择了24 –35％的录像带示例中，以下提示比竞争模型更好，而对于竞争模型的示例比8-11％。评估者还更喜欢Videopoet中的41-54％的示例中的41–54％的示例，比其他模型的11-21％更有趣。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p>; &lt;div style =“线路高：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>;通过videopoet，我们展示了LLMS的高度竞争视频生成质量在各种各样的任务中，尤其是在视频中产生有趣和高质量的动作时。我们的结果表明，LLM在视频生成领域具有有希望的潜力。对于将来的指示，我们的框架应该能够支持“任何一代”一代，例如扩展到文本到原告，音频到视频，以及视频字幕，以及其他许多人。 &lt;/p>; &lt;p>;要查看更多原始质量示例，请参见&lt;a href=&quot;http://sites.research.google/videopoet&quot;>;网站demo &lt;/a>;。 &lt;/p>; &lt;div style =“ line-height：40％;”>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>;确认&lt;/h2>; &lt;p>; &lt;em>;这项研究得到了一大批研究的支持contributors, including Dan Kondratyuk, Lijun Yu, Xiuye Gu, José Lezama, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, Yong Cheng, Ming-Chang Chiu, Josh Dillon, Irfan Essa, Agrim Gupta, Meera Hahn, Anja Hauth, David Hendon, Alonso Martinez, David Minnen, David Ross, Grant Schindler, Mikhail Sirotenko, Kihyuk Sohn, Krishna Somandepalli, Huisheng Wang, Jimmy Yan, Ming-Hsuan Yang, Xuan Yang, Bryan Seybold, and Lu Jiang 。我们还要感谢Aren Jansen，Marco Tagliasacchi，Neil Zeghidour，John Hershey的音频令牌和处理，Angad Singh在“新秀The Raccoon”中为Storyboarding，Cordelia Schmid，Cordelia Schmid，用于研究讨论支持，Jay Yagnik是初始概念的建筑师。&lt;/em>; &lt;/p>; &lt;br />; &lt;p>; &lt;em>; ** &lt;/em>; &lt;br />; &lt;br />; &lt;em>;（a）&lt;a href = “ https://commons.wikimedia.org/wiki/file：rembrandt_christ_in_the_storm_on_the_storm_the_lake_lake_lake_f_galilee.jpg&quot;>; Galilee海上的风暴（b）&lt;a href=&quot;https://commons.wikimedia.org/wiki/wiki/file:pillars_of_creation_2014_hst_wfc3-wfc3-wfc3-uvis_fell-res.jpg&quot;>; Creation的支柱&lt;br />; &lt;em>;（c）&lt;a href=&quot;https://commons.wikimedia.org/wiki/wiki/file：caspar_david_fried_friedrich_-_wanderer_bove_bove_the_sea_sea_sea_sea_sea_of_fog.jpeg.jpeg.jpeg.jpeg.jpeg &quot;>; fog &lt;/a>; wanderer wanderer wander of fog &lt;/a>;弗里德里希（Friedrich），1818年，公共领域&lt;/em>; &lt;br />; &lt;em>;（d）&lt;a href=&quot;https://commons.wikimedia.org/wiki/wiki/file：Mona_lisa_lisa_by_leonardo_leonardo_leonardo_da_da_da_da_vinda_vinda_from_from_from_c2rmf_c2rmf_cretected.jpaqa &lt;/a>;，作者：莱昂纳多·达·芬奇（Leonardo da Vinci），1503年，公共领域。&lt;/em>; &lt;/p>; &lt;/penter>; &lt;link href =“ http://blog.research.google/feeds/551620070703494636207/comments/comments/comments/comments/default/default/default” rel =“回复” title =“ post注释” type =“ application/atom+xml”/>; &lt;link href =“ http://blog.research.google/2023/2023/12/videopoet-lange-lange-language-language-model-model-for -Zero.html＃comment-form“ rel =” reply =“ title =” 0注释“ type” type =“ text/html”/>; &lt;link href =“ http://www.blogger.com/feeds/8474926263314520262626/posts/ default/5516200703494636207&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5516200703494636207&quot; rel=&quot;self&quot; type =“ application/application/atom+xml”/>; &lt;link href =“ http://blog.research.google/2023/12/videopoet-large-lange-language-language-model-model-for-zero.html” =“ videopoet：零摄影视频生成的大型语言模型” type =“ text/html”/>; &lt;under>; &lt;name>; google ai &lt;/name>; &lt;uri>; http://wwwww.blogger.com/profile /12098626514775266161&lt;/uri>;&lt; ：//img1.blogblog.com/img/b16-rounded.gif“ width =“ 16”>; &lt;/gd：image>; &lt;/furet>; &lt;媒体：thumbnail height =“ 72” url =“ https：//blogdger 。 E6C93KUIROG8PKCWEBKBRW4TBTZH3WIOX1TZYZYM3M4AJ4ZYD2R_P5FFLI7NTPQOD9FSGQHWO/S72-C/vIDEOPOETOETOETPOEETPREVIEW.GIF.gif.gif.gif.gif.gif >; &lt;/媒体：缩略图>; &lt;thr：总计>; 0 &lt;/thr：thr>; &lt;/entry>; &lt;/entry>; &lt;entry>; &lt;id>;标签：blogger.com，1999：blog-8474926331452026626.post-158796530372727576226 &lt;/id &lt;/id &lt;/id &lt;/id >; 2023-12-19T08：01：00.000-08：00 &lt;/publined>; &lt;更新>; 2023-12-19T08：15：57.101-08：00 &lt;/updateed &lt;/dipfated>; &lt;category schemion =“ http：///www.bloggergerger .com/atom/ns＃“ term =“ for cocorial good”>; &lt;/category>; &lt;category scheme =“ http://www.blogger.com/atom/ns#” >; &lt;类别方案=“ http://www.blogger.com/atom/ns#” term =“ google Maps”>; &lt;/category>; &lt;/category>; &lt;title type =“ text”>;模拟点亮了事后交通流的路径&lt;/stitle>; &lt;content type =“ html”>; &lt;span class =“ byline-author”>;由Yechen Li和Neha Arora发布，软件工程师，Google Research &lt;/span>; &lt;/span>; &lt;img src =“ https：//blognger。 googleusercontent.com/img/b/R29vZ2xl/AVvXsEj35HCKLS0slKFX6LVrCCK0crWWJ-YwNVxNkDqze9UpfuVTWfD7URw9CyRwyFwAdIT-CHG59vl19KgfrGWEtoufCS6SQOzLuV1n7SYpun6EOAML0MfdxwjGhDKyKrfIz2t6Ivv_T07YVCPlA7uQMmPr8LYrXPSdE3V1WAwOwU0DYR_8wMWMJZh7MLeshXeP/s600/TrafficFlow.gif&quot; style=&quot;display: none;&quot; />; &lt;p>;十五分钟。那就是&lt;a href=&quot;https://colosseum.tours/interesting-facts#:~: text=the%20Colosseum%20Could%20BEOULD%20BE%20FILD，％20A%20A%20MATTEM 20MATTER%20OF%20Minutes.&quot;>;需要多长时间需要多长时间倒空罗马斗兽场&lt;/a>;，这是一个仍然是世界上最大的圆形剧场的工程奇迹。两千年后，这种设计继续运转良好，可以将巨大的人群从体育和娱乐场所移出。 &lt;/p>; &lt;a name =&#39;more&#39;>; &lt;/a>; &lt;p>;，但是当然，退出竞技场只是第一步。接下来，人们必须在周围的街道上导航流量。这是一个古老的问题，至今仍未解决。在罗马，他们通过禁止在街上直接通过的街道上的私人交通来解决这个问题。这项政策在那里有效，但是如果您不在罗马，该怎么办？如果您在超级碗中怎么办？还是在泰勒·斯威夫特（Taylor Swift）的音乐会上？ &lt;/p>; &lt;p>;解决此问题的一种方法是使用模拟模型，有时称为“数字双胞胎”，这是现实世界传输网络的虚拟复制品，试图捕获从街道和交叉点的布局到的每个细节到车辆的流动。这些模型允许交通专家减轻交通拥堵，减少事故并改善驾驶员，骑手和步行者的体验。以前，我们的团队使用这些模型来&lt;a href=&quot;https://arxiv.org/abs/2111.03426&quot;>;量化路由的可持续性影响&lt;/a>;，&lt;a href =“ https://blog.research.google /2023/10/improving-traffic-evacuations-case-study.html&quot;>; test撤离计划&lt;/a>;并在&lt;a href =“ https://blog.google/products/maps/mmaps/google-maps/google-maps/google-maps中显示模拟流量-Immersive-view-Routes/“>;映射沉浸式视图&lt;/a>;。 &lt;/p>; &lt;p>;校准高分辨率交通模拟以匹配特定设置的特定动力学是该领域的长期挑战。总体机动性数据的可用性，详细的Google Maps Road网络数据，运输科学的进步（例如了解关系&lt;a href=&quot;https://tristan2022.org/papers/papers/tristan_2022_3704.pdf&quot;>; s节需求与速度需求与速度&lt; /a>;用于带交通信号的路段）和&lt;a href=&quot;https://research.google/pubs/pubs/pub52679/&quot;>;校准技术&lt;/a>;使用物理知识交通模型中的速度数据是在全球范围内为计算有效的优化铺平道路。 &lt;/p>; &lt;p>;要在现实世界中测试这项技术，Google Research与西雅图运输部（SDOT）合作制定了基于模拟的交通指导计划。我们的目标是帮助成千上万的大型体育和娱乐活动的参与者快速安全地离开体育场区域。拟议的计划在大型事件中离开体育场地区的车辆将平均旅行时间减少了7分钟。我们使用动态消息符号（DMS）与SDOT合作部署了它，并在2023年8月至11月之间对多个事件进行了验证的影响。&lt;/p>; &lt;table align =“ center” cellpadding =“ 0” cellSpacing =“ 0” class = = “ Tr-Caption-Container”样式=“ Margin-Left：auto; Margin-Right：auto;”>; &lt;tbody>; &lt;try>; &lt;tr>; &lt;td style =“ text-align：center; center;”>; &lt;a href =“ https：https：https：https： //blogger.googleusercontent.com/img/b/r29vz2xl/avvxsehy_re_re7-ewmfiwxl9-7r7r7r-w6iztnjfpyfkvppyfkcccccccccccccccccccccccrcrcrcrcrcrcrcrcrcrcrcrcrcrcrckk kkmspkekkkkkkkkkkkkknpkkkkkkkkkkknpkek kknpkeknpknpknppknppknppknppknppknppknppknppknptpknppknppknptpknppknppknptpknppknptpknptpknpptemeyeyey VSLVLPNV48GHLUOH9O70ZJI0GWILCDCFUFQABAJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHJQHZEU2MY_AYCGELUMSV7ML2WKRQGLV/s1200/s1200/preimplementation.gif 0&quot; data-original-height=&quot;518&quot; data-original-width=&quot;1200&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhy_Re7-eWmfiWXL9-7r7r-w6IztNjfP3VPyfkvQc2TkBVfrCovR1enYO45bnwd5f04jM8WjwwmAEYWQwtSsp3bkY1PmiRfzkAFLSSskHaUy5PVsLvlPNV48GhlUoh9o70zJI0GWilCDCFUFQabAjQHj35bFR4IpDMHzEU2my_ayCGeLuMSV7Ml2wkrqgLV/s16000/PreImplementation 。 b/R29vZ2xl/AVvXsEhfOuJeVqGFMNIcVEAWUPtxWJWEjMrxQ-5lP9ytEbGd8yzq13b8s6m1YdIxviZWyBZRsM5DR6ro0O4qmeCxXYcxGf5dvjGxAkpwVRz6AMq_RHvxsdovmiVFifWxe66vGRnIpu1M-bsML2NTqlM4s8TKuwjilDCn0tuvDKNty9lzZFMirDoiHqR2ktBA3wSR/s1200/PostImplementation.gif&quot; style=&quot;margin-left: auto;边缘权利：自动;“>; &lt;img border =“ 0” data-original-height =“ 519” data-eriginal-width =“ 1200” src =“ https://blogger.googleusercontent.com/img/img/b/b/ R29vZ2xl/AVvXsEhfOuJeVqGFMNIcVEAWUPtxWJWEjMrxQ-5lP9ytEbGd8yzq13b8s6m1YdIxviZWyBZRsM5DR6ro0O4qmeCxXYcxGf5dvjGxAkpwVRz6AMq_RHvxsdovmiVFifWxe66vGRnIpu1M-bsML2NTqlM4s8TKuwjilDCn0tuvDKNty9lzZFMirDoiHqR2ktBA3wSR/s16000/PostImplementation.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;我们提出的一项政策建议是将流量从S Spokane St转移，这是一个主要的通道，将该地区连接到I-5和SR 99的高速公路，并且经常在事件发生后被拥挤。建议的更改改善了通过高速公路和动脉街道的交通流量。在体育场附近，减少了交通信号后形成的车辆队列的长度。（请注意，在此剪辑中，车辆比现实大于现实。 >;模拟模型&lt;/h2>; &lt;p>;为此项目，我们创建了一个新的西雅图体育场周围该地区的模拟模型。该模型的目的是在指定的一天中尽可能地重播每个交通情况。我们使用开源仿真软件，&lt;a href=&quot;https://www.eclipse.org/sumo/&quot;>; Urban Mobility的模拟&lt;/a>;（Sumo）。 Sumo的行为模型有助于我们描述流量动态，例如，驾驶员如何做出决定，例如跟踪，改变车道和速度限制限制。我们还使用Google Maps的见解来定义网络的结构和各种静态段属性（例如，车道数量，速度限制，交通信号灯的存在）。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNDnNe6WYClfVTVeD4lwsBtcDbo595yieDfOLEjPxH9e7gp9KRmYpp52c-oRiEaaILGodzScZE0E_IpianSL6pump2hGcB9-Cdj0QgfSDvJ_k8UIuvt9iraOEPCesgw3aeYoKvc5cgSF4H__xspISt4OJulVnhJZ1NEkKQBC_4dGirle3zd9ALtqnyBW2d/s1601/SUMO.png&quot; style =“ Margin-Left：auto; Margin-Right：auto;”>; &lt;img border =“ 0” data-Original-height =“ 643” data-Original-width =“ 1601” src =“ https：// blogger。 googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNDnNe6WYClfVTVeD4lwsBtcDbo595yieDfOLEjPxH9e7gp9KRmYpp52c-oRiEaaILGodzScZE0E_IpianSL6pump2hGcB9-Cdj0QgfSDvJ_k8UIuvt9iraOEPCesgw3aeYoKvc5cgSF4H__xspISt4OJulVnhJZ1NEkKQBC_4dGirle3zd9ALtqnyBW2d/s16000/SUMO.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= “文本 -  align：中心;”>;模拟框架的概述。&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;p>;旅行需求是重要的模拟器输入。要计算它，我们首先将给定的都市区域的路网分解为区域，特别是13级&lt;a href=&quot;http://s2geometry.io/devguide/s2cell_hierarchy.html&quot;>; S2细胞&lt;/a>;有1.27 km &lt;/a>; &lt;Sup>; 2 &lt;/sup>;每个单元区域。从那里开始，我们将旅行需求定义为在给定时间段内从原始区域到目的地区域的预期旅行数量。需求表示为汇总起源 - 死亡（OD）矩阵。 &lt;/p>; &lt;p>;要获得原点区域和目标区域之间的初步预期旅行数，我们使用汇总和匿名的移动性统计信息。然后，我们通过将初始需求与观察到的交通统计数据（如细分速度，旅行时间和车辆计数）相结合来解决OD校准问题，以复制事件场景。 &lt;/p>; &lt;p>;我们在西雅图的T-Mobile Park和Lumen Field中围绕多个过去事件的流量进行建模，并通过计算汇总和匿名的流量统计数据来评估准确性。分析这些事件方案有助于我们了解不同路由政策对该地区拥堵的影响。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style =“ text-align：center;”>; &lt;a href =“ https://blogger.googleusercontent.com/img/r29vz2xl/avvz2xl/avvxsejipewd8ps0yhps0yhps0yhps0yhps0yhps0yhrryhryhryhryhryhryhryhryhryhryhrys 4GyEyKVQD3DANNZZ87CNTOFNCT8LQCBWGKWMW8IM_CQMLDG6ODPAN_UKOQLBAZLKVFK_ENPGURCQ6SQPGBBX1QPGDSUIAJKBBDVDVVV3M7VFD-KQYT6THT6THUKKRYJF4/S160MAP.PRATER “ style =”保证金左：自动; margin-right：auto;“>; &lt;img border =“ 0” data-Original-height =“ 655” data-Original-width =“ 1601” src =“ https：// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjipEowD8pS0yHrySDZtCCOvA_tvr-dty0jq4kBZLaGdN5U_9zcdH67bW8xkOK1Wd6n3zlwjnm4gyeYkVQD3dannZZ877CNTOfnCt8LqCbWGkWmw8IM_CqMLdg6odPan_uKoQlbAzlkvfk__nPGURcq6SqpGdsUIaJKBX1-fv3M7VFD-kQYT6THUKkRyjF4/s16000/TrafficHeatMap.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-字幕“ style =” text-align：center;“>; heatmaps在游戏后与非游戏日的同一时间相比，该地区的旅行数量大幅增加。&lt;/td>; &lt;/td>; &lt;/tr>; &lt; /tbody>; &lt;/table>; &lt;table align =“ center” cellpadding =“ 0” cellspacing =“ 0” class =“ tr-caption-container”样式=“ margin-left：auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiF10JbnM2SHjvrnedtjNB45oN_yi8jN6wEeGyV4zRVnI7eV53aGVdAojwUge-mDG2zFRC_o4RjROXggnY49mtkYWemI11FS9dF4hi73RhAHQKXUYkozX6MXA3o04JkoZ0WYXSyeXu-lgBwbHQIOOMRnI6UpTZoKIBiNlDhk3YxB4ksNQtrD6uaXPgQot0M/s1999/TrafficFlow.png&quot; style=&quot;margin-left: auto;边缘权利：自动;“>; &lt;img border =“ 0” data-original-height =“ 931” data-original-width =“ 1999” R29vZ2xl/AVvXsEiF10JbnM2SHjvrnedtjNB45oN_yi8jN6wEeGyV4zRVnI7eV53aGVdAojwUge-mDG2zFRC_o4RjROXggnY49mtkYWemI11FS9dF4hi73RhAHQKXUYkozX6MXA3o04JkoZ0WYXSyeXu-lgBwbHQIOOMRnI6UpTZoKIBiNlDhk3YxB4ksNQtrD6uaXPgQot0M/s16000/TrafficFlow.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;该图显示了在X轴上观察到的段速度，并在Y轴上的模拟速度显示了建模事件。沿红色X = Y线的数据点的浓度展示了模拟复制现实交通条件的能力。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;h2>;路由政策&lt;/h2>; &lt;p>; SDOT和西雅图警察局（SPD）的当地知识帮助我们确定了需要改进的最拥挤的路线：&lt; /p>; &lt;ul>; &lt;li>;来自T-Mobile Park体育场停车场的交通Northbound Cherry St. I-5斜坡&lt;/li>; &lt;li>;交通经过西雅图的Sodo社区向S Spokane St. &lt;/li>; &lt;/ul>; &lt;p>;我们制定了路由政策，并使用模拟进行了评估模型。为了更快地散布交通，我们尝试了将北行/南行的交通从最近的坡道驶向进一步的高速公路坡道，以缩短等待时间。我们还尝试了开放HOV车道到活动流量，建议替代路线（例如，SR 99），或在不同车道之间进行负载共享以达到最近的体育场坡道。 &lt;/p>; &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_UIXMPB7t5xkh_obQI7KsQe8MXF0RcWk8fmU3g-wh8q5sasXBOhh3L6nB2pgixz6JinYIdCetv0215Xz -GjfLJ3SGTcgVYTALQ5raMDjeIIR-MXXbnly6CNDplcn0vDcqkLG91B1TKRyOHzFQWrZ3K5aMb87EPPrA1PhGmommkDKaKDGuJPDi4Lru9K1x/s1600/NorthboundCherry.gif&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;840&quot; data-original-width= “ 1600” src =“ https://blogger.googleusercontent.com/img/b/r29vz2xl/avvxseg_uixmpb7t5xkh_obqi7ksqe7ksqe7ksqe7ksqe8mu3mu3gmu3g-wh8f-wh8qsasxboh6nszbboh6nb2pgixnb2pmjnb2ppixnb2ppixnbyb2ppixniondppixpixniondpixpixpixpixppixpixniondppixniNINGIN CGVYTALQ5RAMDJEIIR-MXXBNLY6CNDPLCN0VDCQKLG91B1TKRYOHZFQWRZ3K5AMB5B5AMB87EPPRA1PHGMOMMKMOMMKDKDKAKDGAKDGUJPDGUJPDGUJPDGUJPDGUJPDI4LRU9K1X/s16000/s16000/northboundcherry.gif &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2TMCOc-7sYPAHOoFvwEcRlAACKZjelEvcYajm7EgoPS4il1TxabdxuOTjNZ81N0bXurNwpq_w9i-U0wupOjHnES3A0uRPwiTO1KpmI1PDffBOZt4rxagHmwra3hweXVtBx3NRPxZ7VSw75NsygwD2ijowkTSUUATiOUhlEAIVJ2W3EmoYKGE1LmPIdHds/s1600/SouthboundSpokane.gif&quot; style=&quot;margin-left: 1em;边缘权利：1em;“>; &lt;img border =“ 0” data-original-height =“ 837” data-eriginal-width =“ 1600” R29vZ2xl/AVvXsEg2TMCOc-7sYPAHOoFvwEcRlAACKZjelEvcYajm7EgoPS4il1TxabdxuOTjNZ81N0bXurNwpq_w9i-U0wupOjHnES3A0uRPwiTO1KpmI1PDffBOZt4rxagHmwra3hweXVtBx3NRPxZ7VSw75NsygwD2ijowkTSUUATiOUhlEAIVJ2W3EmoYKGE1LmPIdHds/s16000/SouthboundSpokane.gif&quot; />;&lt;/a>;&lt;/div>; &lt;h2>;Evaluation results&lt;/h2>; &lt;p>; We model multiple events with different traffic conditions, event times, and attendee计数。对于每种政策，模拟都重现了赛后流量，并报告了车辆的旅行时间，从离开体育场到到达目的地或离开西雅图Sodo地区。节省时间的计算是作为前/之后的旅行时间差计算该政策，并在下表中显示在大小事件中。我们将每个政策应用于一定百分比，并重新估计旅行时间。结果显示了10％，30％或50车辆的百分比受到政策的影响。在-K1suIbpEc1E1CKzvo67pdIRgP1pCGL1iGQlCuOiVT2zRcMI-ab0ABBhI2-3tABYfpfjcD6ai2XjsUjKusOqAFHSMO7iT7XLgFEsdheSL2lbtEpvToeC23gv6oLzidPT6X3/s1252/TrafficImprovement.png&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;916&quot; data-original- width=&quot;1252&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbtXIUDzRNBrnUuMOh1uGJsM85brY5Z5q37x87YVaJngDk-5hY5YAGduh7x-K1suIbpEc1E1CKzvo67pdIRgP1pCGL1iGQlCuOiVT2zRcMI-ab0ABBhI2-3tABYfpfjcD6ai2XjsUjKusOqAFHSMO7iT7XLgFEsdheSL2lbtEpvToeC23gv6oLzidPT6X3/s16000/TrafficImprovement.png&quot; />;&lt;/a>;&lt;/div>; &lt;p>;基于这些模拟结果，实施的可行性以及其他考虑因素，SDOT决定在大型事件中使用DMS实施“北行樱桃st坡道”和“ Southbound S Spokane St Ramp”政策。这些迹象表明，驾驶员采取其他路线到达目的地。这两项政策的结合基于在大型活动中重新安排30％的交通，平均每辆车节省了7分钟的旅行时间。 &lt;/p>; &lt;br />; &lt;h2>;结论&lt;/h2>; &lt;p>;这项工作证明了模拟的力量，以建模，识别和量化提议的交通指导策略的效果。仿真使网络规划人员能够识别未经许可的细分市场并评估不同路由政策的影响，从而使流量的空间分布更好。离线建模和在线测试表明，我们的方法可以减少总旅行时间。可以通过添加更多的交通管理策略（例如优化交通信号灯）来进行进一步的改进。在历史上，仿真模型一直很耗时，因此仅适用于最大的城市和高股份项目。通过投资更可扩展的技术，我们希望将这些模型带入世界上更多的城市和用例。 &lt;/p>; &lt;br />; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;In collaboration with Alex Shashko, Andrew Tomkins, Ashley Carrick, Carolina Osorio, Chao Zhang, Damien Pierce, Iveel Tsogsuren, Sheila de Guia,和Yi-Fan Chen。约翰·吉利亚德（John Guilyard）的视觉设计。我们要感谢我们的SDOT合作伙伴Carter Danne，Chun Kwan，Ethan Bancroft，Jason Cambridge，Laura Wojcicki，Michael Minor，Mohammed Said，Trevor Partap和SPD Partners中尉Bryan Clenna和Sgt。 brian kokesh。&lt;/em>; &lt;/p>; &lt;/content>; &lt;link href =“ http://blog.research.google/feeds/1587965303727576226/comments/comments/comments/default/default/default” =“ application/atom+xml”/>; &lt;link href =“ http://blog.research.google/2023/12/simulations-illuminate-path-path-path-path-path-post-post.html#comment-form” rel =“ repl =” reply =“ replyies” title =“ 0注释” type =“ text/html”/>; &lt;link href =“ http://www.blogger.com/feeds/feeds/847492633145202626/posts/posts/posts/default/1587965330372727575762262727576226 ATOM+XML“/>; &lt;link href =” http://www.blogger.com/feeds/847492633145202626/posts/posts/default/158796530372727576226 =“ http://blog.research.google/2023/12/simulations-illuminate-path-path-path-path-post.html” rel =“替代” title =“仿真”照亮了事后交通流的路径， text/html&quot;/>;&lt;作者>;&lt;名称>;Google AI&lt;/名称>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>; &lt;gd：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj35HCKLS0slKFX6LVrCCK0crWWJ-YwNVxNkDqze9UpfuVTWfD7URw9CyRwyFwAdIT-CHG59vl19KgfrGWEtoufCS6SQOzLuV1n7SYpun6EOAML0MfdxwjGhDKyKrfIz2t6Ivv_T07YVCPlA7uQMmPr8LYrXPSdE3V1WAwOwU0DYR_8wMWMJZh7MLeshXeP/s72 -c/clabineflow.gif“ width =” 72“ xmlns：媒体=” http：//search.yahoo.com/mrss/“>; &lt;/media：thumbnail>; &lt;thr>; &lt;thr：thr：thr>; 0 &lt;/thr>; 0 &lt;/thr>; thr>; thr>; &lt; /entry>; &lt;entry>; &lt;id>; tag:blogger.com，1999年：blog-8474926331452026626.post-60881181073075362&lt;/id>; >; 2023-12-15T14：34：10.381-08：00 &lt;/updated>; &lt;category scheme =“ http://www.blogger.com/atom/atom/ns#” scheme =“ http://www.blogger.com/atom/ns#” term =“ kaggle”>; &lt;/category>; &lt;类别scheme =“ http://www.blogger.com/atom/ns#” term = “机器学习”>; &lt;/category>; &lt;类别方案=“ http://www.blogger.com/atom/ns#” term =“ tpu”>; &lt;/category>; &lt;title type type =“ text =“ text”>;机器中的进步机器学习的学习&lt;/stitle>; &lt;content type =“ html”>; &lt;span class =“ byline-author”>;由Phitchaya Mangpo Phothilimthana发布，工作人员研究科学家，Google DeepMind和Bryan Perozzi，高级工作人员研究科学家在nnmqjnegnmo5gj5tji5tji5tji5tjivnscmlo7vbhffhs8l-ymoiiicjlm80v9eppyiobg-07cw_vyjzwnfaz0e_vp4f4f8v_wggp4v_wggpn1lu8f3lsjhix ％80％afpm.png“ style =”显示：无;” />; &lt;p>;随着机器学习（ML）的最新进展（ML），机器可以&lt;a href=&quot;https://storage.googleapis.com/deepmind-media/gemini/gemini/gemini/gemini_1_report.pdf&quot;>;了解自然语言&lt; /a>;，&lt;a href=&quot;https://blog.google/technology/ai/lamda/&quot;>;进行对话&lt;/a>;，&lt;a href =“ https://cloud.google.com/vertex- ai/docs/generative-ai/image/概述“>;绘制图像&lt;/a>;，&lt;a href=&quot;https://arxiv.org/abs/2210.02303&quot;>;创建视频&lt;/a>;等等。现代ML模型是使用ML编程框架进行编程和培训的，例如&lt;a href=&quot;https://www.tensorflow.org/&quot;>; Tensorflow &lt;/a>;，&lt;a href =“ https://github.com/ google/jax“>; jax &lt;/a>;，&lt;a href=&quot;https://pytorch.org/&quot;>; pytorch &lt;/a>;等等。这些图书馆为ML从业者提供高级指令，例如线性代数操作（例如，矩阵乘法，卷积等）和神经网络层（例如，&lt;a href =“ https://keras.io/api/api/layers/layers /vernolution_layers/convolution2d/“>; 2D卷积层&lt;/a>;，&lt;a href=&quot;https://keras.io/api/keras_nlp/modeling_layers/transformer_encoder/dransformer_encoder/&quot;>;变形金刚层&lt;/a>;）。重要的是，从业者不必担心如何使其模型在硬件上有效运行，因为ML框架将通过基础&lt;em>;编译器&lt;/em>;自动优化用户的模型。因此，ML工作量的效率取决于编译器的良好程度。编译器通常依靠启发式方法来解决复杂的优化问题，通常会导致次优性能。 &lt;/p>; &lt;a name=&#39;more&#39;>; &lt;/a>; &lt;p>;在此博客文章中，我们在ML中提出了令人兴奋的进步。特别是，我们展示了如何使用ML提高ML工作负载的效率！内部和外部的先前工作表明，我们可以通过选择更好的ML编译器决策来使用ML来提高ML程序的性能。尽管存在一些用于程序性能预测的数据集，但它们针对小的子编程，例如基本块或内核。我们介绍“ &lt;a href=&quot;https://arxiv.org/abs/2308.13490&quot;>; tpugraphs：大型张量计算图上的性能预测数据集&lt;/a>;” .cc/dyferences/2023“>; Neurips 2023 &lt;/a>;），我们最近发布了为了在ML中推动更多研究以进行计划优化。我们主持了&lt;a href=&quot;https://www.kaggle.com/competitions/predict-ai-model-runtime/overview&quot;>; kaggle竞赛&lt;/a>;在数据集中来自66个国家。此外，在“ &lt;a href=&quot;https://arxiv.org/abs/2305.12322&quot;>;通过图段培训学习大图属性&lt;/a>;” ：//arxiv.org/abs/2005.03675“>;图形神经网络&lt;/a>;（GNN）培训以处理表示为图形的大型程序。该技术既可以在具有有限的内存能力的设备上训练任意较大的图形，又可以改善模型的概括。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ML compilers&lt;/h2>; &lt;p>; ML compilers are software routines that convert user-written programs (here, mathematical instructions provided by libraries such as TensorFlow) to executables (instructions to execute on the actual hardware). An ML program can be represented as a computation graph, where a node represents a tensor operation (such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_multiplication&quot;>;matrix multiplication&lt;/a>;), and an edge represents a tensor flowing from one node to another. ML compilers have to solve many complex optimization problems, including &lt;em>;graph-level &lt;/em>;and &lt;em>;kernel-level&lt;/em>; optimizations. A graph-level optimization requires the context of the entire graph to make optimal decisions and transforms the entire graph accordingly. A kernel-level optimization transforms one kernel (a fused subgraph) at a time, independently of other kernels. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKHc-UWtoIPsAxdaadumdb1n3K8jz02HYoAbz3CG1BChwyvcNzLUSniYSdRi7HJdPoc2ObwFrs3vSQVN43pVmpUtcnCsSyYU3aypLI-Qyg5AVQRf869uwnP-lNOT2HR3LASYeBGDpWx727a5_mvYe2Oe5F_039pysTR4nKfCDGW9YpklkmYS_lOD_D7k8w/s1999/image6.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;465&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKHc-UWtoIPsAxdaadumdb1n3K8jz02HYoAbz3CG1BChwyvcNzLUSniYSdRi7HJdPoc2ObwFrs3vSQVN43pVmpUtcnCsSyYU3aypLI-Qyg5AVQRf869uwnP-lNOT2HR3LASYeBGDpWx727a5_mvYe2Oe5F_039pysTR4nKfCDGW9YpklkmYS_lOD_D7k8w/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;Important optimizations in ML compilers include graph-level and kernel-level optimizations.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; To provide a concrete example, imagine a &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_(mathematics)&quot;>;matrix&lt;/a>; (2D tensor): &lt;/p>; &lt;table align=&quot;center&quot; cellpadding =&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCUHoSLc08Cq3T475pnipGS1x1rFt0c8cuRCAIiTLWM70FeQMjHkYprNnnroiH0V4PdhtCM2lU7quJ7vJMUX_113S1RAvKZdSQAFiIvdpxrcr8HvnjQti97F3JE5Sno8UKDyjjirTOB5JrhG4kzz2uUiu0GwZ0p5lG5nmhamEPKgaGq1j5cQ9OU9cXj348/s1999/image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;290&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEjCUHoSLc08Cq3T475pnipGS1x1rFt0c8cuRCAIiTLWM70FeQMjHkYprNnnroiH0V4PdhtCM2lU7quJ7vJMUX_113S1RAvKZdSQAFiIvdpxrcr8HvnjQti97F3JE5Sno8UKDyjjirTOB5JrhG4kzz2uUiu0GwZ0p5lG5nmhamEPKgaGq1j5cQ9OU9cXj348/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; It can be stored in computer memory as [ABC abc] or [A a B b C c], known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Row-_and_column-major_order&quot;>;row- and column-major memory layout&lt;/a>;, respectively. One important ML compiler optimization is to assign memory layouts to all intermediate tensors in the program. The figure below shows two different layout configurations for the same program. Let&#39;s assume that on the left-hand side, the assigned layouts (in red) are the most efficient option for each individual operator. However, this layout configuration requires the compiler to insert a &lt;em>;copy&lt;/em>; operation to transform the memory layout between the &lt;em>;add&lt;/em>; and &lt;em>;convolution&lt;/em>;运营。 On the other hand, the right-hand side configuration might be less efficient for each individual operator, but it doesn&#39;t require the additional memory transformation. The layout assignment optimization has to trade off between local computation efficiency and layout transformation overhead. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_I4RC-UA10yE2aMURcmyfHSZ5_srJ0mxKGxjrUrS6nvEQVNK2CMAp_k__fjCQW8Y20z6IXqA7Fww44Wz5uUAuo6y9njqYxXUPBHu0HGOWfVHFkZ785QZg2mBslF1mrlEmQVt4L60ICPRwk_cbb293MLIx50FT6EsF75xfWi6oa0bCvPAurBB3Y8Mvp1uo/s1999/image3.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;343&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEg_I4RC-UA10yE2aMURcmyfHSZ5_srJ0mxKGxjrUrS6nvEQVNK2CMAp_k__fjCQW8Y20z6IXqA7Fww44Wz5uUAuo6y9njqYxXUPBHu0HGOWfVHFkZ785QZg2mBslF1mrlEmQVt4L60ICPRwk_cbb293MLIx50FT6EsF75xfWi6oa0bCvPAurBB3Y8Mvp1uo/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;A node represents a tensor operator, annotated with its output tensor shape [&lt;em>;n&lt;sub>;0&lt;/sub>;&lt;/em>;, &lt;em>;n&lt;sub>;1&lt;/sub>;&lt;/ em>;, ...], where &lt;em>;n&lt;sub>;i &lt;/sub>;&lt;/em>;is the size of dimension &lt;em>;i&lt;/em>;. Layout {&lt;em>;d&lt;sub>;0&lt;/sub>;&lt;/em>;, &lt;em>;d&lt;sub>;1&lt;/sub>;&lt;/em>;, ...} represents minor-to-major ordering in memory. Applied configurations are highlighted in red, and other valid configurations are highlighted in blue. A layout configuration specifies the layouts of inputs and outputs of influential operators (ie, convolution and reshape). A copy operator is inserted when there is a layout mismatch.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; If the compiler makes optimal choices, significant speedups can be made. For example, we have seen &lt;a href=&quot;https://ieeexplore.ieee.org/document/9563030&quot;>;up to a 32% speedup&lt;/a>; when choosing an optimal layout configuration over the default compiler&#39;s configuration in the &lt;a href=&quot;https://www.tensorflow.org/xla&quot;>;XLA&lt;/a>; benchmark suite. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;TpuGraphs dataset&lt;/h2>; &lt;p>; Given the above, we aim to improve ML model efficiency by improving the ML compiler. Specifically, it can be very effective to equip the compiler&lt;strong>; &lt;/strong>;with a &lt;a href=&quot;https://arxiv.org/abs/2008.01040&quot;>;learned cost model&lt;/a>;&lt;strong>; &lt;/strong>;that takes in an input program and compiler configuration and then outputs the predicted runtime of the program. &lt;/p>; &lt;p>; With this motivation, we &lt;a href=&quot;https://arxiv.org/abs/2308.13490&quot;>;release TpuGraphs&lt;/a>;, a dataset for learning cost models for programs running on Google&#39;s custom &lt;a href=&quot;https://cloud.google.com/tpu/docs/intro-to-tpu&quot;>;Tensor Processing Units&lt;/a>; (TPUs). The dataset targets two XLA compiler configurations: &lt;em>;layout&lt;/em>; (generalization of row- and column-major ordering, from matrices, to higher dimension tensors) and &lt;em>;tiling&lt;/em>; (configurations of tile sizes) 。 We provide download instructions and starter code on the &lt;a href=&quot;https://github.com/google-research-datasets/tpu_graphs&quot;>;TpuGraphs GitHub&lt;/a>;. Each example in the dataset contains a computational graph of an ML workload, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source ML programs, featuring popular model architectures, eg, &lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;>;ResNet&lt;/a>;, &lt;a href=&quot;https://arxiv.org/abs/1905.11946&quot;>;EfficientNet&lt;/a>;, &lt;a href=&quot;https://arxiv.org/abs/1703.06870&quot;>;Mask R-CNN&lt;/a>;, and &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;>;Transformer&lt;/a>;. The dataset provides 25× more graphs than the largest (earlier) graph property prediction dataset (with comparable graph sizes), and graph size is 770× larger on average compared to existing performance prediction datasets on ML programs. With this greatly expanded scale, for the first time we can explore the graph-level prediction task on large graphs, which is subject to challenges such as scalability, training efficiency, and model quality. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmmh8CXbMXvAmeBpyjMGMrfq2MEXlxeczYqEOUJvps1oca9G_Xlc34D8-vnwUHTDZDlgIZDYqTfPUVF_qi7AJlPw5fV4Whwz8BOEQs-l1S-7TDLqhIsiCXbQN78SPa8yoTE86438CChMyQVhUFEy3vQRiWhQOFhOKfwH3IbIVbhl5Fe1gDTjBFL2AsDBX/s2868/image18.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1546&quot; data-original-width=&quot;2868&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmmh8CXbMXvAmeBpyjMGMrfq2MEXlxeczYqEOUJvps1oca9G_Xlc34D8-vnwUHTDZDlgIZDYqTfPUVF_qi7AJlPw5fV4Whwz8BOEQs-l1S-7TDLqhIsiCXbQN78SPa8yoTE86438CChMyQVhUFEy3vQRiWhQOFhOKfwH3IbIVbhl5Fe1gDTjBFL2AsDBX/s16000/image18.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;Scale of TpuGraphs compared to other graph property prediction datasets.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We provide baseline learned cost models with our dataset (architecture shown below). Our baseline models are based on a GNN since the input program is represented as a graph. Node features, shown in blue below, consist of two parts. The first part is an &lt;em>;opcode id&lt;/em>;, the most important information of a node, which indicates the type of tensor operation. Our baseline models, thus, map an opcode id to an &lt;em>;opcode embedding&lt;/em>; via an embedding lookup table. The opcode embedding is then concatenated with the second part, the rest of the node features, as inputs to a GNN. We combine the node embeddings produced by the GNN to create the fixed-size embedding of the graph using a simple graph pooling reduction (ie, sum and mean). The resulting graph embedding is then linearly transformed into the final scalar output by a feedforward layer. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgKH2VD6leBGzfWhjN5LA17iDfKlYLIglznzDDI_A73_Jfs4D-tpZR2gPRe2wpmfrdYv3raxf1Dl2m8YNkW3NcUlUWywpCi8GnJGSnEth8ITn0m387T6Z1Ye-f1SJX81fw_pTfAhgAfQ06NDFK6ahEMPEA6g7vc_jzAb4pHIZHFEUp1rEIH4MrKaGIVhdw3/s2284/image20.png&quot; imageanchor =&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1106&quot; data-original-width=&quot;2284&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgKH2VD6leBGzfWhjN5LA17iDfKlYLIglznzDDI_A73_Jfs4D-tpZR2gPRe2wpmfrdYv3raxf1Dl2m8YNkW3NcUlUWywpCi8GnJGSnEth8ITn0m387T6Z1Ye-f1SJX81fw_pTfAhgAfQ06NDFK6ahEMPEA6g7vc_jzAb4pHIZHFEUp1rEIH4MrKaGIVhdw3/s16000/image20.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr -caption&quot; style=&quot;text-align: center;&quot;>;Our baseline learned cost model employs a GNN since programs can be naturally represented as graphs.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Furthermore we present &lt;a href=&quot;https://arxiv.org/abs/2305.12322&quot;>;Graph Segment Training&lt;/a>; (GST), a method for scaling GNN training to handle large graphs on a device with limited memory capacity in cases where the prediction task is on the entire-graph (ie, graph-level prediction). Unlike scaling training for node- or edge-level prediction, scaling for graph-level prediction is understudied but crucial to our domain, as computation graphs can contain hundreds of thousands of nodes. In a typical GNN training (“Full Graph Training”, on the left below), a GNN model is trained using an entire graph, meaning all nodes and edges of the graph are used to compute gradients. For large graphs, this might be computationally infeasible. In GST, each large graph is partitioned into smaller segments, and a random subset of segments is selected to update the model; embeddings for the remaining segments are produced without saving their intermediate activations (to avoid consuming memory). The embeddings of all segments are then combined to generate an embedding for the original large graph, which is then used for prediction. In addition, we introduce the historical embedding table to efficiently obtain graph segments&#39; embeddings and segment dropout to mitigate the staleness from historical embeddings. Together, our complete method speeds up the end-to-end training time by 3×. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgX7cF7Sl6XY3xYwmUp7lqPoXGsXaV3RqVC0YgUG_AQy4XAv7B75eaWpZy_gmbq0UG6VVX0wEjvuOyg2Ce7ALeuVLaUBgKUvEWvAi0RnYsN61d7z3YAm9NEeCpEKQu_YU7ZTAgS71h6mq-bpX6H2HFv73TIHd_W1DsZyastPfjG4hogWf3cy8uf_5DGJjDV/s790/image2.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;434&quot; data-original-width=&quot;790&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEgX7cF7Sl6XY3xYwmUp7lqPoXGsXaV3RqVC0YgUG_AQy4XAv7B75eaWpZy_gmbq0UG6VVX0wEjvuOyg2Ce7ALeuVLaUBgKUvEWvAi0RnYsN61d7z3YAm9NEeCpEKQu_YU7ZTAgS71h6mq-bpX6H2HFv73TIHd_W1DsZyastPfjG4hogWf3cy8uf_5DGJjDV/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;Comparing Full Graph Training (typical method) vs Graph Segment Training (our proposed method).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40% ;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Kaggle competition&lt;/h2>; &lt;p>; Finally, we ran the “&lt;a href=&quot;https://kaggle.com/competitions/predict-ai-model- runtime&quot;>;Fast or Slow? Predict AI Model Runtime&lt;/a>;” competition over the TpuGraph dataset. This competition ended with 792 participants on 616 teams. We had 10507 submissions from 66 countries.对于 153 名用户（其中​​前 100 名中的 47 名）来说，这是他们的第一次比赛。 We learned many interesting new techniques employed by the participating teams, such as: &lt;/p>; &lt;ul>; &lt;li>;&lt;em>;Graph pruning / compression&lt;/em>;: Instead of using the GST method, many teams experimented with different ways to compress large graphs (eg, keeping only subgraphs that include the configurable nodes and their immediate neighbors). &lt;/li>;&lt;li>;&lt;em>;Feature padding value&lt;/em>;: Some teams observed that the default padding value of 0 is problematic because 0 clashes with a valid feature value, so using a padding value of -1 can improve the model accuracy significantly. &lt;/li>;&lt;li>;&lt;em>;Node features&lt;/em>;: Some teams observed that additional node features (such as &lt;a href=&quot;https://www.tensorflow.org/xla/operation_semantics#dot&quot;>;dot general&#39;s contracting dimensions&lt;/a>;) are important. A few teams found that different encodings of node features also matter. &lt;/li>;&lt;li>;&lt;em>;Cross-configuration attention&lt;/em>;: A winning team designed a simple layer that allows the model to explicitly &quot;compare&quot; configs against each other. This technique is shown to be much better than letting the model infer for each config individually. &lt;/li>; &lt;/ul>; &lt;p>; We will debrief the competition and preview the winning solutions at the competition session at the &lt;a href=&quot;https://mlforsystems.org/&quot;>;ML for Systems workshop&lt;/a>; at NeurIPS on December 16, 2023. Finally, congratulations to all the winners and thank you for your contributions to advancing research in ML for systems! &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;NeurIPS expo&lt;/h2>; &lt;p>; If you are interested in more research about structured data and artificial intelligence, we hosted the NeurIPS Expo panel &lt;a href=&quot;https://nips.cc/Expo/Conferences/2023/talk%20panel/78252&quot;>;Graph Learning Meets Artificial Intelligence&lt;/a>; on December 9, which covered advancing learned cost models and more! &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;Sami Abu-el-Haija (Google Research) contributed significantly to this work and write-up. The research in this post describes joint work with many additional collaborators including Mike Burrows, Kaidi Cao, Bahare Fatemi, Jure Leskovec, Charith Mendis, Dustin Zelle, and Yanqi Zhou.&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6088118107306075362/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/advancements-in-machine-learning-for.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6088118107306075362&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6088118107306075362&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/advancements-in-machine-learning-for.html&quot; rel=&quot;alternate&quot; title=&quot;Advancements in machine learning for machine learning&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh8VzlEwBVhUqzyMz9pok3Vx0ft_8X_IZyvjpiFtX7PewhMGRzI6UmfEtUKSQ_kiO7CW8-KQ1OmDujYmHpwLvRndQFqNnmQJnEgnMo5Gj5tJi5aVnscmlo7vbHFFhS8l-yMoIICJLm80V9EPpyIObG-07Cw_VYjzWNfaZ0E_vp4f8v_WGpn1lU8F3LsJHIx/s72-c/Screenshot%202023-12-15%20at%202.33.10%E2%80%AFPM.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-6479608460479432217&lt;/id>;&lt;published>;2023-12-15T11:40:00.000-08:00&lt;/published>;&lt;updated>;2023-12-15T12:18:41.742-08:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Computer Vision&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;NeurIPS&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Style Transfer&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;StyleDrop: Text-to-image generation in any style&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Kihyuk Sohn and Dilip Krishnan, Research Scientists, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEAbsx3XSFVK_2XyQI-KD2x-h0D2qTD0QZzeVyTLk9umNZJbXEiQk7O84xb8eyNQkfNIu6bqg9UcqVUFC-uKMbsFvxRmRWkokKR4VinfUZsYZlSBdY7BU905YIxWfrCtmCMkT7wcnpL1nnRgN0xPE15uhsLl0CvI8D2OI3ZgBTcRq3G1zVPUJu7L9tO_P8/s1600/StyleDrop%20hero.gif&quot; style=&quot;display: none;&quot; />; &lt;p>; Text-to-image models trained on large volumes of image-text pairs have enabled the creation of rich and diverse images encompassing many genres and themes. Moreover, popular styles such as “anime” or “steampunk”, when added to the input text prompt, may translate to specific visual outputs. While many efforts have been put into &lt;a href=&quot;https://en.wikipedia.org/wiki/Prompt_engineering&quot;>;prompt engineering&lt;/a>;, a wide range of styles are simply hard to describe in text form due to the nuances of color schemes, illumination, and other characteristics. As an example, “watercolor painting” may refer to various styles, and using a text prompt that simply says “watercolor painting style” may either result in one specific style or an unpredictable mix of several. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto ; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjNi6hwWTqFdzKvJ9qxXf5ppyfhixq1qERPyXZqBmdrPVP4ObR94N1pVVIJAGZseKbsLtOcf6qm2M0LgRtNKqXN -7qjC7Isz1keA8Pm4_ADYuzywpXLb3h7W4H5p5X3f7Y_A21uLNQWceazq-Ex6YOLCDzacl0Umk-EhqZvMUz0aZHG9nvxxb52gw-zKz/s959/image5.gif&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height= &quot;403&quot; data-original-width=&quot;959&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjNi6hwWTqFdzKvJ9qxXf5ppyfhixq1qERPyXZqBmdrPVP4ObR94N1pVVIJAGZseKbsLtOcf6qm2M0LgRtNKqXN-7qjC7Isz1keA8Pm4_ADYuzywpXLb3h7W4H5p5X3f7Y_A21uLNQWceazq-Ex6YOLCDzacl0Umk-EhqZvMUz0aZHG9nvxxb52gw-zKz/s16000/image5.gif&quot; />;&lt; /a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;When we refer to &quot;watercolor painting style,&quot; which do we mean? Instead of specifying the style in natural language, StyleDrop allows the generation of images that are consistent in style by referring to a style reference image&lt;sup id=&quot;fnref1&quot;>;&lt;a href=&quot;#fn1&quot; rel=&quot;footnote&quot;>;&lt;span style=&quot;font-size: x-small;&quot;>;*&lt;/span>;&lt;/a>;&lt;/sup>;.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; In this blog we introduce “&lt;a href=&quot;https://arxiv.org/abs/2306.00983&quot;>;StyleDrop: Text-to-Image Generation in Any Style&lt;/a>;”, a tool that allows a significantly higher level of stylized text-to-image synthesis. Instead of seeking text prompts to describe the style, StyleDrop uses one or more style&lt;em>; reference images&lt;/em>; that describe the style for text-to-image generation. By doing so, StyleDrop enables the generation of images in a style consistent with the reference, while effectively circumventing the burden of text prompt engineering. This is done by efficiently fine-tuning the pre-trained text-to-image generation models via &lt;a href=&quot;https://arxiv.org/pdf/1902.00751.pdf&quot;>;adapter tuning&lt;/a>; on a few style参考图像。 Moreover, by iteratively fine-tuning the StyleDrop on a set of images it generated, it achieves the style-consistent image generation from text prompts. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Method overview&lt;/h2>; &lt;p>; StyleDrop is a text-to-image generation model that allows generation of images whose visual styles are consistent with the user-provided style reference images. This is achieved by a couple of iterations of parameter-efficient fine-tuning of pre-trained text-to-image generation models. Specifically, we build StyleDrop on &lt;a href=&quot;https://muse-model.github.io/&quot;>;Muse&lt;/a>;, a text-to-image generative vision transformer. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;Muse: text-to-image generative vision transformer&lt;/h3>; &lt;p>; &lt;a href=&quot;https://muse-model.github.io/&quot;>;Muse&lt;/a>; is a state-of-the-art text-to-image generation model based on the masked generative image transformer (&lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_MaskGIT_Masked_Generative_Image_Transformer_CVPR_2022_paper.pdf&quot;>;MaskGIT&lt;/a>;). Unlike diffusion models, such as &lt;a href=&quot;https://imagen.research.google/&quot;>;Imagen&lt;/a>; or &lt;a href=&quot;https://github.com/CompVis/stable-diffusion&quot;>;Stable Diffusion&lt;/a>;, Muse represents an image as a sequence of discrete tokens and models their distribution using a transformer architecture. Compared to diffusion models, Muse is known to be faster while achieving competitive generation quality. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;Parameter-efficient adapter tuning&lt;/h3>; &lt;p>; StyleDrop is built by fine-tuning the pre-trained Muse model on a few style reference images and their corresponding text prompts. There have been many works on parameter-efficient fine-tuning of transformers, including &lt;a href=&quot;https://arxiv.org/abs/2104.08691&quot;>;prompt tuning&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/2106.09685&quot;>;Low-Rank Adaptation&lt;/a>; (LoRA) of large language models. Among those, we opt for adapter tuning, which is shown to be effective at fine-tuning a large transformer network for &lt;a href=&quot;https://arxiv.org/pdf/1902.00751.pdf&quot;>;language&lt;/a>; and &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2023/papers/Sohn_Visual_Prompt_Tuning_for_Generative_Transfer_Learning_CVPR_2023_paper.pdf&quot;>;image generation&lt;/a>; tasks in a parameter-efficient manner. For example, it introduces less than one million trainable parameters to fine-tune a Muse model of 3B parameters, and it requires only 1000 training steps to converge. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCPhYjNXD7G0dv1imverMl1A5gav3nkrpRawxAUFWmpsFaqE70_IlTN4jAMGc9V8HrYLzgY6bgoOfc0QtqszPFzKu6a6so7Abf52d3Kyu-77Di6YvRncF81xEJoEhSfSKHFlvrhH7JAs9Unmpp43ixlUat-9X8O4g0AF-4XeuW_RXAzmuIpfpTjt06KQyn/s1632/image2.png &quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1152&quot; data-original-width=&quot;1632&quot; src= &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCPhYjNXD7G0dv1imverMl1A5gav3nkrpRawxAUFWmpsFaqE70_IlTN4jAMGc9V8HrYLzgY6bgoOfc0QtqszPFzKu6a6so7Abf52d3Kyu-77Di6YvRncF81xEJoEhSfSKHFlvrhH7JAs9Unmpp43ixlUat-9X8O4g0AF-4XeuW_RXAzmuIpfpTjt06KQyn/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Parameter-efficient adapter tuning of Muse.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height :40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;Iterative training with feedback&lt;/h3>; &lt;p>; While StyleDrop is effective at learning styles from a few style reference images, it is still challenging to learn from a single style reference image. This is because the model may not effectively disentangle the &lt;em>;content &lt;/em>;(ie, what is in the image) and the &lt;em>;style&lt;/em>; (ie, how it is being presented), leading to reduced &lt;em>;text controllability&lt;/em>; in generation. For example, as shown below in Step 1 and 2, a generated image of a chihuahua from StyleDrop trained from a single style reference image shows a leakage of content (ie, the house) from the style reference image. Furthermore, a generated image of a temple looks too similar to the house in the reference image (concept collapse). &lt;/p>; &lt;p>; We address this issue by training a new StyleDrop model on a subset of synthetic images, chosen by the user or by image-text alignment models (eg, &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;CLIP&lt;/a>;), whose images are generated by the first round of the StyleDrop model trained on a single image. By training on multiple synthetic image-text aligned images, the model can easily disentangle the style from the content, thus achieving improved image-text alignment. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWlXhdkbVOB2b33N_H_vfUEXv4ivi4pIsKmUj8d43-V5BCrWM2thw5UBF6ErzS150xlcWSvi8adysDj6WYWAIw416CwaV4R3GvkMSa3CVubpTR0FC-JsX6zmgnG-EtKQPQvzhdKY20wJ-vko62BXQ8GdbQ8c0qi7AtrEUSNycZ3XWht7MWxJm0I7gwrUeT/s1295/image3 .gif&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;825&quot; data-original-width=&quot;1295&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWlXhdkbVOB2b33N_H_vfUEXv4ivi4pIsKmUj8d43-V5BCrWM2thw5UBF6ErzS150xlcWSvi8adysDj6WYWAIw416CwaV4R3GvkMSa3CVubpTR0FC-JsX6zmgnG-EtKQPQvzhdKY20wJ-vko62BXQ8GdbQ8c0qi7AtrEUSNycZ3XWht7MWxJm0I7gwrUeT/s16000/image3.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt; tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Iterative training with feedback&lt;sup id=&quot;fnref1&quot;>;&lt;a href=&quot;#fn1&quot; rel=&quot;footnote&quot;>;&lt;span style=&quot;font-size: x-small;&quot;>;*&lt;/span>;&lt;/a>;&lt;/sup>;. The first round of StyleDrop may result in reduced text controllability, such as a content leakage or concept collapse, due to the difficulty of content-style disentanglement. Iterative training using synthetic images, generated by the previous rounds of StyleDrop models and chosen by human or image-text alignment models, improves the text adherence of stylized text-to-image generation.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Experiments&lt;/h2>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;StyleDrop gallery&lt;/h3>; &lt;p>; We show the effectiveness of StyleDrop by running experiments on 24 distinct style reference images. As shown below, the images generated by StyleDrop are highly consistent in style with each other and with the style reference image, while depicting various contexts, such as a baby penguin, banana, piano, etc. Moreover, the model can render alphabet images with a consistent style. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPYKGwhNBOcWcPl8NMXQvJdUhAQhmmUiaPLHLLk0iHTxCKCkTL2gib1sNq8Df0HbdMbdpsxhp4wEH4z5uNtnWnR2ldPyRTLwUFp8tDyQgt3EQTl8g557icN8XaWCIrK_Lr516C9z66szRIzFTtCZpgeisARikILbRT8qKdgNpodKgbO9msxNcgbKRcWXhf/s1632/image6.gif&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1632&quot; data-original-width=&quot;1536&quot; height=&quot;640&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPYKGwhNBOcWcPl8NMXQvJdUhAQhmmUiaPLHLLk0iHTxCKCkTL2gib1sNq8Df0HbdMbdpsxhp4wEH4z5uNtnWnR2ldPyRTLwUFp8tDyQgt3EQTl8g557icN8XaWCIrK_Lr516C9z66szRIzFTtCZpgeisARikILbRT8qKdgNpodKgbO9msxNcgbKRcWXhf/w602-h640/image6.gif&quot; width=&quot;602&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Stylized text-to-image generation. Style reference images&lt;sup id=&quot;fnref1&quot;>;&lt;a href=&quot;#fn1&quot; rel=&quot;footnote&quot;>;&lt;span style=&quot;font-size: x-small;&quot;>;*&lt;/span>;&lt;/a>;&lt;/sup>; are on the left inside the yellow box. Text prompts used are:&lt;br>; First row: a baby penguin, a banana, a bench.&lt;br>; Second row: a butterfly, an F1 race car, a Christmas tree.&lt;br>; Third row: a coffee maker, a hat, a moose.&lt;br>; Fourth row: a robot, a towel, a wood cabin.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2y-TXUKBTk37cq0owx6UTkkIogGQMYEBXp6-1cYy6TwhGv97_4ySH3UmsTo9SH6PVO9NIti2uv94c1FIJrPYpAyPPdjBT2pS6Bgq2CAppCGBU-sw4QmUpDrN-1lrlpmtxCBRIN3AQN07IJ7tPeSRUvJ5clWly_CclPYukT3zTesLMT2iau076NwlYzrsi/s1526/image1.gif&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;767&quot; data-original-width=&quot;1526&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2y-TXUKBTk37cq0owx6UTkkIogGQMYEBXp6-1cYy6TwhGv97_4ySH3UmsTo9SH6PVO9NIti2uv94c1FIJrPYpAyPPdjBT2pS6Bgq2CAppCGBU-sw4QmUpDrN-1lrlpmtxCBRIN3AQN07IJ7tPeSRUvJ5clWly_CclPYukT3zTesLMT2iau076NwlYzrsi/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Stylized visual character generation. Style reference images&lt;sup id=&quot;fnref1&quot;>;&lt;a href=&quot;#fn1&quot; rel=&quot;footnote&quot;>;&lt;span style=&quot;font-size: x-small;&quot;>;*&lt;/span>;&lt;/a>;&lt;/sup>; are on the left inside the yellow box. Text prompts used are: (first row) letter &#39;A&#39;, letter &#39;B&#39;, letter &#39;C&#39;, (second row) letter &#39;E&#39;, letter &#39;F&#39;, letter &#39;G&#39;.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;Generating images of my object in my style&lt;/h3>; &lt;p>; Below we show generated images by sampling from two personalized generation distributions, one for an object and another for the style. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3rr2OGiWAUqJ6GzI9BpKwzmQlyOJKqALq2oY_3lrXSqGDi63z6i876V6POhhioRDctXt-e4lVaKXkae0yKJdurRp8-rmsqoLkj-oXWqi4xe4HCM2FmKf6knGa_jd5MLGOg6zYHIu62Ye7xSU5q516AcHijL5UsPUAQ2wXFznnT90pn3wxp_s5PBEXf_rc/s1006/image8.gif &quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;412&quot; data-original-width=&quot;1006&quot; src= &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3rr2OGiWAUqJ6GzI9BpKwzmQlyOJKqALq2oY_3lrXSqGDi63z6i876V6POhhioRDctXt-e4lVaKXkae0yKJdurRp8-rmsqoLkj-oXWqi4xe4HCM2FmKf6knGa_jd5MLGOg6zYHIu62Ye7xSU5q516AcHijL5UsPUAQ2wXFznnT90pn3wxp_s5PBEXf_rc/s16000/image8.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Images at the top in the blue border are object reference images from the DreamBooth dataset (teapot, vase, dog and cat), and the image on the left at the bottom in the red border is the style reference image*. Images in the purple border (ie the four lower right images) are generated from the style image of the specific object.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h3>;Quantitative results&lt;/h3>; &lt;p>; For the quantitative evaluation, we synthesize images from a subset of &lt;a href=&quot;https://github.com/google-research/parti/blob/main/PartiPrompts.tsv&quot;>;Parti prompts&lt;/a>; and measure the &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;image-to-image CLIP score&lt;/a>; for style consistency and &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;image-to-text CLIP score&lt;/a>; for text consistency. We study non–fine-tuned models of Muse and Imagen. Among fine-tuned models, we make a comparison to &lt;a href=&quot;https://dreambooth.github.io/&quot;>;DreamBooth&lt;/a>; on &lt;a href=&quot;https://imagen.research.google/&quot;>;Imagen&lt;/a>;, state-of-the-art personalized text-to-image method for subjects. We show two versions of StyleDrop, one trained from a single style reference image, and another, “StyleDrop (HF)”, that is trained iteratively using synthetic images with human feedback as described above. As shown below, StyleDrop (HF) shows significantly improved style consistency score over its non–fine-tuned counterpart (0.694 vs. 0.556), as well as DreamBooth on Imagen (0.694 vs. 0.644). We observe an improved text consistency score with StyleDrop (HF) over StyleDrop (0.322 vs. 0.313). In addition, in a human preference study between DreamBooth on Imagen and StyleDrop on Muse, we found that 86% of the human raters preferred StyleDrop on Muse over DreamBooth on Imagen in terms of consistency to the style reference image. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiID8cTIDI32_6aRRoVhwxHDBJnPrnk_etBx904nBw0kFBDD6z99ttJqzz2574I-irFJ4_5dg0xHPqHPdpgeFi68Tl 1gu4pciiChyphenhyphenFS-wxEgkqvML-2aNHBFSD9qc9-aBrhCBfPhJHHQG5hmWEDn5YwXzH3aQ91kNKUqDPude-kCICKNpmhiJNvYDvI4ux5/s2980 /image16.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1000&quot; data-original-width=&quot;第2980章phenFS-wxEgkqvML-2aNHBFSD9qc9-aBrhCBfPhJHHQG5hmWEDn5YwXzH3aQ91kNKUqDPude-kCIcKNpmhiJNvYDvI4ux5/s16000/image16.png&quot;/>;&lt;/a>;&lt;/td>;&lt; /tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height :40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; StyleDrop 使用一些样式参考图像在文本到图像生成中实现了样式一致性。 Google 的人工智能原则指导了我们 Style Drop 的开发，我们敦促负责任地使用该技术。 StyleDrop 经过改编，可&lt;a href=&quot;https://cloud.google.com/vertex-ai/docs/generative-ai/image/fine-tune-style&quot;>;在 Vertex AI 中创建自定义样式模型&lt;/a>; ，我们相信它对于艺术总监和平面设计师（他们可能想要以自己的风格集思广益或制作视觉资产原型，以提高他们的生产力和创造力）或想要生成新媒体资产的企业来说可能是一个有用的工具体现一个特定的品牌。与其他生成式人工智能功能一样，我们建议从业者确保其与所使用的任何媒体资产的版权保持一致。更多结果请访问我们的&lt;a href=&quot;https://styledrop.github.io/&quot;>;项目网站&lt;/a>;和&lt;a href=&quot;https://youtu.be/gNHD0_hkJ9A&quot;>;YouTube 视频&lt;/一个>;。 &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;这项研究由 Kihyuk Sohn、Nataniel Ruiz 进行， Kimin Lee、Daniel Castro Chin、Irina Blok、Huiwen Chang、Jarred Barber、Lu Jiang、Glenn Entis、李元珍、袁浩、Irfan Essa、Michael Rubinstein 和 Dilip Krishnan。 &lt;/em>;我们感谢实验中使用的图像的所有者（&lt;a href=&quot;https://github.com/styledrop/styledrop.github.io/blob/main/images/assets/data.md&quot;>;链接&lt; /a>; 归属）分享他们的宝贵资产。 &lt;/p>; &lt;!--脚注-->; &lt;hr width=&quot;80%&quot; />; &lt;p>; &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-size: x-small;&quot;>;&lt; super>;&lt;a name=&quot;fn1&quot;>;&lt;b>;*&lt;/b>;&lt;/a>;&lt;/sup>;请参阅&lt;a href=&quot;https://github.com/styledrop/styledrop.github.io/blob/ main/images/assets/data.md&quot;>;图片来源&lt;/a>;&lt;a href=&quot;#fnref1&quot; rev=&quot;footnote&quot;>;&lt;sup>;↩&lt;/sup>;&lt;/a>;&lt;/span>;&lt; /p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6479608460479432217/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot; />;&lt;link href=&quot;http://blog.research.google/2023/12/styledrop-text-to-image- Generation-in.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6479608460479432217&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>; &lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6479608460479432217&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http:// blog.research.google/2023/12/styledrop-text-to-image- Generation-in.html&quot; rel=&quot;alternate&quot; title=&quot;StyleDrop：任何样式的文本到图像生成&quot; type=&quot;text/html &quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:图片高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=“16” &quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEAbsx3XSFVK_2XyQI-KD2x-h0D2qTD0QZzeVyTLk9umNZJbXEiQk7O84xb8eyNQkfNIu6bqg9UcqV UFC-UKMbsFvxRmRWkokKR4VinfuZsYZlSBdY7BU905YIxWfrCtmCMkT7wcnpL1nnRgN0xPE15uhsLl0CvI8D2OI3ZgBTcRq3G1zVPUJu7L9tO_P8/s72- c/StyleDrop%20hero.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>; &lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-8223613466421639113&lt;/id>;&lt;已发布>;2023-12-10T06:11:00.000-08:00&lt;/已发布>;&lt;更新>;2024-01-22T09:18:36.334-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;conference&quot;>;&lt;/category>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=“会议”>;&lt;/类别>;&lt;title type =“text”>;Google在NeurIPS 2023&lt;/stitle>;&lt;content type =“ html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Google 项目经理 Catherine Armato&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjC9GkRLKp8GI42AvrsSQqN2F8gF8QDo06YU1ulV067EXp6MU3F1yYSZ44VRxn7BZl grSZ18249wN7vuwyeDAH4AmXHHo-ryPYOmZ771K3yhsUCkfWguTDsOTx2wBqnH1gF_hxcALrj7nq -kRL2lNttCipemJXYUitvDbRi_LNWk7bRgFpzpsNEqDeetCM2/s1100/google_research_sticker-hero.jpg&quot; style=&quot;显示：无；&quot; />; &lt;p>; 本周，第 37 届年度&lt;a href=&quot;https://neurips.cc/Conferences/2023&quot;>;神经信息处理系统会议&lt;/a>; (NeurIPS 2023) 召开，这是全球最大的机器学习会议今年，在洛杉矶新奥尔良拉开帷幕。 Google 很荣幸成为今年 NeurIPS 的&lt;a href=&quot;https://neurips.cc/Conferences/2023/Sponsors&quot;>;钻石级赞助商&lt;/a>;，并且将在超过 170 篇被接受的论文中占据一席之地，两次主题演讲，并通过组织支持和参与超过 20 个研讨会和教程为更广泛的研究界做出额外贡献。 Google 还很荣幸成为&lt;a href=&quot;https://nips.cc/virtual/2023/affinity-workshop/66602&quot;>;机器学习女性&lt;/a>;和&lt;a href=&quot;的白金赞助商https://nips.cc/virtual/2023/affinity-workshop/66607&quot;>;人工智能中的拉丁语&lt;/a>;研讨会。我们期待分享我们的一些广泛的机器学习研究，并扩大我们与更广泛的机器学习研究社区的合作伙伴关系。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 亲自参加 NeurIPS 2023？欢迎参观 Google 研究展位，详细了解我们为解决该领域一些最有趣的挑战而所做的令人兴奋的工作。访问 &lt;a href=&quot;https://twitter.com/GoogleAI&quot;>;@GoogleAI&lt;/a>; X (Twitter) 帐户，了解 Google 展位活动（例如演示和问答环节）。 &lt;/p>; &lt;p>; 您可以在下面的列表中详细了解我们在会议上展示的最新前沿工作（Google 附属机构以&lt;strong>;粗体&lt;/strong>;突出显示）。请参阅 &lt;a href=&quot;https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023&quot;>;Google DeepMind 博客&lt;/a>;，详细了解他们参加 NeurIPS 2023 的信息。&lt;/p >; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;板和线组委会&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; NeurIPS 董事会：&lt;strong>;Corinna Cortes&lt;/strong>;&lt;br />; 顾问委员会：&lt;strong>;John C. Platt&lt;/strong>; strong>;&lt;br />; 高级领域主席：&lt;strong>;Inderjit S. Dhillon&lt;/strong>;&lt;br />; 创意人工智能主席：&lt;strong>;Isabelle Guyon&lt;/strong>;&lt;br />; 项目主席：&lt;strong>;Amir Globerson &lt;/strong>;&lt;br />; 数据集和基准主席：&lt;b>; Remi Denton&lt;/b>;&lt;br />;博览会主席：&lt;b>;叶文明&lt;/b>;&lt;/p>; &lt;/div>; &lt;div style= &quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Google 研究展位演示/问答时间表&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;h4>;该时间表可能会发生变化。请访问 Google 展位 (#215) 了解更多信息。&lt;/h4>; &lt;p>; 所见即所读？改进文本-图像对齐评估&lt;br />; 演讲者：&lt;strong>;Yonatan Bitton&lt;/strong>;&lt;br />; 12 月 11 日星期一 | &lt;em>;12:15PM - 1:45PM&lt;/em>; &lt;/p>; &lt;p>; 像图一样说话：大型语言模型的图编码&lt;br />; 演讲者：&lt;strong>;Bahar Fatemi&lt;/strong>;、&lt;strong >; Jonathan Halcrow&lt;/strong>;、&lt;strong>; Bryan Perozzi&lt;/strong>;&lt;br />; 12 月 11 日星期一 | &lt;em>;4:00PM - 4:45PM&lt;/em>; &lt;/p>; &lt;p>; VisIT-Bench：受实际使用启发的视觉语言教学基准&lt;br />; 演讲者：&lt;strong>;Yonatan Bitton &lt;/strong>;&lt;br />; 12 月 11 日星期一 | &lt;em>;4:00PM - 4:45PM&lt;/em>; &lt;/p>; &lt;p>; MLCommons Croissant&lt;br />; 演讲者：&lt;strong>;Omar Benjelloun&lt;/strong>;、&lt;strong>; Meg Risdal&lt;/strong>;、&lt; strong>;Lora Aroyo&lt;/strong>;&lt;br />; 12 月 12 日，星期二 | &lt;em>;9:15AM - 10:00AM&lt;/em>; &lt;/p>; &lt;p>; DaTaSeg：驯服通用多数据集多任务分割模型&lt;br />; 演讲者：&lt;strong>;顾秀野&lt;/strong>;&lt; br />; 12 月 12 日星期二 | &lt;em>;12:45PM - 2:15PM&lt;/em>; &lt;/p>; &lt;p>; 嵌入大图&lt;br />; 演讲者：&lt;strong>;Bryan Perozzi&lt;/strong>;、&lt;strong>;Anton Tsitsulin&lt;/strong>;&lt; br />; 12 月 12 日星期二 | &lt;em>;3:20PM - 3:40PM&lt;/em>; &lt;/p>; &lt;p>; 相关噪声被证明可以击败独立噪声，实现差异化的私人学习&lt;br />; 演讲者：&lt;strong>;Krishna Pillutla&lt;/strong>;&lt;br />; 12 月 12 日星期二 | &lt;em>;3:20PM - 3:40PM&lt;/em>; &lt;/p>; &lt;p>; Med-PaLM&lt;br />; 演讲者：&lt;strong>;涂涛&lt;/strong>;&lt;br />; 12 月 12 日，星期二 | &lt;em>;4:45PM - 5:15PM&lt;/em>; &lt;/p>; &lt;p>; StyleDrop：任意样式的文本到图像生成&lt;br />; 演讲者：&lt;strong>;Kihyuk Sohn&lt;/strong>;、&lt;strong >;Lu Jiang&lt;/strong>;、&lt;strong>;Irfan Essa&lt;/strong>;&lt;br />; 12 月 12 日，星期二 | &lt;em>;4:45PM - 5:15PM&lt;/em>; &lt;/p>; &lt;p>; DICES 数据集：对话式 AI 安全评估的多样性&lt;br />; 演讲者：&lt;strong>;Lora Aroyo&lt;/strong>;、&lt;strong>; Alicia Parrish&lt;/strong>;、&lt;strong>;Vinodkumar Prabhakaran&lt;/strong>;&lt;br />; 12 月 13 日星期三 | &lt;em>;9:15AM - 10:00AM&lt;/em>; &lt;/p>; &lt;p>; 谐振器：基于游戏的可扩展大型模型评估&lt;br />; 演讲者：&lt;strong>;Erin Drake Kajioka&lt;/strong>;、&lt;strong >;Michal Todorovic&lt;/strong>;&lt;br />; 12 月 13 日星期三 | &lt;em>;12:45PM - 2:15PM&lt;/em>; &lt;/p>; &lt;p>; Adversarial Nibbler&lt;br />; 演讲者：&lt;strong>;Lora Aroyo&lt;/strong>;&lt;br />; 12 月 13 日星期三 | &lt;em>;12:45PM - 2:15PM&lt;/em>; &lt;/p>; &lt;p>; 迈向通才生物医学人工智能&lt;br />; 演讲者：&lt;strong>;涂涛&lt;/strong>;&lt;br />; 12 月 13 日星期三 | &lt;em>;3:15PM - 3:30PM&lt;/em>; &lt;/p>; &lt;p>; 条件适配器&lt;br />; 演讲者：&lt;strong>;Junwen Bai&lt;/strong>;&lt;br />; 12 月 13 日星期三 | &lt;em>;3:15PM - 3:30PM&lt;/em>; &lt;/p>; &lt;p>; 通过多模式 RAG 进行患者援助&lt;br />; 演讲者：&lt;strong>;Ryan Knuffman&lt;/strong>;、&lt;strong>;Milica Cvetkovic&lt;/strong >;&lt;br />; 12 月 13 日星期三 | &lt;em>;4:15PM - 5:00PM&lt;/em>; &lt;/p>; &lt;p>; Hessian 结构如何解释锐度正则化的奥秘&lt;br />; 演讲者：&lt;strong>;Hossein Mobahi&lt;/strong>;&lt;br />; 星期三， 12 月 13 日 | &lt;em>;4:15PM - 5:00PM&lt;/em>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;主题演讲嘉宾&lt; /h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/invited-talk/73993&quot;>;负责任的人工智能的多面性&lt; /a>;&lt;br />; 演讲者：&lt;strong>;Lora Aroyo&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/invited-talk/73987&quot;>;草图：核心工具、学习增强和自适应鲁棒性&lt;/a>;&lt;br />; 演讲者：&lt;strong>;Jelani Nelson&lt;/strong>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%; &quot;>; &lt;br />; &lt;/div>; &lt;h2>;亲和力研讨会&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/ 2023/affinity-workshop/66602&quot;>;机器学习领域的女性&lt;/a>;&lt;br />; &lt;strong>;Google 赞助 - 白金级&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc /virtual/2023/affinity-workshop/66607&quot;>;AI 中的拉丁语&lt;/a>;&lt;br />; &lt;strong>;Google 赞助 - 白金级&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https:// nips.cc/virtual/2023/affinity-workshop/66605&quot;>;机器学习新进展&lt;/a>;&lt;br />; 组织者：&lt;strong>;Sangnie Bhardwaj&lt;/strong>;&lt;br>; 演讲者：&lt;strong>;Milind Tambe&lt;/strong >; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;研讨会&lt;/h2>; &lt;div style=&quot;margin-left: 20px; &quot;>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66541&quot;>;人工智能加速材料设计&lt;/a>; (AI4Mat-2023)&lt;br />; 炉边聊天：&lt;strong >;Gowoon Cheon&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66524&quot;>;联想记忆与记忆Hopfield Networks 2023 年&lt;/a>;&lt;br />; 小组成员：&lt;strong>;Blaise Agüera y Arcas&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop /66535&quot;>;认知系统中的信息理论原理&lt;/a>; (InfoCog)&lt;br />;演讲者：&lt;strong>;Alexander Alemi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips .cc/virtual/2023/workshop/66518&quot;>;机器学习和物理科学&lt;/a>;&lt;br />;演讲者：&lt;strong>;Alexander Alemi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https ://nips.cc/virtual/2023/workshop/66494&quot;>;UniReps：统一神经模型中的表示&lt;/a>;&lt;br />;组织者：&lt;strong>;Mathilde Caron&lt;/strong>; &lt;/p>; &lt;p>; &lt; a href=&quot;https://nips.cc/virtual/2023/workshop/66517&quot;>;基础模型中零/少样本学习的鲁棒性&lt;/a>; (R0-FoMo)&lt;br />; 演讲者：&lt;strong>; Partha Talukdar&lt;/strong>;&lt;br />; 组织者：&lt;strong>;Ananth Balashankar&lt;/strong>;、&lt;strong>;姚勤&lt;/strong>;、&lt;strong>;Ahmad Beirami&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66539&quot;>;扩散模型研讨会&lt;/a>;&lt;br />;演讲者：&lt;strong>;Tali Dekel&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66502&quot;>;时间视角下的算法公平性&lt;/a>;&lt;br />;圆桌会议负责人：&lt;strong>;Stephen Pfohl&lt;/strong>;&lt; br />; 组织者：&lt;strong>;Golnoosh Farnadi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66550&quot;>;深度学习中的后门：好处、坏人和丑人&lt;/a>;&lt;br />;组织者：&lt;strong>;Eugene Bagdasaryan&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/ Workshop/66549&quot;>;OPT 2023：机器学习优化&lt;/a>;&lt;br />; 组织者：&lt;strong>;Cristóbal Guzmán&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc /virtual/2023/workshop/66545&quot;>;机器学习促进创造力和设计&lt;/a>;&lt;br />;演讲者：&lt;strong>;Aleksander Holynski&lt;/strong>;、&lt;strong>;Alexander Mordvintsev&lt;/strong>; &lt;/p>; &lt; p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66511&quot;>;机器人学习研讨会：大规模模型的预训练、微调和泛化&lt;/a>;&lt;br />;演讲者： &lt;strong>;Matt Barnes&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66516&quot;>;音频机器学习&lt;/a>;&lt;br />;组织者：&lt;strong>;Shrikanth Narayanan&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66531&quot;>;基础模型时代的联邦学习&lt;/ a>; (FL@FM-NeurIPS&#39;23)&lt;br />; 演讲嘉宾：&lt;strong>;谢卓瑞&lt;/strong>;、&lt;strong>;徐峥&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot; https://nips.cc/virtual/2023/workshop/66526&quot;>;社会责任语言建模研究&lt;/a>; (SoLaR)&lt;br />;小组成员：&lt;strong>;Vinodkumar Prabhakaran&lt;/strong>; &lt;/p>; &lt;p >; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66506&quot;>;我不敢相信这不是更好（ICBINB）：基础模型时代的失败模式&lt;/a>;&lt;br / >; 顾问委员会：&lt;strong>;Javier Antorán&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66501&quot;>;系统机器学习&lt;/a>; &lt;br />; 主办方：&lt;strong>;王亚文&lt;/strong>;&lt;br />; 竞赛组委会：&lt;strong>;Bryan Perozzi&lt;/strong>;、&lt;strong>;Sami Abu-el-haija&lt;/strong>;&lt;br />; 指导委员会：&lt;strong>;Milad Hashemi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66514&quot;>;自我监督学习：理论与实践&lt;/ a>;&lt;br />; 组织者：&lt;strong>;Mathilde Caron&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/workshop/66496&quot;>;将模型行为归因于比例&lt;/a>; (ATTRIB 2023)&lt;br />; 组织者：Kevin Guu*、Tolga Bolukbasi* &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/ div>; &lt;h2>;竞赛&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/competition/66581&quot;>;NeurIPS 2023机器遗忘竞赛&lt;/a>;&lt;br />; 组织者：&lt;b>;Isabelle Guyon&lt;/b>;、&lt;strong>;Peter Kairouz&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips. cc/virtual/2023/competition/66593&quot;>;Lux AI 挑战赛第二季 NeurIPS 版&lt;/a>;&lt;br />; 组织者：&lt;strong>;Bovard Doerschuk-Tiberi&lt;/strong>;、&lt;strong>;Addison Howard&lt;/strong>; &lt; /p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;教程&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/tutorial/73949&quot;>;以数据为中心的人工智能，打造可靠且负责任的人工智能：从理论到实践&lt;/a>;&lt;br />; &lt;strong>; Isabelle Guyon&lt;/strong>;、Nabeel Seedat、Mihaela va der Schaar &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;创意 AI 赛道&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; 创意人工智能表演 1 和 20px 2&lt;br />; 演讲者：&lt;strong>;Erin Drake Kajioka&lt;/strong>;、&lt;strong>;Yonatan Bitton&lt;/strong>;&lt;br />; 组织者：&lt;strong>;Isabelle Guyon&lt;/strong>;&lt;br />; &lt;em>;&lt; a href=&quot;https://nips.cc/virtual/2023/session/74093&quot;>;性能 1&lt;/a>;：12 月 11 日星期一 |下午 6:30 - 晚上 8:30，大堂舞台&lt;/em>;&lt;br />; &lt;em>;&lt;a href=&quot;https://nips.cc/virtual/2023/session/74094&quot;>;表演 2&lt;/a>;： 12 月 14 日，星期四 | 7:00PM - 9:00PM，大堂舞台&lt;/em>; &lt;/p>; &lt;p>; 创意人工智能会议 1 – 3&lt;br />; 演讲者：&lt;strong>;Erin Drake Kajioka&lt;/strong>;、&lt;strong>;Yonatan Bitton&lt; /strong>;&lt;br />; 组织者：&lt;strong>;Isabelle Guyon&lt;/strong>;&lt;br />;&lt;em>;&lt;a href=&quot;https://nips.cc/virtual/2023/session/74090&quot;>;会议 1&lt; /a>;：12 月 12 日，星期二 |下午 3:05 - 3:40，D2 厅&lt;/em>;&lt;br />;&lt;em>;&lt;a href=&quot;https://nips.cc/virtual/2023/session/74091&quot;>;会议 2&lt;/a>;： 12 月 13 日，星期三 |上午 10:45 - 下午 2:15，D2 厅&lt;/em>;&lt;br />;&lt;em>;&lt;a href=&quot;https://nips.cc/virtual/2023/session/74092&quot;>;第 3 场会议&lt;/a>;： 12 月 14 日，星期四 |上午 10:45 - 下午 2:15，D2 厅&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/virtual/2023/session/75889&quot;>;创意 AI 视频&lt;/a >;&lt;br />; 主办方：&lt;strong>;Isabelle Guyon&lt;/strong>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;博览会讲座&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://nips.cc/Expo/Conferences/2023/talk%20panel/78252&quot;>;图学习会面人工智能&lt;/a>;&lt;br />;演讲者：&lt;strong>;Bryan Perozzi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://nips.cc/Expo/Conferences/2023/talk%20panel /78243&quot;>;共鸣器：音乐空间&lt;/a>;&lt;br />;演讲者：&lt;strong>;Erin Drake Kajioka&lt;/strong>;、&lt;strong>;Michal Todorovic&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot; https://nips.cc/Expo/Conferences/2023/talk%20panel/78237&quot;>;Empirical Rigor in ML as a Massively Parallelizable Challenge&lt;/a>;&lt;br />; Speaker: &lt;strong>;Megan Risdal (Kaggle)&lt;/ strong>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;口头演讲&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=sW8yGZ4uVJ&quot;>;基于有序条件的策略梯度方法全局收敛&lt;/a>;&lt;br />; 梅金成，博Dai，&lt;strong>;Alekh Agarwal&lt;/strong>;，&lt;strong>; &lt;/strong>;Mohammad Ghavamzadeh*，Csaba Szepesvari，Dale Schuurmans &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum? id=y8UAQQHVTX&quot;>;私人永恒预测&lt;/a>;&lt;br />; Moni Naor、Kobbi Nissim、&lt;strong>;Uri Stemmer&lt;/strong>;、Chao Yan &lt;/p>; &lt;p>; &lt;a href=&quot;https:// openreview.net/forum?id=PITeSdYQkv&quot;>;用户级差异隐私，每个用户的示例很少&lt;/a>;&lt;br />; &lt;strong>;Badih Ghazi&lt;/strong>;、&lt;strong>;Pritish Kamath&lt;/strong>;、&lt; strong>;Ravi Kumar&lt;/strong>;、&lt;strong>;Pasin Manurangsi&lt;/strong>;、Raghu Meka、&lt;strong>;张驰远&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net /forum?id=dVaWCDMBof&quot;>;DataComp：寻找下一代多模态数据集&lt;/a>;&lt;br />; Samir Yitzhak Gadre、Gabriel Ilharco、Alex Fang、Jonathan Hayase、Georgios Smyrnis、Thao Nguyen、Ryan Marten、Mitchell Wortsman、Dhruba Ghosh、张洁宇、Eyal Orgad、Rahim Entezari、Giannis Daras、Sarah Pratt、Vivek Ramanujan、Yonatan Bitton、Kalyani Marathe、Stephen Mussmann、Richard Vencu、Mehdi Cherti、Ranjay Krishna、Pang Wei Koh&lt;/strong >;、Olga Saukh、Alexander Ratner、Shuran Song、Hannaneh Hajishirzi、Ali Farhadi、Romain Beaumont、Sewoong Oh、Alex Dimakis、Jenia Jitsev、Yair Carmon、Vaishaal Shankar、Ludwig Schmidt &lt;/p>; &lt;p>; &lt;a href=&quot;https ://openreview.net/forum?id=w116w62fxH&quot;>;可实现回归的最佳学习者：PAC 学习和在线学习&lt;/a>;&lt;br />; Idan Attias、Steve Hanneke、Alkis Kalavasis、&lt;strong>;Amin Karbasi&lt;/strong >;, Grigoris Velegkas &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=jDIlzSU8wJ&quot;>;扩散模型对于光流和单目深度估计的惊人有效性&lt;/a>;&lt;br />; Saurabh Saxena、&lt;strong>;Charles Herrmann&lt;/strong>;、&lt;strong>;Junhwa Hur&lt;/strong>;、&lt;strong>;Abhishek Kar&lt;/strong>;、&lt;strong>; &lt;/strong>;Mohammad Norouzi*、&lt;strong>;德清太阳&lt;/strong>;，&lt;strong>; &lt;/strong>;大卫·J·弗利特 &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;期刊轨道&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://jmlr.org/papers/v24/20-998.html&quot;>;使用图进行图聚类神经网络&lt;/a>;&lt;br />; &lt;strong>;Anton Tsitsulin&lt;/strong>;、&lt;strong>;John Palowitch&lt;/strong>;、&lt;strong>;Bryan Perozzi&lt;/strong>;、Emmanuel Müller &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;聚焦论文&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href =&quot;https://openreview.net/forum?id=1p6teT6F73&quot;>;高效变压器的交替更新&lt;/a>;（请参阅博客文章）&lt;br />; &lt;strong>;Cenk Baykal&lt;/strong>;、&lt;strong>;Dylan Cutler &lt;/strong>;、&lt;strong>;Nishanth Dikkala&lt;/strong>;、Nikhil Ghosh*、&lt;strong>;Rina Panigrahy&lt;/strong>;、&lt;strong>;王鑫&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot; https://openreview.net/forum?id=EldbUlZtbd&quot;>;Does Localization Inform Editing?语言模型中基于因果关系的本地化与知识编辑的惊人差异&lt;/a>;&lt;br />; &lt;strong>;Peter Hase&lt;/strong>;、Mohit Bansal、&lt;strong>;Been Kim&lt;/strong>;、&lt;strong>; Asma Ghandeharioun &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=jR2FkqW6GB&quot;>;在游戏中学习对学习者有好处吗？&lt;/a>;&lt;br />; William Brown ,&lt;strong>; Jon Schneider&lt;/strong>;,&lt;strong>; Kiran Vodrahalli&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=Bj1QSgiBPP&quot;>;参与式个性化分类&lt;/a>;&lt;br />; Hailey Joren、&lt;strong>;Chirag Nagpal&lt;/strong>;、&lt;strong>;Katherine Heller&lt;/strong>;、&lt;strong>; &lt;/strong>;Berk Ustun &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=c2eedxSlPJ&quot;>;可分离数据上梯度下降的严格风险界限&lt;/a>;&lt;br />; Matan Schliserman，&lt;strong>;Tomer Koren&lt;/strong>; &lt;/p >; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=67o9UQgTD0&quot;>;神经语言模型中的反事实记忆&lt;/a>;&lt;br />; &lt;strong>;张驰远&lt;/strong>;,&lt;strong >; &lt;/strong>;Daphne Ippolito、Katherine Lee、Matthew Jagielski、Florian Tramèr、Nicholas Carlini &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=5NxJuc0T1P&quot;>;Debias Coarsely，示例有条件地：通过最优输运和概率扩散模型进行统计降尺度&lt;/a>;&lt;br />; &lt;strong>;万忠一&lt;/strong>;、Ricardo Baptista、&lt;strong>; Anudhyan Boral&lt;/strong>;、&lt;strong>;陈一凡&lt;/strong>;,&lt;strong>;约翰·安德森&lt;/strong>;,&lt;strong>;沙飞&lt;/strong>;,&lt;strong>; &lt;/strong>;&lt;strong>;莱昂纳多·泽佩达-努涅斯&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=vTug54Uunq&quot;>;通用优化方法的更快利润最大化&lt;/a>;&lt;br />;Guanghui Wang、Zihao Hu、Vidya Muthukumar、&lt;strong>;Jacob Abernethy &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=3PjCt4kmRx&quot;>;从像素到 UI 操作：学习通过图形用户界面遵循说明&lt;/a>;&lt; br />; Peter Shaw、Mandar Joshi、&lt;strong>;James Cohan&lt;/strong>;、&lt;strong>; &lt;/strong>;Jonathan Berant、Panupong Pasupat、胡鹤翔、Urvashi Khandelwal、Kenton Lee、Kristina N Toutanova &lt;/p>; &lt;p >; &lt;a href=&quot;https://openreview.net/forum?id=5Gw9YkJkFF&quot;>;PAC 根据标签比例学习线性阈值&lt;/a>;&lt;br />; &lt;strong>;Anand Brahmbhatt&lt;/strong>;、&lt;strong>; Rishi Saket&lt;/strong>;,&lt;strong>; Aravindan Raghuveer&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=CXPUg86A1D&quot;>;SPAE：用于多模式生成的语义金字塔自动编码器与冻结法学硕士&lt;/a>;&lt;br />;于丽君*、&lt;strong>;程勇&lt;/strong>;、&lt;strong>; &lt;/strong>;王志若、&lt;strong>;Vivek Kumar&lt;/strong>;、&lt;strong>; Wolfgang Macherey &lt;/strong>;、&lt;strong>;黄艳萍&lt;/strong>;、&lt;strong>;大卫·罗斯&lt;/strong>;、&lt;strong>;伊尔凡·埃萨&lt;/strong>;、&lt;strong>; &lt;/strong>;Yonatan Bisk、&lt;strong>;明-宣扬&lt;/strong>;、&lt;strong>;凯文·墨菲&lt;/strong>;、&lt;strong>; &lt;/strong>;亚历山大·豪普特曼、&lt;strong>;陆江&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https: //openreview.net/forum?id=QatZNssk7T&quot;>;平衡对抗模型中的自适应数据分析&lt;/a>;&lt;br />; Kobbi Nissim，&lt;strong>; Uri Stemmer&lt;/strong>;，&lt;strong>; &lt;/strong>;Eliad Tsfadia &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=NiQTy0NW1L&quot;>;Lexinvariant 语言模型&lt;/a>;&lt;br/>;Qian Huang、Eric Zelikman、Sarah Chen、&lt;strong >; Yuhuai Wu&lt;/strong>;、Gregory Valiant、Percy Liang &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=HF6bnhfSqH&quot;>;论量子反向传播、信息重用和作弊测量折叠&lt;/a>;&lt;br />; &lt;strong>;阿米拉·阿巴斯&lt;/strong>;、&lt;strong>; &lt;/strong>;罗比·金、黄心源、&lt;strong>;威廉·J·哈金斯&lt;/strong>;、&lt;strong>;雷米斯莫瓦萨格、&lt;strong>;达尔吉尔博亚&lt;/strong>;、&lt;strong>;&lt;/strong>;&lt;strong>;贾罗德·麦克林&lt;/strong>;&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview. net/forum?id=Pya0kCEpDk&quot;>;随机块模型和混合模型的私有估计算法&lt;/a>;&lt;br />;陈宏杰，&lt;strong>; Vincent Cohen-Addad&lt;/strong>;，&lt;strong>; &lt;/strong>;Tommaso d&#39;Orsi、&lt;strong>; Alessandro Epasto&lt;/strong>;、Jacob Imola、David Steurer、Stefan Tiegel &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=DBz9E5aZey&quot;>;可证明通过虚拟粒子随机逼近的 SVGD 快速有限粒子变体&lt;/a>;&lt;br />; &lt;strong>;Aniket Das&lt;/strong>;、&lt;strong>;Dheeraj Nagaraj&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot; https://openreview.net/forum?id=e0pRF9tOtm&quot;>;重新审视私人（随机）非凸优化：二阶平稳点和过度风险&lt;/a>;&lt;br />; &lt;strong>;Arun Ganesh&lt;/strong>; ,&lt;strong>; &lt;/strong>;刘道高*、Sewoong Oh、Abhradeep Guha Thakurta &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=bKqrWLCMrX&quot;>;揭示视频分布变化下的自监督学习&lt;/a>;&lt;br />; Pritam Sarkar，&lt;strong>;Ahmad Beirami&lt;/strong>;，&lt;strong>;Ali Etemad&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot; https://openreview.net/forum?id=ikkdTD3hQJ&quot;>;AIMS：无所不包的多层次细分&lt;/a>;&lt;br />; Lu Qi, Jason Kuen, Weidong Gui, Jiuxiang Gu, Zhe Lin, Bo杜宇旭、&lt;strong>;杨明轩&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=rheCTpRrxI&quot;>;DreamHuman：来自文本的可动画 3D 头像&lt;/a>;&lt;br />; &lt;strong>;尼科斯·科洛图罗斯&lt;/strong>;、&lt;strong>;蒂莫·阿尔迪克&lt;/strong>;、&lt;strong>;安德烈·赞菲尔&lt;/strong>;、&lt;strong>;爱德华·加布里埃尔·巴扎万&lt;/strong>;、&lt; strong>;Mihai Fieraru&lt;/strong>;、&lt;strong>;Cristian Sminchisescu&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=oaCDiKoJ2w&quot;>;后续行动也很重要: 通过任职后情境改善情境强盗&lt;/a>;&lt;br />;王超奇、叶子宇、&lt;strong>;冯哲&lt;/strong>;、&lt;strong>;Ashwinkumar Badanidiyuru&lt;/strong>;、徐海峰&lt;/p>; &lt; p>; &lt;a href=&quot;https://openreview.net/forum?id=m21rQusNgb&quot;>;学习用于排名的列表级域不变表示&lt;/a>;&lt;br />; 西安睿成*，&lt;strong>;庄红雷&lt; /strong>;、&lt;strong>;秦珍&lt;/strong>;、Hamed Zamani*、&lt;strong>;路静&lt;/strong>;、&lt;strong>;吉马&lt;/strong>;、&lt;strong>;凯辉&lt;/strong>;、韩昭, &lt;strong>;Xuanhui Wang&lt;/strong>;, &lt;strong>;Michael Bendersky&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=hCdqDkA25J&quot;>;最优保证凸优化中的算法再现性和梯度复杂性&lt;/a>;&lt;br />; 张亮，杨俊驰，&lt;strong>;Amin Karbasi&lt;/strong>;，鸟何&lt;/p>; &lt;p>; &lt;a href=&quot;https:// openreview.net/forum?id=hJzEoQHfCe&quot;>;统一嵌入：网络规模机器学习系统经过实战检验的特征表示&lt;/a>;&lt;br />; Benjamin Coleman、Wang-Cheng Kang、&lt;strong>;Matthew Fahrbach&lt;/strong>; ,&lt;strong>; &lt;/strong>;Ruoxi Wang、Lichan Hong、Ed Chi、Derek Cheng &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=xOJUmwwlJc&quot;>;接近通知校准深度神经网络&lt;/a>;&lt;br />; 熊苗、邓爱琳、&lt;strong>;Pang Wei Koh&lt;/strong>;、Jiaying Wu、Shen Li、Jianqing Xu、Bryan Hooi &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;论文&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https ://openreview.net/forum?id=WfsWy59bX2&quot;>;通过相似聚类进行匿名学习：模型泛化的精确分析&lt;/a>;&lt;br />; &lt;strong>;Adel Javanmard&lt;/strong>;,&lt;strong>; Vahab Mirrokni&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=EUiIbwV379&quot;>;通过更好的私有特征选择实现更好的私有线性回归&lt;/a>;&lt;br />; &lt;特拉维斯·迪克，詹妮弗·吉伦沃特*，马修·约瑟夫&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=XAyPlfmWpu&quot;>;二值化神经机器翻译&lt;/a>;&lt;br />; 张一驰、Ankush Garg、曹元、&lt;strong>;Łukasz Lew&lt;/strong>;、Behrooz Ghorbani*、张志如、Orhan Firat &lt;/p>; &lt;p>; &lt;a href= &quot;https://nips.cc/virtual/2023/poster/73665&quot;>;BoardgameQA：具有矛盾信息的自然语言推理数据集&lt;/a>;&lt;br />; &lt;strong>;Mehran Kazemi&lt;/strong>;，&lt;strong>;袁泉&lt;/strong>;、&lt;strong>;Deepti Bhatia&lt;/strong>;、&lt;strong>;Najoung Kim&lt;/strong>;、&lt;strong>;徐鑫&lt;/strong>;、&lt;strong>;Vaiva Imbrasaite&lt;/strong>;、&lt;strong>; Deepak Ramachandran&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=1vvsIJtnnr&quot;>;通过缓和的指数测量进行提升&lt;/a>;&lt;br />; &lt;strong>;Richard诺克，&lt;strong>; &lt;/strong>;埃桑·阿米德，&lt;strong>;曼弗雷德·沃穆斯&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=SGlrCuwdsB &quot;>;（基于分数的）文本控制生成模型的概念代数&lt;/a>;&lt;br />; Zihao Wang，Lin Gui，Jeffrey Negrea，&lt;strong>;Victor Veitch&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=q8mH2d6uw2&quot;>;通过不连续网络进行深度合约设计&lt;/a>;&lt;br />; Tonghan Wang、&lt;strong>;Paul Dütting&lt;/strong>;、Dmitry Ivanov、Inbal Talgam -Cohen，David C. Parkes &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=YoghyvSG0H&quot;>;Diffusion-SS3D：半监督 3D 物体检测的扩散模型&lt;/a >;&lt;br />; 何正如、戴振轩、林彦雨、&lt;strong>;杨明轩&lt;/strong>;、&lt;strong>;蔡艺轩&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=PYASzxr2OP&quot;>;通过比较反馈获取用户偏好以进行个性化多目标决策&lt;/a>;&lt;br />; Han Shao、Lee Cohen、Avrim Blum、 &lt;strong>;Yshay Mansour&lt;/strong>;、Aadirupa Saha、Matthew Walter &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=qCglMj6A4z&quot;>;线性相关噪声的梯度下降：理论差异隐私及其应用&lt;/a>;&lt;br />; Anastasia Koloskova*、&lt;strong>;Ryan McKenna&lt;/strong>;、&lt;strong>;Zachary Charles&lt;/strong>;、&lt;strong>;J Keith Rush&lt;/strong>;、&lt;strong >;Hugh Brendan McMahan&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=LCwToX315b&quot;>;Entrywise 变换矩阵乘积的低秩近似的难度&lt;/a>;&lt; br />; &lt;strong>;Tamas Sarlos&lt;/strong>;、&lt;strong>; &lt;/strong>;宋星友、David P. Woodruff、张秋仪 &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview .net/forum?id=JhQP33aMx2&quot;>;多模态基础模型的逐模块自适应蒸馏&lt;/a>;&lt;br />;&lt;br />; 陈亮，&lt;strong>;于家辉&lt;/strong>;，&lt;strong>;明轩杨&lt;/strong>;、&lt;strong>;Matthew Brown&lt;/strong>;、崔寅、赵拓、&lt;strong>;宫伯清&lt;/strong>;、周天一&lt;/p>; &lt;p>; &lt;a href=&quot;https:// openreview.net/forum?id=zGRWp7yRqd&quot;>;多重交换 k-Means++&lt;/a>;&lt;br />; Lorenzo Beretta、&lt;strong>;Vincent Cohen-Addad&lt;/strong>;、&lt;strong>;Silvio Lattanzi&lt;/strong>;、 &lt;strong>; Nikos Parotsidis&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=8vuDHCxrmy&quot;>;OpenMask3D：开放词汇 3D 实例分割&lt;/a>;&lt;br />; Ayça Takmaz、Elisabetta Fedele、Robert Sumner、Marc Pollefeys、&lt;strong>;Federico Tombari&lt;/strong>;、&lt;strong>;Francis Engelmann&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview .net/forum?id=7RMGI4slcb&quot;>;多语言学习中数据集不平衡的情况下的顺序问题&lt;/a>;&lt;br />; Dami Choi*, &lt;strong>;Derrick Xin&lt;/strong>;, &lt;strong>;Hamid Dadkhahi&lt;/a>;&lt;br />;强>;、Justin Gilmer、Ankush Garg、Orhan Firat、Chih-Kuan Yeh、Andrew M. Dai、Behrooz Ghorbani &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=yEf8NSqTPu&quot; >;PopSign ASL v1.0：通过智能手机收集的独立美国手语数据集&lt;/a>;&lt;br />; Thad Starner、Sean Forbes、Matthew So、David Martin、Rohit Sridhar、Gururaj Deshpande、&lt;strong>;Sam Sepah&lt;/strong >;、Sahir Shahryar、Khushi Bhardwaj、Tyler Kwok、Daksh Sehgal、Saad Hassan、Bill Neubauer、Sofia Vempala、Alec Tan、Jocelyn Heath、Unnathi Kumar、Priyanka Mosur、Tavenner Hall、Rajandeep Singh、Christopher Cui、&lt;strong>;Glenn Cameron&lt; /strong>;、&lt;strong>;索希尔·戴恩&lt;/strong>;、&lt;strong>;加勒特·坦泽&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=gaktiSjatl&quot;>;半隐式去噪扩散模型（SIDDM）&lt;/a>;&lt;br />; 徐彦武*、龚明明、谢少安、&lt;strong>;魏伟&lt;/strong>;、&lt;strong>; Matthias Grundmann&lt;/strong>;、&lt;strong>; &lt;/strong>;Kayhan Batmanghelich，&lt;strong>;侯廷波&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=xGz0wAIJrS&quot;>;State2Explanation：基于概念的解释有益于代理学习和用户理解&lt;/a>;&lt;br />; Devleena Das、Sonia Chernova、&lt;strong>;Been Kim&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum ?id=AwhpBEqmyo&quot;>;StoryBench：连续故事可视化的多方面基准&lt;/a>;&lt;br />; Emanuele Bugliarello*、Hernan Moraldo、Ruben Villegas、Mohammad Babaeizadeh、Mohammad Taghi Saffar、Han Zhang、Dumitru Erhan、&lt;strong>; Vittorio Ferrari&lt;/strong>;、Pieter-Jan Kindermans、&lt;strong>;Paul Voigtlaender&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=wv3bHyQbX7&quot;>;主题驱动通过学徒学习实现文本到图像生成&lt;/a>;&lt;br />;陈文虎、胡鹤翔、&lt;strong>;李彦东&lt;/strong>;、&lt;strong>;Nataniel Ruiz&lt;/strong>;、&lt;strong>;贾旭辉&lt;/strong>; strong>;、Ming-Wei Chang、William W. Cohen &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=plAix1NxhU&quot;>;TpuGraphs：大张量计算图上的性能预测数据集&lt;/a>;&lt;br />; &lt;strong>;Phitchaya Mangpo Phothilimthana&lt;/strong>;、&lt;strong>;Sami Abu-El-Haija&lt;/strong>;、Kaidi Cao*、&lt;strong>;Bahare Fatemi&lt;/strong>;、&lt;strong>; Mike Burrows&lt;/strong>;、Charith Mendis*、&lt;strong>;Bryan Perozzi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=a147pIS2Co&quot;>;培训链-通过潜在变量推理进行思想&lt;/a>;&lt;br />; &lt;strong>;Du Phan&lt;/strong>;、&lt;strong>;Matthew D. Hoffman&lt;/strong>;、David Dohan*、Sholto Douglas、&lt;strong>; Tuan Anh Le&lt;/strong>;、Aaron Parisi、&lt;strong>;Pavel Sountsov&lt;/strong>;、Charles Sutton、Sharad Vikram、&lt;strong>; Rif A. Saurous&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https: //openreview.net/forum?id=1ZzG6td0el&quot;>;信息约束下交互式高维估计的统一下界&lt;/a>;&lt;br />; Jayadev Acharya, Clement L. Canonne, &lt;strong>;孙子腾&lt;/strong>; , Himanshu Tyagi &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=j5AoleAIru&quot;>;所见即所读？改进文本-图像对齐评估&lt;/a>;&lt;br />; &lt;strong>;Michal Yarom&lt;/strong>;、&lt;strong>;Yonatan Bitton&lt;/strong>;、&lt;strong>;Soravit Changpinyo&lt;/strong>;、&lt;strong>;Roee Aharoni&lt; /strong>;、&lt;strong>;乔纳森·赫齐格&lt;/strong>;、&lt;strong>;奥兰·朗&lt;/strong>;、&lt;strong>;&lt;/strong>;&lt;strong>;埃兰·奥菲克&lt;/strong>;、&lt;strong>;伊丹·斯佩克托&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=4KZhZJSPYU&quot;>;什么时候基于置信度的级联延迟就足够了？&lt;/a>;&lt;br />; &lt;strong>;Wittawat Jitkrittum&lt; /strong>;、&lt;strong>;内哈·古普塔&lt;/strong>;、&lt;strong>;阿迪亚·克里希纳·梅农&lt;/strong>;、&lt;strong>;Harikrishna Narasimhan&lt;/strong>;、&lt;strong>;安基特·辛格·拉瓦特&lt;/strong>;、&lt;strong>;Sanjiv Kumar&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=A18PgVSUgf&quot;>;通过知识蒸馏加速分子图神经网络&lt;/a>;&lt;br />; Filip Ekström Kelvinius、Dimitar Georgiev、Artur Petrov Toshev、&lt;strong>;Johannes Gasteiger&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=7EMphtUgCI&quot;>;AVIS：自主视觉信息使用大语言模型智能体进行搜索&lt;/a>;&lt;br />;胡紫牛*、&lt;strong>;Ahmet Iscen&lt;/strong>;、&lt;strong>;孙晨&lt;/strong>;、张凯伟、孙一舟、&lt;strong>;David罗斯&lt;/strong>;、&lt;strong>;科迪莉亚·施密德&lt;/strong>;、&lt;strong>;阿里雷扎·法蒂&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=9mJXDcr17V &quot;>;超越不变性：解决“虚假”相关性的测试时标签转移适应&lt;/a>;&lt;br />; Qingyao Sun、Kevin Patrick Murphy、&lt;strong>;Sayna Ebrahimi&lt;/strong>;、Alexander D&#39;Amour &lt;/p >; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=0tEjORCGFD&quot;>;协作分数蒸馏以实现一致的视觉编辑&lt;/a>;&lt;br />; Subin Kim、Kyungmin Lee、June Suk Choi、Jongheon Jeong、&lt;strong>;Kihyuk Sohn&lt;/strong>;、Jinwoo Shin&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=1SF2tiopYJ&quot;>;CommonScenes：使用 Scene 生成常识性 3D 室内场景图表&lt;/a>;&lt;br />;Guangyao Zhai、Evin Pınar Örnek、Shun-Cheng Wu、Yan Di、&lt;strong>;Federico Tombari&lt;/strong>;、Nassir Navab、Benjamin Busam &lt;/p>; &lt;p>; &lt;a href= &quot;https://openreview.net/forum?id=65aDEXIhih&quot;>;学习神经网络的计算复杂性：平滑性和简并性&lt;/a>;&lt;br />; &lt;strong>;Amit Daniely&lt;/strong>;、Nathan Srebro、Gal Vardi &lt; /p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=BopG5dhH7L&quot;>;一种计算高效的稀疏在线牛顿法&lt;/a>;&lt;br />; Fnu Devvrit*, Sai Surya Duvvuri,&lt; &lt;/strong>;Rohan Anil、&lt;strong>;Vineet Gupta&lt;/strong>;、&lt;strong>;谢卓瑞&lt;/strong>;、&lt;strong>;Inderjit S Dhillon&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=6EDHfVHicP&quot;>;DDF-HO：基于条件定向距离场的手持物体重建&lt;/a>;&lt;br />; 张晨阳光，严迪，张瑞达，光耀翟，&lt;strong>;Fabian Manhardt&lt;/strong>;，&lt;strong>;Federico Tombari&lt;/strong>;，纪向阳&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=2nTpPxJ5Bs&quot; >;双向强盗反馈的双重拍卖&lt;/a>;&lt;br />; &lt;strong>;Soumya Basu&lt;/strong>;，Abiishek Sankararaman &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/abs /2305.19234&quot;>;使用大型语言模型生成特定领域语言的语法提示&lt;/a>;&lt;br />;Bailin Wang, Zi Wang, Xuzhi Wang, &lt;strong>;Yuan Cao&lt;/strong>;, Rif A. Saurous, Yoon Kim &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=5SIz31OGFV&quot;>;深度神经网络训练的不一致、不稳定和泛化差距&lt;/a>;&lt;br />; Rie Johnson，张桐* &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=3YDukx2cpr&quot;>;通过图段训练进行大图属性预测&lt;/a>;&lt;br />;曹凯迪*, &lt;strong>;Phitchaya Mangpo Phothilimthana&lt;/strong>;、&lt;strong>;Sami Abu-El-Haija&lt;/strong>;、&lt;strong>;Dustin Zelle&lt;/strong>;、&lt;strong>;周艳琪&lt;/strong>;、&lt;strong>;&lt;/ strong>;Charith Mendis*、Jure Leskovec、&lt;strong>;Bryan Perozzi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=1GxKVprbwM&quot;>;关于计算成对统计量本地差异隐私&lt;/a>;&lt;br />; &lt;strong>;Badih Ghazi&lt;/strong>;、&lt;strong>;Pritish Kamath&lt;/strong>;、&lt;strong>;Ravi Kumar&lt;/strong>;、&lt;strong>;Pasin Manurangsi&lt;/strong>; , &lt;strong>;Adam Sealfon&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=7UdVPRmpif&quot;>;关于蒸馏中的师生偏差：不服从是否值得？ &lt;/a>;&lt;br />; &lt;strong>;Vaishnavh Nagarajan&lt;/strong>;、&lt;strong>;Aditya Krishna Menon&lt;/strong>;、&lt;strong>;Srinadh Bhojanapalli&lt;/strong>;、&lt;strong>;Hossein Mobahi&lt;/strong>;、 &lt;strong>;Sanjiv Kumar&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=CzkOzKWpMa&quot;>;具有未知上下文分布的上下文强盗的最佳交叉学习&lt;/a >;&lt;br />; &lt;strong>;乔恩·施奈德&lt;/strong>;、&lt;strong>;朱利安·齐默特&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=8XRMbNAP6Z&quot; >;滑动窗口模型中的近最优 k 聚类&lt;/a>;&lt;br />; David Woodruff、&lt;strong>;钟培林&lt;/strong>;、Samson Zhou &lt;/p>; &lt;p>; &lt;a href=&quot;https:/ /openreview.net/forum?id=3H37XciUEv&quot;>;语言模型的事后解释可以改进语言模型&lt;/a>;&lt;br />; Satyapriya Krishna、Jiaqi Ma、Dylan Z Slack、&lt;strong>;Asma Ghandeharioun&lt;/strong>;、 Sameer Singh，Himabindu Lakkaraju &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=BJ0fQUU32w&quot;>;具有生成检索的推荐系统&lt;/a>;&lt;br />; Shashank Rajput*&lt;strong >;、&lt;/strong>;Nikhil Mehta、Anima Singh、&lt;strong>;Raghunandan Hulikal Keshavan&lt;/strong>;、&lt;strong>;Trung Vu、Lukasz Heldt&lt;/strong>;、&lt;strong>; &lt;/strong>;Lichan Hong、Yi Tay&lt;strong>; >;、Vinh Q. Tran&lt;/strong>;、&lt;strong>;Jonah Samost&lt;/strong>;、Maciej Kula、Ed H. Chi、Maheswaran Sathiamoorthy &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net /forum?id=8OTPepXzeh&quot;>;用于微调文本到图像扩散模型的强化学习&lt;/a>;&lt;br />; &lt;strong>;范颖&lt;/strong>;、Olivia Watkins、杜雨晴、刘浩、&lt;strong >;Moonkyung Ryu&lt;/strong>;、&lt;strong>;Craig Boutilier&lt;/strong>;、Pieter Abbeel、Mohammad Ghavamzadeh*、Kangwook Lee、Kimin Lee* &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net /forum?id=5VQFAvUHcd&quot;>;可复制集群&lt;/a>;&lt;br />; &lt;strong>;Hossein Esfandiari&lt;/strong>;、&lt;strong>;Amin Karbasi&lt;/strong>;、&lt;strong>;Vahab Mirrokni&lt;/strong>;、Grigoris Velegkas , Felix Zhou &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=5cPz5hrjy6&quot;>;强化学习的可复制性&lt;/a>;&lt;br />; &lt;strong>;Amin Karbasi&lt;/strong >;、Grigoris Velegkas、林杨、Felix Zhou&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=szFqlNRxeS&quot;>;黎曼投影免费在线学习&lt;/a>;&lt;br / >; Zihao Hu、Guanghui Wang、&lt;strong>;Jacob Abernethy&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=29WbraPk8U&quot;>;锐度感知最小化导致低-排名特征&lt;/a>;&lt;br />; Maksym Andriushchenko、&lt;strong>;Dara Bahri&lt;/strong>;、&lt;strong>;Hossein Mobahi&lt;/strong>;、Nicolas Flammarion &lt;/p>; &lt;p>; &lt;a href=&quot;https: //openreview.net/forum?id=2hQ7MBQApp&quot;>;什么是平坦度正则化的归纳偏差？深度矩阵分解模型研究&lt;/a>;&lt;br />;Khashayar Gatmiry、李志远、庄庆耀、&lt;strong>;Sashank Reddi&lt;/strong>;、马腾宇、Stefanie Jegelka&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=JzQlGqBm8d&quot;>;具有随机优化共享基础的块低阶预处理器&lt;/a>;&lt;br />; Jui-Nan Yen、Sai Surya Duvvuri、&lt;strong>;Inderjit S Dhillon&lt;/strong>;、&lt;strong>;Cho-Jui Hsieh&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=Ntd6X7uWYF&quot;>;阻止合作匪徒：在线具有每项预算约束的协作过滤&lt;/a>;&lt;br />; &lt;strong>;Soumyabrata Pal&lt;/strong>;、&lt;strong>;Arun Sai Suggala&lt;/strong>;、&lt;strong>;Karthikeyan Shanmugam&lt;/strong>;、&lt;strong>; Prateek Jain&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=NIrTSCiIZ7&quot;>;具有扩散模型的边界引导无学习语义控制&lt;/a>;&lt;br / >; 叶朱、吴宇、&lt;strong>;邓志伟&lt;/strong>;、Olga Russakovsky、严岩&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=IyYyKov0Aj&quot;>;有条件适配器：具有快速推理的参数高效迁移学习&lt;/a>;&lt;br />; 雷涛、&lt;strong>;Junwen Bai&lt;/strong>;、Siddhartha Brahma、&lt;strong>; Joshua Ainslie&lt;/strong>;、Kenton Lee、Yanqi Zhou、杜楠*、&lt;strong>;赵云&lt;/strong>;、&lt;strong>;吴跃新&lt;/strong>;、李波、&lt;strong>;张宇&lt;/strong>;、张明伟&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=KTRwpWCMsC&quot;>;利用现代 Hopfield 网络对时间序列进行共形预测&lt;/a>;&lt;br />; Andreas Auer、&lt;strong>;Martin Gauch&lt;/strong>;、 Daniel Klotz、Sepp Hochreiter &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=PzYAMXmIT3&quot;>;视觉预训练有助于端到端推理吗？&lt;/a>;&lt;br / >; &lt;strong>;孙晨&lt;/strong>;、罗志祥、&lt;strong>;周兴一&lt;/strong>;、&lt;strong>;Anurag Arnab&lt;/strong>;、&lt;strong>;Cordelia Schmid&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=PAYXfIUKWY&quot;>;针对不同训练数据的模型的自然分布变化的有效鲁棒性&lt;/a>;&lt;br />;周兴石*，&lt;strong>;Nicholas Carlini&lt; /strong>;、&lt;strong>;Ananth Balashankar&lt;/strong>;、Ludwig Schmidt、&lt;strong>;谢卓瑞&lt;/strong>;、Alex Beutel*、&lt;strong>;姚勤&lt;/strong>; &lt;/p>; &lt;p>; &lt; a href=&quot;https://openreview.net/forum?id=Nh5dp6Uuvx&quot;>;使用人类相似性判断改进神经网络表示&lt;/a>;&lt;br />; Lukas Muttenthaler*、Lorenz Linhardt、Jonas Dippel、Robert A. Vandereulen、 Katherine Hermann、Andrew K. Lampinen、Simon Kornblith &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=N6FhEMnxCU&quot;>;标记鲁棒且差分私有线性回归：计算和统计效率&lt; /a>;&lt;br />; 刘希阳、&lt;strong>;Prateek Jain&lt;/strong>;、&lt;strong>;孔伟豪&lt;/strong>;、&lt;strong>;Sewoong Oh&lt;/strong>;、&lt;strong>;Arun Sai Suggala&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=Fdfyga5i0A&quot;>;Mnemosyne：学习用 Transformer 训练 Transformer&lt;/a>;&lt;br />; Deepali Jain、Krzysztof Choromanski、&lt; strong>;Avinava Dubey&lt;/strong>;、Sumeet Singh、Vikas Sindhwani、Tingnan 张、Jie Tan &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=MCkUS1P3Sh&quot;>;纳什后悔保证线性强盗&lt;/a>;&lt;br />; Ayush Sawarni，&lt;strong>;Soumyabrata Pal&lt;/strong>;，Siddharth Barman &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/abs/2307.03043&quot; >;倒角距离的近线性时间算法&lt;/a>;&lt;br />; Ainesh Bakshi、Piotr Indyk、&lt;strong>;Rajesh Jayaram&lt;/strong>;、Sandeep Silwal、Erik Waingarten。 &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=FviF8vuz5B&quot;>;关于高斯分布和乘积分布的差分隐私采样&lt;/a>;&lt;br />; &lt;strong>;Badih Ghazi&lt; /strong>;, 小胡*, &lt;strong>;Ravi Kumar&lt;/strong>;, &lt;strong>;Pasin Manurangsi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id =LelK6Mfoey&quot;>;马尔可夫决策过程中静态风险度量的动态规划分解&lt;/a>;&lt;br />; Jia Lin Hau, Erick Delage, Mohammad Ghavamzadeh*, Marek Petrik &lt;/p>; &lt;p>; &lt;a href=&quot;https ://openreview.net/forum?id=HFQFAyNucq&quot;>;ResMem：学你能学的，记住其余的&lt;/a>;&lt;br />; Zitong Yang、&lt;strong>;Michal Lukasik&lt;/strong>;、&lt;strong>; Vaishnavh Nagarajan &lt;/strong>;、&lt;strong>;李宗林&lt;/strong>;、&lt;strong>;Ankit Singh Rawat&lt;/strong>;、&lt;strong>;Manzil Zaheer、&lt;/strong>;&lt;strong>;Aditya Krishna Menon&lt;/strong>;、&lt;strong>; Sanjiv Kumar&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=PcNpL9Q39p&quot;>;负责任的人工智能 (RAI) 游戏和集成&lt;/a>;&lt;br />; Yash Gupta、Runtian Zhai、&lt;strong>;Arun Suggala&lt;/strong>;、Pradeep Ravikumar &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=DVlawv2rSI&quot;>;RoboCLIP：一个演示就足够了学习机器人策略&lt;/a>;&lt;br />; Sumedh A Sontakke、Jesse Zhang、&lt;strong>;Sébastien MR Arnold&lt;/strong>;、Karl Pertsch、Erdem Biyik、Dorsa Sadigh、Chelsea Finn、Laurent Itti &lt;/p>; &lt;p >; &lt;a href=&quot;https://openreview.net/forum?id=I6aOjhpcNQ&quot;>;通过核化率失真最大化实现稳健的概念擦除&lt;/a>;&lt;br />; Somnath Basu Roy Chowdhury、Nicholas Monath、&lt;strong>;Kumar Avinava Dubey&lt;/strong>;、&lt;strong>;Amr Ahmed&lt;/strong>;、Sniigdha Chaturvedi &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=FmZVRe0gn8&quot;>;稳健的多代理基于对抗性正则化的强化学习：理论基础和稳定算法&lt;/a>;&lt;br />; Alexander Bukharin, Yan Li, Yue Yu, Qingru Zhu, &lt;strong>;Zhehui Chen&lt;/strong>;, Simiao Zuo, Chao Zhang, Songan Zhang,赵佗&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=PTvxck0QDE&quot;>;1 隐藏层神经网络中的简单性偏差&lt;/a>;&lt;br />; Depen Morwani*, Jatin Batra、&lt;strong>;Prateek Jain&lt;/strong>;、&lt;strong>; Praneeth Netrapalli&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/abs/2302.03806&quot;>;SLaM：学生- 与未标记示例进行蒸馏的标签混合&lt;/a>;&lt;br />; Vasilis Kontonis、&lt;strong>; Fotis Iliopoulos&lt;/strong>;、&lt;strong>;Khoa Trinh&lt;/strong>;、&lt;strong>;Cenk Baykal&lt;/strong>;、&lt; strong>;Gaurav Menghani&lt;/strong>;、&lt;strong>;Erik Vee&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=LCHmP68Gtj&quot;>;SNAP：自我监督用于视觉定位和语义理解的神经图&lt;/a>;&lt;br />; Paul-Edouard Sarlin*、&lt;strong>;Eduard Trulls&lt;/strong>;、Marc Pollefeys、&lt;strong>;Jan Hosang&lt;/strong>;、&lt;strong>;Simon Lynen &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=QvIvWMaQdX&quot;>;SOAR：改进了近似最近邻搜索的索引&lt;/a>;&lt;br />; &lt;strong >;Philip Sun&lt;/strong>;、&lt;strong>;David Simcha&lt;/strong>;、&lt;strong>;Dave Dopson&lt;/strong>;、&lt;strong>;郭瑞琪&lt;/strong>;、&lt;strong>;Sanjiv Kumar&lt;/strong>; &lt;/p >; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=KoaFh16uOc&quot;>;StyleDrop：任何样式的文本到图像合成&lt;/a>;&lt;br />; &lt;strong>;Kihyuk Sohn&lt;/ strong>;、&lt;strong>;蒋路&lt;/strong>;、&lt;strong>;贾里德·巴伯&lt;/strong>;、Kimin Lee*、&lt;strong>;纳塔尼尔·鲁伊斯&lt;/strong>;、&lt;strong>;迪利普·克里希南&lt;/strong>;、张慧文* ,&lt;strong>;李元珍&lt;/strong>;、&lt;strong>;伊尔凡·埃萨&lt;/strong>;、&lt;strong>;迈克尔·鲁宾斯坦&lt;/strong>;、&lt;strong>;郝元&lt;/strong>;、&lt;strong>;格伦·恩蒂斯&lt;/strong>; 、&lt;strong>;伊琳娜·布洛克&lt;/strong>;、&lt;strong>;丹尼尔·卡斯特罗·钦&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=LSYQB4CwD3&quot;>;三塔：使用预训练图像模型进行灵活对比学习&lt;/a>;&lt;br />; Jannik Kossen*,&lt;strong>;Mark Collier&lt;/strong>;,Basil Mustafa,Xiao Wang,Xiaohua Zhai,Lucas Beyer,Andreas Steiner,&lt;strong>;Jesse Berent &lt;/strong>;,&lt;strong>; &lt;/strong>;Rodolphe Jenatton，&lt;strong>; Efi Kokiopoulou&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=GIlsH0T4b2&quot; >;多位专家的两阶段延迟学习&lt;/a>;&lt;br />;毛安琪、Christopher Mohri、&lt;strong>;Mehryar Mohri&lt;/strong>;、钟玉涛&lt;/p>; &lt;p>; &lt;a href=&quot;https: //openreview.net/forum?id=ZBzYWP2Gpl&quot;>;AdANNS：自适应语义搜索框架&lt;/a>;&lt;br />; Aniket Rege、&lt;strong>;Aditya Kusupati&lt;/strong>;、Sharan Ranjit S、Alan Fan、Qingqing Cao、Sham Kakade、&lt;strong>;Prateek Jain&lt;/strong>;、Ali Farhadi &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=Srt1hhQgqa&quot;>;Cappy：超越并提升大型企业具有小评分器的多任务 LM&lt;/a>;&lt;br />; Bowen Tan*、&lt;strong>;Yun Zhu&lt;/strong>;、&lt;strong>;Lijuan Liu&lt;/strong>;、Eric Xing、Zhiting Hu、&lt;strong>;Jindong Chen&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=dJZ3MvDw86&quot;>;文本 OOD 泛化的因果结构驱动增强&lt;/a>;&lt;br />; &lt; strong>;Amir Feder&lt;/strong>;、Yoav Wald、Claudia Shi、Suchi Saria、David Blei &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=S0xrBMFihS&quot;>;稠密指数随机特征：高斯核的尖锐正估计&lt;/a>;&lt;br />; Valerii Likhosherstov、Krzysztof Choromanski、&lt;strong>;Avinava Dubey&lt;/strong>;、&lt;strong>;Frederick Liu&lt;/strong>;、&lt;strong>;Tamas Sarlos&lt; /strong>;, Adrian Weller &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=Vm1zeYqwdc&quot;>;扩散超特征：穿越时空搜索语义对应&lt;/a>;&lt;br />; Grace Luo、Lisa Dunlap、Dong Huk Park、&lt;strong>;Aleksander Holynski&lt;/strong>;、Trevor Darrell &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=qgv56R2YJ7&quot; >;用于可控图像生成的扩散自引导&lt;/a>;&lt;br />; &lt;strong>;Dave Epstein&lt;/strong>;、Allan Jabri、&lt;strong>;Ben Poole&lt;/strong>;、Alexei A Efros、&lt;strong>; Aleksander Holynski&lt; /strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=dnGEPkmnzO&quot;>;Õ(k) 更新时间的完全动态 k 聚类&lt;/a>;&lt;br />;萨扬·巴塔查亚 (Sayan Bhattacharya)、马丁·尼古拉斯·科斯塔 (Martin Nicolas Costa)、&lt;strong>;Silvio Lattanzi&lt;/strong>;、&lt;strong>;Nikos Parotsidis&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id= SVjDiiVySh&quot;>;通过语言重写改进 CLIP 训练&lt;/a>;&lt;br />; &lt;strong>;Lijie Fan&lt;/strong>;、&lt;strong>;Dilip Krishnan&lt;/strong>;、Phillip Isola、Dina Katabi、&lt;strong>;Yonglong Tian&lt;/strong>;强>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=UzUhiKACmS&quot;>;基于距离的隐私的 k 均值聚类&lt;/a>;&lt;br />; &lt;strong>;Alessandro Epasto&lt;/strong>;、&lt;strong>;Vahab Mirrokni&lt;/strong>;、Shyam Narayanan、&lt;strong>;钟培林&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum? id=Xu8aG5Q8M3&quot;>;LayoutGPT：大型语言模型的组合视觉规划和生成&lt;/a>;&lt;br />; Weixi Feng, Wanrong Zhu, Tsu-Jui Fu,&lt;strong>; Varun Jampani&lt;/strong>;, &lt;strong>;Arjun Reddy Akula&lt;/strong>;、何学海、&lt;strong>;Sugato Basu&lt;/strong>;、Xin Eric Wang、William Yang Wang &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id= SxXN3kNTsV&quot;>;用于专家混合对话管理的离线强化学习&lt;/a>;&lt;br />; Dhawal Gupta*、&lt;strong>;Yinlam Chow&lt;/strong>;、&lt;strong>; Azamat Tulepbergenov&lt;/strong>;、Mohammad Ghavamzadeh*、 &lt;strong>;Craig Bouutilier&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=aG6xOP9QY7&quot;>;用于标签差分隐私回归的最佳无偏随机发生器&lt;/a>;&lt; br />; &lt;strong>;Ashwinkumar Badanidiyuru&lt;/strong>;、&lt;strong>;Badih Ghazi&lt;/strong>;、&lt;strong>;Pritish Kamath&lt;/strong>;、&lt;strong>;Ravi Kumar&lt;/strong>;、&lt;strong>;Ethan Jacob Leeman&lt; /strong>;,&lt;strong>; &lt;/strong>;&lt;strong>;Pasin Manurangsi&lt;/strong>;, &lt;strong>;Avinash V Varadarajan&lt;/strong>;, &lt;strong>;张驰远&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=WbFhFvjjKj&quot;>;释义可以逃避人工智能生成文本的检测，但检索是一种有效的防御&lt;/a>;&lt;br />; &lt;strong>;Kalpesh Krishna&lt;/strong>; 、Yixiao Song、Marzena Karpinska、John Wieting、Mohit Iyyer &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=SaMrN9tnxE&quot;>;ReMaX：放松以更好地训练高效全景分割&lt; /a>;&lt;br />;孙书阳*、&lt;strong>;王伟军&lt;/strong>;、于启航*、&lt;strong>;安德鲁·霍华德&lt;/strong>;、菲利普·托尔、陈良杰* &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=SouroWC5Un&quot;>;稳健且主动安全的无服务器协作学习&lt;/a>;&lt;br />; Nicholas Franzese、Adam Dziedzic、&lt;strong>;Christopher A. Choquette-Choo &lt;/strong>;、Mark R. Thomas、Muhammad Ahmad Kaleem、Stephan Rabanser、Congyu Fang、&lt;strong>;Somesh Jha&lt;/strong>;、Nicolas Papernot、Xiao Wang &lt;/p>; &lt;p>; &lt;a href=&quot;https:/ /openreview.net/forum?id=SdYHLTCC5J&quot;>;SpecTr：通过最优传输进行快速推测解码&lt;/a>;&lt;br />; &lt;strong>;Ziteng Sun&lt;/strong>;, &lt;strong>;Ananda Theertha Suresh&lt;/strong>;, &lt; strong>;Jae Hun Ro&lt;/strong>;、&lt;strong>;艾哈迈德·贝拉米&lt;/strong>;、&lt;strong>;Himanshu Jain&lt;/strong>;、&lt;strong>;Felix Yu&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href= &quot;https://openreview.net/forum?id=YZ7ip645Ra&quot;>;具有更强一致性保证的结构化预测&lt;/a>;&lt;br />;毛安琪，&lt;strong>;Mehryar Mohri&lt;/strong>;，钟玉涛&lt;/p>; &lt; p>; &lt;a href=&quot;https://openreview.net/forum?id=qgiG7WZohZ&quot;>;亲和感知图网络&lt;/a>;&lt;br />; &lt;strong>;Ameya Velingker&lt;/strong>;，&lt;strong>; Ali Kemal Sinop&lt;/strong>;、Ira Ktena、Petar Veličković、&lt;strong>;Sreenivas Gollapudi&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=rJc5Lsn5QU&quot;>;ARTIC3D：从嘈杂的网络图像集中学习鲁棒的铰接式 3D 形状&lt;/a>;&lt;br />; Chun-Han Yao*, &lt;strong>;Amit Raj&lt;/strong>;, Wei-Chih Hung,&lt;strong>; Yuanzhen Li&lt;/strong>;, &lt;迈克尔·鲁宾斯坦，&lt;strong>;杨明轩&lt;/strong>;，&lt;strong>; &lt;/strong>;&lt;strong>;瓦伦·詹帕尼&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https ://openreview.net/forum?id=eoDNaH3pfB&quot;>;交互式机器学习的黑盒差异隐私&lt;/a>;&lt;br />; &lt;strong>;Haim Kaplan&lt;/strong>;、&lt;strong>;Yishay Mansour&lt;/strong>;、 &lt;strong>;Shay Moran&lt;/strong>;、Kobbi Nissim、&lt;strong>;Uri Stemmer&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=orh4e0AO9R&quot;>;绕过模拟器：近乎最优的对抗性线性上下文强盗&lt;/a>;&lt;br />; Haolin Liu、Chen-Yu Wei、&lt;strong>;Julian Zimmert&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https:/ /openreview.net/forum?id=kXOXrVnwbb&quot;>;DaTaSeg：驯服通用多数据集多任务分割模型&lt;/a>;&lt;br />; &lt;strong>;Xiuye​​ Gu&lt;/strong>;，Yin Cui*，&lt;strong>;乔纳森·黄&lt;/strong>;、&lt;strong>;阿卜杜拉·拉什万&lt;/strong>;、&lt;strong>;杨轩&lt;/strong>;、&lt;strong>;周兴一&lt;/strong>;、&lt;strong>;Golnaz Ghiasi&lt;/strong>;、&lt;strong>;郭伟成&lt;/strong>;、&lt;strong>;陈慧忠&lt;/strong>;、陈良杰*、&lt;strong>;David Ross&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview. net/forum?id=kqBUgrkm1c&quot;>;从标签比例轻松学习&lt;/a>;&lt;br />; &lt;strong>;Robert Busa-Fekete&lt;/strong>;、Heejin Choi*、&lt;strong>;Travis Dick&lt;/strong>;、&lt;strong >;Claudio Gentile&lt;/strong>;、&lt;strong>;Andres Munoz Medina&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=q3fCWoC9l0&quot;>;高效的数据子集选择跨模型的泛化训练：传导网络和归纳网络&lt;/a>;&lt;br />; Eeshaan Jain、Tushar Nandy、&lt;strong>;Gaurav Aggarwal&lt;/strong>;、&lt;strong>;Ashish Tendulkar&lt;/strong>;、Rishabh Iyer、Abir De &lt;/ p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=h2lkx9SQCD&quot;>;通过二阶方法实现更快的差分隐私凸优化&lt;/a>;&lt;br />; &lt;strong>;Arun Ganesh&lt;/ strong>;、Mahdi Haghifam*、Thomas Steinke、Abhradeep Guha Thakurta &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=gdVcFOvxT3&quot;>;寻找马尔可夫决策过程策略的安全区&lt;/ a>;&lt;br />;Lee Cohen、&lt;strong>;Yishay Mansour&lt;/strong>;、Michal Moshkovitz &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=s1FjXzJ0jy&quot;>;聚焦变压器：情境缩放的对比训练&lt;/a>;&lt;br/>;Szymon Tworkowski、Konrad Staniszewski、Mikołaj Pacek、Yuhuai Wu*、Henryk Michalewski、Piotr Miłoś &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview. net/forum?id=h3kuB4z2G9&quot;>;利用有限的图知识进行超越马尔可夫等价的前门调整&lt;/a>;&lt;br />; Abhin Shah, &lt;strong>;Karthikeyan Shanmugam&lt;/strong>;, Murat Kocaoglu &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=nI7EmXq2PL&quot;>;H 一致性界限：表征和扩展&lt;/a>;&lt;br />; Anqi Mao、&lt;strong>;Mehryar Mohri&lt;/strong>;、Yutao钟&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=kjMGHTo8Cs&quot;>;逆动力学预训练学习多任务模仿的良好表示&lt;/a>;&lt;br />; David Brandfonbrener，&lt;strong >;Ofir Nachum&lt;/strong>;，Joan Bruna &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=pvPujuvjQd&quot;>;大多数神经网络几乎是可以学习的&lt;/a>;&lt;br / >; &lt;strong>;Amit Daniely&lt;/strong>;、Nathan Srebro、Gal Vardi &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=nQ84YY9Iut&quot;>;多类提升：简单直观的弱学习标准&lt;/a>;&lt;br />; Nataly Brukhim、&lt;strong>;Amit Daniely&lt;/strong>;、&lt;strong>;Yishay Mansour&lt;/strong>;、&lt;strong>;Shay Moran&lt;/strong>; &lt;/p>; &lt;p>; &lt; a href=&quot;https://openreview.net/forum?id=gJHAT79cZU&quot;>;NeRF 重温：修复体渲染中的正交不稳定性&lt;/a>;&lt;br />; Mikaela Angelina Uy、Kiyohiro Nakayama、Guandao Yang、Rahul Krishna Thomas、 Leonidas Guibas，&lt;strong>; Ke Li&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=izNfcaHJk0&quot;>;通过压缩增强隐私：实现最佳隐私准确性-分布式均值估计中的通信权衡&lt;/a>;&lt;br />; Wei-Ning Chen, Dan Song, Ayfer Ozgur, &lt;strong>;Peter Kairouz&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https ://openreview.net/forum?id=rzDBoh1tBh&quot;>;私有联合频率估计：适应实例的硬度&lt;/a>;&lt;br />; Jingfeng Wu*, &lt;strong>;Wennan Zhu&lt;/strong>;, &lt;strong >;Peter Kairouz&lt;/strong>;、Vladimir Braverman &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=pVlC0reMKq&quot;>;RETVec：弹性且高效的文本矢量化器&lt;/a>;&lt;br />; &lt;strong>;Elie Bursztein&lt;/strong>;、&lt;strong>;Marina 张&lt;/strong>;、&lt;strong>;Owen Skipper Vallis&lt;/strong>;、&lt;strong>;贾新宇&lt;/strong>;、&lt;strong>;Alexey Kurakin&lt;/strong>; strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=ne6zeqLFCZ&quot;>;优化算法的符号发现&lt;/a>;&lt;br />; 陈向宁*, &lt;strong>;陈梁&lt;/strong>;、&lt;strong>;黄大&lt;/strong>;、&lt;strong>;Esteban Real&lt;/strong>;、&lt;strong>;王开元&lt;/strong>;、&lt;strong>;范晓&lt;/strong>;、&lt;strong>;宣仪董&lt;/strong>;、&lt;strong>;Thang Luong&lt;/strong>;、Cho-Jui Hsieh、&lt;strong>;卢一峰&lt;/strong>;、&lt;strong>;Quoc V. Le&lt;/strong>; &lt;/p>; &lt;p>; &lt; a href=&quot;https://openreview.net/forum?id=lds9D17HRd&quot;>;两个特征的故事：稳定扩散补充 DINO 的零样本语义对应&lt;/a>;&lt;br />; Junyi 张，&lt;strong>;Charles Herrmann&lt;/strong>;、&lt;strong>;Junhwa Hur&lt;/strong>;、&lt;strong>;Luisa F. Polania&lt;/strong>;、&lt;strong>;Varun Jampani&lt;/strong>;、&lt;strong>;孙德庆&lt;/strong>;、&lt;strong>; >; Ming-Hsuan Yang&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=iSd8g75QvP&quot;>;转化式在线学习的三分法&lt;/a>;&lt;br />; Steve Hanneke、Shay Moran、Jonathan Shafer &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=i2H2sEiq2T&quot;>;DP 的统一快速梯度裁剪框架-SGD&lt;/a>;&lt;br />; &lt;strong>;William Kong&lt;/strong>;、&lt;strong>;Andres Munoz Medina&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/ forum?id=mlbes5TAAg&quot;>;在审计差异化私有机器学习中释放随机化的力量&lt;/a>;&lt;br />; &lt;strong>;Krishna Pillutla&lt;/strong>;、&lt;strong>;Galen Andrew&lt;/strong>;、&lt;strong>;Peter Kairouz &lt;/strong>;，&lt;strong>;H.布伦丹·麦克马汉，&lt;strong>;阿丽娜·奥普雷亚&lt;/strong>;，&lt;strong>;吴世雄&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id= zEm6hF97Pz&quot;>;（放大）带状矩阵分解：私人培训的统一方法&lt;/a>;&lt;br />; Christopher A Choquette-Choo、&lt;strong>; Arun Ganesh&lt;/strong>;、&lt;strong>;Ryan McKenna&lt;/strong>;、 &lt;strong>;H Brendan McMahan&lt;/strong>;、&lt;strong>;基思·拉什&lt;/strong>;、&lt;strong>; &lt;/strong>;Abhradeep Guha Thakurta、&lt;strong>;徐峥&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=xcGhx9FdxM&quot;>;通过弃权进行顺序预测中的对抗弹性&lt;/a>;&lt;br />; Surbhi Goel、Steve Hanneke、&lt;strong>;Shay Moran&lt;/strong>;、Abhishek Shetty &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=uTlKUAm68H&quot;>;交替梯度下降和专家混合用于集成多模态感知&lt;/a>;&lt;br />; &lt; strong>;哈桑·阿克巴里&lt;/strong>;、&lt;strong>;丹·康德拉图克&lt;/strong>;、&lt;strong>;崔银&lt;/strong>;、&lt;strong>;雷切尔·霍农&lt;/strong>;、&lt;strong>;王慧生&lt;/strong>;、&lt; strong>;Hartwig Adam&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/pdf/0083ab45a583fe1992b3c4f9222081c50b9d30c3.pdf&quot;>;Android in the Wild：用于 Android 设备控制的大规模数据集&lt; /a>;&lt;br />; &lt;strong>;克里斯托弗·罗尔斯&lt;/strong>;、&lt;strong>;爱丽丝·李&lt;/strong>;、&lt;strong>;丹尼尔·罗德里格斯&lt;/strong>;、&lt;strong>;奥丽安娜·里瓦&lt;/strong>;、蒂莫西·利利克拉普 &lt; /p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=CiRHWaRbp0&quot;>;对抗性图像混淆的鲁棒性基准测试&lt;/a>;&lt;br />; Florian Stimberg，&lt;strong>;Ayan Chakrabarti&lt;/ strong>;、&lt;strong>;卢春达&lt;/strong>;、&lt;strong>;Hussein Hazimeh&lt;/strong>;、&lt;strong>;Otilia Stretcu&lt;/strong>;、&lt;strong>;乔伟&lt;/strong>;、&lt;strong>;刘银涛&lt;/strong>;、&lt;strong>;梅尔维·卡亚&lt;/strong>;、&lt;strong>;赛勒斯·拉什奇安&lt;/strong>;、&lt;strong>;阿里尔·福克斯曼&lt;/strong>;、&lt;strong>;穆罕默德·泰克&lt;/strong>;、斯文·高瓦尔&lt;/p >; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=uIj1jDc8k6&quot;>;通过社区参与构建社会文化包容性刻板印象资源&lt;/a>;&lt;br />; &lt;strong>;Sunipa Dev&lt;/strong >;、贾亚·戈亚尔、&lt;strong>;Dinesh Tewari&lt;/strong>;、&lt;strong>;Shachi Dave&lt;/strong>;、&lt;strong>;Vinodkumar Prabhakaran&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https:// openreview.net/forum?id=L9I9FhHfS3&quot;>;机器学习公平性肤色标注的共识和主观性&lt;/a>;&lt;br />; &lt;strong>;Candice Schumann&lt;/strong>;、&lt;strong>;Gbolahan O Olanubi&lt;/strong>;、 &lt;strong>;奥瑞尔·赖特&lt;/strong>;、小埃利斯·蒙克*、&lt;strong>;考特尼·赫尔德雷斯&lt;/strong>;、&lt;strong>; &lt;/strong>;&lt;strong>;苏珊娜·里科&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=zdli6OxpWd&quot;>;在个人级差异隐私下计算不同元素&lt;/a>;&lt;br />; &lt;strong>;Alexander Knop&lt;/strong>;，Thomas Steinke &lt;/p >; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=GjNvvswoUL&quot;>;DICES 数据集：对话式人工智能安全评估的多样性&lt;/a>;&lt;br />; &lt;strong>;Lora Aroyo&lt;/strong >;、亚历克斯·S·泰勒、&lt;strong>;马克·迪亚兹&lt;/strong>;、&lt;strong>;克里斯托弗·M·霍曼&lt;/strong>;、&lt;strong>;艾丽西亚·帕里什&lt;/strong>;、格雷格·塞拉皮奥-加西亚、&lt;strong>;Vinodkumar Prabhakaran&lt; /strong>;, &lt;strong>;Ding Wang&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=SS3CK3yx5Z&quot;>;ImageNet 迁移到真实世界数据集方面取得进展吗?&lt;/a>;&lt;br />; Alex Fang、&lt;strong>;Simon Kornblith&lt;/strong>;、Ludwig Schmidt &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=AA2uO0HHmr&quot; >;根据 2D 注释估计通用 3D 房间结构&lt;/a>;&lt;br />; Denys Rozumnyi*、&lt;strong>;Stefan Popov&lt;/strong>;、&lt;strong>;Kevis-kokitsi Maninis&lt;/strong>;、Matthias Nießner、&lt;strong>;Vittorio Ferrari&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=6hZIfAY9GD&quot;>;大型语言模型作为属性训练数据生成器：多样性和偏见的故事&lt;/a >;&lt;br />; 余悦、庄雨辰、张洁宇、孟雨、Alexander Ratner、Ranjay Krishna、&lt;strong>;沉家明&lt;/strong>;、&lt;strong>; &lt;/strong>;张超&lt;/p>; &lt;p>; &lt; a href=&quot;https://openreview.net/forum?id=Y45ZCxslFx&quot;>;MADLAD-400：多语言和文档级大型审核数据集&lt;/a>;&lt;br />; Sneha Kudugunta，&lt;strong>;Isaac Caswell&lt;/ strong>;、张彪、Xavier Garcia、Derrick Xin、&lt;strong>;Aditya Kusupati&lt;/strong>;、Romi Stella、Ankur Bapna、Orhan Firat &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/ forum?id=uhKtQMn21D&quot;>;机制：学习率调节器&lt;/a>;&lt;br />; Ashok Cutkosky、Aaron Defazio、&lt;strong>;Harsh Mehta&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https: //openreview.net/forum?id=8TMhs2pIfG&quot;>;NAVI：具有高质量 3D 形状和姿势注释的类别无关图像集合&lt;/a>;&lt;br />; &lt;strong>;Varun Jampani&lt;/strong>;，&lt;strong>; Kevis-kokitsi Maninis&lt;/strong>;、&lt;strong>;安德烈亚斯·恩格尔哈特&lt;/strong>;、&lt;strong>;阿琼·卡普尔&lt;/strong>;、&lt;strong>;Karen Truong&lt;/strong>;、&lt;strong>;凯尔·萨金特&lt;/strong>;、&lt;斯特凡·波波夫、&lt;strong>;安德烈·阿劳霍&lt;/strong>;、&lt;strong>;里卡多·马丁·布鲁阿拉&lt;/strong>;、&lt;strong>;考沙尔·帕特尔&lt;/strong>;、&lt;strong>;丹尼尔·弗拉西奇&lt;/strong>;、 &lt;strong>;维托里奥·法拉利&lt;/strong>;、&lt;strong>;阿米什·马卡迪亚&lt;/strong>;、刘策*、&lt;strong>;李元振&lt;/strong>;、&lt;strong>;周浩&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=x6cOcxRnxG&quot;>;神经理想大涡模拟：用神经随机微分方程模拟湍流&lt;/a>;&lt;br />; &lt;strong>;Anudhyan Boral&lt;/strong>; , &lt;strong>;万钟一&lt;/strong>;, &lt;strong>;Leonardo Zepeda-Nunez&lt;/strong>;, &lt;strong>;James Lottes&lt;/strong>;, &lt;strong>;王清&lt;/strong>;, &lt;strong>;范亦凡陈&lt;/strong>;、&lt;strong>;约翰·罗伯茨·安德森&lt;/strong>;、&lt;strong>;飞沙&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id= wFuemocyHZ&quot;>;重新启动采样以改进生成过程&lt;/a>;&lt;br />;徐一伦、邓明阳、程翔、&lt;strong>;田永龙&lt;/strong>;、刘子明、Tommi Jaakkola&lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=xUyBP16Q5J&quot;>;重新思考推荐系统中的激励措施：单调奖励总是有益的吗？&lt;/a>;&lt;br />; Fan Yao, Chuanhao Li, Karthik Abinav Sankararaman, Yiming Liao , &lt;strong>;朱彦&lt;/strong>;, 王起凡, 王红宁, 徐海峰 &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=jGyMUum1Lq&quot;>;重新审视评估指标语义分割：细粒度交集优化与评估&lt;/a>;&lt;br />; Zifu Wang, &lt;strong>;Maxim Berman&lt;/strong>;, Amal Rannen-Triki, Philip Torr, Devis Tuia, Tinne Tuytelaars, Luc Van Gool、Jiaqian Yu、Matthew B. Blaschko &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=0H5fRQcpQ7&quot;>;RoboHive：机器人学习的统一框架&lt;/a>;&lt;br />; &lt;strong>;Vikash Kumar&lt;/strong>;、Rutav Shah、周高跃、Vincent Moens、Vittorio Caggiano、Abhishek Gupta、&lt;strong>;Aravind Rajeswaran&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https: //openreview.net/forum?id=Vn5qZGxGj3&quot;>;SatBird：利用遥感和公民科学数据进行鸟类物种分布建模&lt;/a>;&lt;br />;Mélisande Teng、Amna Elmustafa、Benjamin Akera、Yoshua Bengio、Hager Radi、&lt; strong>;Hugo Larochelle&lt;/strong>;，David Rolnick &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=sqTcCXkG4P&quot;>;大型嵌入模型的稀疏性保持差分隐私训练&lt;/ a>;&lt;br />; &lt;strong>;Badih Ghazi&lt;/strong>;、Yangsibo Huang*、&lt;strong>;Pritish Kamath&lt;/strong>;、&lt;strong>;Ravi Kumar&lt;/strong>;、&lt;strong>;Pasin Manurangsi&lt;/strong>;、 &lt;strong>;Amer Sinha&lt;/strong>;、&lt;strong>; &lt;/strong>;&lt;strong>;张驰远&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id= xpjsOQtKqx&quot;>;StableRep：从文本到图像模型的合成图像形成强大的视觉表示学习者&lt;/a>;&lt;br />; &lt;strong>;Yonglong Tian&lt;/strong>;、&lt;strong>;Lijie Fan&lt;/strong>;、Phillip Isola、 &lt;strong>;Huiwen Chang&lt;/strong>;、&lt;strong>;Dilip Krishnan&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=EPz1DcdPVE&quot;>;迈向联邦基金会模型：用于小组结构学习的可扩展数据集管道&lt;/a>;&lt;br />; &lt;strong>;Zachary Charles&lt;/strong>;、&lt;strong>;Nicole Mitchell&lt;/strong>;、&lt;strong>;Krishna Pillutla&lt;/strong>;、&lt;strong>; Michael Reneer&lt;/strong>;、&lt;strong>;Zachary Garrett&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=zWxKYyW9ik&quot;>;提示调整的普遍性和局限性&lt; /a>;&lt;br />; 王一涵、Jatin Chauhan、王伟、&lt;strong>;谢卓瑞&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id =sovxUzPzLN&quot;>;使用稳定扩散的无监督语义对应&lt;/a>;&lt;br />; Eric Hedlin、Gopal Sharma、Shweta Mahajan、&lt;strong>;Hossam Isack&lt;/strong>;、&lt;strong>;Abhishek Kar&lt;/strong>;、&lt;strong>; Andrea Tagliasacchi&lt;/strong>;、&lt;strong>; &lt;/strong>;Kwang Moo Yi &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=QEDjXv9OyY&quot;>;YouTube-ASL：大型-规模、开放域美国手语-英语平行语料库&lt;/a>;&lt;br />; &lt;strong>;Dave Uthus&lt;/strong>;、&lt;strong>;Garrett Tanzer&lt;/strong>;、&lt;strong>;Manfred Georg&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://openreview.net/forum?id=swNtr6vGqg&quot;>;具有相关数据的线性回归中的噪声水平&lt;/a>;&lt;br />; Ingvar Ziemann，&lt;strong>; Stephen Tu&lt;/strong>;、George J. Pappas、Nikolai Matni &lt;/p>; &lt;/div>; &lt;!--脚注-->; &lt;hr width=&quot;80%&quot; />; &lt;p>; &lt;span class=&quot;Apple- style-span&quot; style=&quot;font-size:small;&quot;>;&lt;b>;*&lt;/b>;&amp;nbsp;在 Google 期间完成的工作&lt;/span>;&lt;/p>;&lt;/content>;&lt;link href=&quot;http:// /blog.research.google/feeds/8223613466421639113/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research. google/2023/12/google-at-neurips-2023.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www .blogger.com/feeds/8474926331452026626/posts/default/8223613466421639113&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/ posts/default/8223613466421639113&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/google-at-neurips-2023.html &quot; rel=&quot;alternate&quot; title=&quot;Google at NeurIPS 2023&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/ 12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https: //img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjC9GkRLKp8GI42AvrsSQqN2F8gF8QDo06YU1ulV067EXp6MU3F1yYSZ44VRxn7BZlgrSZ18249wN7vuwyeDAH4AmXHHo-ryPYOmZ771K3yhsUCkfWgu TDsOTx2wBqnH1gF_hxcALrj7nq-kRL2lNttCipemJXYUitvDbRi_LNWk7bRgFpzpsNEqDeetCM2/s72-c/google_research_sticker-hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>; &lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-6514019106482066697&lt;/id>;&lt;已发布>; 2023-12-08T10:34:00.000-08:00&lt;/发布>;&lt;更新>;2024-01-08T07:50:55.303-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger. com/atom/ns#&quot; term=&quot;算法&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;深度学习&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Differential Privacy&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;稀疏性保持差分隐私训练&lt;/stitle>;&lt;content type =&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：Google Research 实习生 Yangsibo Huang 和研究科学家 Chiyuan Zhang&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com /img/b/R29vZ2xl/AVvXsEjBm5u6Sg9vPlH8YH8q9caA1g_3nkf1tXzB6qNqZTSbpB38DQERn-pOicng-98oTsQNtza5De5ohjQV4t43a4BhICFwU7EqAs9AZI6aMHLKflVfj6s9DRSn7 bkjUvW-Uq1zCtziKPi2Li3KutFXGJtENqw-HEkAa0p8r1tJgoq48PDqd7FePR3ipWWj2Iz0B/s1600/Sparse%20DP-SGD.png&quot; style=&quot;显示：无；&quot; />; &lt;p>; &lt;em>;大型嵌入模型&lt;/em>;已成为推荐系统中各种应用的基本工具 [&lt;a href=&quot;https://research.google/pubs/pub45530/&quot;>;1&lt;/em>; a>;、&lt;a href=&quot;https://arxiv.org/abs/2104.05158&quot;>;2&lt;/a>;] 和自然语言处理 [&lt;a href=&quot;https://arxiv.org/abs/1310.4546&quot;>; 3&lt;/a>;、&lt;a href=&quot;https://nlp.stanford.edu/pubs/glove.pdf&quot;>;4&lt;/a>;、&lt;a href=&quot;https://arxiv.org/abs/1810.04805 ”>;5&lt;/a>;]。此类模型可以通过映射分类或&lt;a href=&quot;https://en.wikipedia.org/wiki/String_(computer_science)&quot;>;字符串&lt;/a>;值的输入属性，将非数值数据集成到深度学习模型中使用嵌入层将大词汇量转换为固定长度的表示向量。这些模型广泛部署在个性化推荐系统中，并在语言任务中实现了最先进的性能，例如&lt;a href=&quot;https://en.wikipedia.org/wiki/Language_model&quot;>;语言建模&lt;/a >;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Sentiment_analysis&quot;>;情绪分析&lt;/a>;和&lt;a href=&quot;https://en.wikipedia.org/wiki/Question_answering&quot;>;问题回答&lt;/a>;。在许多此类场景中，部署这些模型时隐私是同样重要的功能。因此，人们提出了各种技术来实现私有数据分析。其中，&lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_privacy&quot;>;差分隐私&lt;/a>;（DP）是一种广泛采用的定义，它限制个人用户信息的暴露，同时仍然允许分析人口水平模式。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 对于训练具有 DP 保证的深度神经网络，最广泛使用的算法是 &lt;a href=&quot;https://arxiv.org/abs/1607.00133 &quot;>;DP-SGD&lt;/a>;（DP &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;>;随机梯度下降&lt;/a>;）。 DP-SGD 的一个关键组成部分是在训练期间向梯度向量的每个坐标添加高斯噪声。然而，当应用于大型嵌入模型时，这会带来可扩展性挑战，因为它们依赖梯度稀疏性来进行有效训练，但向所有坐标添加噪声会破坏稀疏性。 &lt;/p>; &lt;p>; 为了缓解这种梯度稀疏问题，请参阅“&lt;a href=&quot;https://arxiv.org/abs/2311.08357&quot;>;大型嵌入模型的稀疏性保持差分隐私训练&lt;/a>;”（将在 &lt;a href=&quot;https://nips.cc/Conferences/2023&quot;>;NeurIPS 2023&lt;/a>; 上展示），我们提出了一种名为&lt;em>;支持自适应过滤的稀疏训练&lt;/em>;的新算法（ DP-AdaFEST）。在较高层面上，该算法通过仅选择在每次迭代时添加噪声的特征行子集来保持梯度的稀疏性。关键是使这种选择具有差分隐私性，从而在隐私成本、训练效率和模型效用之间实现三向平衡。我们的实证评估表明，DP-AdaFEST 实现了显着稀疏的梯度，与标准 DP-SGD 产生的密集梯度相比，梯度大小减少了 10&lt;sup>;5&lt;/sup>;X 以上，同时保持了相当的准确度水平。这种梯度大小的减小可以转化为 20 倍的挂钟时间改进。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;概述&lt;/h2>; &lt;p>; 更好地了解梯度稀疏问题的挑战和我们的解决方案，让我们首先概述一下 DP-SGD 在训练过程中的工作原理。如下图所示，DP-SGD 的运行方式是剪切当前随机样本子集中每个示例的梯度贡献（称为小批量），并按坐标添加 &lt;a href=&quot;https://en. wikipedia.org/wiki/Gaussian_noise&quot;>;高斯噪声&lt;/a>;到&lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;>;随机梯度下降&lt;/a>;每次迭代期间的平均梯度（新加坡元）。 DP-SGD 已证明其在保护用户隐私方面的有效性，同时在各种应用中保持模型实用性 [&lt;a href=&quot;https://arxiv.org/pdf/2204.13650.pdf&quot;>;6&lt;/a>;，&lt;a href =&quot;https://arxiv.org/pdf/2110.06500.pdf&quot;>;7&lt;/a>;]。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1x7i1Ul5_mXMdBgLSsDKsP2iN4vUSaSfC6qoNpOwoz_TYMVysh4JV1kru7q8hhwGcuwc5Hfj_1rW_r-_Unw2k AmdhKKD7_3I4uQE5Z34fHQdG71quOt5u82iuK1M-vTBv6MopTnVPitOisx0w_fLlbdpDZMOPh7yDdgGM3U74jweKtCnRTom8yXmVF2vG/s1999/image5.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;768&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1x7i1Ul5_mXMdBgLSsDKsP2iN4vUSaSfC6qoNpOwoz_TYMVysh4JV1kru7q8hhwGcuwc5Hfj_1rW_r-_Unw2kAmdhKKD7_3I4uQE5Z34fHQdG71 quOt5u82iuK1M-vTBv6MopTnVPitOisx0w_fLlbdpDZMOPh7yDdgGM3U74jweKtCnRTom8yXmVF2vG/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;DP-SGD 工作原理的说明。在每个训练步骤中，都会对一小批示例进行采样，并用于计算每个示例的梯度。这些梯度通过高斯噪声的裁剪、聚合和求和来处理，以产生最终的私有化梯度。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; 将 DP-SGD 应用于大型嵌入模型的挑战主要来自 1）非数字特征字段，如用户/产品 ID 和类别，以及 2）通过嵌入层转换为密集向量的单词和标记。由于这些特征的词汇量大小，该过程需要具有大量参数的大型嵌入表。与参数数量相比，梯度更新通常非常稀疏，因为每个小批量示例仅激活一小部分嵌入行（下图可视化了零值坐标的比率，即稀疏性）不同批量大小下的梯度）。这种稀疏性在有效处理大规模嵌入训练的工业应用中得到了充分利用。例如，&lt;a href=&quot;https://cloud.google.com/tpu&quot;>;Google Cloud TPU&lt;/a>; 是一种定制设计的 AI 加速器，针对大型 AI 模型的训练和推理进行了优化，具有&lt;a href =&quot;https://cloud.google.com/blog/topics/developers-practitioners/building-large-scale-recommenders-using-cloud-tpus&quot;>;专用 API&lt;/a>; 用于处理具有稀疏更新的大型嵌入。与 GPU 上的训练相比，这可以&lt;a href=&quot;https://eng.snap.com/training-models-with-tpus&quot;>;显着提高训练吞吐量&lt;/a>;，而 GPU 目前还没有专门的优化用于稀疏嵌入查找。另一方面，DP-SGD 完全破坏了梯度稀疏性，因为它需要向&lt;em>;所有&lt;/em>;坐标添加独立的高斯噪声。这为大型嵌入模型的私人训练设置了障碍，因为与非私人训练相比，训练效率将显着降低。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwrdsCOpdtbHyfGjQfTWV7AYcyq8dEt3g2pY2Kx5BgwonmVb1XgKPMW8nEM6h-j9M1dniCOpviwIhxqNgrvC4N4 T3Zwqdj-OJEXYOUiaSreBfWljgEEIIaStjpmDhrh9on18CaB_Fc4KDD1m4msv9BM5uqWC3q0qmjJe5BBlbxYJIJGMUAa4vgMkCa5jwS/s1814/image3.png&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1058&quot; data-original-width=&quot;1814&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwrdsCOpdtbHyfGjQfTWV7AYcyq8dEt3g2pY2Kx5BgwonmVb1XgKPMW8nEM6h-j9M1dniCOpviwIhxqNgrvC4N4T3Zwqdj-OJEXYOUiaSreBfWljgEE IIaStjpmDHrh9on18CaB_Fc4KDD1m4msv9BM5uqWC3q0qmjJe5BBlbxYJIJGMUAa4vgMkCa5jwS/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;在 &lt;a href=&quot;http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge&quot; 中嵌入梯度稀疏性（零值梯度坐标的分数） -dataset&quot;>;Criteo pCTR&lt;/a>; 模型（见下文）。该图报告了桶数最多的前 5 个分类特征（总共 26 个）的梯度稀疏度（超过 50 个更新步骤的平均值），以及所有分类特征的稀疏度。随着更多的示例命中嵌入表中的更多行，从而创建非零梯度，稀疏性随着批量大小而减小。然而，即使对于非常大的批量大小，稀疏度也高于 0.97。所有五个功能都一致观察到这种模式。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt; h2>;算法&lt;/h2>; &lt;p>;我们的算法是通过在每次迭代时使用额外的机制扩展标准DP-SGD来构建的，以私下选择“热门特征”，这些特征是由当前的多个训练示例激活的特征。小批量。如下图所示，该机制分几个步骤工作：&lt;/p>; &lt;ol>; &lt;li>;计算有多少示例对每个特征桶做出了贡献（我们将分类特征的每个可能值称为“桶”）。 &lt;/li>;&lt;li>;通过削减每个示例的计数来限制其总贡献。 &lt;/li>;&lt;li>;将高斯噪声添加到每个特征桶的贡献计数中。 &lt;/li>;&lt;li>;仅选择要包含在梯度更新中且计数高于给定阈值（稀疏性控制参数）的特征，从而保持稀疏性。该机制是差分隐私的，并且可以通过将其与标准 DP-SGD 迭代组合来轻松计算隐私成本。 &lt;/li>; &lt;/ol>; &lt;tablealign=“center”cellpadding=“0”cellspacing=“0”class=“tr-caption-container”style=“margin-left：auto；margin-right：auto；” >;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgw4grjzgMGorydps6Oi3iCvQ6OnlWeqhbc9p68PJiycBZBkianO6esb9mo0hRlScm5zHod3isaGDp8OhkaM1d8VPuFR zUhIX34uNNrsHU5_jUrIzR2N1fJvQenxGteqxWc1t1_xMrkLGyYoxEhlBe7g-kd5AcwJwrpH4tcfmxVth2wjl-wG3iNUd-oTYTB/s1600 /image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;743&quot; data-original-width=&quot;1600&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgw4grjzgMGorydps6Oi3iCvQ6OnlWeqhbc9p68PJiycBZBkianO6esb9mo0hRlScm5zHod3isaGDp8OhkaM1d8VPuFRzUhIX34uNNrsHU5_jUrIzR2N1fJv QenxGteqxWc1t1_xMrkLGyYoxEhlBe7g-kd5AcwJwrpH4tcfmxVth2wjl-wG3iNUd-oTYTB/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;说明具有 20 个桶的合成分类特征的算法过程。我们计算对每个桶做出贡献的示例数量，根据每个示例的总贡献（包括对其他特征的贡献）调整值，添加高斯噪声，并仅保留那些噪声贡献超过（噪声）梯度阈值的桶更新。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;理论动机&lt;/h2>; &lt; p>; 我们通过将 DP-AdaFEST 视为使用随机&lt;a href=&quot;https://en.wikipedia.org/wiki/Oracle_complexity_(optimization)&quot;>;梯度预言&lt;/a>;的优化来提供 DP-AdaFEST 背后的理论动机。理论设置中随机梯度下降的标准分析将模型的测试误差分解为“偏差”和“方差” ”条款&lt;/a>;。 DP-AdaFEST 的优点可以被视为以稍微增加偏差为代价来减少方差。这是因为与 DP-SGD 相比，DP-AdaFEST 向较小的一组坐标添加了噪声，DP-SGD 向所有坐标添加了噪声。另一方面，DP-AdaFEST 给梯度带来了一些偏差，因为嵌入特征上的梯度以一定的概率被丢弃。我们建议感兴趣的读者参阅&lt;a href=&quot;https://arxiv.org/abs/2311.08357&quot;>;论文&lt;/a>;的第3.4节以了解更多详细信息。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;实验&lt;/h2>; &lt;p>; 我们通过大型嵌入模型应用来评估算法的有效性，公共数据集，包括一个广告预测数据集 (&lt;a href=&quot;http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset&quot;>;Criteo-Kaggle&lt;/a>;) 和一个语言理解数据集 (&lt;a href=&quot;https://huggingface.co/datasets/sst2&quot;>;SST-2&lt;/a>;)。我们使用&lt;a href=&quot;https://arxiv.org/abs/2103.01294&quot;>;带有指数选择的DP-SGD&lt;/a>;作为基线比较。 &lt;/p>; &lt;p>; DP-AdaFEST 的有效性如下图所示，它比基线实现了显着更高的梯度大小缩减（即梯度稀疏性），同时保持相同水平的效用（即只有最低的性能）降解）。 &lt;/p>; &lt;p>; 具体而言，在 Criteo-Kaggle 数据集上，DP-AdaFEST 将常规 DP-SGD 的梯度计算成本降低了 5x10&lt;sup>;5&lt;/sup>; 倍以上，同时保持了可比的&lt;a href= “https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;>;AUC&lt;/a>;（我们定义为小于 0.005 的损失）。这种减少转化为更高效、更具成本效益的培训过程。相比之下，如下图绿线所示，基线方法无法在如此小的效用损失阈值内实现合理的成本降低。 &lt;/p>; &lt;p>; 在语言任务中，减少梯度大小的潜力不大，因为使用的词汇通常较小并且已经相当紧凑（如下右图所示）。然而，采用保持稀疏性的DP-SGD有效地避免了密集的梯度计算。此外，根据理论分析中提出的偏差-方差权衡，我们注意到当梯度大小的减小最小时，DP-AdaFEST 偶尔会表现出比 DP-SGD 更优越的实用性。相反，当结合稀疏性时，基线算法在维持效用方面面临挑战。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjve3hfmF7VyXPfhxUNK2GT3kUR6tS-5HSlvInImOwkvfPCdxRSJeGHit-2DXKjmlTkl8WY1s8vTJxAPz59C_5YirJhPA UV8-j7Z7b6ECRilTtqxvT4l6rPIWoIUqgdJxm41yv3avYS8vZ1MUHejRJMSYWmBHq70dsLHpHr5ouZ_8r2GFfYbVY5WRfCYXCS/s1860/image6.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;560&quot; data-original-width=&quot;1860&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjve3hfmF7VyXPfhxUNK2GT3kUR6tS-5HSlvInImOwkvfPCdxRSJeGHit-2DXKjmlTkl8WY1s8vTJxAPz59C_5YirJhPAUV8-j7Z7b6ECRilTtqxvT4l6 rPIWoIUqgdJxm41yv3avYS8vZ1MUHejRJMSYWmBHq70dsLHpHr5ouZ_8r2GFfYbVY5WRfCYXCS/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- title&quot; style=&quot;text-align: center;&quot;>;DP 在 ε =1.0 下实现的最佳梯度大小缩减（常规 DP-SGD 和稀疏性保持算法之间的非零梯度值计数的比率）的比较-AdaFEST（我们的算法）和基线算法（&lt;a href=&quot;https://arxiv.org/abs/2103.01294&quot;>;采用指数选择的 DP-SGD&lt;/a>;）与不同效用阈值下的 DP-SGD 进行比较不同之处。曲线越高表示效用/效率的权衡越好。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;在实践中，大多数广告预测模型都在不断地训练和评估。为了模拟这种在线学习设置，我们还使用时间序列数据进行评估，这些数据由于非平稳而极具挑战性。我们的评估使用 &lt;a href=&quot;https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/&quot;>;Criteo-1TB&lt;/a>; 数据集，其中包含真实世界的用户点击24 天内收集的数据。一致的是，DP-AdaFEST 将常规 DP-SGD 的梯度计算成本降低了 10&lt;sup>;4&lt;/sup>; 倍以上，同时保持了相当的 AUC。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgovxJa4jAZSTvwKVCPc0hp6S8KD9hWik-3raaGC-E54_9Udj60TDZPy31ozVcZOhUbpk7QigBSYLLRYgDqvdlfSPOaDHik-_4 WpyU1AmF-3ER11_RwkOGF10uSiDs18lBwnYGKbHrFX9wT4awNj3wlROpMjS4V9XtS6yf7I6_z4FlQBExtsHBCI50FV2fU/s2500/image7 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;891&quot; data-original-width=&quot;2500&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgovxJa4jAZSTvwKVCPc0hp6S8KD9hWik-3raaGC-E54_9Udj60TDZPy31ozVcZOhUbpk7QigBSYLLRYgDqvdlfSPOaDHik-_4WpyU1AmF-3ER11_RwkOGF10u SiDs18lBwnYGKbHrFX9wT4awNj3wlROpMjS4V9XtS6yf7I6_z4FlQBExtsHBCI50FV2fU/s16000/image7.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td 类=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;DP-AdaFEST（我们的算法）和具有指数选择的 DP-SGD（之前的算法）在 ε =1.0 下实现的最佳梯度大小减小的比较与 DP-SGD 在不同阈值下的效用差异进行比较。曲线越高表示效用/效率权衡越好。 DP-AdaFEST 始终优于以前的方法。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;结论&lt;/h2>; &lt;p>; 我们提出了一种新算法 DP-AdaFEST，用于在差分隐私训练中保持梯度稀疏性，特别是在涉及大型嵌入模型的应用中，大型嵌入模型是推荐系统和自然语言处理中各种应用的基本工具。我们的算法显着减小了梯度大小，同时保持了现实世界基准数据集的准确性。此外，它提供了通过稀疏控制参数平衡效用和效率的灵活选项，而我们的建议提供了更好的隐私效用损失。 &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;这项工作是与 Pritish 的 Badih Ghazi 合作完成的Kamath、Ravi Kumar、Pasin Manurangsi 和 Amer Sinha。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6514019106482066697/comments/default&quot; rel=&quot;replies &quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/sparsity-preserving- Differentially.html#comment-form&quot; rel =&quot;回复&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6514019106482066697&quot; rel=&quot;编辑&quot; 类型=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6514019106482066697&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/ >;&lt;link href=&quot;http://blog.research.google/2023/12/sparsity-preserving- Differentially.html&quot; rel=&quot;alternate&quot; title=&quot;稀疏性保留差分私人训练&quot; type=&quot;text/html&quot; />;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image高度=“16” rel=“http://schemas.google.com/g/2005#thumbnail” src=“https://img1.blogblog.com/img/b16-rounded.gif” 宽度=“16” >;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBm5u6Sg9vPlH8YH8q9cA1g_3nkf1tXzB6qNqZTSbpB38DQERn-pOicng-98oTsQNtza5De5ohjQV 4t43a4BhICFwU7EqAs9AZI6aMHLKflVfj6s9DRSn7bkjUvW-Uq1zCtziKPi2Li3KutFXGJtENqw-HEkAa0p8r1tJgoq48PDqd7FePR3ipWWj2Iz0B/s72 -c/Sparse%20DP-SGD.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr ：总计>;&lt;/entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-5912569868305742102&lt;/id>;&lt;发布>;2023-12-07T09:51:00.000-08:00&lt;/已发布>;&lt;更新>;2023-12-07T09:53:23.920-08:00&lt;/更新>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;增强现实&quot;>;&lt; /类别>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语=“HCI”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom/” ns#&quot; term=&quot;Virtual Reality&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;有效：经过感知验证的虚拟化身库，具有包容性和多样性&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class= &quot;byline-author&quot;>;发布者：Mar Gonzalez-Franco，Google AR 和 Google 研究科学家VR&lt;/span>;&lt;p>; 随着虚拟现实 (VR) 和增强现实 (AR) 技术的不断普及，虚拟化身正成为我们数字交互中越来越重要的一部分。特别是，虚拟化身是许多社交 VR 和 AR 交互的中心，因为它们是代表远程参与者和促进协作的关键。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 在过去的十年中，跨学科科学家付出了大量的努力来更好地理解化身的使用，并做出了许多有趣的观察，包括用户&lt;a href=&quot;https://www.frontiersin.org/articles/10.3389/frvir.2020.575943/full&quot;>;体现他们的化身&lt;/a>;的能力（即，认为化身身体是他们自己的错觉） ）和&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9089510&quot;>;自我头像追随者效果&lt;/a>;，它在头像和用户的动作之间创建了足够强的绑定头像实际上可以影响用户行为。 &lt;/p>; &lt;p>; 在实验中使用化身不仅是为了研究用户在 VR 空间中的互动和行为方式，也是为了发现人类感知和神经科学的局限性。事实上，一些 VR 社交实验通常依赖于重新创建在现实世界中无法轻松重现的场景，例如酒吧爬行到 &lt;a href=&quot;https://doi.org/10.1371/journal.pone.0052766&quot; >;探索内群体与外群体效应&lt;/a>;，或欺骗实验，例如&lt;a href=&quot;https://doi.org/10.1371/journal.pone.0209704&quot;>;米尔格拉姆对虚拟现实中权威的服从&lt;/一个>;。其他研究试图探索深层神经科学现象，例如&lt;a href=&quot;https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2021.0453&quot;>;人类运动控制机制&lt;/a>;。这或许遵循大脑可塑性的&lt;a href=&quot;https://www.nature.com/articles/35784&quot;>;橡胶手错觉&lt;/a>;，一个人可以开始感觉自己拥有一块橡胶手，而他们真正的手隐藏在窗帘后面。使用个性化&lt;a href=&quot;https://doi.org/10.1186/s13063-022-06683-1&quot;>;化身&lt;/a>;进行精神治疗的可能疗法也越来越多。在这些情况下，VR 成为一种&lt;a href=&quot;https://en.wikipedia.org/wiki/Ecological_validity&quot;>;生态上有效的&lt;/a>;工具，使科学家能够探索或治疗人类行为和感知。 &lt;/p>; &lt;p>; 如果没有能够方便地进行实验的研究工具和库，这些实验和疗法都不可能存在。因此，近年来围绕头像创建和动画发布了多个系统和开源工具。然而，现有的头像库尚未在多样性谱上进行系统验证。与化身互动时，社会&lt;a href=&quot;https://doi.org/10.1016/j.concog.2013.04.016&quot;>;偏见和动态&lt;/a>;也会转移到 VR/AR 上，这可能会导致得出不完整的结论VR/AR 中人类行为的研究。 &lt;/p>; &lt;p>; 为了部分解决这个问题，我们与中佛罗里达大学合作创建并发布了开源&lt;a href=&quot;https://github.com/google/valid-avatar-library&quot; >;实现包容性和多样性的虚拟头像库&lt;/a>;（有效）。 &lt;a href=&quot;https://doi.org/10.3389/frvir.2023.1248915&quot;>;我们最近的论文&lt;/a>;中进行了描述，发表于&lt;a href=&quot;https://www.frontiersin.org/journals/virtual -reality&quot;>;&lt;i>;虚拟现实前沿&lt;/i>;&lt;/a>;，该化身库可随时用于 VR/AR 实验，其中包括美国人口普查局认可的 7 个不同种族和民族的 210 个化身。这些化身经过感知验证，旨在促进虚拟化身研究的多样性和包容性。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmXa7LCZLvQy98sLB16VdQJa2RZqxfRzHvi_bfXYrUEdVaeqBqBo3yinO4yHFm8dmknahkVxAMt84i1Fv613KSBV0 LLPZ0fXoj3ML2obxjHqpJkE8IXB-aFX95ahDzz6zgszPI2-9PH_6hGGAJfwA3lU2KGZcq8TPj4VKJH0UEl-UiH4FTzoUowwHjkOiA/s1717/image2.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1413&quot; data-original-width=&quot;1717&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmXa7LCZLvQy98sLB16VdQJa2RZqxfRzHvi_bfXYrUEdVaeqBqBo3yinO4yHFm8dmknahkVxAMt84i1Fv613KSBV0LLPZ0fXoj3ML2obxjHqpJkE8 IXB-aFX95ahDzz6zgszPI2-9PH_6hGGAJfwA3lU2KGZcq8TPj4VKJH0UEl-UiH4FTzoUowwHjkOiA/s16000/image2.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;VALID 库中提供的所有 42 个基本头像的头像都是在与来自 &lt;a href=&quot;https://www 的 7 个民族和种族群体的成员的广泛互动中创建的.federalregister.gov/documents/2023/01/27/2023-01635/initial-proposals-for-updating-ombs-race-and-ethnicity-statistical-standards&quot;>;联邦登记册&lt;/a>;，其中包括（AIAN、亚洲人、黑人、西班牙裔、中东和北非地区、NHPI 和白人）。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;库的创建和验证&lt;/h2>; &lt;p>; 我们的多样化头像库的种族和民族的初步选择遵循&lt;a href=&quot;https://www.npr.org/2023/01/26/1151608403/mena-race-categories-us-census的最新指南-middle-eastern-latino-hispanic&quot;>;美国人口普查局&lt;/a>;建议，截至 2023 年，使用代表美国社会大部分人口的 7 个民族和种族群体，这也可以推断到全球人口。这些群体包括西班牙裔或拉丁裔、美洲印第安人或阿拉斯加原住民 (AIAN)、亚洲人、黑人或非裔美国人、夏威夷原住民或其他太平洋岛民 (NHPI)、&lt;/em>; &lt;em>;白人、中东或北非&lt;/em>; (MENA)。我们预计图书馆将继续发展，通过未来添加的头像带来更多的多样性和代表性。 &lt;/p>; &lt;p>; 化身是手工建模和创建的，使用的过程将平均面部特征与每个种族群体的代表利益相关者的广泛合作相结合，他们的反馈用于艺术地修改化身的面部网格。然后我们对来自 33 个国家的参与者进行了一项在线研究，以确定图书馆中每个头像的种族和性别是否可识别。除了头像之外，我们还提供通过观察用户对所有 42 个基本头像的种族和性别进行统计验证的标签（见下文）。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjtBeViSCY2bs4WRXaYkkiJAHNJ5LbfUocNzYR43jFoNuRHbeBWZQpHOf-smqwriUJrR-FTbFA_BJYAPLmGary8-omCVdMSOG 8cTPYqBTj0rnFfLPanvDqyQGi2m8nL4bqkn6xg1x0U6o9-na1MiGK_RZTKhEloOjN4272h8JTt-v9WLquuMb1yMbwIYi-V /s1999/image3.jpg&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;736&quot; data-original-width=&quot;1999&quot; src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjtBeViSCY2bs4WRXaYkkiJAHNJ5LbfUocNzYR43jFoNuRHbeBWZQpHOf-smqwriUJrR-FTbFA_BJYAPLmGary8-omCVdMSOG8cTPYqBTj0rnFfLPanvDq yQGi2m8nL4bqkn6xg1x0U6o9-na1MiGK_RZTKhEloOjN4272h8JTt-v9WLquuMb1yMbwIYi-V/s16000/image3.jpg&quot;/>;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;在库验证期间向参与者展示的黑人/非裔美国人头像的头像示例。&lt;/td>; &lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; 我们发现所有亚洲人、黑人和白人化身都被所有参与者普遍认为是他们的模仿种族，而我们的美洲印第安人或阿拉斯加原住民（AIAN） ）、西班牙裔、中东或北非 (MENA) 化身通常只能由同一种族的参与者识别。这也表明，参与者种族可以提高对同一种族的虚拟角色的识别度。图书馆发布的论文强调了在研究 VR 中的化身行为时如何考虑这种群体内的熟悉度。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsN3AL9HGdePu3n_Q8ttp48pP-JRrg9Hc1dXBSL0ouJ0l8qyC13fkWqEDtgl-jRhUovE1srSLEOy_mUyJLxfLlj kA9JrVTEpKDrliNHzRadqBYBy1MvkKiJxCTJFsDJMxTXOaNj6oxLfFLuxq9EBgSpR8znJ3H2KHrm5G1_UKejqS_DX2SE1_wZqHhsrww/s1999/image1.jpg&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1509&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsN3AL9HGdePu3n_Q8ttp48pP-JRrg9Hc1dXBSL0ouJ0l8qyC13fkWqEDtgl-jRhUovE1srSLEOy_mUyJLxfLljkA9JrVTEpKDrliNHzRadqBYBy1Mvk KiJxCTJFsDJMxTXOaNj6oxLfFLuxq9EBgSpR8znJ3H2KHrm5G1_UKejqS_DX2SE1_wZqHhsrww/s16000/image1.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;由其他种族参与者和同种族参与者分开的 42 个基本化身的同意率的混淆矩阵热图。此矩阵中可见的一个有趣的方面是，参与者在识别自己种族的化身方面明显优于其他种族。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;数据集详细信息&lt;/h2>; &lt;p>; 我们的模型采用 &lt;a href=&quot;https://www.autodesk.com/products/fbx/overview&quot;>;FBX 格式&lt;/a>;，与以前的头像库兼容，例如常用的&lt;a href=&quot;https://github.com/microsoft/Microsoft-Rocketbox&quot;>;Rocketbox&lt;/a>;，并且可以轻松集成到大多数游戏引擎中，例如&lt;a href=&quot;https://unity. com/&quot;>;Unity&lt;/a>; 和 &lt;a href=&quot;https://www.unrealengine.com/&quot;>;Unreal&lt;/a>;。此外，头像还配有 69 块骨骼和 65 种面部混合形状，使研究人员和开发人员能够轻松创建和应用动态面部表情和动画。这些头像被故意制作成部分卡通化，以避免极端相似的场景，在这种情况下，一个人可能被模仿，但仍然具有足够的代表性，能够进行可靠的用户研究和社会实验。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgIlAuxGll4kdY4JweX4OnUk4IYp1FYyGARe-CKX-v1vW9H3W_xmKU_2Z4yuYDDtStl73HXdz_ncyWV3w11nGteTgN WC12kdwkvcDLaUSuq1lod1RUh67-lU0j8tekGZ3dDQ8KUGNGZj8Cl5_y1AzntFxj6Ah_akwRVJpbZVv4rIXxmunmD0CIa8y1Z0sYG/s1999/image4.jpg &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;986&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgIlAuxGll4kdY4JweX4OnUk4IYp1FYyGARe-CKX-v1vW9H3W_xmKU_2Z4yuYDDtStl73HXdz_ncyWV3w11nGteTgNWC12kdwkvcDLaUSuq1lod1RUh67 -lU0j8tekGZ3dDQ8KUGNGZj8Cl5_y1AzntFxj6Ah_akwRVJpbZVv4rIXxmunmD0CIa8y1Z0sYG/s16000/image4.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- title&quot; style=&quot;text-align: center;&quot;>;有效头像中包含的骨架索具（允许动画的骨骼）和一些面部混合形状的图像。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/ table>; &lt;br />; &lt;p>; 头像可以进一步组合休闲装和五种职业装，包括医疗、军事、工人和商务。这是对先前库的有意改进，在某些情况下，在化身服装中再现了陈规定型的性别和种族偏见，并为某些专业化身提供了非常有限的多样性。 &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPP4EicGt6Wa8y5Oxh5Ne8vmmCvgDtdKlep13d6sgaiHTsDgVqoRv28dH2Gg_RkEMOGK09fdC8Krp-BcZBy6t7 PYyNRxatgREydoyV9-3_89_CNHWdt1eY2jwrbAxgIqQ9s7eyeJHSpMf72AYDccehHYian4WGWED6CA7XHKDxywc16Rgt_eF9FecGLEja/s1537/image5.jpg&quot;样式=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1023&quot; data-original-width=&quot;1537&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPP4EicGt6Wa8y5Oxh5Ne8vmmCvgDtdKlep13d6sgaiHTsDgVqoRv28dH2Gg_RkEMOGK09fdC8Krp-BcZBy6t7PYyNRxatgREydoyV9-3_89_CNHWd t1eY2jwrbAxgIqQ9s7eyeJHSpMf72AYDccehHYian4WGWED6CA7XHKDxywc16Rgt_eF9FecGLEja/s16000/image5.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;有效头像中包含一些示例服装的图像。&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;开始使用 VALID&lt;/h2 >; &lt;p>; 我们相信，&lt;a href=&quot;https://github.com/google/valid-avatar-library&quot;>;促进包容性和多样性的虚拟头像库&lt;/a>;（VALID）将成为宝贵的资源致力于 VR/AR 应用的研究人员和开发人员。我们希望它将有助于创造更加包容和公平的虚拟体验。为此，我们邀请您探索我们在开源 &lt;a href=&quot;https://en.wikipedia.org/wiki/MIT_License&quot;>;MIT 许可证&lt;/a>;下发布的头像库。您可以免费下载头像并在各种设置中使用它们。 &lt;/p>; &lt;br />; &lt;h2>;致谢&lt;/h2>; &lt;p>; &lt;em>;这个化身库是与来自纽约大学的 Tiffany D. Do、Steve Zelenty 和 Ryan P McMahan 教授合作诞生的。佛罗里达州中部。&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/5912569868305742102/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; 类型=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/valid-perceptually-validated-virtual.html#comment-form&quot; rel=&quot;replies&quot; title= “0 条评论” type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5912569868305742102&quot; rel=&quot;edit&quot; type=&quot;application/atom+ xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/5912569868305742102&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot; http://blog.research.google/2023/12/valid-perceptually-validated-virtual.html&quot; rel=&quot;alternate&quot; title=&quot;VALID：一个经过感知验证的虚拟化身库，具有包容性和多样性&quot; type=&quot;text/ html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd ：图像高度=“16”rel=“http://schemas.google.com/g/2005#thumbnail”src=“https://img1.blogblog.com/img/b16-rounded.gif”宽度=“ 16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmXa7LCZLvQy98sLB16VdQJa2RZqxfRzHvi_bfXYrUEdVaeqBqBo3yinO4yHFm8dmknahkVxAMt84i1 Fv613KSBV0LLPZ0fXoj3ML2obxjHqpJkE8IXB-aFX95ahDzz6zgszPI2-9PH_6hGGAJfwA3lU2KGZcq8TPj4VKJH0UEl-UiH4FTzoUowwHjkOiA/s72 -c/image2.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt; /entry>;&lt;entry>;&lt;id>;标签：blogger.com,1999:blog-8474926331452026626.post-8414954450937764241&lt;/id>;&lt;已发布>;2023-12-05T17:32:00.000-08:00&lt;/已发布>;&lt;已更新>;2024-01-03T14:16:52.565-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;conference&quot;>;&lt;/category>;&lt;category方案=“http://www.blogger.com/atom/ns#”术语=“会议”>;&lt;/类别>;&lt;类别方案=“http://www.blogger.com/atom/ns#”术语= &quot;EMNLP&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Google 在 EMNLP 2023&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;发布者：项目经理 Malaya Jules，谷歌&lt;/span>; &lt;img src =“https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi63HbbcxUJqps2nNQBmiEoOpsCkh24PH9YXd_Z7VSQ5f00T_shhNlDZ03_dPNw4ge8XALlXyvIfFMmNvWzWMzHWUs80ZVGz _O9dm-bz9p0dnl4bfXPuk34a-lXfU2IKReWUkshFPQFVpL4L6IOreL2Z7RnEUTm-iEKM2XAjj9PdyVXjwGNLi7CK4JhMxnV/s320/EMNLP%202023.png&quot; style=&quot;显示：无；&quot; />; &lt;p>; Google 很荣幸成为 &lt;a href=&quot;https://2023.emnlp.org/sponsors/&quot;>;钻石赞助商&lt;/a>;。 org/&quot;>;自然语言处理的经验方法&lt;/a>; (EMNLP 2023)，这是一个重要的年度会议，本周在新加坡圣淘沙举行。 Google 在今年的会议上表现强劲，收到了超过 65 篇论文，并积极参与了 11 个研讨会和教程。 Google 也很高兴成为&lt;a href=&quot;https://www.winlp.org/winlp-2023-workshop/winlp-2023-sponsors/&quot;>;主要赞助商&lt;/a>; ://www.google.com/url?q=https://www.winlp.org/winlp-2023-workshop/&amp;amp;sa=D&amp;amp;source=editors&amp;amp;ust=1701403043253017&amp;amp;usg=AOvVaw2oPPnFe0AEcdP1iSblNV91&quot;>;拓宽 NLP &lt;/a>; 研讨会 (WiNLP)，旨在强调人工智能和机器学习中的人员、观点和文化的全球代表性。我们期待分享我们一些广泛的 NLP 研究，并扩大我们与更广泛的研究界的合作伙伴关系。 &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; 我们希望您能够参观 Google 展位，与积极追求 NLP 最新创新的研究人员交谈，并查看一些预定的展位活动（例如，下面列出的演示和问答环节）。访问 &lt;a href=&quot;https://twitter.com/GoogleAI&quot;>;@GoogleAI&lt;/a>; X (Twitter) 和 &lt;a href=&quot;https://www.linkedin.com/showcase/googleresearch/?viewAsMember =true&quot;>;LinkedIn&lt;/a>; 帐户，了解有关 EMNLP 2023 上 Google 展位活动的更多信息。&lt;/p>; &lt;p>; 请查看下文，了解有关 EMNLP 2023 上展示的 Google 研究的更多信息（Google 附属机构&lt;strong>;粗体&lt;/strong>;）。 &lt;/p>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;板和线高度组委会&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; 赞助主席：&lt;strong>;&lt;em>;Shyam Upadyay&lt;/em>;&lt;/strong>; &lt;br />; 行业分会主席：&lt; strong>;&lt;em>;Imed Zitouni&lt;/em>;&lt;/strong>; &lt;br />; 高级项目委员会：&lt;strong>;&lt;em>;Roee Aharoni&lt;/em>;&lt;/strong>;、&lt;em>;&lt;strong>;Annie Louis&lt;/ &lt;strong>;&lt;/em>;、&lt;strong>;&lt;em>;Vinodkumar Prabhakaran&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Shruti Rijhwani&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Brian Roark&lt; /em>;&lt;/strong>;、&lt;strong>;&lt;em>;Partha Talukdar&lt;/em>;&lt;/strong>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;已接受论文&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2308.03291.pdf&quot;>;SynJax ：JAX 的结构化概率分布&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Miloš Stanojević&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Laurent Sartran&lt;/em>;&lt;/strong>; &lt;/p >; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2311.11077.pdf&quot;>;适配器：用于参数高效和模块化迁移学习的统一库&lt;/a>; &lt;br />; &lt;em>;Clifton Poth &lt;/em>;、&lt;em>;汉娜·斯特兹&lt;/em>;、&lt;em>;Indraneil Paul&lt;/em>;、&lt;em>;Sukannya Purkayastha&lt;/em>;、&lt;em>;Leon Engländer&lt;/em>;、&lt;em>;蒂莫·伊姆霍夫&lt;/em>;、&lt;em>;伊万·武利奇&lt;/em>;、&lt;strong>;&lt;em>;塞巴斯蒂安·鲁德&lt;/em>;&lt;/strong>;、&lt;em>;伊琳娜·古列维奇&lt;/em>;、&lt;strong>;&lt;em>;乔纳斯·菲弗&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2306.08937.pdf&quot;>;DocumentNet：弥合文档预训练中的数据差距&lt;/a>; &lt;br />; &lt;em>;余丽君&lt;/em>;、&lt;strong>;&lt;em>;苗金&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;孙晓宇&lt;/em>;&lt;/strong>;、&lt;em>; >;Jiayi Chen&lt;/em>;、&lt;em>;Alexander Hauptmann&lt;/em>;、&lt;strong>;&lt;em>;戴汉君&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;魏巍&lt;/em>;&lt;/strong>; >; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2311.08592.pdf&quot;>;AART：人工智能辅助红队为新的法学硕士支持的应用程序提供多种数据生成&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Bhaktipriya Radharapu&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;凯文·罗宾逊&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Lora Aroyo&lt;/em>; &lt;/strong>;,&lt;strong>; &lt;em>;Preethi Lahoti&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.15239.pdf&quot;>;CRoW：在现实世界任务中对常识推理进行基准测试&lt;/a>; &lt;br />; &lt;em>;Mete Ismayilzada&lt;/em>;、&lt;em>;Debjit Paul&lt;/em>;、&lt;em>;Syrielle Montariol&lt;/em>;、&lt;strong>;&lt; em>;Mor Geva&lt;/em>;&lt;/strong>;、&lt;em>;Antoine Bosselut&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2210.11610.pdf&quot;>;大语言模型可以自我改进&lt;/a>; &lt;br />; &lt;em>;Jiaxin Huang&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Shixiang Shane Gu&lt;/em>;&lt;/strong>;、 &lt;strong>; &lt;em>;侯乐&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;吴跃新&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;王学智&lt;/em>;&lt;/strong>; ,&lt;strong>;&lt;em>;于洪坤&lt;/em>;&lt;/strong>;,&lt;em>;韩家伟&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2304.14767 .pdf&quot;>;剖析自回归语言模型中事实关联的回忆&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Mor Geva&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Jasmijn Bastings&lt;/ em>;&lt;/strong>;、&lt;strong>;&lt;em>;Katja Filippova&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;阿米尔·格洛伯森&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href =&quot;https://arxiv.org/pdf/2305.10160.pdf&quot;>;停止以纯文本形式上传测试数据：通过评估基准减轻数据污染的实用策略&lt;/a>; &lt;br />; &lt;em>;Alon Jacovi&lt;/em >;、&lt;strong>;&lt;em>;阿维·卡丘拉鲁&lt;/em>;&lt;/strong>;、&lt;em>;奥马尔·戈德曼&lt;/em>;、&lt;em>;约夫·戈德堡&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot; https://arxiv.org/pdf/2210.16391.pdf&quot;>;选择性标记：如何从根本上降低文档提取模型的数据标记成本&lt;/a>; &lt;br />; &lt;strong>;周一超&lt;/em>; &lt;/strong>;、&lt;strong>;&lt;em>;詹姆斯·布拉德利·温特&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;纳夫尼特·波蒂&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;谢静&lt;/ em>;&lt;/strong>;，&lt;strong>; &lt;em>;桑迪普·塔塔&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2112.12870.pdf&quot;>;在自然语言生成模型中测量归因&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Hannah Rashkin&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Vitaly Nikolaev&lt;/em>;&lt;/strong>;、&lt;强>;&lt;em>;马修·拉姆&lt;/em>;&lt;/strong>;，&lt;strong>;&lt;em>;洛拉·阿罗约&lt;/em>;&lt;/strong>;，&lt;strong>;&lt;em>;迈克尔·柯林斯&lt;/em>;&lt;/strong>;， &lt;strong>; &lt;em>;Dipanjan&lt;/em>; &lt;em>;Das&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;斯拉夫·彼得罗夫&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Gaurav Singh Tomar &lt;/em>;&lt;/strong>;、&lt;em>; &lt;strong>;尤利亚·图尔克&lt;/strong>;&lt;/em>;、&lt;strong>;&lt;em>;大卫·雷特&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt; a href=&quot;https://arxiv.org/pdf/2211.02011.pdf&quot;>;逆缩放可以变成 U 形&lt;/a>; &lt;br />; &lt;em>;Jason Wei&lt;sup>;*&lt;/sup>;&lt;/em >;、&lt;strong>; &lt;em>;Najoung Kim&lt;/em>;&lt;/strong>;、&lt;em>;Yi Tay&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>; &lt;em>;Quoc Le&lt;/em>;&lt; /strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14282.pdf&quot;>;INSTRUCTSCORE：通过自动反馈进行可解释文本生成评估&lt;/a>; &lt;br />; &lt;em >;徐文达&lt;/em>;、&lt;em>;王丹青&lt;/em>;、&lt;em>;潘亮明&lt;/em>;、&lt;em>;宋振桥&lt;/em>;、&lt;strong>;&lt;em>;Markus Freitag&lt;/em>; &lt;/strong>;、&lt;em>;王威廉&lt;/em>;、&lt;em>;李雷&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2206.14796.pdf &quot;>;论会话问答中对话历史表征的鲁棒性：综合研究和基于提示的新方法&lt;/a>; &lt;br />; &lt;em>;Zorik Gekhman&lt;/em>;，&lt;em>;Nadav Oved&lt;/em >;、&lt;strong>; &lt;em>;奥加德·凯勒&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;伊丹·斯佩克托&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Roi Reicart&lt;/em>;&lt;/ strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2208.04347.pdf&quot;>;研究有效扩展 Transformer 以实现长输入汇总&lt;/a>; &lt;br />; &lt;em>;Jason彭&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;姚照&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Peter J Liu&lt;/em>;&lt;/strong>; &lt;/ p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2212.09744.pdf&quot;>;DSI++：使用新文档更新 Transformer 内存&lt;/a>; &lt;br />; &lt;em>;Sanket Vaibhav Mehta&lt;sup>; *&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Jai Gupta&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Yi Tay&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>; Mostafa Dehghani&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Vinh Q. Tran&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;饶金峰&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;马克·纳约克&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;艾玛·斯特鲁贝尔&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;唐纳德·梅茨勒&lt;/em>;&lt;/strong>; &lt;/p >; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.12029.pdf&quot;>;MultiTurnCleanup：多轮口语对话记录清理基准&lt;/a>; &lt;br />; &lt;em>;沉华&lt; support>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Vicky Zayats&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;约翰 C 罗霍尔&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;丹尼尔·大卫·沃克&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;德克·帕德菲尔德&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org /pdf/2304.14318.pdf&quot;>;q2d：将问题转化为对话，教模型如何搜索&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Yonatan Bitton&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em >;Shlomi Cohen-Ganor&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Ido Hakimi&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Yoad Lewenberg&lt;/em>;&lt;/strong>;、&lt;strong>; >; &lt;em>;Roee Aharoni&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Enav Weinreb&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org /pdf/2311.02171.pdf&quot;>;具体序列建模中抽象状态表示的出现&lt;/a>; &lt;br />; &lt;em>;Tian Yun&lt;sup>;*&lt;/sup>;&lt;/em>;，&lt;em>;Zilai Zeng&lt;/ em>;、&lt;em>;Kunal Handa&lt;/em>;、&lt;strong>;&lt;em>;Ashish V Thapliyal&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Bo Pang&lt;/em>;&lt;/strong>;、&lt;em>; >;Ellie Pavlick&lt;/em>;、&lt;em>;Chen Sun&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14332.pdf&quot;>;交叉归因评估和建模-语言问答&lt;/a>; &lt;br />; &lt;em>;Benjamin Muller&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;John Wieting&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;乔纳森·克拉克&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;汤姆·科维亚特科斯基&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;塞巴斯蒂安·鲁德&lt;/em>;&lt;/strong>;、 &lt;strong>;&lt;em>;利维奥·巴尔迪尼·苏亚雷斯&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;罗伊·阿哈罗尼&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;乔纳森·赫齐格&lt;/em>;&lt;/strong>; >;,&lt;strong>; &lt;em>;王欣怡&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://www.google.com/url?q=https://arxiv. org/pdf/2305.14281.pdf&amp;amp;sa=D&amp;amp;source=docs&amp;amp;ust=1701762357021319&amp;amp;usg=AOvVaw2Q_4he8TIMmr8URRV1w4uX&quot;>;多模态预训练中视觉关系的弱监督学习&lt;/a>; &lt;br />; &lt;strong>;&lt;em >;Emanuele Bugliarello&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Aida Nematzadeh&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;丽莎·安妮·亨德里克斯&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.13286.pdf&quot;>;语言如何相互影响？研究 LM 微调过程中的跨语言数据共享&lt;/a>; &lt;br />; &lt;em>;Rochelle Choenni&lt;/em>;、&lt;strong>;&lt;em>;Dan Garrette&lt;/em>;&lt;/strong>;、&lt;em>;Ekaterina Shutova&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14214.pdf&quot;>;CompoundPiece：评估和提高语言模型的分解性能&lt;/a>; &lt;br>; &lt;本杰明·米尼克斯霍夫 (Benjamin Minixhofer)、&lt;strong>;&lt;em>;乔纳斯·菲佛 (Jonas Pfeiffer)&lt;/em>;&lt;/strong>;、&lt;em>;伊万·武利奇 (Ivan Vulić)&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https:/ /arxiv.org/pdf/2302.01328.pdf&quot;>;IC3：委员会共识的图像说明&lt;/a>; &lt;br />; &lt;em>;David Chan&lt;/em>;，&lt;strong>;&lt;em>;Austin Myers&lt;/em>;&lt; /strong>;,&lt;strong>;&lt;em>;Sudheendra Vijayanarasimhan&lt;/em>;&lt;/strong>;,&lt;strong>;&lt;em>;David A Ross&lt;/em>;&lt;/strong>;,&lt;strong>;&lt;em>;John Canny&lt;/em>; >;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.11877.pdf&quot;>;幻觉（无法）回答的奇怪案例：在隐藏的状态中寻找真相- 自信的大型语言模型&lt;/a>; &lt;br />; &lt;em>;Aviv Slobodkin&lt;/em>;、&lt;em>;Omer Goldman&lt;/em>;、&lt;strong>;&lt;em>;Avi Caciularu&lt;/em>;&lt;/strong>;、 &lt;em>;Ido Dagan&lt;/em>;、&lt;em>;Shauli Ravfogel&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.14542.pdf&quot;>;评估大型语言模型受控生成任务研究&lt;/a>; &lt;br />; &lt;em>;孙焦&lt;/em>;、&lt;em>;田宇飞&lt;/em>;、&lt;em>;周望春树&lt;/em>;、&lt;em>;徐楠&lt;/em>; >;, &lt;em>;胡钱&lt;/em>;, &lt;em>;拉胡尔·古普塔&lt;/em>;, &lt;strong>;&lt;em>;John Wieting&lt;/em>;&lt;/strong>;, &lt;em>;彭南云&lt;/em>;, &lt; em>;马学哲&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14324.pdf&quot;>;关系很重要：通过成对精度和关系校准对现代指标进行元评估&lt; /a>; &lt;br />; &lt;strong>;&lt;em>;丹尼尔·多伊奇&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;乔治·福斯特&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;马库斯·弗雷塔格&lt; /em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2210.11399.pdf&quot;>;以 0.1% 的额外计算超越缩放定律&lt;/a>; &lt;br />; &lt;em>;Yi Tay&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;em>;Jason Wei&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;em>;郑亨元&lt;sup>;*&lt;/sup>; &lt;/em>;、&lt;strong>;&lt;em>;Vinh Q. Tran&lt;/em>;&lt;/strong>;、&lt;em>;David R. So&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>; Siamak Shakeri&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Xavier Garcia&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;郑怀秀&lt;/em>;&lt;/strong>;、&lt;strong>; &lt; em>;饶金峰&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Aakanksha Chowdhery&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Denny Zhou&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;唐纳德&lt;/em>; &lt;em>;梅茨勒&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;斯拉夫·彼得罗夫&lt;/em>;&lt;/strong>; &lt;strong>;&lt;em>;尼尔·霍尔斯比&lt;/em>; &lt;/strong>;、&lt;strong>;&lt;em>;Quoc V. Le&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Mostafa Dehghani&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href =&quot;https://arxiv.org/pdf/2311.09006.pdf&quot;>;数据相似性不足以解释语言模型的性能&lt;/a>; &lt;br />; &lt;em>;Gregory Yauney&lt;sup>;*&lt;/sup>;&lt;/ em>;、&lt;strong>;&lt;em>;艾米丽·赖夫&lt;/em>;&lt;/strong>;、&lt;em>;大卫·米姆诺&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf /2311.00913.pdf&quot;>;语言模型预训练的自我影响引导数据重新加权&lt;/a>; &lt;br />; &lt;em>;Megh Thakkar&lt;sup>;*&lt;/sup>;&lt;/em>;，&lt;strong>;&lt;em>; Tolga Bolukbasi&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sriram Ganapathy&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Shikhar Vashishth&lt;/em>;&lt;/strong>;、&lt;em>; Sarath Chandar &lt;/em>;，&lt;strong>;&lt;em>;Partha Talukdar&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.11826.pdf&quot;>;重新标记：推理感知表到分析文本生成&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Deepanway Ghosal&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;Preksha Nema&lt;/em>;&lt;/strong>;，&lt; strong>; &lt;em>;Aravindan Raghuveer&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2303.15265v1.pdf&quot;>;GATITOS：使用新的多语言词典适用于低资源机器翻译&lt;/a>; &lt;br />; &lt;em>;Alex Jones&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Isaac Caswell&lt;/em>;&lt;/strong>;、&lt; strong>; &lt;em>;Ishank Saxena&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.20201v1.pdf&quot;>;视频有用的多模式机器翻译&lt; /a>; &lt;br />; &lt;em>;李一航、清水秀一郎&lt;/em>;、&lt;em>;褚晨辉&lt;/em>;、&lt;em>;黑桥贞雄&lt;/em>;、&lt;strong>;&lt;em>;李伟&lt;/em>; em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.08298.pdf&quot;>;符号调优改善语言模型中的情境学习&lt;/a>; &lt;br / >; &lt;em>;Jerry Wei&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;乐厚&lt;/em>;&lt;/strong>;、&lt;em>; &lt;strong>;Andrew Kyle Lampinen&lt;/strong>;&lt; /em>;、&lt;em>;陈向宁&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;大黄&lt;/em>;&lt;/strong>;、&lt;em>;Yi Tay&lt;sup>;*&lt;/ support>;&lt;/em>;、&lt;strong>;&lt;em>;新云&lt;/em>; &lt;em>;陈&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;卢一峰&lt;/em>;&lt;/strong>;、&lt;strong>; >;&lt;em>;Denny Zhou&lt;/em>;&lt;/strong>;、&lt;em>;马腾宇&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Quoc V Le&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14755.pdf&quot;>;“不要断章取义！”文体重写对语境模型和评估的需求&lt;/a>; &lt;br />; &lt;em>;Akhila Yerukola&lt;/em>;、&lt;em>;周旭辉&lt;/em>;、&lt;strong>;&lt;em>;Elizabeth Clark&lt;/em>; >;&lt;/strong>;、&lt;em>;Maarten Sap&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2211.08264.pdf&quot;>;QAmeleon：只有 5 个示例的多语言 QA &lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Priyanka Agrawal&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;克里斯·阿尔贝蒂&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Fantine Huot &lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;约书亚·梅内斯&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;吉马&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;塞巴斯蒂安Ruder&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;库兹曼·甘切夫&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Dipanjan Das&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>; Mirella Lapata&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2302.03540.pdf&quot;>;说、读和提示：高保真文本到-在最低限度监督下的演讲&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;尤金·哈里托诺夫&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;达米安·文森特&lt;/em>;&lt;/strong>;、&lt;strong>; &lt; em>;Zalán Borsos&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Raphaël Marinier&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sertan Girgin&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Olivier Pietquin&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;马特·沙里菲&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Marco Tagliasacchi&lt;/em>;&lt;/strong>;、&lt;strong>; >; &lt;em>;Neil Zeghidour&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2212.09939.pdf&quot;>;AnyTOD：面向任务的可编程对话系统&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;赵杰&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;曹源&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;拉加夫·古普塔&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Harrison Lee&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Abhinav Rastogi&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;明秋王&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;哈根索尔陶&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;伊扎克·沙夫兰&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;吴永辉&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14613.pdf&quot;>;有选择地回答模棱两可的问题&lt;/a>; &lt;br />; &lt;强>;&lt;em>;杰里米·R.科尔&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;张俊泉&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;丹尼尔·吉利克&lt;/em>;&lt;/ &lt;strong>;、&lt;strong>;&lt;em>;朱利安·马丁·艾森施洛斯&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Bhuwan Dhingra&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;雅各布·爱森斯坦&lt;/em>; &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2303.08954.pdf&quot;>;PRESTO：用于解析现实的面向任务的对话框的多语言数据集&lt;/a>;（参见&lt; a href=&quot;https://blog.research.google/2023/03/presto-multilingual-dataset-for-parsing.html&quot;>;博客文章&lt;/a>;）&lt;br />; &lt;strong>;&lt;em>;Rahul Goel &lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;瓦利德·阿马尔&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;阿迪亚·古普塔&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Siddharth Vashishtha&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;佐野元树&lt;/em>;&lt;/strong>;、&lt;em>; Faiz Surani&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>; &lt;em >;Max Chang&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;HyunJeong Choe&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;大卫·格林&lt;/em>;&lt;/strong>;、&lt;strong>; &lt; em>;Chuan He&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Rattima Nitisaroj&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Anna&lt;/em>; &lt;em>;Trukhina&lt;/em>;&lt; /strong>;,&lt;strong>; &lt;em>;Shachi Paul&lt;/em>;&lt;/strong>;,&lt;strong>; &lt;em>;Pararth Shah&lt;/em>;&lt;/strong>;,&lt;strong>; &lt;em>;Rushin Shah&lt;/em>; &lt;/strong>;,&lt;strong>; &lt;em>;周瑜&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.13281.pdf&quot;>;LM vs LM：通过交叉检查检测事实错误&lt;/a>; &lt;br />; &lt;em>;Roi Cohen&lt;/em>;、&lt;em>;May Hamri&lt;/em>;、&lt;strong>;&lt;em>;Mor Geva&lt;/em>;&lt;/ strong>;,&lt;strong>; &lt;em>;Amir Globerson&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.03668.pdf&quot;>;生成套件多级多模式网页理解任务&lt;/a>; &lt;br />; &lt;em>;Andrea Burns&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Krishna Srinivasan&lt;/em>;&lt;/strong>; ,&lt;strong>;&lt;em>;约书亚·安斯利&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;杰夫·布朗&lt;/em>;&lt;/strong>;、&lt;em>;布莱恩 A. 普卢默&lt;/em>;、&lt;em>; Kate&lt;/em>; &lt;em>;Saenko&lt;/em>;、&lt;strong>;&lt;em>;倪建模&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;郭曼迪&lt;/em>;&lt;/strong>; &lt;/p >; &lt;p>; &lt;a href=&quot;https://www.google.com/url?q=https://arxiv.org/pdf/2302.08956.pdf&amp;sa=D&amp;amp;source=docs&amp;amp;ust=1701763216883702&amp;amp;usg =AOvVaw1QisabqC-Gy-U4ou1jbHAY&quot;>;AfriSenti：非洲语言的 Twitter 情绪分析基准&lt;/a>; &lt;br />; &lt;em>;Shamsuddeen Hassan Muhammad&lt;/em>;、&lt;em>;Idris Abdulmumin&lt;/em>;、&lt;em>; Abinew Ali Ayele&lt;/em>;、&lt;em>;Nedjma Ousidhoum&lt;/em>;、&lt;em>;David Ifeoluwa Adelani&lt;/em>;、&lt;em>;Seid Muhie Yimam&lt;/em>;、&lt;em>;Ibrahim Said Ahmad&lt;/em>; , &lt;em>;Meriem Beloucif&lt;/em>;, &lt;em>;Saif M.&lt;/em>; &lt;em>;Mohammad&lt;/em>;, &lt;strong>;&lt;em>;Sebastian Ruder&lt;/em>;&lt;/strong>;, &lt;em>; Oumaima Hourrane&lt;/em>;、&lt;em>;Alipio Jorge&lt;/em>;、&lt;em>;Pavel Brazdil&lt;/em>;、&lt;em>;Felermino D. M&lt;/em>;。 &lt;em>;A. Ali&lt;/em>;、&lt;em>;Davis David&lt;/em>;、&lt;em>;Salomey Osei&lt;/em>;、&lt;em>;Bello Shehu-Bello&lt;/em>;、&lt;em>;Falalu Ibrahim Lawan&lt;/em>;、&lt; em>;Tajuddeen&lt;/em>; &lt;em>;Gwadabe&lt;/em>;、&lt;em>;Samuel Rutunda&lt;/em>;、&lt;em>;Tadesse Destaw Belay&lt;/em>;、&lt;em>;Wendimu Baye Messelle&lt;/em>;、&lt;em>; >; Hailu Beshada&lt;/em>; &lt;em>;Balcha&lt;/em>;、&lt;em>;Sisay Adugna Chala&lt;/em>;、&lt;em>;Hagos Tesfahun Gebrmichael&lt;/em>;、&lt;em>; Bernard Opoku&lt;/em>;、&lt;em>; >;Stephen Arthur&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.13682.pdf&quot;>;通过令牌消除优化检索增强阅读器模型&lt;/a>; &lt;br / >; &lt;em>;Moshe Berchansky&lt;/em>;、&lt;em>;Peter Izsak&lt;/em>;、&lt;strong>;&lt;em>;Avi Caciularu&lt;/em>;&lt;/strong>;、&lt;em>;Ido Dagan&lt;/em>;、&lt;em>; >;Moshe Wasserblat&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.13194.pdf&quot;>;SEAHORSE：用于摘要评估的多语言、多方面数据集&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;伊丽莎白·克拉克&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Shruti Rijhwani&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;塞巴斯蒂安·格尔曼&lt;/em>;&lt;/ &lt;strong>;、&lt;strong>; &lt;em>;约书亚·梅内斯&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;罗伊·阿哈罗尼&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;维塔利·尼古拉耶夫&lt;/em>;&lt; /strong>;、&lt;strong>;&lt;em>;Thibault Sellam&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Aditya Siddhan&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Dipanjan Das&lt;/em>; &lt;/strong>;，&lt;strong>;&lt;em>;Ankur P Parikh&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.13245.pdf&quot;>;GQA ：从多头检查点训练广义多查询变压器模型&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Joshua Ainslie&lt;/em>;&lt;/strong>;，&lt;strong>;&lt;em>;James Lee-Thorp&lt;/a>; &lt;em>; em>;&lt;/strong>;、&lt;em>;米契尔·德容&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;尤里·泽姆良斯基&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;费德里科勒布朗&lt;/em>;&lt;/strong>;，&lt;strong>;&lt;em>;苏米特桑海&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2303.09752。 pdf&quot;>;CoLT5：具有条件计算的更快的远程变压器&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Joshua Ainslie&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;陶雷&lt;/em>; &lt;/strong>;、&lt;strong>;&lt;em>;米歇尔·德容&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;圣地亚哥·翁塔农&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;悉达多·梵天&lt;/em>; em>;&lt;/strong>;、&lt;strong>; &lt;em>;尤里·泽姆良斯基&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;David Uthus&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;郭曼迪&lt; /em>;&lt;/strong>;、&lt;strong>; &lt;em>;詹姆斯·李-索普&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Yi Tay&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;宋云轩&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;Sumit Sanghai&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf /2310.16523.pdf&quot;>;通过集体批评和自我投票提高大型语言模型中人口表征的多样性&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Preethi Lahoti&lt;/em>;&lt;/strong>;,&lt;strong >; &lt;em>;尼古拉斯·布鲁姆&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;小马&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Raghavendra Kotikalapudi&lt;/em>;&lt;/strong>;、&lt;强>;&lt;em>;Sahitya Potluri&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Qijun Tan&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Hansa Srinivasan&lt;/em>;&lt;/strong>;、 &lt;strong>; &lt;em>;本·帕克&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;艾哈迈德·贝拉米&lt;/em>;&lt;/strong>;、&lt;em>;亚历克斯·博伊特尔&lt;/em>;、&lt;strong>;&lt;em>; Jilin Chen&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14926.pdf&quot;>;通用自适应提示&lt;/a>;（参见&lt;a href=&quot;https://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html&quot;>;博客文章&lt;/a>;) &lt;br />; &lt;em>;万星辰&lt;sup >;*&lt;/sup>;&lt;/em>;、&lt;em>; &lt;strong>;孙若曦、Hootan Nakhost&lt;/strong>;&lt;/em>;、&lt;strong>;&lt;em>;戴汉俊&lt;/em>;&lt;/strong>;、&lt;strong>; >;&lt;em>;朱利安·马丁·艾森施洛斯&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sercan O. Arik&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;托马斯·普菲斯特&lt;/em>;&lt;/strong>; >; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.11171.pdf&quot;>;TrueTeacher：使用大型语言模型学习事实一致性评估&lt;/a>; &lt;br />; &lt;strong>;&lt; em>;佐里克·格赫曼&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;乔纳森·赫齐格&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;罗伊·阿哈罗尼&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Chen Elkind&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Idan Szpektor&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/ pdf/2310.07871.pdf&quot;>;多模态电子健康记录分层预训练&lt;/a>; &lt;br />; &lt;em>;Xiaochen Wang&lt;/em>;，&lt;em>;Junyu Luo&lt;/em>;，&lt;em>;Jiaqi Wang&lt; /em>;、&lt;em>;尹子仪&lt;/em>;、&lt;em>;崔素涵&lt;/em>;、&lt;em>;袁忠&lt;/em>;、&lt;strong>;&lt;em>;王亚庆&lt;/em>;&lt;/strong>; , &lt;em>;马凤龙&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14499.pdf&quot;>;NAIL：具有高效非自回归解码器的词汇检索索引&lt;/ a>; &lt;br />; &lt;strong>;&lt;em>;利维奥·巴尔迪尼·苏亚雷斯&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;丹尼尔·吉利克&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;杰里米·R.科尔&lt;/em>;&lt;/strong>;，&lt;strong>;&lt;em>;汤姆·科维亚特科斯基&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.11841。 pdf&quot;>;生成检索如何扩展到数百万个段落？&lt;/a>; &lt;br />; &lt;em>;Ronak Pradeep&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Kai Hui&lt;/em >;&lt;/strong>;、&lt;strong>; &lt;em>;Jai Gupta&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Adam D. Lelkes&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;庄红雷&lt;/em>;&lt;/strong>;、&lt;em>;林志颖&lt;/em>;、&lt;strong>;&lt;em>;唐纳德·梅茨勒&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Vinh Q. Tran&lt;/em>; &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2302.13959.pdf&quot;>;让每个例子都有意义：论自我影响力从嘈杂的 NLP 中学习的稳定性和实用性数据集&lt;/a>; &lt;br />; &lt;em>;Irina Bejan&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;Artem Sokolov&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>; Katja Filippova&lt;/em>;&lt;/strong>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;EMNLP 的发现&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.11689.pdf&quot;>;适应自我评估以提高法学硕士的选择性预测&lt;/a >; &lt;br />; &lt;em>;陈杰峰&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>; &lt;em>;尹金成&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sayna Ebrahimi&lt;/em>; em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sercan O Arik&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Tomas Pfister&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Somesh Jha &lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.10062.pdf&quot;>;工具辅助生成策略的综合评估&lt;/a>; &lt;br />; &lt;em>;Alon Jacovi&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>; &lt;em>;Avi Caciularu&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Jonathan Herzig&lt;/em>;&lt; /strong>;、&lt;strong>;&lt;em>;Roee Aharoni&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Bernd Bohnet&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Mor Geva&lt;/em>; &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.16568.pdf&quot;>;1-PAGER：一次性答案生成和证据检索&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Palak Jain&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Livio Baldini Soares&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Tom Kwiatkowski&lt;/em>;&lt;/strong>; >; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2209.05401.pdf&quot;>;MaXM：迈向多语言视觉问答&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Soravit Changpinyo&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;薛琳婷&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Ashish V. Thapliyal&lt;/em>;&lt;/strong>;、&lt; strong>;&lt;em>;Idan Szpektor&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Julien&lt;/em>;&lt;em>;Amelot&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;陈曦&lt;/em>; em>;&lt;/strong>;,&lt;strong>; &lt;em>;Radu Soricut&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.18431v1.pdf&quot; >;SDOH-NLI：从临床记录推断健康社会决定因素的数据集&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Adam D. Lelkes&lt;/em>;&lt;/strong>;、&lt;em>;Eric Loreaux&lt;sup >;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;塔尔舒斯特&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;陈明君&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Alvin Rajkomar&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14815.pdf&quot;>;使用基于案例的推理进行机器阅读理解&lt;/ a>; &lt;br />; &lt;em>;Dung Ngoc Thai&lt;/em>;、&lt;em>;Dhruv Agarwal&lt;/em>;、&lt;em>;Mudit Chaudhary&lt;/em>;、&lt;em>;赵文龙&lt;/em>;、&lt;em>; Rajarshi Das&lt;/em>;、&lt;em>; Jay-Yoon Lee&lt;/em>;、&lt;em>;Hannaneh Hajishirzi&lt;/em>;、&lt;strong>;&lt;em>;Manzil Zaheer&lt;/em>;&lt;/strong>;、&lt;em>;安德鲁McCallum&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.06897.pdf&quot;>;非洲语言跨语言开放检索问答&lt;/a>; &lt;br / >; &lt;em>;Odunayo Ogundepo&lt;/em>;、&lt;em>;Tajuddeen Gwadabe&lt;/em>;、&lt;strong>;&lt;em>;Clara E. Rivera&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Jonathan H. Clark &lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sebastian Ruder&lt;/em>;&lt;/strong>;、&lt;em>;David Ifeoluwa Adelani&lt;/em>;、&lt;em>;Bonaventure FP Dossou&lt;/em>;、&lt;em>; >;Abdou Aziz DIOP&lt;/em>;、&lt;em>;Claytone Sikasote&lt;/em>;、&lt;em>;Gilles HACHEME&lt;/em>;、&lt;em>;快乐 Buzaaba&lt;/em>;、&lt;em>;Ignatius Ezeani&lt;/em>;、&lt; Rooweither Mabuya&lt;/em>;、Salomey Osei&lt;/em>;、Chris&lt;/em>;、Chinenye Emezue&lt;/em>;、Albert Kahira&lt;/em>;、&lt;em>; Shamsuddeen Hassan Muhammad&lt;/em>;、&lt;em>;Akintunde Oladipo&lt;/em>;、&lt;em>;Abraham Toluwase Owodunni&lt;/em>;、&lt;em>;Atnafu Lambebo Tonja&lt;/em>;、&lt;em>;Iyanuoluwa Shode&lt;/em>;、 &lt;em>;Akari Asai&lt;/em>;、&lt;em>;Anuoluwapo Aremu&lt;/em>;、&lt;em>;Ayodele Awokoya&lt;/em>;、&lt;em>;Bernard Opoku&lt;/em>;、&lt;em>;Chiamaka Ijeoma Chukwuneke&lt;/em>; 、&lt;em>;Christine Mwase&lt;/em>;、&lt;em>;Clemencia Siro&lt;/em>;、&lt;em>;Stephen Arthur&lt;/em>;、&lt;em>;Tunde Oluwaseyi Ajayi&lt;/em>;、&lt;em>;Verrah Akinyi Otiende&lt;/em>; em>;、&lt;em>;Andre Niyongabo Rubungo&lt;/em>;、&lt;em>;Boyd Sinkala&lt;/em>;、&lt;em>;Daniel Ajisafe&lt;/em>;、&lt;em>;Emeka Felix Onwuegbuzia&lt;/em>;、&lt;em>;Falalu Ibrahim Lawan&lt;/em>;、&lt;em>;Ibrahim Said Ahmad&lt;/em>;、&lt;em>;Jesujoba Oluwadara Alabi&lt;/em>;、&lt;em>;CHINEDU EMMANUEL&lt;/em>; &lt;em>;MBONU&lt;/em>;、&lt;em>;Mofetoluwa Adeyemi&lt;/em>;、&lt;em>;Mofya Phiri&lt;/em>;、&lt;em>;Orevaoghene Ahia&lt;/em>;、&lt;em>;Ruqayya Nasir Iro&lt;/em>;、&lt;em>;Sonia Adhiambo&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2304.08653.pdf&quot;>;概率神经总结中的不确定性校准和选择性生成：基准研究&lt;/a>; &lt;br />; &lt;strong>;&lt;em >;Polina Zablotskaia&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;杜潘&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;约书亚·梅内斯&lt;/em>;&lt;/strong>;、&lt;strong>;&lt; em>;Shashi Narayan&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;任杰&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;刘哲刘&lt;/em>;&lt;/strong>; &lt;/p >; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.09860.pdf&quot;>;Epsilon 采样摇滚：研究机器翻译最小贝叶斯风险解码的采样策略&lt;/a>; &lt;br />; &lt;strong>; &lt;em>;Markus Freitag&lt;/em>;&lt;/strong>;、&lt;em>;Behrooz Ghorbani&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;em>;Patrick Fernandes&lt;sup>;*&lt;/sup>;&lt;/em>; &lt; /p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14552.pdf&quot;>;大型语言模型对推理任务的幻觉来源&lt;/a>; &lt;br />; &lt;em>;Nick McKenna&lt; /em>;、&lt;em>;李天一&lt;/em>;、&lt;em>;梁程&lt;/em>;、&lt;strong>;&lt;em>;Mohammad Javad Hosseini&lt;/em>;&lt;/strong>;、&lt;em>;马克·约翰逊&lt;/em>; >;, &lt;em>;Mark Steedman&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.09017v2.pdf&quot;>;不要添加，不要错过：有效保留从预选文本跨度生成的内容&lt;/a>; &lt;br />; &lt;em>;Aviv Slobodkin&lt;/em>;、&lt;strong>;&lt;em>;Avi Caciularu&lt;/em>;&lt;/strong>;、&lt;em>;Eran Hirsch&lt; /em>;, &lt;em>;Ido Dagan&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2209.07686.pdf&quot;>;什么使思想链提示有效？反事实研究&lt;/a>; &lt;br />; &lt;em>;Aman Madaan&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;em>; &lt;strong>;凯瑟琳·赫尔曼&lt;/strong>;&lt;/em>;、&lt;strong>;&lt; em>;Amir Yazdanbakhsh&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2210.03945.pdf&quot;>;使用大型语言模型理解 HTML&lt;/a>; &lt; br />; &lt;strong>;&lt;em>;Izzeddin Gur&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Ofir Nachum&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;苗英杰&lt;/em>;&lt; /strong>;,&lt;strong>; &lt;em>;穆斯塔法·萨夫达里&lt;/em>;&lt;/strong>;,&lt;strong>; &lt;em>;奥斯汀·黄&lt;/em>;&lt;/strong>;,&lt;strong>; &lt;em>;Aakanksha&lt;/em>; &lt; em>;Chowdery&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sharan Narang&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;诺亚·菲德尔&lt;/em>;&lt;/strong>;、&lt;strong>; &lt; em>;Aleksandra Faust&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2212.09928.pdf&quot;>;通过检测和删除输入来提高摘要模型的鲁棒性噪音&lt;/a>; &lt;br />; &lt;em>;Kundan Krishna&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;姚照&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;任杰&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Balaji Lakshminarayanan&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;罗家明&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>; >;穆罕默德&lt;/em>; &lt;em>;萨利赫&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Peter J. Liu&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https ://arxiv.org/pdf/2310.15916.pdf&quot;>;情境学习创建任务向量&lt;/a>; &lt;br />; &lt;em>;Roee Hendel&lt;/em>;，&lt;strong>;&lt;em>;Mor Geva&lt;/em>; >;&lt;/strong>;,&lt;strong>; &lt;em>;阿米尔·格罗伯森&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2212.10544.pdf&quot;>;预-无注意力训练&lt;/a>; &lt;br />; &lt;em>;王俊雄&lt;/em>;、&lt;em>;Jing Nathan Yan&lt;/em>;、&lt;strong>;&lt;em>;Albert Gu&lt;/em>;&lt;/strong>;、 &lt;strong>; &lt;em>;Alexander M Rush&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2302.12441.pdf&quot;>;MUX-PLM：数据复用用于高吞吐量语言模型&lt;/a>; &lt;br />; &lt;em>;Vishvak Murahari&lt;/em>;、&lt;em>;Ameet Deshpande&lt;/em>;、&lt;em>;Carlos E Jimenez&lt;/em>;、&lt;em>; &lt;strong >;Izhak Shafran&lt;/strong>;&lt;/em>;、&lt;strong>;&lt;em>;王明秋&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;袁&lt;/em>; &lt;em>;曹&lt;/em>;&lt;/em>; strong>;, &lt;em>;Karthik R Narasimhan&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.14408.pdf&quot;>;PaRaDe：使用法学硕士演示进行段落排名&lt;/ a>; &lt;br />; &lt;em>;安德鲁·德罗兹多夫&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;庄红雷&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;戴朱云&lt; /em>;&lt;/strong>;、&lt;strong>;&lt;em>;秦臻&lt;/em>;&lt;/strong>;、&lt;em>;Razieh Rahimi&lt;/em>;、&lt;strong>;&lt;em>;王宣辉&lt;/em>;&lt;/strong>; >;、&lt;strong>;&lt;em>;达纳·阿隆&lt;/em>;&lt;/strong>;、&lt;em>;莫希特·艾耶&lt;/em>;、&lt;em>;安德鲁·麦卡勒姆&lt;/em>;、&lt;em>;唐纳德·梅茨勒&lt;sup>;*&lt;/ support>;&lt;/em>;,&lt;strong>; &lt;em>;凯辉&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.13678.pdf&quot;>;通过大型语言模型上有限状态解码约束的分段进行长格式语音翻译&lt;/a>; &lt;br />; &lt;em>;Arya D. McCarthy&lt;/em>;，&lt;strong>;&lt;em>;张浩&lt;/em>;&lt; /strong>;,&lt;strong>;&lt;em>;尚卡尔·库马尔&lt;/em>;&lt;/strong>;,&lt;strong>;&lt;em>;菲利克斯·斯塔伯格&lt;/em>;&lt;/strong>;,&lt;strong>;&lt;em>;吴克&lt;/em>; &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2209.07496.pdf&quot;>;使用近似测地线进行无监督意见总结&lt;/a>; &lt;br />; &lt;em>;Somnath Basu罗伊·乔杜里&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>; &lt;em>;尼古拉斯·莫纳特&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;库马尔·阿维纳瓦·杜贝&lt;/em>;&lt;/strong>;、 &lt;strong>; &lt;em>;Amr Ahmed&lt;/em>;&lt;/strong>;，&lt;em>;Snigdha Chaturvedi&lt;/em>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2311.02883。 pdf&quot;>;SQLPrompt：使用最少标记数据的上下文文本到 SQL&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Ruoxi Sun&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Sercan O . Arik&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Rajarishi Sinha&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Hootan Nakhost&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>; >;戴汉军&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;殷鹏程&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Tomas Pfister&lt;/em>;&lt;/strong>; &lt;/p>; &lt; p>; &lt;a href=&quot;https://zi-lin.com/pdf/EMNLP_2023_retrieval.pdf&quot;>;利用结构和不确定性进行复杂图的检索增强解析&lt;/a>; &lt;br />; &lt;em>;子林&lt; /em>;、&lt;strong>;&lt;em>;泉源&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Panupong Pasupat&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Jeremiah Zhe Liu&lt;/em>; >;&lt;/strong>;,&lt;strong>; &lt;em>;尚静波&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2310.08740.pdf&quot;>;A结构化反射计算机控制的零样本语言智能体&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;李涛&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;李刚&lt;/em>;&lt;/ strong>;、&lt;strong>;&lt;em>;邓志伟&lt;/em>;&lt;/strong>;、&lt;em>;王布莱恩&lt;sup>;*&lt;/sup>;&lt;/em>;、&lt;strong>;&lt;em>;李杨&lt;/em>; &lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2211.08371.pdf&quot;>;语言基础中的语用学：现象、任务和建模方法&lt;/a>; &lt;br / >; &lt;em>;丹尼尔·弗里德&lt;/em>;、&lt;em>;尼古拉斯·汤姆林&lt;/em>;、&lt;em>;詹妮弗·胡&lt;/em>;、&lt;strong>; &lt;em>;罗马·帕特尔&lt;/em>;&lt;/strong>;、&lt;strong>; >;&lt;em>;Aida Nematzadeh&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.13535.pdf&quot;>;通过主动生成成对反事实来提高分类器的鲁棒性&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Ananth Balashankar&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;王学智&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;秦瑶&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Ben Packer&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Nithum Thain&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;吉林陈&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;Ed H.&lt;/em>; &lt;em>;Chi&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;Alex Beutel&lt;/em>;&lt;/ strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2305.14224.pdf&quot;>;mmT5：模块化多语言预训练解决源语言幻觉&lt;/a>; &lt;br />; &lt;strong >;&lt;em>;乔纳斯·菲佛&lt;/em>;&lt;/strong>;、&lt;em>; &lt;strong>;弗朗西斯科·皮奇诺&lt;/strong>;&lt;/em>;、&lt;strong>;&lt;em>;马西莫·尼科西亚&lt;/em>;&lt;/strong>;、&lt; strong>;&lt;em>;王欣怡&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Machel Reid&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;塞巴斯蒂安&lt;/em>; &lt;em>;Ruder&lt;/ em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2207.10551.pdf&quot;>;缩放法则与模型架构：归纳偏差如何影响缩放？&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Yi Tay&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Mostafa Dehghani&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Samira Abnar&lt;/em>; &lt;/strong>;、&lt;strong>;&lt;em>;郑亨元&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;William Fedus&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;饶金峰&lt;/strong>; em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sharan Narang&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Vinh Q. Tran&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Dani瑜伽塔玛&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em>;唐纳德·梅茨勒&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2211.00142。 pdf&quot;>;TaTA：非洲语言的多语言表到文本数据集&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Sebastian Gehrmann&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Sebastian Ruder&lt; /em>;&lt;/strong>;、&lt;strong>;&lt;em>;维塔利·尼古拉耶夫&lt;/em>; &lt;em>;Jan A. Botha&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;迈克尔·查文达&lt;/em>;&lt; /strong>;, &lt;strong>;&lt;em>;Ankur P Parikh&lt;/em>;&lt;/strong>;,&lt;strong>; &lt;em>;Clara E. Rivera&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href =&quot;https://arxiv.org/pdf/2305.11938.pdf&quot;>;XTREME-UP：针对代表性不足的语言的以用户为中心的稀缺数据基准&lt;/a>; &lt;br />; &lt;strong>;&lt;em>;Sebastian Ruder ，&lt;/em>;&lt;/strong>; &lt;strong>;&lt;em>;乔纳森·克拉克&lt;/em>;&lt;/strong>;，&lt;strong>;&lt;em>;亚历山大·古特金&lt;/em>;&lt;/strong>;，&lt;strong>; &lt;em >;Mihir Kale&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;马敏&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;马西莫·尼科西亚&lt;/em>;&lt;/strong>;、&lt;strong>;&lt; em>;Shruti Rijhwani&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;帕克·莱利&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Jean Michel Amath Sarr&lt;/em>;&lt;/strong>;、&lt;强>; &lt;em>;王欣怡&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;约翰·弗雷德里克&lt;/em>; &lt;em>;Wieting&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Nitish Gupta&lt; /em>;&lt;/strong>;、&lt;strong>; &lt;em>;安娜·卡塔诺娃&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;克里斯托·基洛夫&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Dana L迪金森&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;布莱恩·罗克&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;比迪莎·萨曼塔&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;陶康妮&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;David Ifeoluwa Adelani&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Vera Axelrod&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;艾萨克·雷伯恩&lt;/em>; &lt;em>;卡斯韦尔&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;科林·切里&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;丹·加勒特&lt;/em>; &lt;/strong>;、&lt;strong>; &lt;em>;里夫·英格尔&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;梅尔文·约翰逊&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;德米特里·潘捷列夫&lt;/em>; >;&lt;/strong>;,&lt;strong>; &lt;em>;Partha Talukdar&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://arxiv.org/pdf/2311.00693.pdf&quot;>;关于用于视觉丰富的文档实体检索的任务个性化多模态小样本学习&lt;/a>; &lt;br />; &lt;em>;Jiayi Chen&lt;sup>;*&lt;/sup>;&lt;/em>;，&lt;strong>;&lt;em>;Hanjun Dai&lt; /em>;&lt;/strong>;、&lt;strong>;&lt;em>;戴波&lt;/em>;&lt;/strong>;、&lt;em>;张爱东&lt;/em>;、&lt;em>;魏巍&lt;sup>;*&lt;/sup>;&lt;/ em>; &lt;/p>; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;研讨会&lt;/h2>; &lt;div style=&quot;margin-left: 20px ;&quot;>; &lt;p>; &lt;a href=&quot;https://www.google.com/url?q=https://www.winlp.org/&amp;amp;sa=D&amp;amp;source=docs&amp;amp;ust=1701752203060961&amp;amp;usg =AOvVaw3sRozMNVYuwvyXeLluOgKI&quot;>;第七届拓宽 NLP 研讨会&lt;/a>; (WiNLP) &lt;br />; 主要赞助商&lt;br />; 主办方：&lt;strong>;&lt;em>;Sunipa Dev&lt;/em>;&lt;/strong>; &lt;br />; 小组成员： &lt;strong>;&lt;em>;Preethi Lahoti&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://sites.google.com/corp/view/crac2023/?pli=1&quot;>;第六届指称、照应与共指计算模型研讨会&lt;/a>;（CRAC）&lt;br />;特邀演讲嘉宾：&lt;strong>;&lt;em>;Bernd Bohnet&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt; a href=&quot;https://nlposs.github.io/2023/index.html&quot;>;第三届自然语言处理开源软件研讨会&lt;/a>;（NLP-OSS）&lt;br />;主办方：&lt;strong>;&lt; em>;Geeticka Chauhan&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://splu-robonlp-2023.github.io/&quot;>;空间语言理解与扎根交流联合研讨会机器人学&lt;/a>; (SpLU-RoboNLP) &lt;br />; 特邀演讲嘉宾：&lt;strong>;&lt;em>;Andy Zeng&lt;/​​em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://gem -benchmark.com/workshop&quot;>;自然语言生成、评估和度量&lt;/a>;（GEM）&lt;br />;组织者：&lt;strong>;&lt;em>;Elizabeth Clark&lt;/em>;&lt;/strong>; &lt;/p>; &lt; p>; &lt;a href=&quot;https://arabicnlp2023.sigarab.org/&quot;>;首届阿拉伯自然语言处理会议&lt;/a>;（ArabicNLP）&lt;br />;主办方：&lt;strong>;&lt;em>;Imed Zitouni&lt;/em >;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://www.bigpictureworkshop.com/&quot;>;大局：制定研究叙述&lt;/a>; (BigPicture) &lt;br />; 组织者： &lt;strong>;&lt;em>;诺拉·卡斯纳&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;塞巴斯蒂安·鲁德&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://blackboxnlp .github.io/&quot;>;BlackboxNLP 2023：第六届 NLP 分析和解释神经网络研讨会&lt;/a>; &lt;br />; 组织者：&lt;strong>;&lt;em>;Najoung Kim&lt;/em>;&lt;/strong>; &lt;br / >; 小组成员：&lt;strong>;&lt;em>;Neel Nanda&lt;/em>;&lt;/strong>; &lt;/p>; &lt;p>; &lt;a href=&quot;https://www.conll.org/2023&quot;>;SIGNLL 计算自然会议语言学习&lt;/a>; (CoNLL) &lt;br />; 联合主席：&lt;strong>;&lt;em>;David Reitter&lt;/em>;&lt;/strong>; &lt;br />; 领域和 AC：&lt;strong>;&lt;em>;Kyle Gorman&lt; /em>;&lt;/strong>;（语音和音系），&lt;strong>;&lt;em>;刘飞&lt;/em>;&lt;/strong>;（自然语言生成）&lt;/p>; &lt;p>; &lt;a href=&quot;https:// sigtyp.github.io/ws2023-mrl.html&quot;>;第三届多语言表征学习研讨会&lt;/a>;（MRL）&lt;br />;主办方：&lt;strong>;&lt;em>;Omer Goldman&lt;/em>;&lt;/strong >;, &lt;strong>;&lt;em>;Sebastian Ruder&lt;/em>;&lt;/strong>; &lt;br />; 特邀演讲嘉宾：&lt;strong>;&lt;em>;Orhan Firat&lt;/em>;&lt;/strong>; &lt;/p>; &lt;/div>; &lt; div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;教程&lt;/h2>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; &lt;a href=&quot; https://emnlp2023-creative-nlg.github.io/&quot;>;创意自然语言生成&lt;/a>; &lt;br />; 组织者：&lt;em>;Tuhin Chakrabarty&lt;sup>;*&lt;/sup>;&lt;/em>; &lt;/p >; &lt;/div>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Google 研究展位活动&lt;/h2>; &lt;p>; &lt;i>;此时间表可能会发生变化。请访问 Google 展位了解更多信息。&lt;/i>;&lt;/p>; &lt;div style=&quot;margin-left: 20px;&quot;>; &lt;p>; 开发和利用机器翻译和翻译的评估指标改进多语言 NLP &lt;br />; 演讲者：&lt;strong>;&lt;em>;Isaac Caswell&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Dan Deutch&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>;Jan -Thorsten Peter&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;David Vilar Torres&lt;/em>;&lt;/strong>; &lt;br />; 12 月 8 日星期五 | 10:30AM -11:00AM SST &lt;/p>; &lt;p>; 可微搜索索引和索引生成检索&lt;br />;演讲者：&lt;strong>;&lt;em>;Sanket Vaibhav Mehta&lt;/em>;&lt;/strong>;、&lt;strong>; &lt;em>;Vinh Tran&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em>; Kai Hui&lt;/em>;&lt;/strong>;、&lt;em>;Ronak Pradeep&lt;sup>;*&lt;/sup>;&lt;/em>; &lt;br />; 12 月 8 日星期五 | 3:30PM -4:00PM SST &lt;/p>; &lt;p>; 单次检索和生成&lt;br />; 演讲者：&lt;strong>;&lt;em>;Palak Jain&lt;/em>;&lt;/strong>;、&lt;strong>;&lt;em >;Livio Baldini Soares&lt;/em>;&lt;/strong>; &lt;br />; 12 月 9 日，星期六 | 10:30AM -11:00AM SST &lt;/p>; &lt;p>; 放大对抗性攻击&lt;br />; 演讲者：&lt;strong>; &lt;em>;Anu Sinha&lt;/em>;&lt;/strong>; &lt;br />; 12 月 9 日，星期六 | 12:30PM -1:45PM SST &lt;/p>; &lt;p>; 自动提示设计：通用自适应提示（请参阅&lt;a href=&quot;https://blog.research.google/2023/11/zero-shot-adaptive -prompting-of-large.html&quot;>;博文&lt;/a>;) &lt;br />;演讲者：&lt;strong>;&lt;em>;万星辰&lt;sup>;*&lt;/sup>;&lt;/em>;&lt;/strong>;, &lt;strong>; >;&lt;em>;孙若曦&lt;/em>;&lt;/strong>; &lt;br />; 12 月 9 日，星期六 | 3:30PM -4:00PM SST &lt;/p>; &lt;/div>; &lt;!--脚注-->; &lt;hr width=&quot;80%&quot; />; &lt;p>; &lt;span class=&quot;Apple-style-span&quot; style= &quot;font-size:small;&quot;>;&lt;b>;*&lt;/b>;&amp;nbsp;在 Google 期间完成的工作&lt;/span>;&lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google /feeds/8414954450937764241/comments/default&quot; rel=&quot;replies&quot; title=&quot;发表评论&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/ google-at-emnlp-2023.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 条评论&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds /8474926331452026626/posts/default/8414954450937764241&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/8414954450937764241&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/google-at-emnlp-2023.html&quot; rel=&quot;alternate&quot; title=&quot;Google at EMNLP 2023&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;电子邮件>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog. com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/ b/R29vZ2xl/AVvXsEi63HbbcxUJqps2nNQBmiEoOpsCkh24PH9YXd_Z7VSQ5f00T_shhNlDZ03_dPNw4ge8XALlXyvIfFMmNvWzWMzHWUs80ZVGz_O9dm-bz9p0dnl4bfXPuk34a-lXfU2 IKReWUkshFPQFVpL4L6IOreL2Z7RnEUTm-iEKM2XAjj9PdyVXjwGNLi7CK4JhMxnV/s72-c/EMNLP%202023.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media: thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;/feed>;