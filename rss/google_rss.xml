<feed xmlns="http://www.w3.org/2005/Atom" xmlns:blogger="http://schemas.google.com/blogger/2008" xmlns:gd="http://schemas.google.com/g/2005" xmlns:georss="http://www.georss.org/georss" xmlns:opensearch="http://a9.com/-/spec/opensearchrss/1.0/" xmlns:thr="http://purl.org/syndication/thread/1.0"><id>æ ‡ç­¾ï¼šblogger.comï¼Œ1999ï¼šblog-8474926331452026626</id><updated> 2023-12-04T11:30:11.497-08:00 </updated><category term="Machine Learning"></category><category term="Deep Learning"></category><category term="Computer Vision"></category><category term="Natural Language Processing"></category><category term="Google Brain"></category><category term="open source"></category><category term="Research"></category><category term="Publications"></category><category term="Machine Perception"></category><category term="conference"></category><category term="Natural Language Understanding"></category><category term="TensorFlow"></category><category term="conferences"></category><category term="Education"></category><category term="datasets"></category><category term="Neural Networks"></category><category term="Reinforcement Learning"></category><category term="University Relations"></category><category term="Health"></category><category term="Robotics"></category><category term="AI"></category><category term="CVPR"></category><category term="NLP"></category><category term="Algorithms"></category><category term="Multimodal Learning"></category><category term="Quantum Computing"></category><category term="Speech"></category><category term="Research Awards"></category><category term="Computational Photography"></category><category term="Machine Intelligence"></category><category term="On-device Learning"></category><category term="AI for Social Good"></category><category term="Security and Privacy"></category><category term="Computer Science"></category><category term="HCI"></category><category term="MOOC"></category><category term="ICLR"></category><category term="Quantum AI"></category><category term="Machine Translation"></category><category term="accessibility"></category><category term="optimization"></category><category term="Image Classification"></category><category term="Pixel"></category><category term="Self-Supervised Learning"></category><category term="Visualization"></category><category term="YouTube"></category><category term="AutoML"></category><category term="Hardware"></category><category term="ACL"></category><category term="Audio"></category><category term="NeurIPS"></category><category term="Android"></category><category term="ICML"></category><category term="TPU"></category><category term="Awards"></category><category term="EMNLP"></category><category term="ML"></category><category term="ML Fairness"></category><category term="Physics"></category><category term="Search"></category><category term="Structured Data"></category><category term="video"></category><category term="Image Processing"></category><category term="Information Retrieval"></category><category term="Responsible AI"></category><category term="TTS"></category><category term="User Experience"></category><category term="distributed systems"></category><category term="Automatic Speech Recognition"></category><category term="Collaboration"></category><category term="Google Accelerated Science"></category><category term="Google Maps"></category><category term="Graph Mining"></category><category term="Speech Recognition"></category><category term="Supervised Learning"></category><category term="DeepMind"></category><category term="Environment"></category><category term="Google Translate"></category><category term="Video Analysis"></category><category term="2022 Year-in-Review"></category><category term="ACM"></category><category term="Chemistry"></category><category term="Earth Engine"></category><category term="K-12"></category><category term="statistics"></category><category term="Acoustic Modeling"></category><category term="Diversity"></category><category term="Interspeech"></category><category term="Systems"></category><category term="UI"></category><category term="Vision Research"></category><category term="Voice Search"></category><category term="data science"></category><category term="ph.d. fellowship"></category><category term="Cloud Computing"></category><category term="Compression"></category><category term="ICCV"></category><category term="Machine Hearing"></category><category term="NIPS"></category><category term="RAI-HCT Highlights"></category><category term="Semi-supervised Learning"></category><category term="Software"></category><category term="Translate"></category><category term="Unsupervised Learning"></category><category term="grants"></category><category term="market algorithms"></category><category term="Augmented Reality"></category><category term="Faculty Summit"></category><category term="Google Cloud Platform"></category><category term="Google Genomics"></category><category term="Recommender Systems"></category><category term="Semantic Models"></category><category term="crowd-sourcing"></category><category term="Art"></category><category term="Biology"></category><category term="Course Builder"></category><category term="Data Discovery"></category><category term="Google Photos"></category><category term="Google+"></category><category term="PhD Fellowship"></category><category term="Social Networks"></category><category term="WWW"></category><category term="ads"></category><category term="renewable energy"></category><category term="Climate"></category><category term="Computational Imaging"></category><category term="Differential Privacy"></category><category term="Europe"></category><category term="Expander"></category><category term="Fusion Tables"></category><category term="Google Books"></category><category term="Moore's Law"></category><category term="Ngram"></category><category term="Optical Character Recognition"></category><category term="Year in Review"></category><category term="schema.org"></category><category term="API"></category><category term="Africa"></category><category term="App Engine"></category><category term="Gmail"></category><category term="Google Play Apps"></category><category term="High Dynamic Range Imaging"></category><category term="Image Annotation"></category><category term="India"></category><category term="Internet of Things"></category><category term="Kaggle"></category><category term="Large Language Models"></category><category term="NAACL"></category><category term="Networks"></category><category term="Virtual Reality"></category><category term="economics"></category><category term="internationalization"></category><category term="publication"></category><category term="resource optimization"></category><category term="search ads"></category><category term="wikipedia"></category><category term="Adaptive Data Analysis"></category><category term="Android Wear"></category><category term="App Inventor"></category><category term="China"></category><category term="DeepDream"></category><category term="EMEA"></category><category term="Exacycle"></category><category term="Gboard"></category><category term="Genomics"></category><category term="Google Docs"></category><category term="Google Drive"></category><category term="Google Science Fair"></category><category term="Google Sheets"></category><category term="Graph"></category><category term="Inbox"></category><category term="KDD"></category><category term="Keyboard Input"></category><category term="Labs"></category><category term="Low-Light Photography"></category><category term="MapReduce"></category><category term="Policy"></category><category term="Proposals"></category><category term="Style Transfer"></category><category term="TensorBoard"></category><category term="VLDB"></category><category term="Weather"></category><category term="electronics"></category><category term="osdi"></category><category term="patents"></category><category term="trends"></category><category term="April Fools"></category><category term="Australia"></category><category term="BigQuery"></category><category term="CHI"></category><category term="Cantonese"></category><category term="Chrome"></category><category term="Conservation"></category><category term="Data Center"></category><category term="ECCV"></category><category term="Electronic Commerce and Algorithms"></category><category term="Encryption"></category><category term="Entity Salience"></category><category term="Faculty Institute"></category><category term="Flu Trends"></category><category term="Google Cloud"></category><category term="Google I/O"></category><category term="Google Trips"></category><category term="Google Voice Search"></category><category term="Government"></category><category term="Graphs"></category><category term="High-Performance Computing"></category><category term="ICSE"></category><category term="IPython"></category><category term="Journalism"></category><category term="Klingon"></category><category term="Korean"></category><category term="Linear Optimization"></category><category term="Magenta"></category><category term="Market Research"></category><category term="Mixed Reality"></category><category term="Network Management"></category><category term="Nexus"></category><category term="Peer Review"></category><category term="PhotoScan"></category><category term="PiLab"></category><category term="Professional Development"></category><category term="Public Data Explorer"></category><category term="SIGCOMM"></category><category term="SIGMOD"></category><category term="Site Reliability Engineering"></category><category term="Sound Search"></category><category term="TV"></category><category term="UNIX"></category><category term="Visiting Faculty"></category><category term="Wiki"></category><category term="adsense"></category><category term="adwords"></category><category term="correlate"></category><category term="entities"></category><category term="gamification"></category><category term="jsm"></category><category term="jsm2011"></category><category term="localization"></category><category term="materials science"></category><category term="operating systems"></category><category term="osdi10"></category><title type="text">Google AI åšå®¢&lt;/stitle>;&lt;subtitle type=&quot;html&quot;>;æ¥è‡ª Google AI çš„æœ€æ–°æ–°é—»ã€‚&lt;/substitle>;&lt;link href=&quot;http://blog.research.google/feeds/posts/default&quot; rel=&quot; http://schemas.google.com/g/2005#feed&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default? alt=atom&amp;redirect=false&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/&quot; rel=&quot;alternate&quot; type=&quot;text/html&quot; />;&lt;link href=&quot;http://pubsubhubbub.appspot.com/&quot; rel=&quot;hub&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default?alt= atom&amp;start-index=26&amp;max-results=25&amp;redirect=false&quot; rel=&quot;next&quot; type=&quot;application/atom+xml&quot;/>;&lt;author>;&lt;name>;ewood&lt;/name>;&lt;uri>;http://www.blogger. com/profile/12341551220176883769&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src =&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;generator uri=&quot;http://www.blogger.com &quot; version=&quot;7.00&quot;>;Blogger&lt;/generator>;&lt;opensearch:totalresults>;1313&lt;/opensearch:totalresults>;&lt;opensearch:startindex>;1&lt;/opensearch:startindex>;&lt;opensearch:itemsperpage>;25&lt;/opensearch:itemsperpage>;&lt;entry >;&lt;id>;æ ‡ç­¾ï¼šblogger.comï¼Œ1999ï¼šblog-8474926331452026626.post-68038970217457115&lt;/id>;&lt;å‘å¸ƒ>;2023-12-04T10:00:00.000-08:00&lt;/å‘å¸ƒ>;&lt;æ›´æ–°>;2023-12- 04T11:29:40.224-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;ads&quot;>;&lt;/category>;&lt;category schema=&quot;http: //www.blogger.com/atom/ns#&quot; term=&quot;optimization&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;å®‰å…¨å’Œéšç§&quot; >;&lt;/category>;&lt;title type=&quot;text&quot;>;Privacy Sandbox å½’å› æŠ¥å‘Š API ä¸­çš„æ‘˜è¦æŠ¥å‘Šä¼˜åŒ–&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;ç”± Hidayet Aksu å‘å¸ƒï¼Œ Google è½¯ä»¶å·¥ç¨‹å¸ˆå…¼ç ”ç©¶ç§‘å­¦å®¶ Adam Sealfon&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFxpfW7ZN6OUw0lsK3lruiscqMgB3Jt8aBViPGNvHA0MzUPSFp6TRDOPdqSfO4A_0QgpWQo5mT0Vdpl v5uBFQmdSePT1LPlwN-hLJ1TP-SHwmIMXYfoNL9CxBw11ABp89ril2o6lDJcT8MCJQ6HwU13vmN6CqnCnNwSpH9d4lgO_CISNxVqKCYSyT_SiwN/s320/hero.jpg&quot;æ ·å¼= â€œæ˜¾ç¤ºï¼šæ— ï¼›â€ />; &lt;p>; è¿‘å¹´æ¥ï¼ŒæŽ¨å‡ºäº†&lt;a href=&quot;https://privacysandbox.com/&quot;>;éšç§æ²™ç›’&lt;/a>;è®¡åˆ’ï¼Œæ—¨åœ¨æŽ¢ç´¢å¹¿å‘Šå•†å¦‚ä½•è´Ÿè´£ä»»åœ°è¡¡é‡å…¶å¹¿å‘Šæ´»åŠ¨çš„æœ‰æ•ˆæ€§ï¼Œå…¶ç›®æ ‡æ˜¯&lt;a href=&quot;https://blog.chromium.org/2020/01/building-more-private-web-path-towards.html&quot;>;å¼ƒç”¨ç¬¬ä¸‰æ–¹ Cookie&lt;/a>;ï¼ˆå—&lt;a href =&quot;https://www.gov.uk/cma-cases/investigation-into-googles-privacy-sandbox-browser-changes&quot;>;ä¸Žè‹±å›½ç«žäº‰å’Œå¸‚åœºç®¡ç†å±€è§£å†³ä»»ä½•ç«žäº‰é—®é¢˜&lt;/a>;ï¼‰ã€‚ &lt;a href=&quot;https://en.wikipedia.org/wiki/HTTP_cookie#Third-party_cookie&quot;>;Cookie&lt;/a>; æ˜¯ç½‘ç«™å­˜å‚¨åœ¨ç”¨æˆ·è®¾å¤‡ä¸Šçš„åŒ…å«ç”¨æˆ·åå¥½è®¾ç½®çš„å°æ•°æ®ï¼›å®ƒä»¬å¯ç”¨äºŽæä¾›æ›´å¥½çš„æµè§ˆä½“éªŒï¼ˆä¾‹å¦‚ï¼Œå…è®¸ç”¨æˆ·è‡ªåŠ¨ç™»å½•ï¼‰å¹¶æä¾›ç›¸å…³å†…å®¹æˆ–å¹¿å‘Šã€‚ Privacy Sandbox è¯•å›¾é€šè¿‡æä¾›éšç§ä¿æŠ¤æ›¿ä»£æ–¹æ¡ˆæ¥è§£å†³æœ‰å…³ä½¿ç”¨ cookie è·Ÿè¸ªæ•´ä¸ªç½‘ç»œæµè§ˆæ•°æ®çš„é—®é¢˜ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; è®¸å¤šæµè§ˆå™¨ä½¿ç”¨&lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_privacy&quot;>;å·®åˆ†éšç§&lt;/a>;ï¼ˆDP ï¼‰æä¾›éšç§ä¿æŠ¤ APIï¼Œä¾‹å¦‚&lt;a href=&quot;https://developer.chrome.com/docs/privacy-sandbox/attribution-reporting&quot;>;å½’å› æŠ¥å‘Š API&lt;/a>; (ARA)ï¼Œä¸ä¾èµ– cookie æ¥è¡¡é‡å¹¿å‘Šè½¬åŒ–ã€‚ ARA ä¼šå¯¹ä¸ªäººç”¨æˆ·æ“ä½œè¿›è¡ŒåŠ å¯†ï¼Œå¹¶å°†å…¶æ”¶é›†åˆ°èšåˆçš„&lt;a href=&quot;https://developer.chrome.com/docs/privacy-sandbox/summary-reports/&quot;>;æ‘˜è¦æŠ¥å‘Š&lt;/a>;ä¸­ï¼Œè¯¥æŠ¥å‘Šä¼šä¼°è®¡æµ‹é‡ç›®æ ‡ï¼Œä¾‹å¦‚å½’å› äºŽå¹¿å‘Šæ´»åŠ¨çš„è½¬åŒ–ï¼ˆç½‘ç«™ä¸Šçš„æœ‰ç”¨æ“ä½œï¼Œä¾‹å¦‚è´­ä¹°æˆ–æ³¨å†Œé‚®ä»¶åˆ—è¡¨ï¼‰çš„æ•°é‡å’Œä»·å€¼ã€‚ &lt;/p>; &lt;p>; é…ç½® API å‚æ•°çš„ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œåœ¨ä¸åŒçš„è½¬åŒ–ä¹‹é—´åˆ†é…è´¡çŒ®é¢„ç®—ï¼‰å¯¹äºŽæœ€å¤§åŒ–æ‘˜è¦æŠ¥å‘Šçš„æ•ˆç”¨éžâ€‹â€‹å¸¸é‡è¦ã€‚åœ¨â€œ&lt;a href=&quot;https://arxiv.org/abs/2311.13586&quot;>;Privacy Sandbox å½’å› æŠ¥å‘Š API ä¸­çš„æ‘˜è¦æŠ¥å‘Šä¼˜åŒ–&lt;/a>;â€ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ç”¨äºŽå¯¹æ‘˜è¦æŠ¥å‘Šè¿›è¡Œå»ºæ¨¡çš„æ­£å¼æ•°å­¦æ¡†æž¶ã€‚ç„¶åŽï¼Œæˆ‘ä»¬å°†æœ€å¤§åŒ–æ‘˜è¦æŠ¥å‘Šæ•ˆç”¨çš„é—®é¢˜è¡¨è¿°ä¸ºä¼˜åŒ–é—®é¢˜ï¼Œä»¥èŽ·å¾—æœ€ä½³ ARA å‚æ•°ã€‚æœ€åŽï¼Œæˆ‘ä»¬ä½¿ç”¨çœŸå®žå’Œåˆæˆæ•°æ®é›†è¯„ä¼°è¯¥æ–¹æ³•ï¼Œå¹¶è¯æ˜Žä¸ŽåŸºçº¿éžä¼˜åŒ–æ‘˜è¦æŠ¥å‘Šç›¸æ¯”ï¼Œå®žç”¨æ€§æ˜¾ç€æé«˜ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ARA æ‘˜è¦æŠ¥å‘Š&lt;/h2>; &lt;p>; æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ç¤ºä¾‹æ¥è¯´æ˜Žæˆ‘ä»¬çš„ç¬¦å·ã€‚æƒ³è±¡ä¸€å®¶åä¸º &lt;em>;Du &amp;amp; çš„è™šæž„ç¤¼å“åº—ã€‚ Penc&lt;/em>; ä½¿ç”¨æ•°å­—å¹¿å‘Šæ¥å¸å¼•å®¢æˆ·ã€‚ä¸‹è¡¨è®°å½•äº†ä»–ä»¬çš„å‡æ—¥é”€å”®æƒ…å†µï¼Œå…¶ä¸­æ¯æ¡è®°å½•éƒ½åŒ…å«å±•ç¤ºæ¬¡æ•°ç‰¹å¾ï¼Œå…¶ä¸­åŒ…æ‹¬ (i) å±•ç¤ºæ¬¡æ•° IDã€(ii) å¹¿å‘Šæ´»åŠ¨å’Œ (iii) å±•ç¤ºå¹¿å‘Šçš„åŸŽå¸‚ï¼Œä»¥åŠè½¬åŒ–ç‰¹å¾ï¼ŒåŒ…æ‹¬ (i)è´­ä¹°çš„ç‰©å“æ•°é‡ä»¥åŠ (ii) è¿™äº›ç‰©å“çš„æ€»ç¾Žå…ƒä»·å€¼ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqrhtaPxDlj8o5sbubBQLdCq_RRnT2ZPmhxuvEIC_9SvLfhKkXh1t_elS4eRCQyHv2pYX4YkAX1UkEX3c3B dbB5PejqLF0uq_MAXuXKVA1YPKVnZ5tqertr02eNDFjJ0nnoeD_rGdDFWxLrTsCNGXOE9LrGSsuPhrtZ6SgqRomWRjpun1JdrwWDfnfJF0n/s1035/image4.png&quot; style=&quot;margin-å·¦ï¼šè‡ªåŠ¨ï¼›å³è¾¹è·ï¼šè‡ªåŠ¨ï¼›&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;397&quot; data-original-width=&quot;1035&quot; height=&quot;245&quot; src=&quot;https://blogger .googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqrhtaPxDlj8o5sbubBQLdCq_RRnT2ZPmhxuvEIC_9SvLfhKkXh1t_elS4eRCQyHv2pYX4YkAX1UkEX3c3BdbB5PejqLF0uq_MAXuXKVA1YPKVn Z5tqertr02eNDFjJ0nnoeD_rGdDFWxLrTsCNGXOE9LrGSsuPhrtZ6SgqRomWRjpun1JdrwWDfnfJF0n/w640-h245/image4.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;Du &amp;amp; çš„å±•ç¤ºå’Œè½¬åŒ–åŠŸèƒ½æ—¥å¿—Penc.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;æ•°å­¦æ¨¡åž‹&lt; /h3>; &lt;p>; ARA æ‘˜è¦æŠ¥å‘Šå¯ä»¥é€šè¿‡å››ç§ç®—æ³•å»ºæ¨¡ï¼š(1) è´¡çŒ®å‘é‡ï¼Œ(2) &lt;a href=&quot;https://github.com/WICG/attribution-reporting-api/blob/main/ AGGREGATE.md#contribution-bounding-and-budgeting&quot;>;è´¡çŒ®è¾¹ç•Œ&lt;/a>;ï¼Œ(3) &lt;a href=&quot;https://github.com/WICG/attribution-reporting-api/blob/main/AGGREGATION_SERVICE_TEEã€‚ md?&quot;>;æ‘˜è¦æŠ¥å‘Š&lt;/a>;ï¼Œä»¥åŠ (4) é‡æž„å€¼ã€‚è´¡çŒ®è¾¹ç•Œå’Œæ‘˜è¦æŠ¥å‘Šç”± ARA æ‰§è¡Œï¼Œè€Œè´¡çŒ®å‘é‡å’Œé‡æž„å€¼ç”± AdTech æä¾›å•†ï¼ˆä½¿ä¼ä¸šèƒ½å¤Ÿè´­ä¹°å’Œé”€å”®æ•°å­—å¹¿å‘Šçš„å·¥å…·å’Œç³»ç»Ÿï¼‰æ‰§è¡Œã€‚è¿™é¡¹å·¥ä½œçš„ç›®çš„æ˜¯ååŠ©å¹¿å‘ŠæŠ€æœ¯å…¬å¸ä¼˜åŒ–æ‘˜è¦æŠ¥å‘Šç®—æ³•ã€‚ &lt;/p>; &lt;p>; è´¡çŒ®å‘é‡ç®—æ³•å°†æµ‹é‡ç»“æžœè½¬æ¢ä¸ºç¦»æ•£åŒ–å’Œç¼©æ”¾çš„ ARA æ ¼å¼ã€‚ç¼©æ”¾éœ€è¦è€ƒè™‘æ¯æ¬¡å±•ç¤ºçš„æ€»ä½“è´¡çŒ®é™åˆ¶ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å‰ªè¾‘å¹¶æ‰§è¡Œéšæœºèˆå…¥çš„æ–¹æ³•ã€‚è¯¥ç®—æ³•çš„ç»“æžœæ˜¯å¯èšåˆé”®å’Œå€¼çš„ç›´æ–¹å›¾ã€‚ &lt;/p>; &lt;p>; æŽ¥ä¸‹æ¥ï¼Œè´¡çŒ®è¾¹ç•Œç®—æ³•åœ¨å®¢æˆ·ç«¯è®¾å¤‡ä¸Šè¿è¡Œï¼Œå¹¶å¯¹å½’å› æŠ¥å‘Šå¼ºåˆ¶æ‰§è¡Œè´¡çŒ®è¾¹ç•Œï¼Œå…¶ä¸­ä»»ä½•è¶…å‡ºé™åˆ¶çš„è¿›ä¸€æ­¥è´¡çŒ®éƒ½ä¼šè¢«ä¸¢å¼ƒã€‚è¾“å‡ºæ˜¯å½’å› è½¬åŒ–çš„ç›´æ–¹å›¾ã€‚ &lt;/p>; &lt;p>; æ‘˜è¦æŠ¥å‘Šç®—æ³•åœ¨&lt;a href=&quot;https://en.wikipedia.org/wiki/Trusted_execution_environment&quot;>;å¯ä¿¡æ‰§è¡ŒçŽ¯å¢ƒ&lt;/a>;å†…çš„æœåŠ¡å™¨ç«¯è¿è¡Œï¼Œå¹¶è¿”å›žå˜ˆæ‚çš„èšåˆç»“æžœæ»¡è¶³DPã€‚å™ªå£°æ˜¯ä»Žç¦»æ•£çš„&lt;a href=&quot;https://en.wikipedia.org/wiki/Laplace_distribution&quot;>;æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒ&lt;/a>;ä¸­é‡‡æ ·çš„ï¼Œå¹¶ä¸”ä¸ºäº†æ‰§è¡Œéšç§é¢„ç®—ï¼Œå¯ä»¥ä»…æŸ¥è¯¢æŠ¥å‘Šä¸€æ¬¡ã€‚ &lt;/p>; &lt;p>; æœ€åŽï¼Œé‡å»ºå€¼ç®—æ³•å°†æµ‹é‡å€¼è½¬æ¢å›žåŽŸå§‹æ¯”ä¾‹ã€‚é‡å»ºå€¼å’Œè´¡çŒ®å‘é‡ç®—æ³•ç”± AdTech è®¾è®¡ï¼Œä¸¤è€…éƒ½ä¼šå½±å“ä»Žæ‘˜è¦æŠ¥å‘Šä¸­æ”¶åˆ°çš„æ•ˆç”¨ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0gUXyl66S0s9xVnnRLOOITvsG3eL9r9K53ouX_0VS7PBeXLepqo2IVasreHXMPjsMOQhf3qOfmhBITnoOvQ1_usH9rRPeK ysIXb5Zeebn5FS9vfpU2Qhst8VFHNZvdzV7spvp4Sc3fVVyH4cG3pmbipD4gz6etV2-MsbrrByChGE7WP1ua8iIDvC97LA7/s1999/image1.png&quot;æ ·å¼=&quot;å·¦è¾¹è·ï¼šè‡ªåŠ¨ï¼›å³è¾¹è·ï¼šè‡ªåŠ¨ï¼›&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1014&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEh0gUXyl66S0s9xVnnRLOOITvsG3eL9r9K53ouX_0VS7PBeXLepqo2IVasreHXMPjsMOQhf3qOfmhBITnoOvQ1_usH9rRPeKysIXb5Zeebn5FS9vfpU2Qhst8VFHNZvdz V7spvp4Sc3fVVyH4cG3pmbipD4gz6etV2-MsbrrByChGE7WP1ua8iIDvC97LA7/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;ARA æ‘˜è¦æŠ¥å‘Šçš„è¯´æ˜Žæ€§ç”¨æ³•ï¼Œå…¶ä¸­åŒ…æ‹¬è´¡çŒ®å‘é‡ï¼ˆç®—æ³• Aï¼‰ã€è´¡çŒ®è¾¹ç•Œï¼ˆç®—æ³• Cï¼‰ã€æ‘˜è¦æŠ¥å‘Šï¼ˆç®—æ³• Sï¼‰å’Œé‡æž„å€¼ï¼ˆç®—æ³• Rï¼‰ã€‚ç®—æ³•Cå’ŒSåœ¨APIä¸­æ˜¯å›ºå®šçš„ã€‚ AdTech è®¾è®¡äº† â€‹â€‹A å’Œ Rã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt; h2>;è¯¯å·®åº¦é‡&lt;/h2>; &lt;p>;åœ¨é€‰æ‹©è¯¯å·®åº¦é‡æ¥è¯„ä¼°è¿‘ä¼¼è´¨é‡æ—¶éœ€è¦è€ƒè™‘å‡ ä¸ªå› ç´ ã€‚ä¸ºäº†é€‰æ‹©ç‰¹å®šçš„åº¦é‡ï¼Œæˆ‘ä»¬è€ƒè™‘äº†è¯¯å·®åº¦é‡çš„ç†æƒ³å±žæ€§ï¼Œè¯¥å±žæ€§å¯ä»¥è¿›ä¸€æ­¥ç”¨ä½œç›®æ ‡å‡½æ•°ã€‚è€ƒè™‘åˆ°æ‰€éœ€çš„å±žæ€§ï¼Œæˆ‘ä»¬é€‰æ‹©äº†&lt;a href=&quot;https://developer.chrome.com/docs/privacy-sandbox/summary-reports/design-decisions/#rmsre&quot;>;ðœ-æˆªæ–­å‡æ–¹æ ¹ç›¸å¯¹è¯¯å·®&lt;/ a>; (RMSRE&lt;sub>;ðœ&lt;/sub>;) ä½œä¸ºå…¶å±žæ€§çš„è¯¯å·®æŒ‡æ ‡ã€‚æœ‰å…³è¯¦ç»†è®¨è®ºä»¥åŠä¸Žå…¶ä»–å¯èƒ½æŒ‡æ ‡çš„æ¯”è¾ƒï¼Œè¯·å‚é˜…&lt;a href=&quot;https://arxiv.org/abs/2311.13586&quot;>;è®ºæ–‡&lt;/a>;ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ä¼˜åŒ–&lt;/h2>; &lt;p>; æ ¹æ® RMSRE æµ‹é‡ä¼˜åŒ–æ•ˆç”¨&lt;sub>;ðœ&lt;/ sub>;ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªåˆ‡ç‰‡é€‰æ‹©ä¸€ä¸ªä¸Šé™å‚æ•° C å’Œéšç§é¢„ç®— ð›¼ã€‚ä¸¤è€…çš„ç»„åˆå†³å®šäº†å¦‚ä½•åœ¨ AdTech ç«¯å¯¹å®žé™…æµ‹é‡ï¼ˆä¾‹å¦‚æ€»ä»·å€¼ä¸º 3 ç¾Žå…ƒçš„ä¸¤æ¬¡è½¬åŒ–ï¼‰è¿›è¡Œç¼–ç ï¼Œç„¶åŽä¼ é€’ç»™ ARA è¿›è¡Œè´¡çŒ®è¾¹ç•Œç®—æ³•å¤„ç†ã€‚ RMSRE&lt;sub>;ðœ&lt;/sub>; å¯ä»¥ç²¾ç¡®è®¡ç®—ï¼Œå› ä¸ºå®ƒå¯ä»¥ç”¨é™å¹…åå·®å’Œå™ªå£°åˆ†å¸ƒæ–¹å·®æ¥è¡¨ç¤ºã€‚æŒ‰ç…§è¿™äº›æ­¥éª¤ï¼Œæˆ‘ä»¬å‘çŽ°å›ºå®šéšç§é¢„ç®— ð›¼&lt;sub>; &lt;/sub>; æˆ–ä¸Šé™å‚æ•° C çš„ RMSRE&lt;sub>;ðœ&lt;/sub>; æ˜¯ &lt;a href=&quot;https://en. wikipedia.org/wiki/Convex_optimization&quot;>;å‡¸&lt;/a>;ï¼ˆå› æ­¤å¯ä»¥æœ‰æ•ˆåœ°èŽ·å¾—å…¶ä»–å‚æ•°çš„è¯¯å·®æœ€å°åŒ–å€¼ï¼‰ï¼Œè€Œå¯¹äºŽè”åˆå˜é‡ï¼ˆCï¼Œð›¼ï¼‰ï¼Œå®ƒå˜æˆéžå‡¸çš„ï¼ˆå› æ­¤æˆ‘ä»¬å¯èƒ½ä¸ä¼šå§‹ç»ˆèƒ½å¤Ÿé€‰æ‹©æœ€ä½³çš„å‚æ•°ï¼‰ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œä»»ä½•çŽ°æˆçš„ä¼˜åŒ–å™¨éƒ½å¯ä»¥ç”¨äºŽé€‰æ‹©éšç§é¢„ç®—å’Œä¸Šé™å‚æ•°ã€‚åœ¨æˆ‘ä»¬çš„å®žéªŒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/optimize.minimize-slsqp.html&quot;>;SLSQP&lt;/a>;æœ€å°åŒ–å™¨https://docs.scipy.org/doc/scipy/reference/ generated/scipy.optimize.minimize.html&quot;>;scipy.optimize&lt;/a>; åº“ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;åˆæˆæ•°æ®&lt;/h2>; &lt;p>; ä¸åŒçš„ ARA é…ç½®å¯ä»¥é€šè¿‡åœ¨è½¬æ¢æ•°æ®é›†ã€‚ç„¶è€Œï¼Œç”±äºŽéšç§é—®é¢˜ï¼Œå¯¹æ­¤ç±»æ•°æ®çš„è®¿é—®å¯èƒ½ä¼šå—åˆ°é™åˆ¶æˆ–ç¼“æ…¢ï¼Œæˆ–è€…æ ¹æœ¬ä¸å¯ç”¨ã€‚è§£å†³è¿™äº›é™åˆ¶çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å¤åˆ¶çœŸå®žæ•°æ®ç‰¹å¾çš„åˆæˆæ•°æ®ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šè¿‡çŽ°å®žä¸–ç•Œè½¬æ¢æ•°æ®é›†çš„ç»Ÿè®¡å»ºæ¨¡æ¥è´Ÿè´£ä»»åœ°ç”Ÿæˆåˆæˆæ•°æ®çš„æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆå¯¹çœŸå®žè½¬æ¢æ•°æ®é›†è¿›è¡Œå®žè¯åˆ†æžï¼Œä»¥æ­ç¤º ARA çš„ç›¸å…³ç‰¹å¾ã€‚ç„¶åŽï¼Œæˆ‘ä»¬è®¾è®¡ä¸€ä¸ªç®¡é“ï¼Œä½¿ç”¨è¿™ç§åˆ†å¸ƒçŸ¥è¯†æ¥åˆ›å»ºå¯ä»¥é€šè¿‡è¾“å…¥å‚æ•°è¿›è¡Œè‡ªå®šä¹‰çš„çœŸå®žåˆæˆæ•°æ®é›†ã€‚ &lt;/p>; &lt;p>; ç®¡é“é¦–å…ˆæ ¹æ®&lt;a href=&quot;https://en.wikipedia.org/wiki/Power_law&quot;>;å¹‚å¾‹åˆ†å¸ƒ&lt;/a>;ç”Ÿæˆå±•ç¤ºæ¬¡æ•°ï¼ˆç¬¬ 1 æ­¥ï¼‰ï¼Œç„¶åŽæ¯æ¬¡å±•ç¤ºéƒ½ä¼šæ ¹æ®&lt;a href=&quot;https://en.wikipedia.org/wiki/Poisson_distribution&quot;>;æ³Šæ¾åˆ†å¸ƒ&lt;/a>;ç”Ÿæˆè½¬åŒ–ï¼ˆç¬¬ 2 æ­¥ï¼‰ï¼Œæœ€åŽï¼Œå¯¹äºŽæ¯æ¬¡è½¬åŒ–ï¼Œå®ƒä¼šç”Ÿæˆæå–çš„è½¬åŒ–å€¼æ¥è‡ª&lt;a href=&quot;https://en.wikipedia.org/wiki/Log-normal_distribution&quot;>;å¯¹æ•°æ­£æ€åˆ†å¸ƒ&lt;/a>;ï¼ˆæ­¥éª¤ 3ï¼‰ã€‚é€šè¿‡ä¸Žæ•°æ®é›†ç›¸å…³çš„å‚æ•°ï¼Œæˆ‘ä»¬å‘çŽ°è¿™äº›åˆ†å¸ƒä¸Žå¹¿å‘Šæ•°æ®é›†ç‰¹å¾å¯†åˆ‡åŒ¹é…ã€‚å› æ­¤ï¼Œäººä»¬å¯ä»¥ä»ŽåŽ†å²æˆ–å…¬å…±æ•°æ®é›†ä¸­å­¦ä¹ å‚æ•°å¹¶ç”Ÿæˆç”¨äºŽå®žéªŒçš„åˆæˆæ•°æ®é›†ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj7tcj0k-h4e2ZsEdIfG6FtkppEv0_Z_Vl4smOLgUoXKqFUSByNdDuvutA58TATLM9BmjZVugPG9TWL5VUd4f IQ_acxdIhJx-EK3qY-D8WJi_aqTvhgNZXfqwLyXxBOSS-vIHIWHYKWa-7_kNyrqHlkWxmRlBl4LbeYdx9sonX159djwHBP41W1jNBLMEJ/s841 /image2.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;841&quot; data-original-width=&quot;840&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj7tcj0k-h4e2ZsEdIfG6FtkppEv0_Z_Vl4smOLgUoXKqFUSByNdDuvutA58TATLM9BmjZVugPG9TWL5VUd4fIQ_acxdIhJx-EK3qY-D8WJ i_aqTvhgNZXfqwLyXxBOSS-vIHIWHYKWa-7_kNyrqHlkWxmRlBl4LbeYdx9sonX159djwHBP41W1jNBLMEJ/s16000/image2.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;æ€»ä½“æ•°æ®é›†ç”Ÿæˆæ­¥éª¤ä»¥åŠç”¨äºŽè¯´æ˜Žçš„åŠŸèƒ½ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>; å®žéªŒè¯„ä¼° &lt;/h2>; &lt;p>; æˆ‘ä»¬åœ¨ä¸‰ä¸ªçœŸå®žæ•°æ®é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„ç®—æ³•ï¼ˆ&lt;a href=&quot; https://ailab.criteo.com/criteo-spoke-search-conversion-log-dataset/&quot;>;Criteo&lt;/a>;ã€AdTech Real Estate å’Œ AdTech Travelï¼‰å’Œä¸‰ä¸ªç»¼åˆæ•°æ®é›†ã€‚ Criteo åŒ…å« 1500 ä¸‡æ¬¡ç‚¹å‡»ï¼Œæˆ¿åœ°äº§åŒ…å« 10 ä¸‡æ¬¡è½¬åŒ–ï¼Œæ—…æ¸¸åŒ…å« 3 ä¸‡æ¬¡è½¬åŒ–ã€‚æ¯ä¸ªæ•°æ®é›†è¢«åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è®­ç»ƒé›†ç”¨äºŽé€‰æ‹©è´¡çŒ®é¢„ç®—ã€è£å‰ªé˜ˆå€¼å‚æ•°å’Œè½¬åŒ–è®¡æ•°é™åˆ¶ï¼ˆçŽ°å®žæ•°æ®é›†æ¯æ¬¡ç‚¹å‡»åªæœ‰ä¸€æ¬¡è½¬åŒ–ï¼‰ï¼Œå¹¶åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°è¯¯å·®ã€‚æ¯ä¸ªæ•°æ®é›†éƒ½ä½¿ç”¨å°è±¡ç‰¹å¾åˆ’åˆ†ä¸ºåˆ‡ç‰‡ã€‚å¯¹äºŽçŽ°å®žä¸–ç•Œçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬è€ƒè™‘æ¯ä¸ªåˆ‡ç‰‡çš„ä¸‰ä¸ªæŸ¥è¯¢ï¼›å¯¹äºŽåˆæˆæ•°æ®é›†ï¼Œæˆ‘ä»¬è€ƒè™‘æ¯ä¸ªåˆ‡ç‰‡çš„ä¸¤ä¸ªæŸ¥è¯¢ã€‚ &lt;/p>; &lt;p>; å¯¹äºŽæ¯ä¸ªæŸ¥è¯¢ï¼Œæˆ‘ä»¬é€‰æ‹© RMSRE&lt;sub>;ð‰&lt;/sub>; ðœ å€¼ä½œä¸ºè®­ç»ƒæ•°æ®é›†æŸ¥è¯¢ä¸­å€¼çš„äº”å€ã€‚è¿™ç¡®ä¿äº†è¯¯å·®åº¦é‡å¯¹æ•°æ®é‡æ–°ç¼©æ”¾çš„ä¸å˜æ€§ï¼Œå¹¶å…è®¸æˆ‘ä»¬é€šè¿‡å¯¹æ¯ä¸ªç‰¹å¾ä½¿ç”¨ ð‰ æ¥ç»„åˆæ¥è‡ªä¸åŒå°ºåº¦ç‰¹å¾çš„è¯¯å·®ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_y5lBRvm3MhfZn6vSJgY2kAQw-95oT5wVCl2Mblkv3Cn1069EBJIaNFrXddOqSk1b5YUbNZUGAmmbFYdKLIqg5 ngm5wUJXwnTcnhya3l_ovwMhgsPwJN5I6tKKJGYI4iNgEynK6ismsXKeay6UfhlVIZt8aEmLrIybPwHbkmt9L07K_s1C9rKIxwrKCpr/s1971/image5.png&quot;æ ·å¼=&quot;å·¦è¾¹è·ï¼šè‡ªåŠ¨ï¼›å³è¾¹è·ï¼šè‡ªåŠ¨ï¼›&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1028&quot; data-original-width=&quot;1971&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEi_y5lBRvm3MhfZn6vSJgY2kAQw-95oT5wVCl2Mblkv3Cn1069EBJIaNFrXddOqSk1b5YUbNZUGAmmbFYdKLIqg5ngm5wUJXwnTcnhya3l_ovwMhgsPwJN5I 6tKKJGYI4iNgEynK6ismsXKeay6UfhlVIZt8aEmLrIybPwHbkmt9L07K_s1C9rKIxwrKCpr/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;çŽ°å®žä¸–ç•Œæ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œè¯´æ˜Žè§‚å¯Ÿè½¬æ¢å€¼çš„æ¦‚çŽ‡ã€‚æ‹Ÿåˆæ›²çº¿ä»£è¡¨äº†æœ€ä½³å¯¹æ•°æ­£æ€åˆ†å¸ƒæ¨¡åž‹ï¼Œå¯ä»¥æœ‰æ•ˆæ•èŽ·æ•°æ®ä¸­çš„åŸºæœ¬æ¨¡å¼ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40 %;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;ç»“æžœ&lt;/h3>; &lt;p>; æˆ‘ä»¬å°†åŸºäºŽä¼˜åŒ–çš„ç®—æ³•ä¸Žç®€å•çš„åŸºçº¿æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚å¯¹äºŽæ¯ä¸ªæŸ¥è¯¢ï¼ŒåŸºçº¿ä½¿ç”¨ç›¸ç­‰çš„è´¡çŒ®é¢„ç®—å’Œè®­ç»ƒæ•°æ®çš„å›ºå®šåˆ†ä½æ•°æ¥é€‰æ‹©è£å‰ªé˜ˆå€¼ã€‚æˆ‘ä»¬çš„ç®—æ³•äº§ç”Ÿçš„è¯¯å·®è¿œä½ŽäºŽçŽ°å®žä¸–ç•Œå’Œåˆæˆæ•°æ®é›†çš„åŸºçº¿ã€‚æˆ‘ä»¬åŸºäºŽä¼˜åŒ–çš„æ–¹æ³•é€‚åº”éšç§é¢„ç®—å’Œæ•°æ®ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjRJcmMU1Snvx2N4hdh5iMmadldy6nLn1jXjOGCoefqSRT7auQ3u_zZsgefqfzmsyHUBEZHR6z6ZW2CkFgxrEBe0hBeY TMihk1qtHOF-qBw_WbEdq6C8x0iQy_DvXHqMrCBqH7tnmXNCPlZI29oAiTitD-RU3hH29MKlCHiLUN_3SFkXB71-fv3fU4jx-1q/s1999/image3 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1999&quot; data-original-width=&quot;1730&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjRJcmMU1Snvx2N4hdh5iMmadldy6nLn1jXjOGCoefqSRT7auQ3u_zZsgefqfzmsyHUBEZHR6z6ZW2CkFgxrEBe0hBeYTMihk1qtHOF-qBw_WbEdq6C 8x0iQy_DvXHqMrCBqH7tnmXNCPlZI29oAiTitD-RU3hH29MKlCHiLUN_3SFkXB71-fv3fU4jx-1q/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td ç±»=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;RMSRE&lt;sub>;Ï„&lt;/sub>; ç”¨äºŽæˆ‘ä»¬çš„ç®—æ³•å’ŒåŸºçº¿çš„éšç§é¢„ç®— {1, 2, 4, 8, 16, 32, 64}ä¸‰ä¸ªçœŸå®žä¸–ç•Œæ•°æ®é›†å’Œä¸‰ä¸ªåˆæˆæ•°æ®é›†ã€‚æˆ‘ä»¬åŸºäºŽä¼˜åŒ–çš„æ–¹æ³•å§‹ç»ˆæ¯”ä½¿ç”¨å›ºå®šåˆ†ä½æ•°ä½œä¸ºè£å‰ªé˜ˆå€¼å¹¶åœ¨æŸ¥è¯¢ä¹‹é—´å¹³å‡åˆ†é…è´¡çŒ®é¢„ç®—çš„åŸºçº¿å®žçŽ°æ›´ä½Žçš„é”™è¯¯ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ç»“è®º&lt;/h2>; &lt;p>; æˆ‘ä»¬ç ”ç©¶äº† ARA ä¸­æ‘˜è¦æŠ¥å‘Šçš„ä¼˜åŒ–ï¼Œç›®å‰å·²éƒ¨ç½²åœ¨æ•°ç™¾ä¸ªè®¾å¤‡ä¸Šæ•°ä»¥ç™¾ä¸‡è®¡çš„ Chrome æµè§ˆå™¨ã€‚æˆ‘ä»¬æå‡ºäº† ARA ç¼´æ¬¾é¢„ç®—ä¼˜åŒ–é—®é¢˜çš„ä¸¥æ ¼è¡¨è¿°ï¼Œç›®çš„æ˜¯ä¸ºç ”ç©¶äººå‘˜æä¾›ç¨³å¥çš„æŠ½è±¡ï¼Œä»¥ä¿ƒè¿›å®žé™…æ”¹è¿›ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬çš„æ–¹æ¡ˆåˆ©ç”¨åŽ†å²æ•°æ®æ¥é™åˆ¶å’Œæ‰©å±•å·®å¼‚éšç§ä¸‹æœªæ¥æ•°æ®çš„è´¡çŒ®ï¼Œéžå¸¸é€šç”¨ï¼Œé€‚ç”¨äºŽå¹¿å‘Šä»¥å¤–çš„è®¾ç½®ã€‚åŸºäºŽè¿™é¡¹å·¥ä½œçš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨è¿‡åŽ»çš„æ•°æ®æ¥å­¦ä¹ æ•°æ®åˆ†å¸ƒçš„å‚æ•°ï¼Œç„¶åŽåº”ç”¨ä»Žè¯¥åˆ†å¸ƒå¯¼å‡ºçš„åˆæˆæ•°æ®æ¥ä¸ºæœªæ¥æ•°æ®çš„æŸ¥è¯¢è¿›è¡Œéšç§é¢„ç®—ã€‚è¯·å‚é˜…&lt;a href=&quot;https://arxiv.org/abs/2311.13586&quot;>;è®ºæ–‡&lt;/a>;å’Œ&lt;a href=&quot;https://github.com/google-research/google-research/tree/ master/ara_optimization&quot;>;é™„å¸¦ä»£ç &lt;/a>;ï¼Œäº†è§£è¯¦ç»†çš„ç®—æ³•å’Œè¯æ˜Žã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è‡´è°¢&lt;/h2>; &lt;p>; &lt;em>;è¿™é¡¹å·¥ä½œæ˜¯ä¸Ž Badih Ghazi åˆä½œå®Œæˆçš„ï¼Œæ™®é‡Œè’‚ä»€Â·å¡é©¬æ–¯ã€æ‹‰ç»´Â·åº“é©¬å°”ã€å¸•è¾›Â·é©¬åŠªæœ—è¥¿å’Œé˜¿ç»´çº³ä»€Â·ç“¦æ‹‰è¾¾æ‹‰æ‰¬ã€‚æˆ‘ä»¬æ„Ÿè°¢ Akash Nadan çš„å¸®åŠ©ã€‚&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/68038970217457115/comments/default&quot; rel=&quot;replies&quot; title= â€œå‘è¡¨è¯„è®ºâ€ type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/summary-report-optimization-in-privacy.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/68038970217457115&quot; rel=&quot;edit&quot;ç±»åž‹=â€œapplication/atom+xmlâ€/>;&lt;link href=â€œhttp://www.blogger.com/feeds/8474926331452026626/posts/default/68038970217457115â€rel=â€œselfâ€ç±»åž‹=â€œapplication/atom+xmlâ€ />;&lt;link href=&quot;http://blog.research.google/2023/12/summary-report-optimization-in-privacy.html&quot; rel=&quot;alternate&quot; title=&quot;Privacy Sandbox å½’å› æŠ¥å‘Šä¸­çš„æ‘˜è¦æŠ¥å‘Šä¼˜åŒ–API&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@bloggerã€‚ com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16- rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFxpfW7ZN6OUw0lsK3lruiscqMgB3Jt8aBViPGNvHA0MzUPSFp6TRDOPdqSfO4A_0QgpWQ o5mT0Vdplv5uBFQmdSePT1LPlwN- hLJ1TP-SHwmIMXYfoNL9CxBw11ABp89ril2o6lDJcT8MCJQ6HwU13vmN6CqnCnNwSpH9d4lgO_CISNxVqKCYSyT_SiwN/s72-c/hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;th r:æ€»è®¡>;0&lt;/ thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;æ ‡ç­¾ï¼šblogger.com,1999:blog-8474926331452026626.post-8288223977991952319&lt;/id>;&lt;å‘å¸ƒ>;2023-12-01T09:19:00.000-08:00&lt; /published>;&lt;æ›´æ–°>;2023-12-01T10:12:05.885-08:00&lt;/æ›´æ–°>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;æœºå™¨ç¿»è¯‘&quot;>; &lt;/ç±»åˆ«>;&lt;ç±»åˆ«æ–¹æ¡ˆ=â€œhttp://www.blogger.com/atom/ns#â€æœ¯è¯­=â€œè¯­éŸ³â€>;&lt;/ç±»åˆ«>;&lt;ç±»åˆ«æ–¹æ¡ˆ=â€œhttp://www.blogger.com/atomâ€ /ns#&quot; term=&quot;Translate&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;å•è¯­è¨€æ•°æ®çš„æ— ç›‘ç£è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline -author&quot;>;å‘å¸ƒè€…ï¼šGoogle ç ”ç©¶éƒ¨ç§‘å­¦å®¶ Eliya Nachmani å’Œè½¯ä»¶å·¥ç¨‹å¸ˆ Michelle Tadmor Ramanovich&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuXgYf5aJuSobrasrRUpb5IUKH05RFHJ5_vcwW-XyOLQdKOEonciXcyXtcJ N2zPkHu5_k4wvIsl6oFZd4UfYsBfjSK27YaIcw7s1 -3dekdJVxTBM-4hrBvndT-go6YOsscswtV6FvE_3QHml8zZjWIz7J4quRh8UBL9gzW9guAVYd4czuHYhY6lu9TkK4K/s1600/T3.png&quot; style=&quot;æ˜¾ç¤ºï¼šæ— ï¼›&quot; />; &lt;p>; è¯­éŸ³è½¬è¯­éŸ³ç¿»è¯‘ (S2ST) æ˜¯ä¸€ç§&lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_translation&quot;>;æœºå™¨ç¿»è¯‘&lt;/a>;ï¼Œå®ƒå°†å£è¯­ä»Žä¸€ç§è¯­è¨€è½¬æ¢ä¸ºä¸€ç§è¯­è¨€ã€‚è¯­è¨€åˆ°å¦ä¸€ç§è¯­è¨€ã€‚è¿™é¡¹æŠ€æœ¯æœ‰æ½œåŠ›æ‰“ç ´è¯­è¨€éšœç¢ï¼Œä¿ƒè¿›ä¸åŒæ–‡åŒ–å’ŒèƒŒæ™¯çš„äººä»¬ä¹‹é—´çš„æ²Ÿé€šã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; ä¹‹å‰ï¼Œæˆ‘ä»¬ä»‹ç»äº†&lt;a href=&quot;https://ai.googleblog.com/2019/05/introducing-translatotron-end-to- end.html&quot;>;ç¿»è¯‘æœº 1&lt;/a>; å’Œ &lt;a href=&quot;https://ai.googleblog.com/2021/09/high-quality-robust-and-responsible.html&quot;>;ç¿»è¯‘æœº 2&lt;/a>; ï¼Œç¬¬ä¸€ä¸ªèƒ½å¤Ÿç›´æŽ¥åœ¨ä¸¤ç§è¯­è¨€ä¹‹é—´ç¿»è¯‘è¯­éŸ³çš„æ¨¡åž‹ã€‚ç„¶è€Œï¼Œä»–ä»¬æ˜¯åœ¨ç›‘ç£çŽ¯å¢ƒä¸­ä½¿ç”¨å¹¶è¡Œè¯­éŸ³æ•°æ®è¿›è¡Œè®­ç»ƒçš„ã€‚å¹¶è¡Œè¯­éŸ³æ•°æ®çš„ç¨€ç¼ºæ˜¯è¯¥é¢†åŸŸçš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ï¼Œä»¥è‡³äºŽå¤§å¤šæ•°å…¬å…±æ•°æ®é›†éƒ½æ˜¯ä»Žæ–‡æœ¬åŠæˆ–å®Œå…¨åˆæˆçš„ã€‚è¿™ç»™å­¦ä¹ ç¿»è¯‘å’Œé‡å»ºè¯­éŸ³å±žæ€§å¢žåŠ äº†é¢å¤–çš„éšœç¢ï¼Œè¿™äº›å±žæ€§æ²¡æœ‰åœ¨æ–‡æœ¬ä¸­è¡¨ç¤ºï¼Œå› æ­¤æ²¡æœ‰åæ˜ åœ¨åˆæˆçš„è®­ç»ƒæ•°æ®ä¸­ã€‚ &lt;/p>; &lt;p>; åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å±•ç¤ºäº† &lt;a href=&quot;https://arxiv.org/abs/2305.17547&quot;>;Translatotron 3&lt;/a>;ï¼Œä¸€ç§æ–°é¢–çš„æ— ç›‘ç£è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘æž¶æž„ã€‚åœ¨ Translatotron 3 ä¸­ï¼Œæˆ‘ä»¬è¯æ˜Žå¯ä»¥ä»…ä»Žå•è¯­è¨€æ•°æ®å­¦ä¹ è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä¸ºæ›´å¤šè¯­è¨€å¯¹ä¹‹é—´çš„ç¿»è¯‘æ‰“å¼€äº†å¤§é—¨ï¼Œè€Œä¸”è¿˜ä¸ºéžæ–‡æœ¬è¯­éŸ³å±žæ€§ï¼ˆä¾‹å¦‚åœé¡¿ã€è¯­é€Ÿå’Œè¯´è¯è€…èº«ä»½ï¼‰çš„ç¿»è¯‘æ‰“å¼€äº†å¤§é—¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸åŒ…æ‹¬å¯¹ç›®æ ‡è¯­è¨€çš„ä»»ä½•ç›´æŽ¥ç›‘ç£ï¼Œå› æ­¤æˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯åœ¨ç¿»è¯‘è¿‡ç¨‹ä¸­ä¿ç•™æºè¯­éŸ³çš„å‰¯è¯­è¨€ç‰¹å¾ï¼ˆä¾‹å¦‚è¯­æ°”ã€æƒ…æ„Ÿï¼‰çš„æ­£ç¡®æ–¹å‘ã€‚ä¸ºäº†å®žçŽ°è¯­éŸ³åˆ°è¯­éŸ³çš„ç¿»è¯‘ï¼Œæˆ‘ä»¬ä½¿ç”¨&lt;a href=&quot;https://arxiv.org/abs/1511.06709&quot;>;åå‘ç¿»è¯‘&lt;/a>;ï¼Œè¿™æ˜¯ä¸€ç§æ¥è‡ªæ— ç›‘ç£æœºå™¨ç¿»è¯‘ (UMT) çš„æŠ€æœ¯ï¼Œå…¶ä¸­æºè¯­è¨€çš„åˆæˆç¿»è¯‘ç”¨äºŽ&lt;a href=&quot;https://arxiv.org/abs/1710.11041&quot;>;ç¿»è¯‘æ²¡æœ‰åŒè¯­æ–‡æœ¬æ•°æ®é›†çš„æ–‡æœ¬&lt;/a>;ã€‚è¥¿ç­ç‰™è¯­å’Œè‹±è¯­ä¹‹é—´çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ä»»åŠ¡çš„å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒTranslatotron 3 çš„æ€§èƒ½ä¼˜äºŽåŸºçº¿çº§è”ç³»ç»Ÿã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Translatotron 3 &lt;/h2>; &lt;p>; Translatotron 3 è§£å†³äº†æ— ç›‘ç£ S2ST çš„é—®é¢˜ï¼Œå¯ä»¥æ¶ˆé™¤åŒè¯­è¯­éŸ³æ•°æ®é›†çš„è¦æ±‚ã€‚ä¸ºæ­¤ï¼ŒTranslatotron 3 çš„è®¾è®¡åŒ…å«ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼š&lt;/p>; &lt;ol>; &lt;li>;å°†æ•´ä¸ªæ¨¡åž‹é¢„è®­ç»ƒä¸º &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2022/html /He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.html&quot;>;å¸¦æœ‰ &lt;a href=&quot;https://arxiv.org/abs/1904.08779&quot;>;SpecAugment&lt;/a>; çš„æŽ©ç è‡ªåŠ¨ç¼–ç å™¨&lt;/a>;ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºŽè¯­éŸ³è¯†åˆ«çš„ç®€å•æ•°æ®å¢žå¼ºæ–¹æ³•ï¼Œåœ¨å¯¹æ•°ä¸Šè¿è¡Œè¾“å…¥éŸ³é¢‘ï¼ˆè€Œä¸æ˜¯åŽŸå§‹éŸ³é¢‘æœ¬èº«ï¼‰çš„&lt;a href=&quot;https://en.wikipedia.org/wiki/Mel-Frequency_cepstrum&quot;>;æ¢…å°”é¢‘è°±å›¾&lt;/a>;ï¼Œå¹¶è¢«è¯æ˜Žå¯ä»¥æœ‰æ•ˆæé«˜ç¼–ç å™¨ã€‚ &lt;/li>;&lt;li>;åŸºäºŽ&lt;a href=&quot;https://arxiv.org/abs/1710.04087&quot;>;å¤šè¯­è¨€æ— ç›‘ç£åµŒå…¥&lt;/a>;ï¼ˆMUSEï¼‰çš„æ— ç›‘ç£åµŒå…¥æ˜ å°„ï¼Œå®ƒåœ¨ä¸é…å¯¹çš„è¯­è¨€ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†å…è®¸æ¨¡åž‹æ¥å­¦ä¹ æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¹‹é—´å…±äº«çš„åµŒå…¥ç©ºé—´ã€‚ &lt;/li>;&lt;li>;åŸºäºŽåå‘ç¿»è¯‘çš„é‡å»ºæŸå¤±ï¼Œä»¥å®Œå…¨æ— ç›‘ç£çš„æ–¹å¼è®­ç»ƒç¼–ç å™¨-è§£ç å™¨ç›´æŽ¥ S2ST æ¨¡åž‹ã€‚ &lt;/li>; &lt;/ol>; &lt;p>; è¯¥æ¨¡åž‹ä½¿ç”¨æ— ç›‘ç£ MUSE åµŒå…¥æŸå¤±ã€é‡å»ºæŸå¤±å’Œ S2S åå‘ç¿»è¯‘æŸå¤±çš„ç»„åˆè¿›è¡Œè®­ç»ƒã€‚åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­ï¼Œå…±äº«ç¼–ç å™¨ç”¨äºŽå°†è¾“å…¥ç¼–ç åˆ°å¤šè¯­è¨€åµŒå…¥ç©ºé—´ä¸­ï¼ŒéšåŽç”±ç›®æ ‡è¯­è¨€è§£ç å™¨è¿›è¡Œè§£ç ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;æž¶æž„&lt;/h3>; &lt;p>; Translatotron 3 é‡‡ç”¨å…±äº«ç¼–ç å™¨å¯¹æºå’Œç›®æ ‡è¿›è¡Œç¼–ç è¯­è¨€ã€‚è§£ç å™¨ç”±è¯­è¨€è§£ç å™¨ã€å£°å­¦åˆæˆå™¨ï¼ˆè´Ÿè´£ç¿»è¯‘è¯­éŸ³çš„å£°å­¦ç”Ÿæˆï¼‰å’Œå•ä¸€æ³¨æ„æ¨¡å—ç»„æˆï¼Œå¦‚ Translatotron 2ã€‚ä½†æ˜¯ï¼Œå¯¹äºŽ Translatotron 3 æœ‰ä¸¤ä¸ªè§£ç å™¨ï¼Œä¸€ä¸ªç”¨äºŽæºè¯­è¨€ï¼Œå¦ä¸€ä¸ªç”¨äºŽæºè¯­è¨€ä¸ºç›®æ ‡è¯­è¨€ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å•è¯­è¯­éŸ³æ–‡æœ¬æ•°æ®é›†ï¼ˆå³ï¼Œè¿™äº›æ•°æ®ç”±è¯­éŸ³æ–‡æœ¬å¯¹ç»„æˆï¼›å®ƒä»¬ä¸æ˜¯ç¿»è¯‘ï¼‰ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;ç¼–ç å™¨&lt;/h3>; &lt;p>; ç¼–ç å™¨ä¸Ž Translatotron ä¸­çš„è¯­éŸ³ç¼–ç å™¨å…·æœ‰ç›¸åŒçš„æž¶æž„2. ç¼–ç å™¨çš„è¾“å‡ºåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šç¬¬ä¸€éƒ¨åˆ†åŒ…å«è¯­ä¹‰ä¿¡æ¯ï¼Œç¬¬äºŒéƒ¨åˆ†åŒ…å«å£°å­¦ä¿¡æ¯ã€‚é€šè¿‡ä½¿ç”¨ MUSE æŸå¤±ï¼Œè¾“å‡ºçš„å‰åŠéƒ¨åˆ†è¢«è®­ç»ƒä¸ºè¾“å…¥è¯­éŸ³é¢‘è°±å›¾æ–‡æœ¬çš„ MUSE åµŒå…¥ã€‚åŽåŠéƒ¨åˆ†æ›´æ–°åŽæ²¡æœ‰MUSEæŸå¤±ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¹‹é—´å…±äº«ç›¸åŒçš„ç¼–ç å™¨ã€‚æ­¤å¤–ï¼ŒMUSE åµŒå…¥æœ¬è´¨ä¸Šæ˜¯å¤šè¯­è¨€çš„ã€‚å› æ­¤ï¼Œç¼–ç å™¨èƒ½å¤Ÿå­¦ä¹ è·¨æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„å¤šè¯­è¨€åµŒå…¥ç©ºé—´ã€‚è¿™å…è®¸å¯¹è¾“å…¥è¿›è¡Œæ›´é«˜æ•ˆå’Œæœ‰æ•ˆçš„ç¼–ç ï¼Œå› ä¸ºç¼–ç å™¨èƒ½å¤Ÿå°†ä¸¤ç§è¯­è¨€çš„è¯­éŸ³ç¼–ç åˆ°å…¬å…±åµŒå…¥ç©ºé—´ä¸­ï¼Œè€Œä¸æ˜¯ä¸ºæ¯ç§è¯­è¨€ç»´æŠ¤å•ç‹¬çš„åµŒå…¥ç©ºé—´ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;è§£ç å™¨&lt;/h3>; &lt;p>; ä¸Ž Translatotron 2 ä¸€æ ·ï¼Œè§£ç å™¨ç”±ä¸‰ä¸ªä¸åŒçš„ç»„ä»¶ç»„æˆï¼šå³è¯­è¨€è§£ç å™¨ã€å£°å­¦åˆæˆå™¨å’Œæ³¨æ„åŠ›æ¨¡å—ã€‚ç„¶è€Œï¼Œä¸ºäº†æœ‰æ•ˆå¤„ç†æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„ä¸åŒå±žæ€§ï¼ŒTranslatotron 3 é’ˆå¯¹æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€é…å¤‡äº†ä¸¤ä¸ªç‹¬ç«‹çš„è§£ç å™¨ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;ä¸¤éƒ¨åˆ†è®­ç»ƒ&lt;/h3>; &lt;p>; è®­ç»ƒæ–¹æ³•ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š(1)å¸¦é‡å»ºçš„è‡ªåŠ¨ç¼–ç å’Œï¼ˆ2ï¼‰åå‘ç¿»è¯‘é¡¹ã€‚åœ¨ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œç½‘ç»œè¢«è®­ç»ƒä¸ºä½¿ç”¨ MUSE æŸå¤±å’Œé‡å»ºæŸå¤±å°†è¾“å…¥è‡ªåŠ¨ç¼–ç åˆ°å¤šè¯­è¨€åµŒå…¥ç©ºé—´ã€‚æ­¤é˜¶æ®µçš„ç›®çš„æ˜¯ç¡®ä¿ç½‘ç»œç”Ÿæˆæœ‰æ„ä¹‰çš„å¤šè¯­è¨€è¡¨ç¤ºã€‚åœ¨ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œç½‘ç»œè¢«è¿›ä¸€æ­¥è®­ç»ƒä»¥åˆ©ç”¨åå‘ç¿»è¯‘æŸå¤±æ¥ç¿»è¯‘è¾“å…¥é¢‘è°±å›¾ã€‚ç¼“è§£ &lt;a href=&quot;https://en.wikipedia.org/wiki/Catastropic_interference#:~:text=Catastropic%20interference%2C%20also%20known%20as,information%20upon%20learning%20new%20information çš„é—®é¢˜.&quot;>;ç¾éš¾æ€§é—å¿˜&lt;/a>;å’Œå¼ºåˆ¶æ½œåœ¨ç©ºé—´ä¸ºå¤šè¯­è¨€ã€MUSE æŸå¤±å’Œé‡å»ºæŸå¤±ä¹Ÿåº”ç”¨äºŽè®­ç»ƒçš„ç¬¬äºŒéƒ¨åˆ†ã€‚ä¸ºäº†ç¡®ä¿ç¼–ç å™¨å­¦ä¹ è¾“å…¥çš„æœ‰æ„ä¹‰çš„å±žæ€§ï¼Œè€Œä¸æ˜¯ç®€å•åœ°é‡å»ºè¾“å…¥ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªé˜¶æ®µå°† SpecAugment åº”ç”¨äºŽç¼–ç å™¨è¾“å…¥ã€‚äº‹å®žè¯æ˜Žï¼Œå®ƒå¯ä»¥é€šè¿‡å¢žåŠ è¾“å…¥æ•°æ®æ¥æœ‰æ•ˆæé«˜ç¼–ç å™¨çš„æ³›åŒ–èƒ½åŠ›ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;è®­ç»ƒç›®æ ‡&lt;/h3>; &lt;p>; åœ¨åå‘ç¿»è¯‘è®­ç»ƒé˜¶æ®µï¼ˆå¦‚ç« èŠ‚æ‰€ç¤ºï¼‰å¦‚ä¸‹ï¼‰ï¼Œç½‘ç»œç»è¿‡è®­ç»ƒå°†è¾“å…¥é¢‘è°±å›¾ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€ï¼Œç„¶åŽå†ç¿»è¯‘å›žæºè¯­è¨€ã€‚åå‘ç¿»è¯‘çš„ç›®æ ‡æ˜¯å¼ºåˆ¶æ½œåœ¨ç©ºé—´æ˜¯å¤šè¯­è¨€çš„ã€‚ä¸ºäº†å®žçŽ°è¿™ä¸€ç›®æ ‡ï¼Œåº”ç”¨äº†ä»¥ä¸‹æŸå¤±ï¼š &lt;/p>; &lt;ul>; &lt;li>;MUSE æŸå¤±ï¼šMUSE æŸå¤±è¡¡é‡è¾“å…¥é¢‘è°±å›¾çš„å¤šè¯­è¨€åµŒå…¥ä¸Žåå‘ç¿»è¯‘é¢‘è°±å›¾çš„å¤šè¯­è¨€åµŒå…¥ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ &lt;/li>;&lt;li>;é‡å»ºæŸå¤±ï¼šé‡å»ºæŸå¤±è¡¡é‡è¾“å…¥é¢‘è°±å›¾å’Œåå‘ç¿»è¯‘é¢‘è°±å›¾ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ &lt;/li>; &lt;/ul>; &lt;p>; é™¤äº†è¿™äº›æŸè€—ä¹‹å¤–ï¼ŒSpecAugment è¿˜åº”ç”¨äºŽä¸¤ä¸ªé˜¶æ®µçš„ç¼–ç å™¨è¾“å…¥ã€‚åœ¨åç¿»è¯‘è®­ç»ƒé˜¶æ®µä¹‹å‰ï¼Œç½‘ç»œè¢«è®­ç»ƒä¸ºä½¿ç”¨ MUSE æŸå¤±å’Œé‡å»ºæŸå¤±å°†è¾“å…¥è‡ªåŠ¨ç¼–ç åˆ°å¤šè¯­è¨€åµŒå…¥ç©ºé—´ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;MUSE æŸå¤±&lt;/h3>; &lt;p>; ç¡®ä¿ç¼–ç å™¨ç”Ÿæˆæœ‰æ„ä¹‰çš„å¤šè¯­è¨€è¡¨ç¤ºå¯¹äºŽè¿™ä¸¤ä¸ªè§£ç å™¨ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´éƒ½é‡‡ç”¨äº† MUSE æŸå¤±ã€‚ MUSE æŸå¤±è¿«ä½¿ç¼–ç å™¨é€šè¿‡ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„ MUSE åµŒå…¥æ¥ç”Ÿæˆè¿™æ ·çš„è¡¨ç¤ºã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç»™å®šè¾“å…¥æ–‡æœ¬è½¬å½•æœ¬ï¼Œæˆ‘ä»¬ä»Žè¾“å…¥è¯­è¨€çš„åµŒå…¥ä¸­æå–ç›¸åº”çš„ MUSE åµŒå…¥ã€‚ç„¶åŽï¼ŒMUSE åµŒå…¥å’Œç¼–ç å™¨è¾“å‡ºå‘é‡ä¹‹é—´çš„è¯¯å·®è¢«æœ€å°åŒ–ã€‚è¯·æ³¨æ„ï¼Œç”±äºŽåµŒå…¥çš„å¤šè¯­è¨€æ€§è´¨ï¼Œç¼–ç å™¨åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­å¯¹è¾“å…¥çš„è¯­è¨€æ— å…³ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgK9JBHeNh-ZSB1HNPC4Czr65zaUaybMGUImC6UV9ZXkwJLKm-50R4D53tyKq4J-HpMfVLjm65eyAE3_A87e1z5 N9sXsUHPGlRtMB08uE2zmkd6bbcHT4ftxzNN_vbYw3lLQqXgaTjL2yLaOG-cBd3Xumg8o38TUvFqKIlNuj0h9Xl4zQt1OzhwwWIr7d-V/s1999 /image2.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;999&quot; data-original-width=&quot; 1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgK9JBHeNh-ZSB1HNPC4Czr65zaUaybMGUImC6UV9ZXkwJLKm-50R4D53tyKq4J-HpMfVLjm65eyAE3_A87e1z5N9sXsUHPGl RtMB08uE2zmkd6bbcHT4ftxzNN_vbYw3lLQqXgaTjL2yLaOG-cBd3Xumg8o38TUvFqKIlNuj0h9Xl4zQt1OzhwwWIr7d-V/s16000/image2.png&quot;/>;&lt;/a>;&lt;/td>;&lt; /tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Translatotron 3 ä¸­çš„è®­ç»ƒå’ŒæŽ¨ç†ã€‚è®­ç»ƒåŒ…æ‹¬é€šè¿‡è‡ªåŠ¨ç¼–ç è·¯å¾„çš„é‡å»ºæŸå¤±å¹¶é‡‡ç”¨é‡å»ºæŸå¤±é€šè¿‡åå‘ç¿»è¯‘ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;h2>;éŸ³é¢‘æ ·æœ¬&lt;/h2>; &lt;p>; ä»¥ä¸‹æ˜¯ Translatotron 3 ç›´æŽ¥è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘çš„ç¤ºä¾‹ï¼š&lt;/ p>; &lt;h3>;è¥¿ç­ç‰™è¯­åˆ°è‹±è¯­ï¼ˆåœ¨å¯¹è¯æ•°æ®é›†ä¸Šï¼‰&lt;/h3>; &lt;br />; &lt;tablealign=&quot;center&quot;cellpadding=&quot;0&quot;cellpacing=&quot;0&quot;class=&quot;tr-caption-container&quot;æ ·å¼=â€œå·¦è¾¹è·ï¼šè‡ªåŠ¨â€ï¼› margin-right: auto;&quot;>; &lt;tbody>; &lt;tr>; &lt;td>;è¾“å…¥ï¼ˆè¥¿ç­ç‰™è¯­ï¼‰&lt;/td>; &lt;td>;&lt;audiocontrols=&quot;controls&quot; src=&quot;https://google-research.github.io/ lingvo-lab/translatotron3/examples/conv_es_en/1/src.wav&quot;>;&lt;/audio>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;TTS åˆæˆå‚è€ƒï¼ˆè‹±æ–‡ï¼‰&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/ td>; &lt;td>;&lt;éŸ³é¢‘æŽ§åˆ¶=â€œæŽ§åˆ¶â€src =â€œhttps://google-research.github.io/lingvo-lab/translatotron3/examples/conv_es_en/1/ref.wavâ€>;&lt;/éŸ³é¢‘>;&lt;/ td>; &lt;/tr>; &lt;tr>; &lt;td>;Translatotron 3ï¼ˆè‹±è¯­ï¼‰&lt;/td>; &lt;td>;&lt;audiocontrols=&quot;controls&quot; src=&quot;https://google-research.github.io/lingvo-lab/ translatotron3/examples/conv_es_en/1/pred.wav&quot;>;&lt;/audio>;&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;h3>;è¥¿ç­ç‰™è¯­åˆ°è‹±è¯­ï¼ˆåœ¨ CommonVoice11 åˆæˆæ•°æ®é›†ä¸Šï¼‰ )&lt;/h3>; &lt;br />; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>; &lt;tbody>; &lt;tr>; &lt;td>;è¾“å…¥ï¼ˆè¥¿ç­ç‰™è¯­ï¼‰&lt;/td>; &lt;td>;&lt;audiocontrols=&quot;controls&quot; src=&quot;https://google-research.github.io/ lingvo-lab/translatotron3/examples/cm-s_es_en/1/src.wav&quot;>;&lt;/audio>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;TTS åˆæˆå‚è€ƒï¼ˆè‹±æ–‡ï¼‰ &lt;/td>; &lt;td>;&lt;éŸ³é¢‘æŽ§åˆ¶=â€œæŽ§åˆ¶â€src =â€œhttps://google-research.github.io/lingvo-lab/translatotron3/examples/cm-s_es_en/1/ref.wavâ€>;&lt;/éŸ³é¢‘>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;Translatotron 3ï¼ˆè‹±è¯­ï¼‰&lt;/td>; &lt;td>;&lt;audiocontrols=&quot;controls&quot; src=&quot;https://google-research.github.io/ lingvo-lab/translatotron3/examples/cm-s_es_en/1/pred.wav&quot;>;&lt;/audio>;&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;h3>;è¥¿ç­ç‰™è¯­-è‹±è¯­ï¼ˆåœ¨ CommonVoice11 æ•°æ®é›†ä¸Šï¼‰&lt;/h3>; &lt;br />; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>; &lt;tbody>; &lt;tr>; &lt;td>;è¾“å…¥ï¼ˆè¥¿ç­ç‰™è¯­ï¼‰&lt;/td>; &lt;td>;&lt;audiocontrols=&quot;controls&quot; src=&quot;https://google-research.github.io/ lingvo-lab/translatotron3/examples/cm-e/1/src.wav&quot;>;&lt;/audio>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;TTS å‚è€ƒï¼ˆè‹±æ–‡ï¼‰&lt;/td>; &lt;td>;&lt;éŸ³é¢‘æŽ§ä»¶=â€œæŽ§åˆ¶â€src =â€œhttps://google-research.github.io/lingvo-lab/translatotron3/examples/cm-e/1/ref.wavâ€>;&lt;/audio>;&lt;/td>; &lt;/ tr>; &lt;tr>; &lt;td>;Translatotron 3ï¼ˆè‹±è¯­ï¼‰&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>; &lt;td>;&lt;audiocontrols=&quot;controls&quot; src=&quot;https://google-research.github.io/lingvo- lab/translatotron3/examples/cm-e/1/pred.wav&quot;>;&lt;/audio>;&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;div style=&quot;line-height: 40%;&quot; >; &lt;br />; &lt;/div>; &lt;h2>;æ€§èƒ½&lt;/h2>; &lt;p>;ä¸ºäº†å‡­ç»éªŒè¯„ä¼°æ‰€æå‡ºæ–¹æ³•çš„æ€§èƒ½ï¼Œæˆ‘ä»¬ä½¿ç”¨å„ç§æ•°æ®é›†ï¼ˆåŒ…æ‹¬&lt;a href=&quot;https: //aclanthology.org/2020.lrec-1.520/&quot;>;Common Voice 11&lt;/a>; æ•°æ®é›†ï¼Œä»¥åŠæºè‡ª &lt;a href=&quot;https://arxiv.org/abs/1811.02050&quot;>; çš„ä¸¤ä¸ªåˆæˆæ•°æ®é›†ä¼šè¯&lt;/a>;å’Œ Common Voice 11 æ•°æ®é›†ã€‚ &lt;/p>; &lt;p>; ç¿»è¯‘è´¨é‡é€šè¿‡ ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ä¸Šçš„ &lt;a href=&quot;https://en.wikipedia.org/wiki/BLEU&quot;>;BLEU&lt;/a>; æ¥è¡¡é‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ç¿»è¯‘è¯­éŸ³çš„è½¬å½•ï¼Œä¸Žç›¸åº”çš„å‚è€ƒç¿»è¯‘æ–‡æœ¬è¿›è¡Œæ¯”è¾ƒã€‚è€Œè¯­éŸ³è´¨é‡æ˜¯é€šè¿‡ &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_opinion_score&quot;>;MOS&lt;/a>; åˆ†æ•°æ¥è¡¡é‡çš„ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ã€‚æ­¤å¤–ï¼Œè¯´è¯è€…ç›¸ä¼¼åº¦æ˜¯é€šè¿‡&lt;a href=&quot;https://en.wikipedia.org/wiki/Cosine_similarity&quot;>;å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦&lt;/a>;æ¥è¡¡é‡çš„ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ã€‚ &lt;/p>; &lt;p>; ç”±äºŽ Translatotron 3 æ˜¯ä¸€ç§&lt;em>;æ— ç›‘ç£&lt;/em>;æ–¹æ³•ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨çº§è” S2ST ç³»ç»Ÿä½œä¸ºåŸºçº¿ï¼Œè¯¥ç³»ç»Ÿç»“åˆäº† ASRã€æ— ç›‘ç£æœºå™¨ç¿»è¯‘ (UMT) å’Œ TTSï¼ˆæ–‡æœ¬åˆ°æ–‡æœ¬ï¼‰ -æ¼”è®²ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨ UMTï¼Œå®ƒä½¿ç”¨åµŒå…¥ç©ºé—´ä¸­çš„æœ€è¿‘é‚»å±…æ¥åˆ›å»ºç¿»è¯‘ã€‚ &lt;/p>; &lt;p>; Translatotron 3 åœ¨æˆ‘ä»¬æµ‹é‡çš„å„ä¸ªæ–¹é¢éƒ½å¤§å¹…ä¼˜äºŽåŸºå‡†ï¼šç¿»è¯‘è´¨é‡ã€è¯´è¯è€…ç›¸ä¼¼åº¦å’Œè¯­éŸ³è´¨é‡ã€‚å®ƒåœ¨&lt;a href=&quot;https://arxiv.org/abs/1811.02050&quot;>;ä¼šè¯è¯­æ–™åº“&lt;/a>;ä¸Šè¡¨çŽ°å°¤å…¶å‡ºè‰²ã€‚æ­¤å¤–ï¼ŒTranslatotron 3 å®žçŽ°äº†ä¸Žåœ°é¢çœŸå®žéŸ³é¢‘æ ·æœ¬ç›¸ä¼¼çš„è¯­éŸ³è‡ªç„¶åº¦ï¼ˆé€šè¿‡ &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_opinion_score&quot;>;MOS&lt;/a>; æµ‹é‡ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiUTs76BWvt7hs_NTQSVtz_rQjl1WDu-xadGg5xL7wFo6JLZZ7jYIUmKC6M8HXL1RvnDrjjHTESOnvxKeSX1G-y h9vCPEKshy4TDiYAjlYWlTCXEi2HtiKZjwnzFoYNzQwZrJIL-YGA08MVT1fYwlUDDD6wBsvfTOPHKYMGm0rZXJEyva3XbkQd3hSxyFAb/s1200/image4.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiUTs76BWvt7hs_NTQSVtz_rQjl1WDu-xadGg5xL7wFo6JLZZ7jYIUmKC6M8HXL1RvnDrjjHTESOnvxKeSX1G-yh9vCPEKshy4TDiYAjlYWlTCXEi 2HtiKZjwnzFoYNzQwZrJIL-YGA08MVT1fYwlUDDD6wBsvfTOPHKYMGm0rZXJEyva3XbkQd3hSxyFAb/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- Caption&quot; style=&quot;text-align: center;&quot;>;åœ¨ä¸‰ä¸ªè¥¿ç­ç‰™è¯­-è‹±è¯­è¯­æ–™åº“ä¸Šè¯„ä¼°ç¿»è¯‘è´¨é‡ï¼ˆé€šè¿‡ BLEU è¡¡é‡ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;è¡¨å¯¹é½=â€œä¸­å¿ƒâ€cellpadding=â€œ0â€cellspacing=â€œ0â€ç±»=â€œtr-caption-containerâ€æ ·å¼=â€œmargin-leftï¼šè‡ªåŠ¨ï¼› margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgJMoR3EyxNHlSyVzTpiIkMMsVXYJa0c3uJjdRkfCTKhLpLoNBCCBlzMQkWgNxCJj1GJFpCqAUtLLF Zjuv6F6WYzj_q9tqt4Qq9xYzs8osVN2IjfxhY2weXdPJ2AdecRKP4MD8pgB0- dCwCP2QWcJx0cJs1Dbg-WgJRrgPvHY6OvZPOtuAwm_HqKuSyCh5V/s1200/image3.png&quot; style=&quot;margin-left: è‡ªåŠ¨; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEgJMoR3EyxNHlSyVzTpiIkMMsVXYJa0c3uJjdRkfCTKhLpLoNBCCBlzMQkWgNxCJj1GJFpCqAUtLLFZjuv6F6WYzj_q9tqt4Qq9xYzs8osVN2IjfxhY2weXdPJ2AdecRKP 4MD8pgB0-dCwCP2QWcJx0cJs1Dbg-WgJRrgPvHY6OvZPOtuAwm_HqKuSyCh5V/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot; >;åœ¨ä¸‰ä¸ªè¥¿ç­ç‰™è¯­-è‹±è¯­è¯­æ–™åº“ä¸Šè¯„ä¼°è¯­éŸ³ç›¸ä¼¼åº¦ï¼ˆé€šè¿‡è¾“å…¥è¯´è¯è€…å’Œè¾“å‡ºè¯´è¯è€…ä¹‹é—´çš„å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¡¡é‡ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;tablealign=&quot;ä¸­å¿ƒ&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQ4hT_YlcTEbE- WAqE0IjP_uBP_q6TttLPO8CwF_Gm9WBJyW6UwEHaMr2nQo6kBs8ffUvx20mJCX_Gcj93iUCh1CDueObHoU4PhaCgqmzKcmZCijHVCr9uvRX99d2LHGM3DgnKyyfX6xg4PmDwyPg0I7t FhHE-CX-iPsV0zygPL8z1P74h4XXZYXc42_XJ/s1200/image1.png&quot; style=&quot;margin-left: è‡ªåŠ¨; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEgQ4hT_YlcTEbE-WAqE0IjP_uBP_q6TttLPO8CwF_Gm9WBJyW6UwEHaMr2nQo6kBs8ffUvx20mJCX_Gcj93iUCh1CDueObHoU4PhaCgqmzKcmZCijHVCr9uvRX99d2LH GM3DgnKyyfX6xg4PmDwyPg0I7tFhHE-CX-iPsV0zygPL8z1P74h4XXZYXc42_XJ/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center ;&quot;>;åœ¨ä¸‰ä¸ªè¥¿ç­ç‰™è¯­-è‹±è¯­è¯­æ–™åº“ä¸Šè¯„ä¼°çš„å¹³å‡æ„è§å¾—åˆ†ï¼ˆé€šè¿‡å¹³å‡ MOS æŒ‡æ ‡è¡¡é‡ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line -height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;æœªæ¥çš„å·¥ä½œ&lt;/h2>; &lt;p>; ä½œä¸ºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬å¸Œæœ›å°†å·¥ä½œæ‰©å±•åˆ°æ›´å¤šè¯­è¨€ï¼Œå¹¶ç ”ç©¶é›¶æ ·æœ¬ S2ST æ˜¯å¦å¯ä»¥ä¸Žåå‘ç¿»è¯‘æŠ€æœ¯ä¸€èµ·åº”ç”¨ã€‚æˆ‘ä»¬è¿˜æƒ³ç ”ç©¶åå‘ç¿»è¯‘åœ¨ä¸åŒç±»åž‹çš„è¯­éŸ³æ•°æ®ä¸­çš„ä½¿ç”¨ï¼Œä¾‹å¦‚å™ªå£°è¯­éŸ³å’Œä½Žèµ„æºè¯­è¨€ã€‚&lt;/p>; &lt;div style=&quot;line-height : 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è‡´è°¢&lt;/h2>; &lt;p>; &lt;em>;è¿™é¡¹å·¥ä½œçš„ç›´æŽ¥è´¡çŒ®è€…åŒ…æ‹¬ Eliya Nachmaniã€Alon Levkovitchã€Yifan Dingã€Chulayutsh Asawaroengchaiã€Heigazhenã€å’Œç±³æ­‡å°”Â·å¡”å¾·èŽ«Â·æ‹‰é©¬è¯ºç»´å¥‡ã€‚æˆ‘ä»¬è¿˜è¦æ„Ÿè°¢&lt;a href=&quot;https://pub-tools.googleplex.com/v2/people/identity-93206143435047873025899696102580793814&quot;>;å¼ å®‡&lt;/a>;ã€&lt;a href=&quot;https://pub-tools.googleplex .com/v2/people/identity-100501641418409000382760334738251480377&quot;>;Yuma Koizumi&lt;/a>;ã€Soroosh Mariooryadã€RJ Skerry-Ryanã€Neil Zeghidourã€Christian Frankã€Marco Tagliasacchiã€Nadav Barã€Benny Schlesinger å’Œ &lt;a href=&quot;https:/ /pub-tools.googleplex.com/v2/people/identity-15837328604369916640918707776141319378&quot;>;å´æ°¸è¾‰&lt;/a>;ã€‚&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research. google/feeds/8288223977991952319/comments/default&quot; rel=&quot;replies&quot; title=&quot;å‘è¡¨è¯„è®º&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12 /unsupervised-speech-to-speech.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/ feed/847492631452026626/posts/default/828822239799191952319â€œ rel =â€ rel =â€œ editâ€ type =â€œ application/application/atom+xmlâ€/>; &lt;link href = &lt;link href =â€œ 8223977991952319 â€œ rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/12/unsupervised-speech-to-speech.html&quot; rel=&quot;alternate &quot; title=&quot;å•è¯­è¨€æ•°æ®çš„æ— ç›‘ç£è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile /12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https ://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger .googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuXgYf5aJuSobrasrRUpb5IUKH05RFHJ5_vcwW-XyOLQdKOEonciXcyXtcJN2zPkHu5_k4wvIsl6oFZd4UfYsBfjSK27YaIcw7s1-3dekdJVxTBM- 4hrBvndT-go6YOsscswtV6FvE_3QHml8zZjWIz7J4quRh8UBL9gzW9guAVYd4czuHYhY6lu9TkK4K/s72-c/T3.pngâ€œå®½åº¦=â€72â€œxmlnsï¼šåª’ä½“=â€œhttp://search.yahoo.com/mrss /&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;æ ‡ç­¾ï¼šblogger.com,1999:blog-8474926331452026626.post-1055595481112584523&lt;/id>; &lt;å‘å¸ƒ>;2023-11-22T08:03:00.000-08:00&lt;/å‘å¸ƒ>;&lt;æ›´æ–°>;2023-11-30T13:46:35.804-08:00&lt;/æ›´æ–°>;&lt;category schema=&quot;http://www .blogger.com/atom/ns#&quot; term=&quot;é«˜æ€§èƒ½è®¡ç®—&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Physics&quot;>;&lt; /category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Weather&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;æ”¹è¿›äº‘åŠå…¶å¯¹æ°”å€™å½±å“çš„æ¨¡æ‹Ÿ&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;å‘å¸ƒè€…ï¼šGoogle ç ”ç©¶é™¢è®¿é—®ç ”ç©¶å‘˜ Tapio Schneider å’Œå·¥ç¨‹ä¸»ç®¡é™ˆä¸€å‡¡&lt;/span>; &lt;img src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEipIpAUM7d1E-XNQdqZ3hiRC7VgksSfuI249KFq9yL5ZTZF8-DJ5Sfo-fRf2m7hTKuTeJwSGQzwz6rtfdZs8PxlualXz7U53miz6ahU3oyO9WQ WkePA1fgr5mxRa75NYKKPe0KLOYSPLxzfDfoIABePqL1etrqaDuRPjJotAVEIbuBRw6EWrJSxXB-BzCTS/s320/hero.gif&quot; style=&quot;æ˜¾ç¤ºï¼šæ— ï¼›&quot; />; &lt;p>; å½“ä»Šçš„æ°”å€™æ¨¡åž‹æˆåŠŸåœ°æ•æ‰äº†å¹¿æ³›çš„å…¨çƒå˜æš–è¶‹åŠ¿ã€‚ç„¶è€Œï¼Œç”±äºŽ&lt;a href=&quot;https://physicalstoday.sitation.org/doi/abs/10.1063/PT.3.4772&quot;>;è§„æ¨¡å°ä½†å…·æœ‰å…¨çƒé‡è¦æ€§&lt;/a>;çš„è¿‡ç¨‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚&lt;a href=&quot;http://rdcu.be/ohot&quot;>;äº‘&lt;/a>;å’Œ&lt;a href=&quot;https://doi.org/10.3389/fmars.2019.00065&quot;>;æµ·æ´‹æ¹æµ&lt;/a>;ï¼Œè¿™äº›æ¨¡åž‹å¯¹å³å°†åˆ°æ¥çš„æ°”å€™å˜åŒ–çš„é¢„æµ‹åœ¨ç»†èŠ‚ä¸Šä¸æ˜¯å¾ˆå‡†ç¡®ã€‚ä¾‹å¦‚ï¼Œé¢„æµ‹åœ°çƒå…¨çƒå¹³å‡è¡¨é¢æ¸©åº¦ç›¸å¯¹äºŽå·¥ä¸šåŒ–å‰æ—¶æœŸå°†å˜æš–2â„ƒçš„æ—¶é—´ï¼Œ&lt;a href=&quot;https://www.ipcc.ch/report/ar6/wg1/downloads/ report/IPCC_AR6_WGI_TS.pdf&quot;>;å½“ä»Šçš„æ¨¡åž‹ç›¸å·® 40-50 å¹´&lt;/a>;ï¼ˆæ•´æ•´ä¸€ä»£äººï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ²¡æœ‰è§„åˆ’å¼¹æ€§åŸºç¡€è®¾æ–½æ‰€éœ€çš„&lt;a href=&quot;https://www.nature.com/articles/s41558-020-00984-6&quot;>;å‡†ç¡®ä¸”ç²¾ç»†çš„åœ°ç†é¢„æµ‹&lt;/a>; ï¼Œè°ƒæ•´ä¾›åº”é“¾ä»¥é€‚åº”æ°”å€™ç ´åï¼Œå¹¶è¯„ä¼°è„†å¼±ç¤¾åŒºé¢ä¸´çš„æ°”å€™ç›¸å…³å±å®³çš„é£Žé™©ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; è¿™åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯å› ä¸ºäº‘åœ¨æœªæ¥å‡ åå¹´çš„æ°”å€™é¢„æµ‹ä¸­ä¸»å¯¼ç€é”™è¯¯å’Œä¸ç¡®å®šæ€§ [&lt;a href=&quot;https://doi.org /10.1029/2005GL023851&quot;>;1&lt;/a>;ï¼Œ&lt;a href=&quot;https://link.springer.com/article/10.1007/s00382-013-1725-9&quot;>;2&lt;/a>;ï¼Œ&lt;a href= â€œhttps://doi.org/10.1038/nclimate3402&quot;>;3&lt;/a>;]ã€‚äº‘åå°„é˜³å…‰å¹¶äº§ç”Ÿ&lt;a href=&quot;https://en.wikipedia.org/wiki/Greenhouse_effect&quot;>;æ¸©å®¤æ•ˆåº”&lt;/a>;ï¼Œè¿™ä½¿å¾—å®ƒä»¬å¯¹äºŽè°ƒèŠ‚åœ°çƒçš„èƒ½é‡å¹³è¡¡å’Œè°ƒèŠ‚æ°”å€™ç³»ç»Ÿå¯¹æ°”å€™çš„å“åº”è‡³å…³é‡è¦ã€‚æ¸©å®¤æ°”ä½“æµ“åº¦çš„å˜åŒ–ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„è§„æ¨¡å¤ªå°ï¼Œæ— æ³•åœ¨å½“ä»Šçš„æ°”å€™æ¨¡åž‹ä¸­ç›´æŽ¥è§£æžã€‚ç›®å‰çš„æ°”å€™æ¨¡åž‹å¯ä»¥è§£å†³æ•°ååˆ°ä¸€ç™¾å…¬é‡Œå°ºåº¦çš„è¿åŠ¨ï¼Œ&lt;a href=&quot;https://link.springer.com/article/10.1186/s40645-019-0304-z&quot;>;å¾ˆå°‘æœ‰æŽ¨åŠ¨&lt;/a >; &lt;a href=&quot;https://journals.ametsoc.org/view/journals/bams/101/5/bams-d-18-0167.1.xml&quot;>;åƒç±³è§„æ¨¡&lt;/a>;ã€‚ç„¶è€Œï¼Œç»´æŒè¦†ç›–å¤§ç‰‡çƒ­å¸¦æµ·æ´‹çš„ä½Žäº‘ç­‰çš„æ¹æµç©ºæ°”è¿åŠ¨çš„å°ºåº¦ä¸ºæ•°ç±³è‡³æ•°åç±³ã€‚ç”±äºŽè§„æ¨¡å·®å¼‚å·¨å¤§ï¼Œæ°”å€™æ¨¡åž‹ä½¿ç”¨äº‘çš„ç»éªŒå‚æ•°åŒ–ï¼Œè€Œä¸æ˜¯ç›´æŽ¥æ¨¡æ‹Ÿå®ƒä»¬ï¼Œè¿™ä¼šå¯¼è‡´è¾ƒå¤§çš„è¯¯å·®å’Œä¸ç¡®å®šæ€§ã€‚ &lt;/p>; &lt;p>; è™½ç„¶äº‘æ— æ³•åœ¨å…¨çƒæ°”å€™æ¨¡åž‹ä¸­ç›´æŽ¥è§£æžï¼Œä½†å¯ä»¥é€šè¿‡ä½¿ç”¨é«˜åˆ†è¾¨çŽ‡&lt;a href=&quot;https://en.wikipedia.org/wiki/Large_eddy_simulation åœ¨æœ‰é™åŒºåŸŸå†…æ¨¡æ‹Ÿäº‘çš„æ¹æµåŠ¨åŠ›å­¦&quot;>;å¤§æ¶¡æµæ¨¡æ‹Ÿ&lt;/a>; (LES)ã€‚ç„¶è€Œï¼Œä½¿ç”¨ LES æ¨¡æ‹Ÿäº‘çš„é«˜è®¡ç®—æˆæœ¬é˜»ç¢äº†å¹¿æ³›å’Œç³»ç»Ÿçš„æ•°å€¼å®žéªŒï¼Œå¹¶ä¸”é˜»ç¢äº†ç”¨äºŽè®­ç»ƒå‚æ•°åŒ–æ–¹æ¡ˆä»¥åœ¨è¾ƒç²—åˆ†è¾¨çŽ‡çš„å…¨çƒæ°”å€™æ¨¡åž‹ä¸­è¡¨ç¤ºäº‘çš„å¤§åž‹æ•°æ®é›†çš„ç”Ÿæˆã€‚ &lt;/p>; &lt;p>; åœ¨â€œ&lt;a href=&quot;https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2023MS003619&quot;>;ä½¿ç”¨å¼ é‡å¤„ç†å•å…ƒåŠ é€Ÿäº‘çš„å¤§æ¶¡æ¨¡æ‹Ÿ&lt;/a>; â€ï¼Œå‘è¡¨äºŽ &lt;em>;&lt;a href=&quot;https://agupubs.onlinelibrary.wiley.com/journal/19422466&quot;>;åœ°çƒç³»ç»Ÿå»ºæ¨¡è¿›å±•æ‚å¿—&lt;/a>;&lt;/em>; (JAMES) å’Œæˆ‘ä»¬ä¸Ž Google å®¢åº§ç ”ç©¶å‘˜&lt;a href=&quot;https://clima.caltech.edu/&quot;>;æ°”å€™æ¨¡æ‹Ÿè”ç›Ÿ&lt;/a>; (CliMA) è´Ÿè´£äººåˆä½œï¼Œè¯æ˜Ž&lt;a href=&quot;https:/ /cloud.google.com/tpu&quot;>;å¼ é‡å¤„ç†å•å…ƒ&lt;/a>; (TPU) â€” æœ€åˆä¸ºæœºå™¨å­¦ä¹  (ML) åº”ç”¨å¼€å‘çš„ä¸“ç”¨é›†æˆç”µè·¯ â€” å¯æœ‰æ•ˆç”¨äºŽæ‰§è¡Œäº‘çš„ LESã€‚æˆ‘ä»¬è¯æ˜Žï¼ŒTPU ä¸Žå®šåˆ¶çš„è½¯ä»¶å®žçŽ°ç›¸ç»“åˆï¼Œå¯ç”¨äºŽåœ¨ç‰¹å®šæ¡ä»¶ä¸‹æ¨¡æ‹Ÿè®¡ç®—ä¸Šç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§çš„&lt;a href=&quot;https://en.wikipedia.org/wiki/Marine_stratocumulus&quot;>;æµ·æ´‹å±‚ç§¯äº‘&lt;/a>;åœ¨&lt;a href=&quot;https://doi.org/10.1175/MWR2930.1&quot;>;æµ·æ´‹å±‚ç§¯äº‘åŠ¨åŠ›å­¦å’ŒåŒ–å­¦&lt;/a>; (DYCOMS) å®žåœ°ç ”ç©¶æœŸé—´è§‚å¯Ÿåˆ°çš„ç»“æžœã€‚è¿™ä¸ªåŸºäºŽ TPU çš„æˆåŠŸ LES ä»£ç æ­ç¤ºäº† TPU çš„å®žç”¨æ€§ï¼Œä»¥åŠå…¶åºžå¤§çš„è®¡ç®—èµ„æºå’Œç´§å¯†çš„äº’è¿žï¼Œç”¨äºŽäº‘æ¨¡æ‹Ÿã€‚ &lt;/p>; &lt;p>; è¿‡åŽ» 20 å¹´æ¥ï¼Œæ°”å€™æ¨¡åž‹å¯¹é™æ°´é‡æˆ–å¤§æ°”å±‚é¡¶éƒ¨èƒ½é‡å¹³è¡¡ç­‰å…³é”®æŒ‡æ ‡çš„å‡†ç¡®æ€§æ¯åå¹´æé«˜äº†çº¦ 10%ã€‚æˆ‘ä»¬è¿™é¡¹ç ”ç©¶çš„ç›®æ ‡æ˜¯é€šè¿‡æ”¹å–„äº‘çš„è¡¨çŽ°ï¼Œå°†æ°”å€™æ¨¡åž‹çš„è¯¯å·®å‡å°‘ 50%ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;TPU ä¸Šçš„å¤§æ¶¡æ¨¡æ‹Ÿ&lt;/h2>; &lt;p>; åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹å…³æ³¨å±‚ç§¯äº‘äº‘ï¼Œè¦†ç›–çº¦ 20% çš„çƒ­å¸¦æµ·æ´‹ï¼Œæ˜¯åœ°çƒä¸Šæœ€æ™®éçš„äº‘ç±»åž‹ã€‚å½“å‰çš„æ°”å€™æ¨¡åž‹å°šæ— æ³•æ­£ç¡®å†çŽ°å±‚ç§¯äº‘çš„è¡Œä¸ºï¼Œè¿™ä¸€ç›´æ˜¯è¿™äº›æ¨¡åž‹ä¸­æœ€å¤§çš„é”™è¯¯æ¥æºä¹‹ä¸€ã€‚æˆ‘ä»¬çš„å·¥ä½œå°†ä¸ºå¤§è§„æ¨¡æ°”å€™æ¨¡åž‹æä¾›æ›´å‡†ç¡®çš„åœ°é¢äº‹å®žã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬åœ¨ TPU ä¸Šå¯¹äº‘çš„æ¨¡æ‹Ÿè¡¨çŽ°å‡ºå‰æ‰€æœªæœ‰çš„è®¡ç®—åžåé‡å’Œæ‰©å±•èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥åœ¨æœ€å¤§çº¦ 35 Ã— 54 km çš„åŒºåŸŸå†…æ¨¡æ‹Ÿå±‚ç§¯äº‘ï¼Œå…¶å®žæ—¶æ¼”åŒ–é€Ÿåº¦æé«˜ 10 å€&lt; sup>;2&lt;/sup>;ã€‚è¿™æ ·çš„åŸŸå¤§å°æŽ¥è¿‘å…¸åž‹å…¨çƒæ°”å€™æ¨¡åž‹ç½‘æ ¼ç›’çš„æ¨ªæˆªé¢ç§¯ã€‚æˆ‘ä»¬çš„ç»“æžœä¸ºè®¡ç®—å®žéªŒå¼€è¾Ÿäº†æ–°é€”å¾„ï¼Œå¹¶å¤§å¤§æ‰©å¤§äº†å¯ç”¨äºŽè®­ç»ƒå…¨çƒæ°”å€™æ¨¡åž‹äº‘å‚æ•°åŒ–çš„ LES æ ·æœ¬ã€‚&lt;/p>; &lt;tablealign=&quot;center&quot; cellpadding=&quot;8&quot; cellspacing=&quot;4&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>; &lt;td>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbx0OTXHC32wHSDDNIqQkj-NLjggGrcW9Hfy4o_TCIiP_n6Lt0zpOSu0OIVd0BkWmPaGUNS6oF0q Z2KfUcBZQQi9EGgq6dEhvMiY4PGq_bj6nrnP1p3uQz -dO3AlK7TJCIlMSZcQIRxuOwm7q2lhEVdJTumMfLubHFNZpg7FnRh5GLG5lqhZygSdT-0AY5/s540/image3.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;320&quot; data-original-width= â€œ540â€src =â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbx0OTXHC32wHSDDNIqQkj-NLjggGrcW9Hfy4o_TCIiP_n6Lt0zpOSu0OIVd0BkWmPaGUNS6oF0qZ2KfUcBZQQi9EGgq6dEhvMiY4 PGq_bj6nrnP1p3uQz-dO3AlK7TJCIlMSZcQIRxuOwm7q2lhEVdJTumMfLubHFNZpg7FnRh5GLG5lqhZygSdT-0AY5/s16000/image3.gif&quot; />;&lt;/a>;&lt;/td>; &lt;td>;&lt; a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5_r1YHNKYhQtxQZKBIAZ67d7AJOwEm79UlI-d-MftNzbnogH2CwkB8XpC8XN1FMa_Y6fVo9dTz2AG4DrbXkLjauQTLsu11KXfgd Nxt_AAHpfCeSovo8cCrjWs7KqBOCCYU3-Os3smHz0bZIax9Iyf8L39edQD-rSq7kqV8SGkhlO5VelXE8MJfPk0rjwP/s540/image4.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;320&quot; data-original-width=&quot;540&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEj5_r1YHNKYhQtxQZKBIAZ67d7AJOwEm79ULI-d-MftNzbnogH2CwkB8XpC8XN1FMa_Y6fVo9dTz2AG4DrbXkLjauQTLsu11KXfgdNxt_AAHpfCeSovo8cCrjWs7 KqBOCCYU3-Os3smHz0bZIax9Iyf8L39edQD-rSq7kqV8SGkhlO5VelXE8MJfPk0rjwP/s16000/image4.gif&quot; />;&lt;/a>;&lt;/td>; &lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;tablealign=&quot;center&quot;cellpadding=&quot; 0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;æ¨¡æ‹Ÿ 285 x 285 x 2 å…¬é‡Œçš„äº‘æ¼”å˜æ¸²æŸ“&lt;sup>;3&lt;/sup>; å±‚ç§¯äº‘ç‰‡ã€‚è¿™æ˜¯æœ‰å²ä»¥æ¥æ¨¡æ‹Ÿçš„æœ€å¤§çš„åŒç±»äº‘ç‰‡ã€‚&lt;strong>;å·¦&lt;/strong>;ï¼šç›¸æœºå·¡èˆªæ—¶äº‘åœºçš„æ–œè§†å›¾ã€‚&lt;strong>;å³&lt; /strong>;ï¼šäº‘åœºä¿¯è§†å›¾ï¼Œæ‘„åƒæœºé€æ¸æ‹‰å¼€ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; LES ä»£ç æ˜¯ç”¨ TensorFlow ç¼–å†™çš„ï¼ŒTensorFlow æ˜¯ä¸€ä¸ªå¼€æ”¾çš„-Google ä¸º ML åº”ç”¨ç¨‹åºå¼€å‘çš„æºè½¯ä»¶å¹³å°ã€‚è¯¥ä»£ç åˆ©ç”¨äº† TensorFlow çš„å›¾å½¢è®¡ç®—å’Œ&lt;a href=&quot;https://www.tensorflow.org/xla&quot;>;åŠ é€Ÿçº¿æ€§ä»£æ•°&lt;/a>; (XLA) ä¼˜åŒ–ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨ TPU ç¡¬ä»¶ï¼ŒåŒ…æ‹¬é«˜é€Ÿã€ä½Žå»¶è¿Ÿçš„&lt;a href=&quot;https://patents.google.com/patent/US9372800&quot;>;èŠ¯ç‰‡é—´äº’è¿ž&lt;/a>; (ICI)å¸®åŠ©æˆ‘ä»¬å®žçŽ°äº†å‰æ‰€æœªæœ‰çš„æ€§èƒ½ã€‚åŒæ—¶ï¼ŒTensorFlow ä»£ç å¯ä»¥è½»æ¾åœ°å°† ML ç»„ä»¶ç›´æŽ¥åˆå¹¶åˆ°åŸºäºŽç‰©ç†çš„æµä½“æ±‚è§£å™¨ä¸­ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿå¤§æ°”æµåŠ¨æ±‚è§£å™¨çš„å…¸åž‹æµ‹è¯•ç”¨ä¾‹æ¥éªŒè¯ä»£ç ï¼Œä¾‹å¦‚åœ¨ä¸­æ€§åˆ†å±‚ä¸­ä¸Šå‡çš„æµ®åŠ›æ°”æ³¡ï¼Œä»¥åŠä¸‹æ²‰å¹¶æ’žå‡»è¡¨é¢çš„è´Ÿæµ®åŠ›æ°”æ³¡ã€‚è¿™äº›æµ‹è¯•ç”¨ä¾‹è¡¨æ˜Žï¼ŒåŸºäºŽ TPU çš„ä»£ç å¿ å®žåœ°æ¨¡æ‹Ÿäº†æµåŠ¨ï¼Œéšç€åˆ†è¾¨çŽ‡çš„æé«˜ï¼Œæ¹æµç»†èŠ‚ä¹Ÿè¶Šæ¥è¶Šç²¾ç»†ã€‚éªŒè¯æµ‹è¯•çš„æœ€ç»ˆç»“æžœæ˜¯æ¨¡æ‹Ÿ DYCOMS çŽ°åœºæ´»åŠ¨æœŸé—´çš„æ¡ä»¶ã€‚åŸºäºŽ TPU çš„ä»£ç å¯é åœ°å†çŽ°äº†é£žæœºåœ¨é‡Žå¤–æ´»åŠ¨ä¸­è§‚å¯Ÿåˆ°çš„äº‘åœºå’Œæ¹æµç‰¹å¾ï¼Œè¿™ä¸€å£®ä¸¾&lt;a href=&quot;https://doi.org/10.1175/MWR2930.1&quot;>;å¯¹äºŽLES&lt;/a>;æ˜¯å› ä¸ºå±‚ç§¯äº‘é¡¶éƒ¨çš„&lt;a href=&quot;https://doi.org/10.1029/2018MS001312&quot;>;æ¸©åº¦å’Œå…¶ä»–çƒ­åŠ›å­¦ç‰¹æ€§çš„å¿«é€Ÿå˜åŒ–&lt;/a>;ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiwHPP1IE_dz44C374eIoiL9Gq7OcYIdAuZkUQ4t1PPAcdgnU-Cf8C_7UAYBKkEQZBBY1tbBzBkqGi01-kUA Mgs7tbjvH5PtSQDxGHVRPawtZTDEc8ounOJTnzAi5fG1EgKTbxZ1TQJiZc7blSmDKTFJzdHp6B_xwfqM_-n4DXp9nR_F3Zx5QramRMLCjV/s1023/image2.png â€œ style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;815&quot; data-original-width=&quot;1023&quot; height=&quot;510&quot; src= â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiwHPP1IE_dz44C374eIoiL9Gq7OcYIdAuZkUQ4t1PPAcdgnU-Cf8C_7UAYBKkEQZBBY1tbBzBkqGi01-kUAMgs7tbjvH5PtSQDxGHVRPa wtZTDEc8ounOJTnzAi5fG1EgKTbxZ1TQJiZc7blSmDKTFJzdHp6B_xwfqM_-n4DXp9nR_F3Zx5QramRMLCjV/w640-h510/image2.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;ç”¨äºŽéªŒè¯æˆ‘ä»¬çš„ TPU äº‘æ¨¡æ‹Ÿå™¨çš„æµ‹è¯•ç”¨ä¾‹ä¹‹ä¸€ã€‚ä¸Žä½Žåˆ†è¾¨çŽ‡ç½‘æ ¼ï¼ˆ200 mï¼Œé¡¶è¡Œï¼‰ç›¸æ¯”ï¼Œé«˜åˆ†è¾¨çŽ‡ç½‘æ ¼ï¼ˆ10 mï¼Œåº•è¡Œï¼‰å¯ä»¥æ›´å¥½åœ°è§£æžè´Ÿæµ®åŠ›æ°”æ³¡æ’žå‡»è¡¨é¢æ‰€äº§ç”Ÿçš„å¯†åº¦ç”µæµçš„ç²¾ç»†ç»“æž„ã€‚&lt;/td>; &lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;å¤–è§‚&lt;/h2>; &lt;p>; ä¸Žå»ºç«‹äº†è¿™ä¸ªåŸºç¡€åŽï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªç›®æ ‡æ˜¯å¤§å¹…æ‰©å¤§çŽ°æœ‰çš„é«˜åˆ†è¾¨çŽ‡äº‘æ¨¡æ‹Ÿ&lt;a href=&quot;https://doi.org/10.1029/2021MS002631&quot;>;æ•°æ®åº“&lt;/a>;ï¼Œæž„å»ºæ°”å€™æ¨¡åž‹çš„ç ”ç©¶äººå‘˜å¯ä»¥ä½¿ç”¨è¿™äº›æ•°æ®åº“æ¥å¼€å‘æ›´å¥½çš„äº‘å‚æ•°åŒ–â€”â€”æ— è®ºæ˜¯åŸºäºŽç‰©ç†çš„æ¨¡åž‹ã€æœºå™¨å­¦ä¹ æ¨¡åž‹è¿˜æ˜¯ä¸¤è€…çš„æ··åˆã€‚è¿™éœ€è¦è¶…å‡º&lt;a href=&quot;https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2023MS003619&quot;>;è®ºæ–‡&lt;/a>;ä¸­æè¿°çš„é¢å¤–ç‰©ç†è¿‡ç¨‹ï¼›ä¾‹å¦‚ï¼Œéœ€è¦å°†è¾å°„ä¼ è¾“è¿‡ç¨‹é›†æˆåˆ°ä»£ç ä¸­ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç”Ÿæˆå„ç§äº‘ç±»åž‹çš„æ•°æ®ï¼Œä¾‹å¦‚é›·æš´äº‘ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAj2-AUpLOJOGakUMp5e4anHQLS8k9yJNN4MKg7Eh9skhe2zJz7PRvjv_0Xob4pVEvS2ypPJWa2LxO6b_zygTMw9Y q6c3PfCm2NttTdmv0thdw4yBye9hT-6CokiI-ddKCGqGVl-yLCJmZa0adj8jQpVR93amGh9EbvDzuMTAjIxfO3G8W2Vu9x5LU9rdF/s540/image1 .gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;303&quot; data-original-width=&quot;540&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAj2-AUpLOJOGakUMp5e4anHQLS8k9yJNN4MKg7Eh9skhe2zJz7PRvjv_0Xob4pVEvS2ypPJWa2LxO6b_zygTMw9Yq6c3PfCm2NttTdmv0thdw 4yBye9hT-6CokiI-ddKCGqGVl-yLCJmZa0adj8jQpVR93amGh9EbvDzuMTAjIxfO3G8W2Vu9x5LU9rdF/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td ç±»=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;ä½¿ç”¨ä¸Žå±‚ç§¯äº‘æ¨¡æ‹Ÿå·¥ä½œç›¸åŒçš„æ¨¡æ‹Ÿå™¨æ¸²æŸ“é›·æš´æ¨¡æ‹Ÿã€‚åœ¨åœ°é¢é™„è¿‘ä¹Ÿå¯ä»¥è§‚å¯Ÿåˆ°é™é›¨ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>;è¿™é¡¹å·¥ä½œè¯´æ˜Žäº†æœºå™¨å­¦ä¹ ç¡¬ä»¶çš„è¿›æ­¥åœ¨é‡æ–°ç”¨äºŽå…¶ä»–ç ”ç©¶æ—¶å¦‚ä½•èƒ½å¤Ÿå–å¾—æƒŠäººçš„æ•ˆæžœé¢†åŸŸâ€”â€”åœ¨æœ¬ä¾‹ä¸­æ˜¯æ°”å€™å»ºæ¨¡ã€‚è¿™äº›æ¨¡æ‹Ÿä¸ºäº‘å†…æ¹æµç­‰è¿‡ç¨‹æä¾›äº†è¯¦ç»†çš„è®­ç»ƒæ•°æ®ï¼Œè¿™äº›è¿‡ç¨‹æ— æ³•ç›´æŽ¥è§‚å¯Ÿåˆ°ï¼Œä½†å¯¹äºŽæ°”å€™å»ºæ¨¡å’Œé¢„æµ‹è‡³å…³é‡è¦ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è‡´è°¢&lt;/h2>; &lt;p>; &lt;em>;æˆ‘ä»¬è¦æ„Ÿè°¢ä»¥ä¸‹å†…å®¹çš„åˆè‘—è€…ï¼šè®ºæ–‡ä½œè€…ï¼šSheide Chammasã€Qing Wangã€Matthias Ihme å’Œ John Andersonã€‚æˆ‘ä»¬è¿˜è¦æ„Ÿè°¢ Carla Brombergã€Rob Carverã€Fei Sha å’Œ Tyler Russell å¯¹è¿™é¡¹å·¥ä½œçš„è§è§£å’Œè´¡çŒ®ã€‚&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog .research.google/feeds/1055595481112584523/comments/default&quot; rel=&quot;replies&quot; title=&quot;å‘è¡¨è¯„è®º&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/ 2023/11/improving-simulations-of-clouds-and.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www .blogger.com/feeds/8474926331452026626/posts/default/1055595481112584523&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/ posts/default/1055595481112584523&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/improving-simulations-of-clouds-and .html&quot; rel=&quot;alternate&quot; title=&quot;æ”¹è¿›äº‘çš„æ¨¡æ‹ŸåŠå…¶å¯¹æ°”å€™çš„å½±å“&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www .blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#ç¼©ç•¥å›¾&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url= â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEipIpAUM7d1E-XNQdqZ3hiRC7VgksSfuI249KFq9yL5ZTZF8-DJ5Sfo-fRf2m7hTkuTeJwSGQzwz6rtfdZs8PxlualXz7U53miz6ahU3oyO9W QWkePA1fgr5mxRa75NYKKPe0KLOYSPLxzfDfoIABePqL1etrqaDuRPjJotAVEIbuBRw6EWrJSxXB-BzCTS/s72-c/hero.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search .yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;æ ‡ç­¾ï¼šblogger.com,1999:blog-8474926331452026626.post -3970135078050750650&lt;/id>;&lt;å‘å¸ƒ>;2023-11-21T10:09:00.000-08:00&lt;/å‘å¸ƒ>;&lt;æ›´æ–°>;2023-11-21T10:09:33.541-08:00&lt;/æ›´æ–°>;&lt;ç±»åˆ«æ–¹æ¡ˆ= â€œhttp://www.blogger.com/atom/ns#â€ term=&quot;accessibility&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;AIç¤¾ä¼šå…¬ç›Š&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;è®¡ç®—æœºè§†è§‰&quot;>;&lt;/category>;&lt;category schema=&quot;http://www .blogger.com/atom/ns#&quot; term=&quot;æœºå™¨æ„ŸçŸ¥&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;å¼€æº&quot;>;&lt;/ category>;&lt;title type=&quot;text&quot;>;å¼€æºé¡¹ç›®æŒ‡å—ï¼šè®¡ç®—æœºè§†è§‰è¾…åŠ©æŠ€æœ¯å¹³å°&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;å‘å¸ƒè€…ï¼šDave Hawkeyï¼Œè½¯ä»¶Google ç ”ç©¶å·¥ç¨‹å¸ˆ&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrfdKR8ZnuQ1jMtsIsG9AViwd_vkXhbwavfXUC_RYoIeTF8EppGOxlWSp9DNCgzFlUY0Ea4q3deujDXSdXJ_C4lOC89e GfIXz_POk_upHVlx5DdBab8rh0FQuigi3fhluHAOX30GhT9LkZnpU5KMmDMp8jWNpjxKDI8nLwYTqAcExYk3tW7klykfOZ-Sm_/s320/hero.jpg&quot; style=&quot;æ˜¾ç¤º: æ— ;&quot; />; &lt;p>; ä¸¤å¹´å‰ï¼Œæˆ‘ä»¬&lt;a href=&quot;https://ai.googleblog.com/2021/05/project-guideline-enabling-those-with.html&quot;>;å‘å¸ƒäº†é¡¹ç›®æŒ‡å—&lt;/a>;ï¼Œ Google Research ä¸Ž&lt;a href=&quot;https://www.guidingeyes.org/&quot;>;Guiding Eyes for the Blind&lt;/a>; åˆä½œï¼Œå¸®åŠ©è§†åŠ›éšœç¢ï¼ˆä¾‹å¦‚å¤±æ˜Žå’Œå¼±è§†ï¼‰äººå£«æ­¥è¡Œã€æ…¢è·‘ï¼Œå¹¶ç‹¬ç«‹è¿è¡Œã€‚ Project Guideline ä»…ä½¿ç”¨ Google Pixel æ‰‹æœºå’Œè€³æœºï¼Œåˆ©ç”¨è®¾å¤‡ä¸Šçš„æœºå™¨å­¦ä¹  (ML) å¼•å¯¼ç”¨æˆ·æ²¿ç€æ ‡æœ‰ç”»çº¿çš„æˆ·å¤–è·¯å¾„è¡Œé©¶ã€‚è¯¥æŠ€æœ¯å·²ç»&lt;a href=&quot;https://projectguidelinejp.withgoogle.com/intl/en/&quot;>;åœ¨ä¸–ç•Œå„åœ°è¿›è¡Œäº†æµ‹è¯•&lt;/a>;ï¼Œç”šè‡³åœ¨&lt;a href=&quot;https://www. youtube.com/live/2cW1-plwqeQ?si=MTIX2uJkyWuLluht&amp;amp;t=7334&quot;>;2020 å¹´ä¸œäº¬æ®‹å¥¥ä¼šå¼€å¹•å¼&lt;/a>;ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; è‡ªæœ€åˆå‘å¸ƒä»¥æ¥ï¼Œæˆ‘ä»¬å¼€å§‹é€šè¿‡åµŒå…¥éšœç¢ç‰©æ£€æµ‹å’Œé«˜çº§è·¯å¾„è§„åˆ’ç­‰æ–°åŠŸèƒ½æ¥æ”¹è¿›é¡¹ç›®æŒ‡å—ï¼Œä»¥å®‰å…¨å¯é åœ°å¯¼èˆªç”¨æˆ·é€šè¿‡æ›´å¤æ‚çš„åœºæ™¯ï¼ˆä¾‹å¦‚æ€¥è½¬å¼¯å’Œé™„è¿‘çš„è¡Œäººï¼‰ã€‚æ—©æœŸç‰ˆæœ¬å…·æœ‰ç®€å•çš„é€å¸§å›¾åƒåˆ†å‰²åŠŸèƒ½ï¼Œå¯æ£€æµ‹è·¯å¾„çº¿ç›¸å¯¹äºŽå›¾åƒå¸§çš„ä½ç½®ã€‚è¿™è¶³ä»¥å°†ç”¨æˆ·å®šå‘åˆ°çº¿è·¯ï¼Œä½†æä¾›äº†æœ‰å…³å‘¨å›´çŽ¯å¢ƒçš„æœ‰é™ä¿¡æ¯ã€‚æ”¹å–„å¯¼èˆªä¿¡å·ï¼Œä¾‹å¦‚éšœç¢ç‰©å’Œå³å°†è½¬å¼¯çš„è­¦æŠ¥ï¼Œéœ€è¦æ›´å¥½åœ°ç†è§£å’Œç»˜åˆ¶ç”¨æˆ·çŽ¯å¢ƒã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æž„å»ºäº†ä¸€ä¸ªå¹³å°ï¼Œå¯ç”¨äºŽæ— éšœç¢ç©ºé—´åŠå…¶ä»–é¢†åŸŸçš„å„ç§ç©ºé—´æ„ŸçŸ¥åº”ç”¨ç¨‹åºã€‚ &lt;/p>; &lt;p>; ä»Šå¤©ï¼Œæˆ‘ä»¬å®£å¸ƒ&lt;a href=&quot;https://github.com/google-research/project-guideline&quot;>;å¼€æºç‰ˆæœ¬çš„é¡¹ç›®æŒ‡å—&lt;/a>;ï¼Œä¾›ä»»ä½•äººä½¿ç”¨ç”¨äºŽæ”¹è¿›å’Œæž„å»ºæ–°çš„æ— éšœç¢ä½“éªŒã€‚è¯¥ç‰ˆæœ¬åŒ…æ‹¬æ ¸å¿ƒå¹³å°çš„&lt;a href=&quot;https://github.com/google-research/project-guideline&quot;>;æºä»£ç &lt;/a>;ï¼Œä»¥åŠ&lt;a href=&quot;https://github.com/ google-research/project-guideline/tree/main/project_guideline/android&quot;>;Android åº”ç”¨&lt;/a>;ï¼Œç»è¿‡é¢„è®­ç»ƒ&lt;a href=&quot;https://github.com/google-research/project-guideline/tree/ main/project_guideline/vision/models&quot;>;ML æ¨¡åž‹&lt;/a>;ï¼Œä»¥åŠ &lt;a href=&quot;https://github.com/google-research/project-guideline/tree/main/project_guideline/unreal&quot;>;3D æ¨¡æ‹Ÿæ¡†æž¶&lt;/a>;ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ç³»ç»Ÿè®¾è®¡&lt;/h2>; &lt;p>; ä¸»è¦ç”¨ä¾‹æ˜¯ Android åº”ç”¨ç¨‹åºï¼Œä½†æ˜¯æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿä»¥å¯é‡çŽ°çš„æ–¹å¼åœ¨å„ç§çŽ¯å¢ƒä¸­è¿è¡Œã€æµ‹è¯•å’Œè°ƒè¯•æ ¸å¿ƒé€»è¾‘ã€‚è¿™ä¿ƒä½¿æˆ‘ä»¬ä½¿ç”¨ C++ è®¾è®¡å’Œæž„å»ºç³»ç»Ÿï¼Œä»¥ä¾¿ä¸Ž &lt;a href=&quot;https://developers.google.com/mediapipe&quot;>;MediaPipe&lt;/a>; å’Œå…¶ä»–æ ¸å¿ƒåº“ç´§å¯†é›†æˆï¼ŒåŒæ—¶ä»ç„¶èƒ½å¤Ÿä¸ŽAndroid ä½¿ç”¨ &lt;a href=&quot;https://developer.android.com/ndk&quot;>;Android NDK&lt;/a>;ã€‚ &lt;/p>; &lt;p>; åœ¨åº•å±‚ï¼ŒProject Guideline ä½¿ç”¨ &lt;a href=&quot;https://developers.google.com/ar&quot;>;ARCore&lt;/a>; æ¥ä¼°è®¡ç”¨æˆ·åœ¨å¯¼èˆªæ—¶çš„ä½ç½®å’Œæ–¹å‘ã€‚è¯¾ç¨‹ã€‚åŸºäºŽ &lt;a href=&quot;https://arxiv.org/abs/1802.02611&quot;>;DeepLabV3+&lt;/a>; æ¡†æž¶æž„å»ºçš„åˆ†å‰²æ¨¡åž‹ï¼Œå¤„ç†æ¯ä¸ªç›¸æœºå¸§ä»¥ç”ŸæˆæŒ‡å—çš„äºŒè¿›åˆ¶æŽ©ç ï¼ˆè¯·å‚é˜…&lt;a href =&quot;https://ai.googleblog.com/2021/05/project-guideline-enabling-those-with.html&quot;>;ä¸Šä¸€ç¯‡åšæ–‡&lt;/a>;äº†è§£æ›´å¤šè¯¦æƒ…ï¼‰ã€‚ç„¶åŽï¼Œä½¿ç”¨ ARCore æä¾›çš„ç›¸æœºä½å§¿å’Œé•œå¤´å‚æ•°ï¼ˆå†…åœ¨å‚æ•°ï¼‰å°†åˆ†æ®µå¼•å¯¼çº¿ä¸Šçš„ç‚¹ä»Žå›¾åƒç©ºé—´åæ ‡æŠ•å½±åˆ°ä¸–ç•Œç©ºé—´åœ°å¹³é¢ä¸Šã€‚ç”±äºŽæ¯ä¸ªå¸§éƒ½æä¾›ä¸åŒçš„çº¿æ¡è§†å›¾ï¼Œå› æ­¤ä¸–ç•Œç©ºé—´ç‚¹ä¼šèšåˆåœ¨å¤šä¸ªå¸§ä¸Šä»¥æž„å»ºçŽ°å®žä¸–ç•ŒæŒ‡å—çš„è™šæ‹Ÿæ˜ å°„ã€‚è¯¥ç³»ç»Ÿå¯¹æŒ‡å¯¼ä¸–ç•Œç©ºé—´åæ ‡è¿›è¡Œåˆ†æ®µæ›²çº¿é€¼è¿‘ï¼Œä»¥æž„å»ºæ—¶ç©ºä¸€è‡´çš„è½¨è¿¹ã€‚å½“ç”¨æˆ·æ²¿ç€è·¯å¾„å‰è¿›æ—¶ï¼Œè¿™å…è®¸ç»†åŒ–ä¼°è®¡çš„çº¿è·¯ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhr5dbXb4Dhjd-HqBRwKYd0YAjHxUr4avoU_rlp6aBR3LJlBtRGD2OjgCibJCIE_WRxwo6SYYKL7oQHOuW39kEvTH7 B2rMnoI5wKosp3L8hliQJivnl4LdWDqZ_cK3BlQxFDedBiFy_JR3HYaAVd53KwRYeOmMVQiL3prW6qYcpjBbvV4-cRXhmYyPyr4nY/s800/image1.gif&quot;æ ·å¼=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;355&quot; data-original-width=&quot;800&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhr5dbXb4Dhjd-HqBRwKYd0YAjHxUr4avoU_rlp6aBR3LJlBtRGD2OjgCibJCIE_WRxwo6SYYKL7oQHOuW39kEvTH7B2rMnoI5wKosp3L8hliQJivnl4Ld WDqZ_cK3BlQxFDedBiFy_JR3HYaAVd53KwRYeOmMVQiL3prW6qYcpjBbvV4-cRXhmYyPyr4nY/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;Project Guideline æž„å»ºæŒ‡å—çš„ 2D åœ°å›¾ï¼Œèšåˆæ¯å¸§ä¸­æ£€æµ‹åˆ°çš„ç‚¹ï¼ˆ&lt;strong>;çº¢è‰²&lt;/strong>;ï¼‰ä»¥æž„å»ºæœ‰çŠ¶æ€çš„è¡¨ç¤ºï¼ˆ&lt;strong>;è“è‰²&lt;/strong>;ï¼‰éšç€è·‘æ­¥è€…æ²¿ç€è·¯å¾„å‰è¿›ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;æŽ§åˆ¶ç³»ç»Ÿæ ¹æ®ç”¨æˆ·å½“å‰çš„ä½ç½®ã€é€Ÿåº¦ã€å’Œæ–¹å‘ã€‚ç„¶åŽå‘ç”¨æˆ·æä¾›éŸ³é¢‘åé¦ˆä¿¡å·ä»¥è°ƒæ•´å…¶èˆªå‘ä»¥ä¸Žå³å°†åˆ°æ¥çš„çº¿æ®µä¸€è‡´ã€‚é€šè¿‡ä½¿ç”¨è·‘æ­¥è€…çš„é€Ÿåº¦çŸ¢é‡è€Œä¸æ˜¯ç›¸æœºæ–¹å‘æ¥è®¡ç®—å¯¼èˆªä¿¡å·ï¼Œæˆ‘ä»¬æ¶ˆé™¤äº†è·‘æ­¥è¿‡ç¨‹ä¸­å¸¸è§çš„ä¸è§„åˆ™ç›¸æœºè¿åŠ¨å¼•èµ·çš„å™ªå£°ã€‚æˆ‘ä»¬ç”šè‡³å¯ä»¥åœ¨ç”¨æˆ·ä¸åœ¨æ‘„åƒæœºè§†é‡ŽèŒƒå›´å†…æ—¶å°†ç”¨æˆ·å¯¼èˆªå›žçº¿è·¯ï¼Œä¾‹å¦‚ï¼Œå¦‚æžœç”¨æˆ·è½¬å¼¯è¿‡å¤´ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸º ARCore ç»§ç»­è·Ÿè¸ªç›¸æœºçš„å§¿åŠ¿ï¼Œå¯ä»¥å°†å…¶ä¸Žä»Žå…ˆå‰ç›¸æœºå›¾åƒæŽ¨æ–­å‡ºçš„çŠ¶æ€çº¿å›¾è¿›è¡Œæ¯”è¾ƒã€‚ &lt;/p>; &lt;p>; é¡¹ç›®æŒ‡å—è¿˜åŒ…æ‹¬éšœç¢ç‰©æ£€æµ‹å’Œå›žé¿åŠŸèƒ½ã€‚ ML æ¨¡åž‹ç”¨äºŽä¼°è®¡å•ä¸ªå›¾åƒçš„æ·±åº¦ã€‚ä¸ºäº†è®­ç»ƒè¿™ä¸ªå•ç›®æ·±åº¦æ¨¡åž‹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† &lt;a href=&quot;https://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html&quot;>;SANPO&lt;/a>;ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§åž‹æˆ·å¤–æ•°æ®é›†æ¥è‡ªå†…éƒ¨ç­–åˆ’çš„åŸŽå¸‚ã€å…¬å›­å’ŒéƒŠåŒºçŽ¯å¢ƒçš„å›¾åƒã€‚è¯¥æ¨¡åž‹èƒ½å¤Ÿæ£€æµ‹å„ç§éšœç¢ç‰©çš„æ·±åº¦ï¼ŒåŒ…æ‹¬äººã€è½¦è¾†ã€æŸ±å­ç­‰ã€‚æ·±åº¦å›¾è¢«è½¬æ¢ä¸º 3D ç‚¹äº‘ï¼Œç±»ä¼¼äºŽçº¿åˆ†å‰²è¿‡ç¨‹ï¼Œç”¨äºŽæ£€æµ‹ç”¨æˆ·è·¯å¾„ä¸Šæ˜¯å¦å­˜åœ¨éšœç¢ç‰©ï¼Œç„¶åŽé€šè¿‡éŸ³é¢‘ä¿¡å·æé†’ç”¨æˆ·ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjpEuQPa-p3TKMgYhMl6BD7e53W7PNZPxJTqaE2gqhEx6b8wHIcVpWv9b3C21z_-c1dsR5Qlb2LqRjmTOsPV 2YH9nflHTaPsjiKoILBpl5sDkWBrmn5PJ7Yeaq0Uismxtbv6CmHBlK_sNqM__4TxHkFZFuuy5fry6Z5EKsevc_2jMfngNp7JBpc78Sb3MCG/s800/image2.gif&quot;æ ·å¼=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;600&quot; data-original-width=&quot;800&quot; height=&quot;480&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjpEuQPa-p3TKMgYhMl6BD7e53W7PNZPxJTqaE2gqhEx6b8wHIcVpWv9b3C21z_-c1dsR5Qlb2LqRjmTOsPV2YH9nflHTaPsjiKoILBpl5sDkW Brmn5PJ7Yeaq0Uismxtbv6CmHBlK_sNqM__4TxHkFZFuuy5fry6Z5EKsevc_2jMfngNp7JBpc78Sb3MCG/w640-h480/image2.gif&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Project Guideline ä½¿ç”¨å•ç›®æ·±åº¦ ML æ¨¡åž‹æž„å»ºçŽ¯å¢ƒçš„ 3D ç‚¹äº‘ï¼Œä»¥æ£€æµ‹å¹¶æé†’ç”¨æˆ·è·¯å¾„æ²¿çº¿çš„æ½œåœ¨éšœç¢ç‰©.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>;åŸºäºŽ&lt;a href=&quot;https://developer.android.com/ndk/guides/audio/ çš„ä½Žå»¶è¿ŸéŸ³é¢‘ç³»ç»Ÿaaudio/aaudio&quot;>;AAudio API&lt;/a>; çš„å®žçŽ°æ˜¯ä¸ºäº†å‘ç”¨æˆ·æä¾›å¯¼èˆªå£°éŸ³å’Œæç¤ºã€‚é¡¹ç›®æŒ‡å—ä¸­æä¾›äº†å¤šä¸ª&lt;em>;å£°éŸ³åŒ…&lt;/em>;ï¼ŒåŒ…æ‹¬ä½¿ç”¨&lt;a href=&quot;https://resonance-audio.github.io/resonance-audio/&quot;>;Resonance Audio API&lt;çš„ç©ºé—´å£°éŸ³å®žçŽ°/a>;.è¿™äº›å£°éŸ³åŒ…æ˜¯ç”± Google çš„å£°éŸ³ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆå›¢é˜Ÿå¼€å‘çš„ï¼Œä»–ä»¬è®¾è®¡å¹¶æµ‹è¯•äº†è®¸å¤šä¸åŒçš„å£°éŸ³æ¨¡åž‹ã€‚è¿™äº›å£°éŸ³ç»“åˆäº†å¹³ç§»ã€éŸ³é«˜å’Œç©ºé—´åŒ–æ¥å¼•å¯¼ç”¨æˆ·æ²¿ç€çº¿èµ°ã€‚ä¾‹å¦‚ï¼Œå‘å³è½¬å‘çš„ç”¨æˆ·å¯èƒ½ä¼šåœ¨å·¦è€³ä¸­å¬åˆ°å˜Ÿå˜Ÿå£°ï¼Œä»¥æŒ‡ç¤ºçº¿è·¯å‘å·¦ï¼Œéšç€é¢‘çŽ‡çš„å¢žåŠ ï¼Œä»¥èŽ·å¾—æ›´å¤§çš„è·¯çº¿ä¿®æ­£ã€‚å¦‚æžœç”¨æˆ·è¿›ä¸€æ­¥è½¬å‘ï¼Œå¯èƒ½ä¼šå¬åˆ°é«˜éŸ³è°ƒçš„è­¦å‘Šå£°ï¼Œè¡¨æ˜Žæ­£åœ¨æŽ¥è¿‘è·¯å¾„è¾¹ç¼˜ã€‚æ­¤å¤–ï¼Œå¦‚æžœç”¨æˆ·åç¦»çº¿è·¯å¤ªè¿œã€æ£€æµ‹åˆ°å¼‚å¸¸æƒ…å†µæˆ–ç³»ç»Ÿæ— æ³•æä¾›å¯¼èˆªä¿¡å·ï¼Œåˆ™å§‹ç»ˆä¼šå‘å‡ºæ¸…æ™°çš„â€œåœæ­¢â€éŸ³é¢‘æç¤ºã€‚ &lt;/p>; &lt;p>; é¡¹ç›®æŒ‡å—ä¸“ä¸ºå…·æœ‰ &lt;a href=&quot;https://store.google.com/intl/en/ideas/articles/google-tensor-pixel-smartphone/ çš„ Google Pixel æ‰‹æœºè€Œæž„å»º&quot;>;Google Tensor&lt;/a>; èŠ¯ç‰‡ã€‚ Google Tensor èŠ¯ç‰‡ä½¿ä¼˜åŒ–çš„æœºå™¨å­¦ä¹ æ¨¡åž‹èƒ½å¤Ÿåœ¨è®¾å¤‡ä¸Šè¿è¡Œï¼Œå¹¶å…·æœ‰æ›´é«˜çš„æ€§èƒ½å’Œæ›´ä½Žçš„åŠŸè€—ã€‚è¿™å¯¹äºŽä»¥æœ€å°çš„å»¶è¿Ÿå‘ç”¨æˆ·æä¾›å®žæ—¶å¯¼èˆªæŒ‡ä»¤è‡³å…³é‡è¦ã€‚åœ¨ Pixel 8 ä¸Šï¼Œåœ¨ &lt;a href=&quot;https://store.google.com/intl/en/ideas/articles/google-tensor-pixel-smartphone/&quot;>; ä¸Šè¿è¡Œæ·±åº¦æ¨¡åž‹æ—¶ï¼Œå»¶è¿Ÿæé«˜äº† 28 å€å¼ é‡å¤„ç†å•å…ƒï¼ˆTPUï¼‰ä»£æ›¿CPUï¼Œä¸ŽGPUç›¸æ¯”æå‡9å€ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEho9fs3Uxbd3L59poeHKbR_sbeCPN8jRjVhwtoXoeKHS8uJuKyAtHdaQQA8ZRHw_J5n-g4g3JN_mWQFt2ze1TKYfg IMyquc5-0oANrRXL2g6wDwDB8qibAQDbRoYZ2wVQjP-j1B9lnjUpHKVMtBu2wc81nGAza65E9VY-8X7JFlkfYh0hQb3UWK4GoCzgvJ/s1124/image3 .jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;748&quot; data-original-width=&quot;1124&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEho9fs3Uxbd3L59poeHKbR_sbeCPN8jRjVhwtoXoeKHS8uJuKyAtHdaQQA8ZRHw_J5n-g4g3JN_mWQFt2ze1TKYfgIMyquc5-0oANrRXL2g6 wDwDB8qibAQDbRoYZ2wVQjP-j1B9lnjUpHKVMtBu2wc81nGAza65E9VY-8X7JFlkfYh0hQb3UWK4GoCzgvJ/s16000/image3.jpg&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt; /tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;æµ‹è¯•å’Œæ¨¡æ‹Ÿ&lt;/h2>; &lt;p>; é¡¹ç›®æŒ‡å—åŒ…æ‹¬æ¨¡æ‹Ÿå™¨ï¼Œå¯ä»¥åœ¨è™šæ‹ŸçŽ¯å¢ƒä¸­å¿«é€Ÿæµ‹è¯•ç³»ç»Ÿå¹¶è¿›è¡ŒåŽŸåž‹è®¾è®¡ã€‚ä»Žæœºå™¨å­¦ä¹ æ¨¡åž‹åˆ°éŸ³é¢‘åé¦ˆç³»ç»Ÿçš„æ‰€æœ‰å†…å®¹éƒ½åœ¨æ¨¡æ‹Ÿå™¨ä¸­æœ¬åœ°è¿è¡Œï¼Œæ— éœ€è®¾ç½®æ‰€æœ‰ç¡¬ä»¶å’Œç‰©ç†çŽ¯å¢ƒå³å¯æä¾›å®Œæ•´çš„é¡¹ç›®æŒ‡å—ä½“éªŒã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhwv0GHi2zGV5Qk3Tsun98oSCf0au8mc4kV4XPkuzp0V_zgxoM5ymQhuRRja93BkwtvdCN9HJPxWmRWTVI1eXPIj9 Jh-9aS57qCz1vIGvm2uylQzT70F53hOQIoHYNTJefwIav_GEz2zK0z2lB1MtD0hnAojnxPXKXGIfV1QO9kksIMaM_d0qoeHMJxsjWc/s1200/image4.jpg&quot;æ ·å¼=&quot;å·¦è¾¹è·ï¼šè‡ªåŠ¨ï¼›å³è¾¹è·ï¼šè‡ªåŠ¨ï¼›&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1200&quot; height=&quot;480&quot; src=&quot;https:// /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhwv0GHi2zGV5Qk3Tsun98oSCf0au8mc4kV4XPkuzp0V_zgxoM5ymQhuRRja93BkwtvdCN9HJPxWmRWTVI1eXPIj9Jh-9aS57qCz1vIGvm2uylQz T70F53hOQIoHYNTJefwIav_GEz2zK0z2lB1MtD0hnAojnxPXKXGIfV1QO9kksIMaM_d0qoeHMJxsjWc/w640-h480/image4.jpg&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td ç±»=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Project Guideline æ¨¡æ‹Ÿå™¨çš„å±å¹•æˆªå›¾ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line- height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;æœªæ¥æ–¹å‘&lt;/h2>; &lt;p>;ä¸ºäº†æŽ¨åŠ¨æŠ€æœ¯å‘å‰å‘å±•ï¼Œ&lt;a href=&quot;https://www.wear.works&quot;>;WearWorks &lt;/a>; å·²æˆä¸ºæ—©æœŸé‡‡ç”¨è€…ï¼Œå¹¶ä¸Ž Project Guideline åˆä½œï¼Œæ•´åˆå…¶èŽ·å¾—ä¸“åˆ©çš„è§¦è§‰å¯¼èˆªä½“éªŒï¼Œé™¤äº†å£°éŸ³ä¹‹å¤–è¿˜åˆ©ç”¨è§¦è§‰åé¦ˆæ¥å¼•å¯¼è·‘æ­¥è€…ã€‚ WearWorks å¼€å‘è§¦è§‰æŠ€æœ¯å·²è¶…è¿‡ 8 å¹´ï¼Œæ­¤å‰æ›¾å¸®åŠ©ç¬¬ä¸€ä½ç›²äººé©¬æ‹‰æ¾è¿åŠ¨å‘˜åœ¨æ²¡æœ‰è§†åŠ›å¸®åŠ©çš„æƒ…å†µä¸‹å®Œæˆçº½çº¦é©¬æ‹‰æ¾æ¯”èµ›ã€‚æˆ‘ä»¬å¸Œæœ›è¿™æ ·çš„æ•´åˆèƒ½å¤Ÿå¸¦æ¥æ–°çš„åˆ›æ–°ï¼Œè®©ä¸–ç•Œå˜å¾—æ›´åŠ æ— éšœç¢ã€‚&lt;br />; &lt;/p>; &lt;p>; é¡¹ç›®æŒ‡å—å›¢é˜Ÿä¹Ÿåœ¨åŠªåŠ›åˆ©ç”¨æœ€æ–°çš„æŠ€æœ¯è¿›æ­¥ï¼Œå½»åº•æ¶ˆé™¤ç”»çº¿ã€‚ç§»åŠ¨æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œä¾‹å¦‚ &lt;a href=&quot;https://developers.google.com/ar/develop/scene-semantics&quot;>;ARCore Scene Semantics API&lt;/a>;ï¼Œå¯ä»¥è¯†åˆ«äººè¡Œé“ã€å»ºç­‘ç‰©å’Œå…¶ä»–ç‰©ä½“åœ¨å®¤å¤–åœºæ™¯ä¸­ã€‚æˆ‘ä»¬é‚€è¯·æ— éšœç¢ç¤¾åŒºåœ¨è¿™é¡¹æŠ€æœ¯çš„åŸºç¡€ä¸Šè¿›è¡Œå¼€å‘å’Œæ”¹è¿›ï¼ŒåŒæ—¶æŽ¢ç´¢å…¶ä»–é¢†åŸŸçš„æ–°ç”¨ä¾‹ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è‡´è°¢&lt;/h2>; &lt;p>; &lt;em>;è®¸å¤šäººå‚ä¸Žäº†é¡¹ç›®æŒ‡å—çš„åˆ¶å®šåŠå…¶èƒŒåŽçš„æŠ€æœ¯ã€‚æˆ‘ä»¬è¦æ„Ÿè°¢é¡¹ç›®æŒ‡å—å›¢é˜Ÿæˆå‘˜ï¼šDror Avalonã€Phil Bayerã€Ryan Burkeã€Lori Dooleyã€Song Chun Fanã€Matt Hallã€AmÃ©lie Jean-aimÃ©eã€Dave Hawkeyã€Amit Pitaruã€Alvin Shiã€Mikhail Sirotenkoã€Sagar Waghmareã€çº¦ç¿°Â·æ²ƒç‰¹é‡‘æ£®ã€é‡‘ä½°åˆ©Â·å¨å°”ä¼¯ã€é©¬ä¿®Â·å¨å°”æ£®ã€æ¨è½©ã€é©¬å…‹Â·æ‰Žé‡Œå¥‡ã€å²è’‚æ–‡Â·å…‹æ‹‰å…‹ã€å‰å§†Â·åº“è¥¿ã€ä¹”ä»€Â·åŸƒåˆ©æ–¯ã€æ±¤å§†Â·éœå…¹ã€è¿ªå…‹Â·é‡Œæ˜‚ã€å…‹é‡Œæ–¯Â·ç±³åˆ‡å°”ã€è’å°¾æ‚Ÿã€éƒ‘æœ‰çã€ä¹”Â·å¼—èŽ±ã€å¤å¸‚å’Œäººã€å°æž—éƒç¾Žã€ä¸¸å±±å‡¯è¥¿ã€Minh Nguyenã€Alto Okamuraã€Yosuke Suzuki å’Œ Bryan Tanakaã€‚æ„Ÿè°¢ ARCore è´¡çŒ®è€…ï¼šRyan DuToitã€Abhishek Kar å’Œ Eric Turnerã€‚æ„Ÿè°¢ Alec Goã€Jing Liã€Liviu Panaitã€Stefano Pellegriniã€Abdullah Rashwanã€Lu Wangã€Qifei Wang å’Œ Fan Yang æä¾› ML å¹³å°æ”¯æŒã€‚æˆ‘ä»¬è¿˜è¦æ„Ÿè°¢ Hartwig Adamã€Tomas Izoã€Rahul Sukthankarã€Blaise Aguera y Arcas å’Œ Huisheng Wang çš„é¢†å¯¼æ”¯æŒã€‚ç‰¹åˆ«æ„Ÿè°¢æˆ‘ä»¬çš„åˆä½œä¼™ä¼´ Guiding Eyes for the Blind å’Œ Achilles Internationalã€‚&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/3970135078050750650/comments/default&quot; rel =&quot;replies&quot; title=&quot;å‘è¡¨è¯„è®º&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/open-commerce-project-guideline.html# comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/3970135078050750650&quot; rel =&quot;ç¼–è¾‘&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/3970135078050750650&quot; rel=&quot;self&quot; type=&quot;application/ atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/open-commerce-project-guideline.html&quot; rel=&quot;alternate&quot; title=&quot;å¼€æºé¡¹ç›®æŒ‡å—ï¼šä¸€ä¸ªå¹³å°è®¡ç®—æœºè§†è§‰è¾…åŠ©æŠ€æœ¯â€ type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>; noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/ img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEgrfdKR8ZnuQ1jMtsIsG9AViwd_vkXhbwavfXUC_RYoIetF8EppGOxlWSp9DNCgzFlUY0Ea4q3deujDXSdXJ_C4lOC89eGfIXz_POk_upHVlx5DdBab8rh0FQuigi3fhluHAOX3 0GhT9LkZnpU5KMmDMp8jWNpjxKDI8nLwYTqAcExYk3tW7klykfOZ-Sm_/s72-c/hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0 &lt;/thrï¼štotal>;&lt;/entry>;&lt;entry>;&lt;id>;æ ‡ç­¾ï¼šblogger.comï¼Œ1999ï¼šblog-8474926331452026626.post-6563276834599281497&lt;/id>;&lt;å‘å¸ƒ>;2023-11-17T11ï¼š36ï¼š00.000-08ï¼š 00&lt;/published>;&lt;updated>;2023-11-17T11:36:32.036-08:00&lt;/updated>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;AI forç¤¾ä¼šå…¬ç›Š&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;ç ”ç©¶å¥–&quot;>;&lt;/category>;&lt;category schema=&quot;http://www. blogger.com/atom/ns#&quot; term=&quot;å¤§å­¦å…³ç³»&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½çš„æ–°å…´å®žè·µ&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class =&quot;byline-author&quot;>;å‘å¸ƒè€…ï¼šAnoop Sinhaï¼ŒæŠ€æœ¯ä¸Žç ”ç©¶æ€»ç›‘åä¼šå’Œ Google ç ”ç©¶éƒ¨å‰¯æ€»è£ Yossi Matias&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghkgEei5l04Gs6hz4cLk9IqdDbXcx-41xZsRsJ-b2WHLDng1eZzJqo9eAwBZjZHc5P2akAKxT6v QLbn0-5nxy_OuPA5QIyWAV9Yy_4iIGch-zM2W-88Y-6e8HxkbG39hemnzheAx5GUvkMspUCaQiqE5RtxYvFKj- bI0pKzOhFVrWmSOgHJisYHBDfGdCl/s1200/lockup_GoogleResearch_FullColor_Hero.jpg&quot; style=&quot;æ˜¾ç¤ºï¼šæ— ï¼›&quot; />; &lt;p>; &lt;a href=&quot;https://ai.google/responsibility/principles/&quot;>;Google äººå·¥æ™ºèƒ½åŽŸåˆ™&lt;/a>;çš„ç¬¬ä¸€æ¡æ˜¯â€œå¯¹ç¤¾ä¼šæœ‰ç›Šâ€ã€‚ä½œä¸ºäººå·¥æ™ºèƒ½ä»Žä¸šè€…ï¼Œæˆ‘ä»¬å—åˆ°äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å˜é©æ½œåŠ›çš„å¯å‘ï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯èƒ½å¤Ÿä»¥å‰æ‰€æœªæœ‰çš„è§„æ¨¡å’Œé€Ÿåº¦é€ ç¦ç¤¾ä¼šå’Œæˆ‘ä»¬çš„å…±äº«çŽ¯å¢ƒã€‚ä»Ž&lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/google-ai-climate-change-solutions/&quot;>;å¸®åŠ©åº”å¯¹æ°”å€™å±æœº&lt;/a>;åˆ°&lt;a href=&quot;https:// /blog.google/technology/health/how-were-using-ai-to-help-transform-healthcare/&quot;>;å¸®åŠ©åŒ»ç–—ä¿å¥è½¬åž‹&lt;/a>;ï¼Œ&lt;a href=&quot;https://blog.google/outreach -initiatives/accessibility/global-accessibility-awareness-day-google-product-update/&quot;>;è®©æ•°å­—ä¸–ç•Œå˜å¾—æ›´åŠ æ— éšœç¢&lt;/a>;ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è´Ÿè´£ä»»åœ°åº”ç”¨äººå·¥æ™ºèƒ½ï¼Œä¸ºå…¨çƒæ›´å¤šçš„äººæä¾›å¸®åŠ©ã€‚å®žçŽ°å…¨çƒè§„æ¨¡éœ€è¦ç ”ç©¶äººå‘˜å’Œç¤¾åŒºåœ¨æ•´ä¸ªäººå·¥æ™ºèƒ½ç”Ÿæ€ç³»ç»Ÿä¸­å…±åŒæ€è€ƒå¹¶é‡‡å–è¡ŒåŠ¨ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; æˆ‘ä»¬å°†è¿™ç§æ–¹æ³•ç§°ä¸ºâ€œä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½â€ã€‚å®ƒæ—¢æ˜¯&lt;a href=&quot;https://hcil.umd.edu/ human-centered-ai/&quot;>;ä»¥äººä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½çš„å»¶ä¼¸å’Œæ‰©å±•ï¼Œ&lt;/a>;å…³æ³¨ç¤¾ä¼šçš„æ€»ä½“éœ€æ±‚ä»ç„¶æ ¹æ®ä¸ªäººç”¨æˆ·çš„éœ€æ±‚æä¾›ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨æ›´å¤§çš„ã€å…±äº«çš„äººç±»ç»éªŒçš„èƒŒæ™¯ä¸‹ã€‚æœ€è¿‘çš„äººå·¥æ™ºèƒ½è¿›æ­¥æä¾›äº†å‰æ‰€æœªæœ‰çš„ç¤¾ä¼šå±‚é¢çš„èƒ½åŠ›ï¼Œå¦‚æžœæˆ‘ä»¬å°†é›†ä½“çš„ã€å¤šå­¦ç§‘çš„äººå·¥æ™ºèƒ½ç ”ç©¶åº”ç”¨äºŽç¤¾ä¼šå±‚é¢çš„å…±åŒæŒ‘æˆ˜ï¼Œä»Žé¢„æµ‹é¥¥é¥¿åˆ°é¢„æµ‹ç–¾ç—…ï¼Œå†åˆ°æé«˜ç”Ÿäº§åŠ›ï¼Œæˆ‘ä»¬çŽ°åœ¨å¯ä»¥æœ‰æ¡ä¸ç´Šåœ°æ»¡è¶³è¿™äº›éœ€æ±‚ã€‚ &lt;/p>; &lt;p>; &lt;a href=&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/AI_Opportunity_Agenda.pdf&quot;>;äººå·¥æ™ºèƒ½é€ ç¦ç¤¾ä¼šçš„æœºä¼š&lt;/a>;æ¯å¢žåŠ ä¸€æ¬¡å¤©ã€‚æˆ‘ä»¬å®¡è§†äº†æˆ‘ä»¬åœ¨è¿™äº›é¢†åŸŸçš„å·¥ä½œä»¥åŠæˆ‘ä»¬æ”¯æŒçš„ç ”ç©¶é¡¹ç›®ã€‚æœ€è¿‘ï¼ŒGoogle &lt;a href=&quot;https://research.google/outreach/air-program/recipients/&quot;>;å®£å¸ƒé€‰å‡º 70 åæ•™æŽˆ&lt;/a>;å‚åŠ &lt;a href=&quot;https://research.google /outreach/air-program/&quot;>;2023 å¹´åŒ…å®¹æ€§ç ”ç©¶è®¡åˆ’å¥–&lt;/a>;ï¼Œè¯¥è®¡åˆ’æ”¯æŒæ»¡è¶³å…¨çƒåŽ†å²ä¸Šè¾¹ç¼˜åŒ–ç¾¤ä½“éœ€æ±‚çš„å­¦æœ¯ç ”ç©¶ã€‚é€šè¿‡å¯¹è¿™é¡¹å·¥ä½œçš„è¯„ä¼°ï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸€äº›ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½çš„æ–°å…´å®žè·µï¼š&lt;/p>; &lt;ul>; &lt;li>;&lt;strong>;äº†è§£ç¤¾ä¼šçš„éœ€æ±‚&lt;/strong>; &lt;br />;å€¾å¬ç¤¾åŒºå’Œåˆä½œä¼™ä¼´çš„æ„è§å¯¹äºŽæ·±å…¥ç†è§£é‡å¤§é—®é¢˜å¹¶ç¡®å®šéœ€è¦è§£å†³çš„ä¼˜å…ˆæŒ‘æˆ˜ã€‚ä½œä¸ºä¸€ç§æ–°å…´çš„é€šç”¨æŠ€æœ¯ï¼Œäººå·¥æ™ºèƒ½æœ‰æ½œåŠ›è§£å†³å¯¹äººä»¬ç”Ÿæ´»äº§ç”Ÿé‡å¤§å½±å“çš„å…¨çƒé‡å¤§ç¤¾ä¼šé—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œæ•™è‚²å·¥äººã€æ”¹å–„åŒ»ç–—ä¿å¥å’Œæé«˜ç”Ÿäº§åŠ›ï¼‰ã€‚æˆ‘ä»¬å‘çŽ°å½±å“åŠ›çš„å…³é”®æ˜¯ä»¥ç¤¾ä¼šéœ€æ±‚ä¸ºä¸­å¿ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨ç¤¾ä¼šä¸€è‡´åŒæ„åº”ä¼˜å…ˆè€ƒè™‘çš„ç›®æ ‡ä¸Šï¼Œä¾‹å¦‚è”åˆå›½çš„&lt;a href=&quot;https://globalgoals.withgoogle.com/globalgoals/globalgoals&quot;>;17 é¡¹å¯æŒç»­å‘å±•ç›®æ ‡&lt;/a>;æ˜¯ç”± 190 å¤šä¸ªå›½å®¶å…±åŒåˆ¶å®šçš„ä¸€ç³»åˆ—ç›¸äº’å…³è”çš„ç›®æ ‡ï¼Œæ—¨åœ¨åº”å¯¹å…¨çƒæŒ‘æˆ˜ã€‚ &lt;/li>;&lt;li>;&lt;strong>;é›†ä½“åŠªåŠ›æ»¡è¶³è¿™äº›éœ€æ±‚&lt;br />;&lt;/strong>;é›†ä½“åŠªåŠ›å°†åˆ©ç›Šç›¸å…³è€…ï¼ˆä¾‹å¦‚ï¼Œå½“åœ°å’Œå­¦æœ¯ç•Œã€éžæ”¿åºœç»„ç»‡ã€å…¬ç§åˆä½œï¼‰çº³å…¥è®¾è®¡çš„è”åˆè¿‡ç¨‹ï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¼€å‘ã€å®žæ–½å’Œè¯„ä¼°ï¼Œå› ä¸ºå®ƒä»¬æ­£åœ¨å¼€å‘å’Œéƒ¨ç½²ä»¥æ»¡è¶³ç¤¾ä¼šéœ€æ±‚ã€‚ &lt;/li>;&lt;li>;&lt;strong>;é€šè¿‡åŠªåŠ›æ»¡è¶³ç¤¾ä¼šéœ€æ±‚çš„ç¨‹åº¦æ¥è¡¡é‡æˆåŠŸ&lt;br />;&lt;/strong>;è¡¡é‡äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆæ»¡è¶³ç¤¾ä¼šéœ€æ±‚çš„ç¨‹åº¦éžå¸¸é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æˆ‘ä»¬çš„æ¯ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬éƒ½ç¡®å®šäº†é€šè¿‡ä¸Žåˆ©ç›Šç›¸å…³è€…åˆä½œä¼˜åŒ–çš„ä¸»è¦å’Œæ¬¡è¦å½±å“æŒ‡æ ‡ã€‚ &lt;/li>; &lt;/ul>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ä¸ºä»€ä¹ˆä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½å¾ˆé‡è¦ï¼Ÿ&lt;/h2>; &lt;p>; æ¡ˆä¾‹ä¸‹é¢æè¿°çš„ç¤ºä¾‹å±•ç¤ºäº†ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½æ–¹æ³•å¦‚ä½•å¯¹æ— éšœç¢ã€å¥åº·å’Œæ°”å€™ç­‰ä¸»é¢˜äº§ç”Ÿå½±å“ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;äº†è§£è¨€è¯­ä¸æ ‡å‡†çš„ä¸ªäººçš„éœ€æ±‚&lt;/h3>; &lt;p>;æœ‰&lt;a href=&quot;https://www.nidcd.nih.gov/health/statistics/quick-statistics-voice-speech-language&quot;>;æ•°ä»¥ç™¾ä¸‡è®¡çš„äºº&lt;/a>;æœ‰ä¸æ ‡å‡†çš„è¨€è¯­ï¼ˆä¾‹å¦‚ï¼Œå‘éŸ³éšœç¢ï¼Œ&lt;a href=&quot;https://en.wikipedia.org/wiki/Dysarthria&quot;>;æž„éŸ³éšœç¢&lt;/a>;ã€&lt;a href=&quot;https://en.wikipedia.org/wiki/Spasmodic_dysphonia&quot;>;å‘å£°å›°éš¾&lt;/a>;ï¼‰ä»…åœ¨ç¾Žå›½ã€‚ &lt;a href=&quot;https://blog.google/outreach-initiatives/accessibility/impaired-speech-recognition/&quot;>;2019 å¹´&lt;/a>;ï¼ŒGoogle Research æŽ¨å‡ºäº†&lt;a href=&quot;https://blog.research. google/2019/08/project-euphonias-personalized-speech.html&quot;>;Project Euphonia&lt;/a>;ï¼Œä¸€ç§å…è®¸ä½¿ç”¨éžæ ‡å‡†è¯­éŸ³çš„ä¸ªäººç”¨æˆ·è®­ç»ƒä¸ªæ€§åŒ–è¯­éŸ³è¯†åˆ«æ¨¡åž‹çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æˆåŠŸå§‹äºŽæˆ‘ä»¬å¯¹çŽ°åœ¨èƒ½å¤Ÿåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šä½¿ç”¨è¯­éŸ³å¬å†™çš„æ¯ä¸ªäººçš„å½±å“ã€‚ &lt;/p>; &lt;p>; Euphonia ä»Žä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½æ–¹æ³•å¼€å§‹ï¼ŒåŒ…æ‹¬ä¸Žéžè¥åˆ©ç»„ç»‡ &lt;a href=&quot;http://als.net/&quot;>;ALS æ²»ç–—å‘å±•ç ”ç©¶æ‰€&lt;/a>; å’Œ&lt;a href=&quot;http://www.alsri.org/&quot;>;ALS å±…ä½è®¡åˆ’&lt;/a>;ï¼Œäº†è§£&lt;a href=&quot;https://en.wikipedia.org/wiki/ALS&quot; æ‚£è€…çš„éœ€æ±‚>;è‚ŒèŽç¼©ä¾§ç´¢ç¡¬åŒ–ç—‡&lt;/a>;ï¼ˆALSï¼‰åŠå…¶ä½¿ç”¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„èƒ½åŠ›ã€‚åŽæ¥ï¼Œæˆ‘ä»¬å¼€å‘äº†&lt;a href=&quot;https://blog.research.google/2021/09/personalized-asr-models-from-large-and.html&quot;>;ä¸–ç•Œä¸Šæœ€å¤§çš„éžæ ‡å‡†è¯­æ–™åº“&lt;/a>;è¯­éŸ³å½•éŸ³ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒ&lt;a href=&quot;https://blog.research.google/2023/03/universal-speech-model-usm-state-of-art.html&quot;>;é€šç”¨è¯­éŸ³æ¨¡åž‹&lt;/ a>;&lt;a href=&quot;https://blog.research.google/2023/06/responsible-ai-at-google-research-ai.html&quot;>;çœŸå®žè¯†åˆ«æ··ä¹±è¯­éŸ³çš„èƒ½åŠ›æé«˜ 37%&lt;/a>;å¯¹è¯&lt;a href=&quot;https://en.wikipedia.org/wiki/Word_error_rate&quot;>;å•è¯é”™è¯¯çŽ‡&lt;/a>; (WER) æµ‹é‡ã€‚è¿™ä¹Ÿä¿ƒæˆäº†ä¼Šåˆ©è¯ºä¼Šå¤§å­¦é¦™æ§Ÿåˆ†æ ¡ã€Alphabet å’Œ Apple ä¹‹é—´çš„ &lt;a href=&quot;https://blog.google/outreach-initiatives/accessibility/speech-accessibility-project/&quot;>;2022&lt;/a>; åˆä½œã€Metaã€å¾®è½¯å’Œäºšé©¬é€Šå¯åŠ¨&lt;a href=&quot;https://speechaccessibilityproject.beckman.illinois.edu/&quot;>;è¯­éŸ³æ— éšœç¢é¡¹ç›®&lt;/a>;ï¼Œè¿™æ˜¯ä¸€é¡¹æŒç»­çš„è®¡åˆ’ï¼Œæ—¨åœ¨åˆ›å»ºä¸€ä¸ªå…¬å¼€çš„æ— åºè¯­éŸ³æ ·æœ¬æ•°æ®é›†æ”¹è¿›äº§å“å¹¶ä½¿è¯­éŸ³è¯†åˆ«æ›´åŠ åŒ…å®¹ä¸åŒçš„è¯­éŸ³æ¨¡å¼ã€‚å…¶ä»–ä½¿ç”¨äººå·¥æ™ºèƒ½å¸®åŠ©æ¶ˆé™¤æ¨¡å¼å’Œè¯­è¨€éšœç¢çš„æŠ€æœ¯åŒ…æ‹¬&lt;a href=&quot;https://about.google/stories/making-conversation-more-accessible-with-live-transcribe/&quot;>;å®žæ—¶è½¬å½•&lt;/ a>;ã€&lt;a href=&quot;https://blog.google/outreach-initiatives/accessibility/first-time-i-was-able-call-my-23-year-old-son/&quot;>;å®žæ—¶å­—å¹•&lt;/ a>; å’Œ&lt;a href=&quot;https://blog.google/intl/en-in/products/explore-communicate/easier-access-to-web-pages-let/&quot;>;å¤§å£°æœ—è¯»&lt;/a>;ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;å…³æ³¨ç¤¾ä¼šå¥åº·éœ€æ±‚&lt;/h3>; &lt;p>;åŠæ—¶èŽ·å–å­•äº§å¦‡å¥åº·ä¿¡æ¯å¯æŒ½æ•‘ç”Ÿå‘½å…¨çƒï¼š&lt;a href=&quot;https://www.who.int/news/item/23-02-2023-a-woman-dies-every-two-mins- due-to-pregnancy-or-childbirth--è”åˆå›½æœºæž„&quot;>;æ¯ä¸¤åˆ†é’Ÿå°±æœ‰ä¸€åå¦‡å¥³åœ¨æ€€å­•æˆ–åˆ†å¨©æœŸé—´æ­»äº¡&lt;/a>;å’Œ&lt;a href=&quot;https://data.unicef.org/topic/child-survival/under- Five-mortality/&quot;>;1 26 åå„¿ç«¥åœ¨äº”å²ä¹‹å‰æ­»äº¡&lt;/a>;ã€‚åœ¨å°åº¦å†œæ‘åœ°åŒºï¼Œé’ˆå¯¹ä¸Žæ€€å­•å’Œå©´å„¿ç›¸å…³çš„å…³é”®å¥åº·é—®é¢˜å¯¹å­•å¦‡å’Œæ–°å¦ˆå¦ˆè¿›è¡Œæ•™è‚²éœ€è¦å¯æ‰©å±•ã€ä½Žæˆæœ¬çš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚ Google Research ä¸Ž &lt;a href=&quot;https://armman.org/&quot;>;ARMMAN&lt;/a>; ä¸€èµ·æ”¯æŒ&lt;a href=&quot;https://blog.research.google/2022/08/using-ml-to -boost-engagement-with.html&quot;>;è¯¥è®¡åˆ’&lt;/a>;ä½¿ç”¨ç§»åŠ¨æ¶ˆæ¯ä¼ é€’å’Œæœºå™¨å­¦ä¹  (ML) ç®—æ³•æ¥é¢„æµ‹å¥³æ€§ä½•æ—¶å¯ä»¥ä»ŽæŽ¥å—å¹²é¢„æŽªæ–½ï¼ˆå³æœ‰é’ˆå¯¹æ€§çš„é¢„é˜²æ€§æŠ¤ç†ä¿¡æ¯ï¼‰ä¸­å—ç›Šï¼Œå¹¶é¼“åŠ±å¥¹ä»¬å‚ä¸Ž&lt;a href=&quot;https://armman.org/mmitra/&quot;>;mMitra&lt;/a>; å…è´¹è¯­éŸ³é€šè¯ç¨‹åºã€‚ä¸€å¹´ä¹‹å†…ï¼ŒmMitra è®¡åˆ’æ˜¾ç¤ºå‡ºç”Ÿä½“é‡å¢žåŠ ä¸‰å€çš„å©´å„¿æ•°é‡å¢žåŠ äº† 17%ï¼Œäº†è§£æ€€å­•æœŸé—´æœç”¨é“ç‰‡é‡è¦æ€§çš„å¥³æ€§æ•°é‡å¢žåŠ äº† 36%ã€‚è¿™ä¸€è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆå·²æƒ åŠè¶…è¿‡ 175,000 åæ¯äº²å’Œæˆé•¿ä¸­çš„æ¯äº²ï¼Œå…¬å…±å«ç”Ÿå·¥ä½œè€…åˆ©ç”¨è¯¥è§£å†³æ–¹æ¡ˆæ¥æé«˜ä¿¡æ¯ä¼ é€’çš„è´¨é‡ã€‚ &lt;/p>; &lt;p>; ç”±äºŽç¤¾åŒºå’Œäººå·¥æ™ºèƒ½æŠ€æœ¯å¼€å‘äººå‘˜ä¹‹é—´å¯†åˆ‡çš„é›†ä½“åˆä½œä¼™ä¼´å…³ç³»ï¼Œè¿™äº›åŠªåŠ›åœ¨æ”¹å–„å¥åº·æ–¹é¢å–å¾—äº†æˆåŠŸã€‚æˆ‘ä»¬é€šè¿‡ä¸ŽæŠ¤ç†äººå‘˜åˆä½œï¼Œé‡‡ç”¨äº†åŒæ ·çš„æ–¹æ³•æ¥æ»¡è¶³å„ç§åŒ»ç–—éœ€æ±‚ã€‚ä¸€äº›ç¤ºä¾‹åŒ…æ‹¬ï¼šä½¿ç”¨&lt;a href=&quot;https://health.google/caregivers/arda/&quot;>;è‡ªåŠ¨è§†ç½‘è†œç–¾ç—…è¯„ä¼°&lt;/a>; (ARDA) æ¥&lt;a href=&quot;https://blog. google/technology/health/5-myths-about-medical-ai-debunked/&quot;>;å¸®åŠ©å…¨ä¸–ç•Œè¯Šæ‰€çš„ 250,000 åæ‚£è€…ç­›æŸ¥ç³–å°¿ç—…è§†ç½‘è†œç—…å˜&lt;/a>;ï¼›æˆ‘ä»¬ä¸Ž &lt;a href=&quot;https://www.icadmed.com/&quot;>;iCAD&lt;/a>; åˆä½œï¼Œå°†æˆ‘ä»¬çš„&lt;a href=&quot;https://blog.google/technology/ai/icad-partnership-breast -ç™Œç—‡ç­›æŸ¥/&quot;>;ä¹³æˆ¿Xçº¿ç…§ç›¸æœ¯&lt;/a>;äººå·¥æ™ºèƒ½æ¨¡åž‹åº”ç”¨äºŽä¸´åºŠçŽ¯å¢ƒï¼Œä»¥å¸®åŠ©ä¹³è…ºç™Œæ£€æµ‹ï¼›ä»¥åŠ &lt;a href=&quot;https://sites.research.google/med-palm/&quot;>;Med-PaLM 2&lt;/a>; çš„å¼€å‘ï¼Œè¿™æ˜¯ä¸€ç§åŒ»å­¦å¤§è¯­è¨€æ¨¡åž‹ï¼Œç›®å‰æ­£åœ¨&lt;a href=&quot;https: //cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model&quot;>;ç»è¿‡äº‘åˆä½œä¼™ä¼´æµ‹è¯•&lt;/a>;ï¼Œå¸®åŠ©åŒ»ç”Ÿæä¾›æ›´å¥½çš„æœåŠ¡ç—…äººæŠ¤ç†ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;æŒç»­åŠªåŠ›åº”å¯¹å±æœºæ‰€äº§ç”Ÿçš„å¤åˆå½±å“&lt;/h3>; &lt;p>; Google ç ”ç©¶å¼€å§‹å¼€å±•æ´ªæ°´é¢„æµ‹å·¥ä½œ2018 å¹´å°åº¦çš„&lt;a href=&quot;https://www.blog.google/products/search/helping-keep-people-safe-ai-enabled-flood-forecasting/&quot;>;æ´ªæ°´é¢„æŠ¥&lt;/a>;ä»¥åŠ&lt; a href=&quot;https://www.undp.org/bangladesh/blog/climate-change-google-and-bangladesh-floods&quot;>;æ‰©å±•åˆ°å­ŸåŠ æ‹‰å›½&lt;/a>;ï¼Œä»¥å¸®åŠ©åº”å¯¹æ¯å¹´æ´ªæ°´é€ æˆçš„ç¾éš¾æ€§ç ´åã€‚æœ€åˆçš„åŠªåŠ›å§‹äºŽä¸Ž&lt;a href=&quot;https://cwc.gov.in/&quot;>;å°åº¦ä¸­å¤®æ°´åŠ¡å§”å‘˜ä¼š&lt;/a>;ã€åœ°æ–¹æ”¿åºœå’Œç¤¾åŒºçš„åˆä½œã€‚è¿™äº›å·¥ä½œçš„å®žæ–½ä½¿ç”¨äº†æœç´¢å’Œåœ°å›¾ä¸Šçš„ &lt;a href=&quot;https://www.blog.google/products/search/helping-people-crisis/&quot;>;SOS è­¦æŠ¥&lt;/a>;ï¼Œå¹¶ä¸”æœ€è¿‘æ›´å¹¿æ³›åœ°ä½¿ç”¨äº†é€šè¿‡&lt;a href=&quot;https://sites.research.google/floods/l/0/0/3&quot;>;Flood Hub&lt;/a>;æ‰©å¤§è®¿é—®èŒƒå›´ã€‚æŒç»­&lt;a href=&quot;https://blog.research.google/2023/04/directing-ml-toward-natural-hazard.html&quot;>;åˆä½œ&lt;/a>;å¹¶æŽ¨è¿›åŸºäºŽäººå·¥æ™ºèƒ½çš„å…¨çƒæ´ªæ°´é¢„æŠ¥æ¨¡åž‹ä½¿æˆ‘ä»¬èƒ½å¤Ÿ&lt;a href=&quot;https://blog.google/technology/ai/expanding-our-ml-based-flood-forecasting/&quot;>;å°†æ­¤åŠŸèƒ½æ‰©å±•&lt;/a>;è‡³&lt;a href=&quot;https://blog .google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/&quot;>;éžæ´²ã€äºšå¤ªåœ°åŒºã€æ¬§æ´²ä»¥åŠå—éƒ¨ã€ä¸­éƒ¨å’ŒåŒ—éƒ¨çš„ 80 å¤šä¸ªå›½å®¶&lt;/a>;ç¾Žå›½ã€‚æˆ‘ä»¬è¿˜ä¸Žç¤¾åŒºå¿—æ„¿è€…ç½‘ç»œåˆä½œï¼Œè¿›ä¸€æ­¥åŠ å¼ºæ´ªæ°´è­¦æŠ¥ã€‚é€šè¿‡ä¸Žæ”¿åºœå’Œç¤¾åŒºåˆä½œè¡¡é‡è¿™äº›åŠªåŠ›å¯¹ç¤¾ä¼šçš„å½±å“ï¼Œæˆ‘ä»¬æ¯å¹´éƒ½ä¼šæ”¹è¿›æˆ‘ä»¬çš„æ–¹æ³•å’Œç®—æ³•ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨è¿™äº›æ–¹æ³•å’Œä¸€äº›åº•å±‚æŠ€æœ¯ï¼Œä¾‹å¦‚&lt;a href=&quot;https://www.blog.google/products/search/helping-people-crisis/&quot;>; SOS è­¦æŠ¥&lt;/a>;ï¼Œä»Ž&lt;a href=&quot;https://sites.research.google/floodforecasting/&quot;>;æ´ªæ°´é¢„æŠ¥&lt;/a>;åˆ°ç±»ä¼¼çš„ç¤¾ä¼šéœ€æ±‚ï¼Œä¾‹å¦‚&lt;a href=&quot;https://blog .google/products/search/mapping-wildfires-with-satellite-data/&quot;>;é‡Žç«é¢„æŠ¥&lt;/a>;å’Œ&lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/extreme-heat-support /&quot;>;é«˜æ¸©è­¦æŠ¥&lt;/a>;ã€‚æˆ‘ä»¬ä¸Žå„ç»„ç»‡çš„æŒç»­åˆä½œä¿ƒæˆäº†&lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/early-warning-system-wmo-google/&quot;>;å¯¹å…¶ä»–å·¥ä½œçš„æ”¯æŒ&lt;/a>;ï¼Œä¾‹å¦‚ä¸–ç•Œæ°”è±¡ç»„ç»‡ (WMO) çš„&lt;a href=&quot;https://public.wmo.int/en/earlywarningsforall&quot;>;å…¨æ°‘é¢„è­¦å€¡è®®&lt;/a>;ã€‚ä¸Žç¤¾åŒºçš„æŒç»­æŽ¥è§¦ä½¿æˆ‘ä»¬èƒ½å¤Ÿéšç€æ—¶é—´çš„æŽ¨ç§»äº†è§£ç”¨æˆ·åœ¨ç¤¾ä¼šå±‚é¢çš„éœ€æ±‚ï¼Œæ‰©å¤§æˆ‘ä»¬çš„åŠªåŠ›ï¼Œå¹¶æ‰©å¤§æˆ‘ä»¬åŠªåŠ›çš„ç¤¾ä¼šå½±å“åŠ›ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è¿›ä¸€æ­¥æ”¯æŒä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½ç ”ç©¶&lt;/h2>; &lt;p>; &lt;a href=&quot;https: //research.google/outreach/air-program/recipients/&quot;>;æˆ‘ä»¬æœ€è¿‘èµ„åŠ©äº†&lt;/a>; 18 é¡¹å¤§å­¦ç ”ç©¶ææ¡ˆï¼Œè¿™äº›ææ¡ˆä½“çŽ°äº†ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½æ–¹æ³•ï¼Œè¿™æ˜¯&lt;a href=&quot;https://research ä¸­çš„ä¸€ä¸ªæ–°æ–¹å‘.google/outreach/air-program/&quot;>;Google åŒ…å®¹æ€§ç ”ç©¶è®¡åˆ’å¥–&lt;/a>;ã€‚è¿™äº›ç ”ç©¶äººå‘˜æ­£åœ¨é‡‡ç”¨ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½æ–¹æ³•ï¼Œå¹¶å¸®åŠ©åœ¨ä¸–ç•Œå„åœ°åˆ›å»ºæœ‰ç›Šçš„åº”ç”¨ç¨‹åºã€‚ä¸€äº›èµ„åŠ©é¡¹ç›®çš„ä¾‹å­åŒ…æ‹¬ï¼š&lt;/p>; &lt;ul>; &lt;li>;&lt;strong>;äººå·¥æ™ºèƒ½é©±åŠ¨çš„å—å†²çªå½±å“å›½å®¶æ€åº¦æžåŒ–ç›‘æµ‹ï¼Œä»¥ä¿ƒè¿›åŒ…å®¹æ€§å’Œå¹³è¿›ç¨‹å’Œå¦‡å¥³èµ‹æƒï¼š&lt;/strong>;è¯¥é¡¹ç›®çš„ç›®æ ‡æ˜¯åˆ›å»ºç”±æ³•å­¦ç¡•å£«æ”¯æŒçš„å·¥å…·ï¼Œå¯ç”¨äºŽç›‘æŽ§å‘å±•ä¸­å›½å®¶åœ¨çº¿å¯¹è¯çš„å’Œå¹³ã€‚æœ€åˆçš„ç›®æ ‡ç¤¾åŒºæ˜¯å’Œå¹³ä¸æ–­å˜åŒ–çš„ç¤¾åŒºï¼Œè¿™é¡¹å·¥ä½œå°†ç‰¹åˆ«å¼ºè°ƒå‡è½»å½±å“å¦‡å¥³çš„ä¸¤æžåˆ†åŒ–å’Œä¿ƒè¿›å’Œè°ã€‚&lt;/li>; &lt;li>;&lt;strong>;äººå·¥æ™ºèƒ½è¾…åŠ©åˆ†å¸ƒå¼åä½œå®¤å†…æ±¡æŸ“è®¡ï¼šæ¡ˆä¾‹ç ”ç©¶å°åº¦ç¤¾åŒºçš„éœ€æ±‚åˆ†æžå’Œä½Žæˆæœ¬å¥åº·å®¶å±…è§£å†³æ–¹æ¡ˆï¼š&lt;/strong>;è¯¥é¡¹ç›®æ­£åœ¨ç ”ç©¶å¦‚ä½•ä½¿ç”¨ä½Žæˆæœ¬æ±¡æŸ“ç›‘æµ‹ä»ªä¸Žäººå·¥æ™ºèƒ½è¾…åŠ©æ–¹æ³•ç›¸ç»“åˆï¼Œä¸ºç¤¾åŒºå’Œå®¶åº­æä¾›æ”¹å–„ç©ºæ°”è´¨é‡çš„å»ºè®®å¥åº·ã€‚æœ€åˆçš„ç›®æ ‡ç¤¾åŒºå—åˆ°æ±¡æŸ“çš„ä¸¥é‡å½±å“ï¼Œä¸Žä»–ä»¬çš„è”åˆå·¥ä½œåŒ…æ‹¬åˆ¶å®šå¦‚ä½•è¡¡é‡å½“åœ°ç¤¾åŒºæˆæžœæ”¹å–„çš„ç›®æ ‡ã€‚ &lt;/li>; &lt;li>;&lt;strong>;åä½œå¼€å‘äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆï¼Œä»¥æ‰©å¤§ä¹Œå¹²è¾¾é’å°‘å¹´èŽ·å¾—æ€§å¥åº·å’Œç”Ÿæ®–å¥åº·æ•™è‚²å’ŒæœåŠ¡çš„æœºä¼šï¼š&lt;/strong>;è¯¥é¡¹ç›®çš„ç›®æ ‡æ˜¯åˆ›å»ºæ³•å­¦ç¡•å£«æ”¯æŒçš„å·¥å…·ï¼Œä»¥æä¾›ä¸ªæ€§åŒ–çš„æŒ‡å¯¼å’ŒæœåŠ¡ã€‚æ»¡è¶³ç”¨æˆ·å¯¹æ’’å“ˆæ‹‰ä»¥å—éžæ´²ä½Žæ”¶å…¥åœ°åŒºæ€§å¥åº·å’Œç”Ÿæ®–å¥åº·æ•™è‚²ä¸»é¢˜çš„éœ€æ±‚ã€‚å½“åœ°ç¤¾ä¼šéœ€æ±‚å·¨å¤§ï¼Œä¼°è®¡&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9652643/&quot;>;å°‘å¥³æ€€å­•çŽ‡è¾¾åˆ° 25%&lt;/a>;ï¼Œå¹¶ä¸”é¡¹ç›®æ—¨åœ¨é€šè¿‡äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆçš„é›†ä½“å¼€å‘æµç¨‹æ¥æ»¡è¶³éœ€æ±‚ã€‚&lt;strong>; &lt;/strong>; &lt;/li>; &lt;/ul>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt; /div>; &lt;h2>;æœªæ¥æ–¹å‘&lt;/h2>; &lt;p>; å…³æ³¨ç¤¾ä¼šéœ€æ±‚ï¼Œé€šè¿‡å¤šå­¦ç§‘é›†ä½“ç ”ç©¶å¼€å±•å·¥ä½œï¼Œå¹¶è¡¡é‡å¯¹ç¤¾ä¼šçš„å½±å“ï¼Œæœ‰åŠ©äºŽäº§ç”Ÿç›¸å…³ã€æŒä¹…ã€èµ‹æƒå’Œæœ‰ç›Šçš„äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆã€‚è¯·å‚é˜…&lt;a href=&quot;https://globalgoals.withgoogle.com/globalgoals/&quot;>;äººå·¥æ™ºèƒ½å®žçŽ°å…¨çƒç›®æ ‡&lt;/a>;ï¼Œè¯¦ç»†äº†è§£æ½œåœ¨çš„ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½ç ”ç©¶é—®é¢˜ã€‚ &lt;a href=&quot;https://blog.google/outreach-initiatives/google-org/httpsbloggoogleoutreach-initiativesgoogle-orgunited-nations-global-goals-google-ai-/&quot;>;æˆ‘ä»¬ä¸Žéžè¥åˆ©ç»„ç»‡çš„åˆä½œ&lt;/a>;è¿™äº›é¢†åŸŸä¸Žæˆ‘ä»¬æ­£åœ¨å¼€å±•å’Œé¼“åŠ±çš„ç ”ç©¶ç›¸è¾…ç›¸æˆã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œä½¿ç”¨ä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½çš„è¿›ä¸€æ­¥ä¸¾æŽªå°†å¸®åŠ©é›†ä½“ç ”ç©¶ç¤¾åŒºè§£å†³é—®é¢˜å¹¶å¯¹æ•´ä¸ªç¤¾ä¼šäº§ç”Ÿç§¯æžå½±å“ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è‡´è°¢&lt;/h2>; &lt;p>; &lt;em>;éžå¸¸æ„Ÿè°¢è®¸å¤šå‚ä¸Žæ­¤é¡¹ç›®çš„äººå‘˜è¿™äº› Google é¡¹ç›®åŒ…æ‹¬ Shruti Shethã€Reena Janaã€Amy Chung-Yu Chouã€Elizabeth Adkisonã€Sophie Allweisã€Dan Altmanã€Eve Anderssonã€Ayelet Benjamini&lt;/em>;ã€&lt;em>;Julie Cattiauã€Yuval Carnyã€Richard Caveã€Katherine Chou , Greg Corrado, Carlos De Segovia, Remi Denton, Dotan Emanuel, Ashley Gardner, Oren Gilon, Taylor Goddu, Brigitte Hoyer Gosselink, Jordan Green, Alon Harris&lt;/em>;, &lt;em>;Avinatan Hassidim, Rus Heywood, Sunny Jansen, Pan -æ½˜æ±Ÿã€å®‰ä¸œÂ·å¡æ–¯ç‰¹ã€çŽ›ä¸½èŽ²Â·æ‹‰å¾·ç»´æ ¼ã€ç½—å°¼ç‰¹Â·èŽ±ç»´Â·èŽ«æ‹‰å¾·ã€é²å‹ƒÂ·éº¦å…‹å”çº³ã€è‰¾ä¸½è¥¿äºšÂ·é©¬ä¸ã€æ²™åŸºå°”Â·ç©†ç½•é»˜å¾·ã€è²åˆ©æ™®Â·å°¼å°”æ£®ã€èŽ«é‡ŒäºšÂ·ç½—ä¼Šå…¹ã€å‡¯è’‚Â·è¥¿å¼—ã€ä¹”å°”Â·è‚–å°”ã€ç±³æž—å¾·Â·å¦è´ã€é˜¿å¸•å¨œÂ·å¡”å†…è´¾ã€è¿ªç»´Â·å¡”å¡ã€å‰ç±³Â·æ‰˜å®¾ã€å¡ç‰¹ç³Â·æ‰˜é©¬å†…å…‹ã€ Blake Walshã€Gal Weissã€Kasumi Widnerã€Lihong Xi å’Œå›¢é˜Ÿã€‚&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6563276834599281497/comments/default&quot; rel=&quot;replies&quot; title=&quot;å‘è¡¨è¯„è®º&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/emerging-practices-for-society-centered .html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 æ¡è¯„è®º&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/ 6563276834599281497&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6563276834599281497&quot; rel=&quot;self&quot; type= &quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/emerging-practices-for-society-centered.html&quot; rel=&quot;alternate&quot; title=&quot;æ–°å…´å®žè·µä»¥ç¤¾ä¼šä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½â€ type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>; noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/ img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEghkgEei5l04Gs6hz4cLk9IqdDbXcx-41xZsRsJ-b2WHLDng1eZzJqo9eAwBZjZHc5P2akAKxT6vQLbn0-5nxy_OuPA5QIyWAV9Yy_4iIGch-zM2W-88Y-6e8Hxkb G39hemnzheAx5GUvkMspUCaQiqE5RtxYvFKj-bI0pKzOhFVrWmSOgHJisYHBDfGdCl/s72-c/lockup_GoogleResearch_FullColor_Hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>; &lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;æ ‡ç­¾ï¼šblogger.com,1999:blog-8474926331452026626.post-6928081948246813203&lt;/id>;&lt;å·²å‘å¸ƒ>; 2023-11-16T13:11:00.000-08:00&lt;/published>;&lt;updated>;2023-11-17T07:42:58.683-08:00&lt;/updated>;&lt;title type=&quot;text&quot;>;Google ç ”ç©¶é™¢çš„è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®‰å…¨çš„å¯¹æŠ—æ€§æµ‹è¯•&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;å‘å¸ƒè€…ï¼šKathy Meier-Hellsternï¼Œæž„å»ºè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½å’Œäººå·¥æ™ºèƒ½æ•°æ®ç³»ç»Ÿï¼ŒGoogle ç ”ç©¶æ€»ç›‘&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghkgEei5l04Gs6hz4cLk9IqdDbXcx-41xZsRsJ-b2WHLDng1eZzJqo9eAwBZjZHc5P2akAKxT6vQLbn0-5nxy _OuPA5QIyWAV9Yy_4iIGch-zM2W-88Y-6e8HxkbG39hemnzheAx5GUvkMspUCaQiqE5RtxYvFKj-bI0pKzOhFVrWmSOgHJisYHBDfGdCl/s1200/ lockup_GoogleResearch_FullColor_Hero.jpg&quot; style=&quot;æ˜¾ç¤ºï¼šæ— ï¼›&quot; />; &lt;p>;&lt;em>; &lt;/em>;&lt;a href=&quot;https://research.google/teams/responsible-ai/&quot;>;è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½å’Œä»¥äººä¸ºæœ¬çš„æŠ€æœ¯&lt;/a>; (RAI-HCT) Google ç ”ç©¶å›¢é˜Ÿè‡´åŠ›äºŽé€šè¿‡æ–‡åŒ–æ„è¯†ç ”ç©¶çš„è§†è§’æŽ¨è¿›è´Ÿè´£ä»»çš„ä»¥äººä¸ºæœ¬çš„äººå·¥æ™ºèƒ½çš„ç†è®ºå’Œå®žè·µï¼Œä»¥æ»¡è¶³å½“ä»Šæ•°åäº¿ç”¨æˆ·çš„éœ€æ±‚ï¼Œå¹¶ä¸ºæ›´ç¾Žå¥½çš„äººå·¥æ™ºèƒ½æœªæ¥å¼€è¾Ÿé“è·¯ã€‚ RAI-HCT å†…çš„ BRAIDSï¼ˆæž„å»ºè´Ÿè´£ä»»çš„ AI æ•°æ®å’Œè§£å†³æ–¹æ¡ˆï¼‰å›¢é˜Ÿæ—¨åœ¨é€šè¿‡åˆ©ç”¨å¯æ‰©å±•çš„å·¥å…·ã€é«˜è´¨é‡æ•°æ®ã€ç®€åŒ–çš„æµç¨‹å’Œæ–°é¢–çš„ç ”ç©¶æ¥ç®€åŒ– RAI å®žè·µçš„é‡‡ç”¨ï¼Œç›®å‰çš„é‡ç‚¹æ˜¯è§£å†³ç‹¬ç‰¹çš„æŒ‘æˆ˜ç”±&lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_artificial_intelligence&quot;>;ç”Ÿæˆäººå·¥æ™ºèƒ½&lt;/a>; (GenAI) æå‡ºã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; GenAI æ¨¡åž‹å®žçŽ°äº†å‰æ‰€æœªæœ‰çš„åŠŸèƒ½ï¼Œå¯¼è‡´åˆ›æ–°åº”ç”¨ç¨‹åºè¿…é€Ÿæ¿€å¢žã€‚ Google ç§¯æžåˆ©ç”¨ &lt;a href=&quot;https://ai.google/discover/foundation-models/&quot;>;GenAI&lt;/a>; æ¥&lt;a href=&quot;https://cloud.google.com/vertex-ai/docs /generative-ai/code/code-models-overview&quot;>;å¢žå¼º&lt;/a>;å…¶&lt;a href=&quot;https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now -available&quot;>;äº§å“çš„å®žç”¨æ€§&lt;/a>;å¹¶æ”¹å–„ç”Ÿæ´»ã€‚ GenAI å¸¦æ¥å·¨å¤§å¥½å¤„çš„åŒæ—¶ï¼Œä¹Ÿå¸¦æ¥äº†è™šå‡ä¿¡æ¯ã€åè§å’Œå®‰å…¨æ–¹é¢çš„é£Žé™©ã€‚ 2018 å¹´ï¼ŒGoogle çŽ‡å…ˆæå‡ºäº†&lt;a href=&quot;https://ai.google/responsibility/principles/&quot;>;äººå·¥æ™ºèƒ½åŽŸåˆ™&lt;/a>;ï¼Œå¼ºè°ƒæœ‰ç›Šåˆ©ç”¨å’Œé¢„é˜²ä¼¤å®³ã€‚è‡ªé‚£æ—¶èµ·ï¼ŒGoogle ä¸€ç›´è‡´åŠ›äºŽé€šè¿‡ 1) å…¨é¢çš„é£Žé™©è¯„ä¼°æ¡†æž¶æœ‰æ•ˆè½å®žæˆ‘ä»¬åœ¨&lt;a href=&quot;https://ai.google/responsibility/responsible-ai-practices/&quot;>;è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½å®žè·µ&lt;/a>;ä¸­çš„åŽŸåˆ™ï¼Œ2ï¼‰å†…éƒ¨æ²»ç†ç»“æž„ï¼Œ3ï¼‰æ•™è‚²ï¼Œä½¿è°·æ­Œå‘˜å·¥èƒ½å¤Ÿå°†äººå·¥æ™ºèƒ½åŽŸåˆ™èžå…¥åˆ°ä»–ä»¬çš„å·¥ä½œä¸­ï¼Œä»¥åŠ4ï¼‰å¼€å‘ç”¨äºŽè¯†åˆ«ã€è¡¡é‡å’Œåˆ†æžäººå·¥æ™ºèƒ½äº§å“æ•´ä¸ªç”Ÿå‘½å‘¨æœŸä¸­é“å¾·é£Žé™©çš„æµç¨‹å’Œå·¥å…·ã€‚ BRAIDS å›¢é˜Ÿä¸“æ³¨äºŽæœ€åŽä¸€ä¸ªé¢†åŸŸï¼Œåˆ›å»ºç”¨äºŽè¯†åˆ« GenAI äº§å“ä¸­é“å¾·å’Œå®‰å…¨é£Žé™©çš„å·¥å…·å’ŒæŠ€æœ¯ï¼Œä½¿ Google å†…éƒ¨çš„å›¢é˜Ÿèƒ½å¤Ÿåº”ç”¨é€‚å½“çš„ç¼“è§£æŽªæ–½ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;æ˜¯ä»€ä¹ˆè®© GenAI éš¾ä»¥è´Ÿè´£ä»»åœ°æž„å»ºï¼Ÿ&lt;/h2>; &lt;p>; GenAI æ¨¡åž‹å‰æ‰€æœªæœ‰çš„åŠŸèƒ½ä¼´éšç€ä¸€ç³»åˆ—æ–°çš„æ½œåœ¨æ•…éšœï¼Œå‡¸æ˜¾äº†åœ¨æ¨¡åž‹å¹¿æ³›ä½¿ç”¨ä¹‹å‰é‡‡å–å…¨é¢ã€ç³»ç»Ÿçš„ RAI æ–¹æ³•æ¥ç†è§£å’Œå‡è½»æ½œåœ¨å®‰å…¨é—®é¢˜çš„ç´§è¿«æ€§ã€‚ç”¨äºŽäº†è§£æ½œåœ¨é£Žé™©çš„ä¸€é¡¹å…³é”®æŠ€æœ¯æ˜¯å¯¹æŠ—æ€§æµ‹è¯•ï¼Œè¯¥æµ‹è¯•æ˜¯ä¸ºäº†ç³»ç»Ÿåœ°è¯„ä¼°æ¨¡åž‹è€Œè¿›è¡Œçš„æµ‹è¯•ï¼Œä»¥äº†è§£å®ƒä»¬åœ¨ä¸€ç³»åˆ—åœºæ™¯ä¸­è¢«æä¾›æ¶æ„æˆ–æ— æ„ä¸­æœ‰å®³çš„è¾“å…¥æ—¶çš„è¡Œä¸ºæ–¹å¼ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬çš„ç ”ç©¶é›†ä¸­åœ¨ä¸‰ä¸ªæ–¹å‘ï¼š&lt;/p>; &lt;ol>; &lt;li>;&lt;em>;è§„æ¨¡åŒ–å¯¹æŠ—æ•°æ®ç”Ÿæˆ&lt;/em>;&lt;br />; è€ƒè™‘åˆ°ä¸åŒçš„ç”¨æˆ·ç¤¾åŒºã€ç”¨ä¾‹å’Œè¡Œä¸ºï¼Œå®ƒåœ¨æŽ¨å‡ºäº§å“æˆ–æœåŠ¡ä¹‹å‰å¾ˆéš¾å…¨é¢è¯†åˆ«å…³é”®å®‰å…¨é—®é¢˜ã€‚äººæœºäº¤äº’çš„å¤§è§„æ¨¡å¯¹æŠ—æ€§æ•°æ®ç”Ÿæˆé€šè¿‡åˆ›å»ºåŒ…å«å„ç§ä¸åŒä¸”å¯èƒ½ä¸å®‰å…¨çš„æ¨¡åž‹è¾“å…¥çš„æµ‹è¯•é›†æ¥æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼Œè¿™äº›è¾“å…¥ä¼šåœ¨ä¸åˆ©æƒ…å†µä¸‹å¼ºè°ƒæ¨¡åž‹çš„èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨ BRAIDS ä¸­çš„ç‹¬ç‰¹é‡ç‚¹åœ¨äºŽç¡®å®šå—æˆ‘ä»¬çš„æ¨¡åž‹å½±å“çš„ä¸åŒç”¨æˆ·ç¤¾åŒºçš„ç¤¾ä¼šå±å®³ã€‚ &lt;/li>; &lt;li>;&lt;em>;è‡ªåŠ¨åŒ–æµ‹è¯•é›†è¯„ä¼°å’Œç¤¾åŒºå‚ä¸Ž&lt;/em>;&lt;br />;æ‰©å±•æµ‹è¯•æµç¨‹ï¼Œä»¥ä¾¿å¿«é€Ÿè¯„ä¼°æ•°åƒä¸ªæ¨¡åž‹å“åº”ï¼Œä»¥äº†è§£æ¨¡åž‹å¦‚ä½•åœ¨å¹¿æ³›çš„èŒƒå›´å†…å“åº”è‡ªåŠ¨åŒ–æµ‹è¯•é›†è¯„ä¼°æœ‰åŠ©äºŽå‘çŽ°æ½œåœ¨çš„æœ‰å®³åœºæ™¯ã€‚é™¤äº†ä½¿ç”¨å¯¹æŠ—æ€§æµ‹è¯•é›†è¿›è¡Œæµ‹è¯•ä¹‹å¤–ï¼Œç¤¾åŒºå‚ä¸Žæ˜¯æˆ‘ä»¬è¯†åˆ«â€œæœªçŸ¥çš„æœªçŸ¥æ•°â€å¹¶ä¸ºæ•°æ®ç”Ÿæˆè¿‡ç¨‹æä¾›ç§å­çš„æ–¹æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚&lt;/li>; &lt;li>;&lt;em>;è¯„ä¼°è€…å¤šæ ·æ€§&lt;/em>;&lt;br />;å®‰å…¨è¯„ä¼°ä¾èµ–äºŽäººçš„åˆ¤æ–­ï¼Œè€Œäººçš„åˆ¤æ–­æ˜¯ç”±ç¤¾åŒºå’Œæ–‡åŒ–å¡‘é€ çš„ï¼Œå¹¶ä¸”ä¸å®¹æ˜“è‡ªåŠ¨åŒ–ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä¼˜å…ˆç ”ç©¶è¯„ä¼°è€…å¤šæ ·æ€§ã€‚&lt;/li>; &lt;/ol>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;è§„æ¨¡åŒ–å¯¹æŠ—æ•°æ®ç”Ÿæˆ&lt;/ h2>; &lt;p>; é«˜è´¨é‡ã€å…¨é¢çš„æ•°æ®æ”¯æ’‘ç€ Google çš„è®¸å¤šå…³é”®é¡¹ç›®ã€‚æœ€åˆä¾èµ–æ‰‹åŠ¨æ•°æ®ç”Ÿæˆï¼Œæˆ‘ä»¬åœ¨è‡ªåŠ¨åŒ–å¯¹æŠ—æ•°æ®ç”Ÿæˆè¿‡ç¨‹æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚å…·æœ‰ç”¨ä¾‹å’Œæ”¿ç­–ä¸€è‡´æç¤ºçš„é›†ä¸­å¼æ•°æ®å­˜å‚¨åº“å¯ç”¨äºŽå¿«é€Ÿå¯åŠ¨æ–°çš„å¯¹æŠ—æ€§æµ‹è¯•çš„ç”Ÿæˆã€‚æˆ‘ä»¬è¿˜å¼€å‘äº†å¤šç§åŸºäºŽå¤§åž‹è¯­è¨€æ¨¡åž‹ (LLM) çš„åˆæˆæ•°æ®ç”Ÿæˆå·¥å…·ï¼Œè¿™äº›å·¥å…·ä¼˜å…ˆç”Ÿæˆåæ˜ ä¸åŒç¤¾ä¼šèƒŒæ™¯çš„æ•°æ®é›†ï¼Œå¹¶é›†æˆæ•°æ®è´¨é‡æŒ‡æ ‡ä»¥æé«˜æ•°æ®é›†è´¨é‡å’Œå¤šæ ·æ€§ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬çš„æ•°æ®è´¨é‡æŒ‡æ ‡åŒ…æ‹¬ï¼š&lt;/p>; &lt;ul>; &lt;li>;è¯­è¨€é£Žæ ¼åˆ†æžï¼ŒåŒ…æ‹¬æŸ¥è¯¢é•¿åº¦ã€æŸ¥è¯¢ç›¸ä¼¼æ€§å’Œè¯­è¨€é£Žæ ¼çš„å¤šæ ·æ€§ã€‚&lt;/li>; &lt;li>;è·¨ç»´åº¦çš„è¡¡é‡å¹¿æ³›çš„ç¤¾ä¼šå’Œå¤šå…ƒæ–‡åŒ–ç»´åº¦ï¼Œåˆ©ç”¨ &lt;a href=&quot;https://github.com/google-research-datasets/seegull/tree/main&quot;>;SeeGULL&lt;/a>;ã€&lt;a href=&quot; https://github.com/google-research-datasets/SPICE/tree/main&quot;>;SPICE&lt;/a>;ï¼Œ&lt;a href=&quot;https://medium.com/jigsaw/scaling-machine-learning-fairness -with-societal-context-be73d4ad38e2&quot;>;ç¤¾ä¼šæƒ…å¢ƒå­˜å‚¨åº“&lt;/a>;ã€‚&lt;/li>; &lt;li>;è¡¡é‡ä¸Ž Google çš„ä¸€è‡´æ€§&lt;a href=&quot;https://policies.google.com/terms/generative-ai /use-policy&quot;>;ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç­–ç•¥&lt;/a>;å’Œé¢„æœŸç”¨ä¾‹ã€‚&lt;/li>; &lt;li>;åˆ†æžå¯¹æŠ—æ€§ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬æ£€æŸ¥æ˜¾å¼ï¼ˆè¾“å…¥æ˜Žæ˜¾è®¾è®¡ä¸ºäº§ç”Ÿä¸å®‰å…¨çš„è¾“å‡ºï¼‰å’Œéšå¼ï¼ˆè¾“å…¥æ— å®³ä½†è¾“å‡ºæœ‰å®³ï¼‰æŸ¥è¯¢ã€‚ &lt;/li>; &lt;/ul>; &lt;p>; æˆ‘ä»¬çš„å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆæ–¹æ³•ä¹‹ä¸€åœ¨æˆ‘ä»¬å…³äºŽ&lt;a href=&quot;https://arxiv.org/abs/2311.08592&quot;>;äººå·¥æ™ºèƒ½è¾…åŠ©çº¢é˜Ÿ&lt;/ a>;ï¼ˆAARTï¼‰ã€‚ AART ç”Ÿæˆå…·æœ‰é«˜åº¦å¤šæ ·æ€§çš„è¯„ä¼°æ•°æ®é›†ï¼ˆä¾‹å¦‚ï¼Œç‰¹å®šäºŽå¹¿æ³›æ–‡åŒ–å’Œåœ°ç†åŒºåŸŸçš„æ•æ„Ÿå’Œæœ‰å®³æ¦‚å¿µï¼‰ï¼Œå¹¶ç”±äººå·¥æ™ºèƒ½è¾…åŠ©æ–¹æ³•å¼•å¯¼ï¼Œä»¥åœ¨åº”ç”¨ç¨‹åºçŽ¯å¢ƒä¸­å®šä¹‰ã€èŒƒå›´å’Œä¼˜å…ˆè€ƒè™‘å¤šæ ·æ€§ã€‚ä¸Žä¸€äº›æœ€å…ˆè¿›çš„å·¥å…·ç›¸æ¯”ï¼ŒAART åœ¨æ¦‚å¿µè¦†ç›–çŽ‡å’Œæ•°æ®è´¨é‡æ–¹é¢æ˜¾ç¤ºå‡ºäº†æœ‰å¸Œæœ›çš„ç»“æžœã€‚å¦å¤–ï¼Œæˆ‘ä»¬è¿˜ä¸Ž MLCommons åˆä½œï¼Œä¸º&lt;a href=&quot;https://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html&quot;>;äººå·¥æ™ºèƒ½å®‰å…¨å…¬å…±åŸºå‡†åšå‡ºè´¡çŒ®&lt;/ä¸€ä¸ª>;ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;å¯¹æŠ—æ€§æµ‹è¯•å’Œç¤¾åŒºè§è§£&lt;/h2>; &lt;p>; ä½¿ç”¨å¯¹æŠ—æ€§æµ‹è¯•é›†è¯„ä¼°æ¨¡åž‹è¾“å‡ºä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨éƒ¨ç½²ä¹‹å‰è¯†åˆ«å…³é”®å®‰å…¨é—®é¢˜ã€‚æˆ‘ä»¬çš„åˆæ­¥è¯„ä¼°å®Œå…¨ä¾èµ–äºŽäººå·¥è¯„çº§ï¼Œç”±äºŽç¼ºä¹æ ‡å‡†åŒ–çš„å®‰å…¨å®šä¹‰å’Œæ”¿ç­–ï¼Œå¯¼è‡´å‘¨è½¬æ—¶é—´ç¼“æ…¢ä¸”ä¸ä¸€è‡´ã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸Žæ”¿ç­–ä¸€è‡´çš„è¯„ä¼°è€…æŒ‡å—æ¥æé«˜äººç±»è¯„ä¼°è€…çš„å‡†ç¡®æ€§ï¼Œä»Žè€Œæé«˜äº†è¯„ä¼°çš„è´¨é‡ï¼Œå¹¶ä¸”æ­£åœ¨ç ”ç©¶å…¶ä»–æ”¹è¿›æŽªæ–½ï¼Œä»¥æ›´å¥½åœ°åæ˜ ä¸åŒç¤¾åŒºçš„è§‚ç‚¹ã€‚æ­¤å¤–ï¼Œä½¿ç”¨åŸºäºŽ LLM çš„è‡ªåŠ¨è¯„åˆ†å™¨è¿›è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•é›†è¯„ä¼°å¯æé«˜æ•ˆçŽ‡å’Œè§„æ¨¡ï¼ŒåŒæ—¶å…è®¸æˆ‘ä»¬å°†å¤æ‚æˆ–æ¨¡ç³Šçš„æ¡ˆä¾‹äº¤ç»™äººç±»è¿›è¡Œä¸“å®¶è¯„åˆ†ã€‚ &lt;/p>; &lt;p>; é™¤äº†ä½¿ç”¨å¯¹æŠ—æ€§æµ‹è¯•é›†è¿›è¡Œæµ‹è¯•ä¹‹å¤–ï¼Œæ”¶é›†ç¤¾åŒºè§è§£å¯¹äºŽä¸æ–­å‘çŽ°â€œæœªçŸ¥çš„æœªçŸ¥æ•°â€è‡³å…³é‡è¦ã€‚ä¸ºäº†æä¾›è§„æ¨¡åŒ–æµç¨‹æ‰€éœ€çš„é«˜è´¨é‡äººåŠ›æŠ•å…¥ï¼Œæˆ‘ä»¬ä¸Ž &lt;a href=&quot;https://sites.google.com/corp/google.com/earr-external-research-group ç­‰å›¢ä½“åˆä½œ/home&quot;>;å…¬å¹³äººå·¥æ™ºèƒ½ç ”ç©¶åœ†æ¡Œä¼šè®®&lt;/a>; (EARR)ï¼Œå¹¶ä¸Žæˆ‘ä»¬çš„å†…éƒ¨é“å¾·å’Œåˆ†æžå›¢é˜Ÿåˆä½œï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä»£è¡¨ä½¿ç”¨æˆ‘ä»¬æ¨¡åž‹çš„å¤šå…ƒåŒ–ç¤¾åŒºã€‚ &lt;a href=&quot;https://dynabench.org/tasks/adversarial-nibbler&quot;>;å¯¹æŠ—æ€§ Nibbler æŒ‘æˆ˜&lt;/a>;å¸å¼•å¤–éƒ¨ç”¨æˆ·äº†è§£&lt;a href=&quot;https://arxiv.org/abs /2305.14384&quot;>;å‘æœ€ç»ˆç”¨æˆ·å¤§è§„æ¨¡è¾“å‡ºä¸å®‰å…¨ã€æœ‰åè§æˆ–æš´åŠ›çš„å†…å®¹&lt;/a>;ã€‚æˆ‘ä»¬å¯¹ç¤¾åŒºå‚ä¸Žçš„æŒç»­æ‰¿è¯ºåŒ…æ‹¬æ”¶é›†ä¸åŒç¤¾åŒºçš„åé¦ˆå¹¶ä¸Žç ”ç©¶ç¤¾åŒºåˆä½œï¼Œä¾‹å¦‚åœ¨&lt;a href=&quot;https://sites.google.com/view/art-of-safety&quot;>;å®‰å…¨çš„è‰ºæœ¯æœŸé—´&lt;a href=&quot;http://www.ijcnlp-aacl2023.org/&quot;>;è®¡ç®—è¯­è¨€å­¦åä¼šä¼šè®®äºšå¤ªåˆ†ä¼š&lt;/a>; (IJCNLP-AACL 2023) ä¸¾åŠžçš„ç ”è®¨ä¼š&lt;/a>;ï¼Œä»¥è§£å†³å¯¹æŠ—æ€§é—®é¢˜GenAI çš„æµ‹è¯•æŒ‘æˆ˜ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;å®‰å…¨è¯„ä¼°ä¸­çš„è¯„ä¼°è€…å¤šæ ·æ€§&lt;/h2>; &lt;p>;äº†è§£å’Œå‡è½» GenAI å®‰å…¨é£Žé™©æ—¢æ˜¯æŠ€æœ¯å’Œç¤¾ä¼šæŒ‘æˆ˜ã€‚å®‰å…¨è®¤çŸ¥æœ¬è´¨ä¸Šæ˜¯ä¸»è§‚çš„ï¼Œå¹¶å—åˆ°å¤šç§äº¤å‰å› ç´ çš„å½±å“ã€‚æˆ‘ä»¬å¯¹äººå£ç»Ÿè®¡å¯¹å®‰å…¨è®¤çŸ¥çš„å½±å“è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ï¼ŒæŽ¢è®¨äº†&lt;a href=&quot;https://arxiv.org/abs/2306.11530&quot;>;è¯„ä¼°è€…äººå£ç»Ÿè®¡æ•°æ®çš„äº¤å‰å½±å“&lt;/a>;ï¼ˆä¾‹å¦‚ç§æ—/æ°‘æ—ã€æ€§åˆ«ã€å¹´é¾„ï¼‰ ï¼‰å’Œ GenAI è¾“å‡ºå®‰å…¨è¯„ä¼°çš„å†…å®¹ç‰¹å¾ï¼ˆä¾‹å¦‚å±å®³ç¨‹åº¦ï¼‰ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¿½è§†äº†å›ºæœ‰çš„ä¸»è§‚æ€§å’Œè¯„ä¼°è€…ä¹‹é—´çš„ç³»ç»Ÿæ€§åˆ†æ­§ï¼Œè¿™å¯èƒ½æŽ©ç›–é‡è¦çš„æ–‡åŒ–å·®å¼‚ã€‚æˆ‘ä»¬çš„&lt;a href=&quot;https://arxiv.org/abs/2311.05074&quot;>;åˆ†æ­§åˆ†æžæ¡†æž¶&lt;/a>;æ­ç¤ºäº†æ¥è‡ªä¸åŒèƒŒæ™¯çš„è¯„ä¼°è€…ä¹‹é—´çš„å„ç§åˆ†æ­§æ¨¡å¼ï¼ŒåŒ…æ‹¬â€œåŸºæœ¬äº‹å®žâ€ä¸“å®¶è¯„çº§ã€‚è¿™ä¸ºè¯„ä¼°äººç±»æ³¨é‡Šè´¨é‡å’Œæ¨¡åž‹è¯„ä¼°çš„æ–°æ–¹æ³•é“ºå¹³äº†é“è·¯ï¼Œè€Œä¸ä»…ä»…æ˜¯ç®€å•åœ°ä½¿ç”¨é‡‘æ ‡ç­¾ã€‚æˆ‘ä»¬çš„ &lt;a href=&quot;https://arxiv.org/abs/2306.11247&quot;>;NeurIPS 2023 å‡ºç‰ˆç‰©&lt;/a>;ä»‹ç»äº†&lt;a href=&quot;https://github.com/google-research-datasets/dices-dataset &quot;>;DICES&lt;/a>;ï¼ˆå¯¹è¯å¼äººå·¥æ™ºèƒ½å®‰å…¨è¯„ä¼°çš„å¤šæ ·æ€§ï¼‰æ•°æ®é›†ï¼Œæœ‰åŠ©äºŽå¯¹æ³•å­¦ç¡•å£«è¿›è¡Œç»†è‡´å…¥å¾®çš„å®‰å…¨è¯„ä¼°ï¼Œå¹¶è€ƒè™‘ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„å·®å¼‚ã€æ¨¡ç³Šæ€§å’Œå¤šæ ·æ€§ã€‚ &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;æ€»ç»“&lt;/h2>; &lt;p>; GenAIå¸¦æ¥äº†æŠ€æœ¯å˜é©ï¼Œä¸ºå¿«é€Ÿå‘å±•æä¾›äº†å¯èƒ½æ€§ç”šè‡³æ— éœ€ç¼–ç å³å¯è¿›è¡Œå®šåˆ¶ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿå­˜åœ¨äº§ç”Ÿæœ‰å®³è¾“å‡ºçš„é£Žé™©ã€‚æˆ‘ä»¬çš„ä¸»åŠ¨å¯¹æŠ—æ€§æµ‹è¯•è®¡åˆ’å¯è¯†åˆ«å¹¶å‡è½» GenAI é£Žé™©ï¼Œä»¥ç¡®ä¿åŒ…å®¹æ€§çš„æ¨¡åž‹è¡Œä¸ºã€‚å¯¹æŠ—æ€§æµ‹è¯•å’Œçº¢é˜Ÿæ˜¯å®‰å…¨ç­–ç•¥çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä»¥å…¨é¢çš„æ–¹å¼è¿›è¡Œå®ƒä»¬è‡³å…³é‡è¦ã€‚åˆ›æ–°çš„å¿«é€Ÿæ­¥ä¼è¦æ±‚æˆ‘ä»¬ä¸æ–­æŒ‘æˆ˜è‡ªæˆ‘ï¼Œä¸Žå†…éƒ¨åˆä½œä¼™ä¼´ã€å¤šå…ƒåŒ–çš„ç”¨æˆ·ç¤¾åŒºå’Œå…¶ä»–è¡Œä¸šä¸“å®¶åˆä½œï¼Œå¯»æ‰¾â€œæœªçŸ¥çš„æœªçŸ¥â€ã€‚ &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6928081948246813203/comments/default&quot; rel=&quot;replies&quot; title=&quot;å‘è¡¨è¯„è®º&quot; type=&quot;application/atom+xml &quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/responsible-ai-at-google-research_16.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 æ¡è¯„è®º&quot; ç±»åž‹=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6928081948246813203&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;é“¾æŽ¥ href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6928081948246813203&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog .research.google/2023/11/responsible-ai-at-google-research_16.html&quot; rel=&quot;alternate&quot; title=&quot;Google Research çš„è´Ÿè´£ä»» AIï¼šç”Ÿæˆå¼ AI å®‰å…¨çš„å¯¹æŠ—æ€§æµ‹è¯•&quot; type=&quot;text/html&quot;/ >;&lt;ä½œè€…>;&lt;åç§°>;Google AI&lt;/åç§°>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;ç”µå­é‚®ä»¶>;noreply@blogger.com&lt;/ç”µå­é‚®ä»¶>;&lt;gdï¼šå›¾åƒé«˜åº¦=â€œ16â€rel =â€œhttp://schemas.google.com/g/2005#thumbnailâ€src =â€œhttps://img1.blogblog.com/img/b16-rounded.gifâ€å®½åº¦=â€œ16â€>; &lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghkgEei5l04Gs6hz4cLk9IqdDbXcx-41xZsRsJ-b2WHLDng1eZzJqo9eAwBZjZHc5P2akAKxT6vQL bn0-5nxy_OuPA5QIyWAV9Yy_4iIGch-zM2W-88Y- 6e8HxkbG39hemnzheAx5GUvkMspUCaQiqE5RtxYvFKj-bI0pKzOhFVrWmSOgHJisYHBDfGdCl/s72-c/lockup_GoogleResearch_FullColor_Hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:toæ€»è®¡>;0&lt;/ thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;æ ‡ç­¾ï¼šblogger.com,1999:blog-8474926331452026626.post-1338549955376716163&lt;/id>;&lt;å‘å¸ƒ>;2023-11-14T12:28:00.000-08:00&lt; /å·²å‘å¸ƒ>;&lt;æ›´æ–°>;2023-11-14T14:09:51.250-08:00&lt;/æ›´æ–°>;&lt;ç±»åˆ«æ–¹æ¡ˆ=â€œhttp://www.blogger.com/atom/ns#â€æœ¯è¯­=â€œAIâ€>;&lt; /category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;è®¡ç®—æœºè§†è§‰&quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom /ns#&quot; term=&quot;å¤šæ¨¡å¼å­¦ä¹ &quot;>;&lt;/category>;&lt;category schema=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;è§†é¢‘åˆ†æž&quot;>;&lt;/category>;&lt;title type= &quot;text&quot;>;å°†å¤šæ¨¡æ€ç†è§£æ‰©å±•åˆ°é•¿è§†é¢‘&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;å‘å¸ƒè€…ï¼šGoogle ç ”ç©¶é™¢è½¯ä»¶å·¥ç¨‹å¸ˆ Isaac Noble å’Œç ”ç©¶ç§‘å­¦å®¶ Anelia Angelovaï¼Œè°·æ­Œ DeepMind &lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhS9q_iPaPNyYexT4zpSTnERwHJJGcmOemvRjjqD9sNPMwibC-iV5AU2P4J9VrPE_NGFyFz5QLxHpCti9Y-bOPEi9XPCev 5YwIpNKPMECDxk1prmksf99tPHgf1uQb7EW3zSmnIMWIFwAjvM7GldhsEtW7eogo1sG1L1nxD8UPIi0fpHR_Iwp8fJTdoUnQB/s1600/mirasol.png&quot; style=&quot;æ˜¾ç¤ºï¼šæ— ï¼›&quot; />; &lt;p>; åœ¨ä¸ºçŽ°å®žç”Ÿæ´»åº”ç”¨æž„å»ºæœºå™¨å­¦ä¹ æ¨¡åž‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘å¤šç§æ¨¡å¼çš„è¾“å…¥ï¼Œä»¥æ•èŽ·æˆ‘ä»¬å‘¨å›´ä¸–ç•Œçš„å„ä¸ªæ–¹é¢ã€‚ä¾‹å¦‚ï¼ŒéŸ³é¢‘ã€è§†é¢‘å’Œæ–‡æœ¬éƒ½æä¾›æœ‰å…³è§†è§‰è¾“å…¥çš„å„ç§è¡¥å……ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç”±äºŽæ¨¡æ€çš„å¼‚è´¨æ€§ï¼Œæž„å»ºå¤šæ¨¡æ€æ¨¡åž‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸€äº›æ¨¡å¼å¯èƒ½åœ¨æ—¶é—´ä¸Šå¾ˆå¥½åœ°åŒæ­¥ï¼ˆä¾‹å¦‚ï¼ŒéŸ³é¢‘ã€è§†é¢‘ï¼‰ï¼Œä½†ä¸Žæ–‡æœ¬ä¸å¯¹é½ã€‚æ­¤å¤–ï¼Œè§†é¢‘å’ŒéŸ³é¢‘ä¿¡å·ä¸­çš„æ•°æ®é‡æ¯”æ–‡æœ¬ä¸­çš„æ•°æ®é‡å¤§å¾—å¤šï¼Œå› æ­¤å½“å°†å®ƒä»¬ç»„åˆæˆå¤šæ¨¡æ€æ¨¡åž‹æ—¶ï¼Œè§†é¢‘å’ŒéŸ³é¢‘é€šå¸¸ä¸èƒ½è¢«å……åˆ†æ¶ˆè€—ï¼Œå¹¶ä¸”éœ€è¦ä¸æˆæ¯”ä¾‹åœ°åŽ‹ç¼©ã€‚å¯¹äºŽè¾ƒé•¿çš„è§†é¢‘è¾“å…¥ï¼Œè¿™ä¸ªé—®é¢˜ä¼šæ›´åŠ ä¸¥é‡ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; åœ¨â€œ&lt;a href=&quot;https://arxiv.org/abs/2311.05698&quot;>;Mirasol3Bï¼šä¸€ç§å¤šæ¨¡æ€è‡ªå›žå½’æ¨¡åž‹ï¼Œç”¨äºŽæ—¶é—´å¯¹é½å’Œä¸Šä¸‹æ–‡æ¨¡æ€&lt;/a>;â€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤šæ¨¡æ€&lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_model&quot;>;è‡ªå›žå½’&lt;/a>;æ¨¡åž‹ï¼ˆMirasol3Bï¼‰ï¼Œç”¨äºŽè·¨éŸ³é¢‘ã€è§†é¢‘å’Œæ–‡æœ¬å­¦ä¹ æ–¹å¼ã€‚ä¸»è¦æ€æƒ³æ˜¯å°†å¤šæ¨¡æ€å»ºæ¨¡è§£è€¦ä¸ºå•ç‹¬çš„èšç„¦è‡ªå›žå½’æ¨¡åž‹ï¼Œæ ¹æ®æ¨¡æ€çš„ç‰¹å¾å¤„ç†è¾“å…¥ã€‚æˆ‘ä»¬çš„æ¨¡åž‹ç”±ä¸€ä¸ªç”¨äºŽæ—¶é—´åŒæ­¥æ¨¡æ€ï¼ˆéŸ³é¢‘å’Œè§†é¢‘ï¼‰çš„è‡ªå›žå½’ç»„ä»¶å’Œä¸€ä¸ªå•ç‹¬çš„è‡ªå›žå½’ç»„ä»¶ç»„æˆï¼Œè¯¥è‡ªå›žå½’ç»„ä»¶ç”¨äºŽä¸ä¸€å®šæ˜¯æ—¶é—´å¯¹é½ä½†ä»ç„¶æ˜¯é¡ºåºçš„æ¨¡æ€ï¼Œä¾‹å¦‚æ–‡æœ¬è¾“å…¥ï¼Œå¦‚æ ‡é¢˜æˆ–æè¿°ã€‚æ­¤å¤–ï¼Œæ—¶é—´å¯¹é½çš„æ¨¡æ€åœ¨æ—¶é—´ä¸Šè¿›è¡Œåˆ’åˆ†ï¼Œå¯ä»¥å…±åŒå­¦ä¹ å±€éƒ¨ç‰¹å¾ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒéŸ³è§†é¢‘è¾“å…¥è¢«åŠæ—¶å»ºæ¨¡ï¼Œå¹¶ä¸”æ¯”ä»¥å‰çš„å·¥ä½œåˆ†é…äº†ç›¸å¯¹æ›´å¤šçš„å‚æ•°ã€‚ä¸Žå…¶ä»–å¤šæ¨¡å¼æ¨¡åž‹ç›¸æ¯”ï¼Œé€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾å¤„ç†æ›´é•¿çš„è§†é¢‘ï¼ˆä¾‹å¦‚ï¼Œ128-512 å¸§ï¼‰ã€‚åœ¨ 3B å‚æ•°ä¸‹ï¼ŒMirasol3B æ¯”ä¹‹å‰çš„ &lt;a href=&quot;https://arxiv.org/abs/2204.14198&quot;>;Flamingo&lt;/a>; (80B) å’Œ &lt;a href=&quot;https://arxiv.org/ abs/2305.18565&quot;>;PaLI-X&lt;/a>; (55B) åž‹å·ã€‚æœ€åŽï¼ŒMirasol3B åœ¨&lt;a href=&quot;https://blog.research.google/2022/08/efficient-video-text-learning-with.html&quot;>;è§†é¢‘é—®ç­”&lt;æ–¹é¢ä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•&lt; /a>;ï¼ˆè§†é¢‘ QAï¼‰ã€é•¿è§†é¢‘ QA å’ŒéŸ³é¢‘-è§†é¢‘-æ–‡æœ¬åŸºå‡†ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgshWPBWMbvzrYbGl-41QRmA5NWiQ4GKMb_nlTl-uKlY6D9TEKosZWbJk_wnllLqyq4GUQT6feI_rLH4rrYV oZHHQET750qT1pxkkiju6mWqG7ddCxLjgpywTb3rnQdDtaUTOeRvnZD0_a2mMauvs7vu6pzboeWcTCt_7bloNMDdZfNyM3Y_7UKcN-7VSqS/s1240/image5.gif â€œ imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;960&quot; data-original-width=&quot;1240&quot; src= â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgshWPBWMbvzrYbGl-41QRmA5NWiQ4GKMb_nlTl-uKlY6D9TEKosZWbJk_wnllLqyq4GUQT6feI_rLH4rrYVoZHHQET750qT1pxkkiju6mW qG7ddCxLjgpywTb3rnQdDtaUTOeRvnZD0_a2mMauvs7vu6pzboeWcTCt_7bloNMDdZfNyM3Y_7UKcN-7VSqS/s16000/image5.gif&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Mirasol3B æž¶æž„ç”±ä¸€ä¸ªç”¨äºŽæ—¶é—´å¯¹é½æ¨¡æ€ï¼ˆéŸ³é¢‘å’Œè§†é¢‘ï¼‰çš„è‡ªå›žå½’æ¨¡åž‹ï¼ˆæŒ‰å—åˆ’åˆ†ï¼‰å’Œä¸€ä¸ªå•ç‹¬çš„è‡ªå›žå½’æ¨¡åž‹ç»„æˆæœªå¯¹é½çš„ä¸Šä¸‹æ–‡æ¨¡å¼ï¼ˆä¾‹å¦‚æ–‡æœ¬ï¼‰ã€‚è”åˆç‰¹å¾å­¦ä¹ ç”±ç»„åˆå™¨è¿›è¡Œï¼Œå®ƒå­¦ä¹ ç´§å‡‘ä½†ä¿¡æ¯ä¸°å¯Œçš„ç‰¹å¾ï¼Œå…è®¸å¤„ç†é•¿è§†é¢‘/éŸ³é¢‘è¾“å…¥ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line- height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;åè°ƒæ—¶é—´å¯¹é½å’Œä¸Šä¸‹æ–‡æ¨¡å¼&lt;/h2>; &lt;p>; è§†é¢‘ã€éŸ³é¢‘å’Œæ–‡æœ¬æ˜¯å…·æœ‰ä¸åŒç‰¹å¾çš„å¤šç§æ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œè§†é¢‘æ˜¯æ¯ç§’ 30-100 å¸§çš„æ—¶ç©ºè§†è§‰ä¿¡å·ï¼Œä½†ç”±äºŽæ•°æ®é‡è¾ƒå¤§ï¼Œå½“å‰æ¨¡åž‹é€šå¸¸æ¯ä¸ªè§†é¢‘ä»…æ¶ˆè€— 32-64 å¸§ã€‚éŸ³é¢‘æ˜¯ä¸€ç§ä»¥æ¯”è§†é¢‘é«˜å¾—å¤šçš„é¢‘çŽ‡èŽ·å¾—çš„ä¸€ç»´æ—¶é—´ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œ16 &lt;a href=&quot;https://en.wikipedia.org/wiki/Hertz&quot;>;Hz&lt;/a>;ï¼‰ï¼Œè€Œæ–‡æœ¬è¾“å…¥é€‚ç”¨äºŽæ•´ä¸ªè§†é¢‘çš„å•è¯åºåˆ—é€šå¸¸ä¸º 200-300 ä¸ªå•è¯åºåˆ—ï¼Œå¹¶ç”¨ä½œéŸ³é¢‘-è§†é¢‘è¾“å…¥çš„ä¸Šä¸‹æ–‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹ç”±ä¸€ä¸ªè‡ªå›žå½’ç»„ä»¶å’Œå¦ä¸€ä¸ªè‡ªå›žå½’ç»„ä»¶ç»„æˆï¼Œè¯¥è‡ªå›žå½’ç»„ä»¶èžåˆå¹¶å…±åŒå­¦ä¹ å‡ºçŽ°åœ¨é«˜é¢‘ä¸”å¤§è‡´åŒæ­¥çš„æ—¶é—´å¯¹é½ä¿¡å·ï¼Œä»¥åŠå¦ä¸€ä¸ªç”¨äºŽå¤„ç†éžå¯¹é½ä¿¡å·çš„è‡ªå›žå½’ç»„ä»¶ã€‚æ—¶é—´å¯¹é½å’Œä¸Šä¸‹æ–‡æ¨¡å¼çš„ç»„ä»¶ä¹‹é—´çš„å­¦ä¹ é€šè¿‡äº¤å‰æ³¨æ„æœºåˆ¶è¿›è¡Œåè°ƒï¼Œè¯¥æœºåˆ¶å…è®¸ä¸¤è€…åœ¨æŒ‰é¡ºåºå­¦ä¹ çš„åŒæ—¶äº¤æ¢ä¿¡æ¯ï¼Œè€Œæ— éœ€åŠæ—¶åŒæ­¥å®ƒä»¬ã€‚ &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;è§†é¢‘å’ŒéŸ³é¢‘çš„æ—¶é—´å¯¹é½è‡ªå›žå½’å»ºæ¨¡&lt;/h2>; &lt;p>;é•¿è§†é¢‘å¯ä»¥ä¼ è¾¾ä¸°å¯Œçš„ä¿¡æ¯ä»¥åŠæŒ‰é¡ºåºå‘ç”Ÿçš„æ´»åŠ¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ¨¡åž‹é€šè¿‡ä¸€æ¬¡æå–æ‰€æœ‰ä¿¡æ¯æ¥è¿›è¡Œè§†é¢‘å»ºæ¨¡ï¼Œè€Œæ²¡æœ‰è¶³å¤Ÿçš„æ—¶é—´ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åº”ç”¨äº†ä¸€ç§è‡ªå›žå½’å»ºæ¨¡ç­–ç•¥ï¼Œåœ¨è¯¥ç­–ç•¥ä¸­ï¼Œæˆ‘ä»¬æ ¹æ®å…ˆå‰æ—¶é—´é—´éš”çš„ç‰¹å¾è¡¨ç¤ºæ¥è°ƒèŠ‚ä¸€ä¸ªæ—¶é—´é—´éš”å†…è”åˆå­¦ä¹ çš„è§†é¢‘å’ŒéŸ³é¢‘è¡¨ç¤ºã€‚è¿™ä¿ç•™äº†æ—¶é—´ä¿¡æ¯ã€‚ &lt;/p>; &lt;p>; è§†é¢‘é¦–å…ˆè¢«åˆ†å‰²æˆæ›´å°çš„è§†é¢‘å—ã€‚æ¯ä¸ªå—æœ¬èº«å¯ä»¥æ˜¯ 4-64 å¸§ã€‚ç„¶åŽï¼Œä¸Žæ¯ä¸ªå—ç›¸å¯¹åº”çš„ç‰¹å¾ç”±ç§°ä¸ºç»„åˆå™¨ï¼ˆå¦‚ä¸‹æ‰€è¿°ï¼‰çš„å­¦ä¹ æ¨¡å—è¿›è¡Œå¤„ç†ï¼Œè¯¥æ¨¡å—åœ¨å½“å‰æ­¥éª¤ä¸­ç”Ÿæˆè”åˆéŸ³é¢‘å’Œè§†é¢‘ç‰¹å¾è¡¨ç¤ºâ€”â€”æ­¤æ­¥éª¤æå–å¹¶åŽ‹ç¼©æ¯ä¸ªå—æœ€é‡è¦çš„ä¿¡æ¯ã€‚æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªå›žå½’ Transformer å¤„ç†è¿™ä¸ªè”åˆç‰¹å¾è¡¨ç¤ºï¼Œå®ƒå°†æ³¨æ„åŠ›é›†ä¸­åˆ°ä¹‹å‰çš„ç‰¹å¾è¡¨ç¤ºä¸Šï¼Œå¹¶ç”Ÿæˆä¸‹ä¸€æ­¥çš„è”åˆç‰¹å¾è¡¨ç¤ºã€‚å› æ­¤ï¼Œæ¨¡åž‹ä¸ä»…å­¦ä¹ å¦‚ä½•è¡¨ç¤ºæ¯ä¸ªå•ç‹¬çš„å—ï¼Œè¿˜å­¦ä¹ å¦‚ä½•è¡¨ç¤ºå—åœ¨æ—¶é—´ä¸Šçš„å…³è”ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh90Ao2yyoC5TSypNxQzA7F80lQla0f4STDrB6ZdVhINwiiQjOq1WppROFurlUn9-Lq_UUQ9uuQIeRDld-j2NMYl1 e5q2Cg2L0zOHXSG0dAkpCSqVe-wEyE8QZtUup7AUazE3sBEyoO2T3RhWSc5Z7o1w0pyqMH0WzTts3vaxUnMNOa61uWXvQ2Wj92evO5/s1259/image1.png â€œ imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;744&quot; data-original-width=&quot;1259&quot; src= â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh90Ao2yyoC5TSypNxQzA7F80lQla0f4STDrB6ZdVhINwiiQjOq1WppROFurlUn9-Lq_UUQ9uuQIeRDld-j2NMYl1e5q2Cg2L0zOHXSG0dAkp CSqVe-wEyE8QZtUup7AUazE3sBEyoO2T3RhWSc5Z7o1w0pyqMH0WzTts3vaxUnMNOa61uWXvQ2Wj92evO5/s16000/image1.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;æˆ‘ä»¬å¯¹éŸ³é¢‘å’Œè§†é¢‘è¾“å…¥ä½¿ç”¨è‡ªå›žå½’å»ºæ¨¡ï¼ŒæŒ‰æ—¶é—´å¯¹å®ƒä»¬è¿›è¡Œåˆ†åŒºå¹¶å­¦ä¹ è”åˆç‰¹å¾è¡¨ç¤ºï¼Œç„¶åŽæŒ‰é¡ºåºè‡ªå›žå½’å­¦ä¹ ã€‚&lt;/ td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;ä½¿ç”¨æ¨¡æ€ç»„åˆå™¨å¯¹é•¿è§†é¢‘è¿›è¡Œå»ºæ¨¡&lt;/h2>; &lt;ä¸ºäº†ç»„åˆæ¯ä¸ªè§†é¢‘å—ä¸­è§†é¢‘å’ŒéŸ³é¢‘ä¿¡æ¯çš„ä¿¡å·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç§°ä¸ºç»„åˆå™¨çš„å­¦ä¹ æ¨¡å—ã€‚é€šè¿‡èŽ·å–ä¸Žç‰¹å®šè§†é¢‘æ—¶é—´å¸§ç›¸å¯¹åº”çš„éŸ³é¢‘è¾“å…¥æ¥å¯¹é½è§†é¢‘å’ŒéŸ³é¢‘ä¿¡å·ã€‚ç„¶åŽï¼Œæˆ‘ä»¬åœ¨æ—¶ç©ºä¸Šå¤„ç†è§†é¢‘å’ŒéŸ³é¢‘è¾“å…¥ï¼Œæå–ä¸Žè¾“å…¥å˜åŒ–ç‰¹åˆ«ç›¸å…³çš„ä¿¡æ¯ï¼ˆå¯¹äºŽæˆ‘ä»¬ä½¿ç”¨çš„è§†é¢‘&lt;a href=&quot;https://arxiv.org/abs/2212.03229&quot;>;ç¨€ç–è§†é¢‘ç®¡&lt;/a>;ï¼Œå¯¹äºŽéŸ³é¢‘ï¼Œæˆ‘ä»¬åº”ç”¨&lt;a href=&quot;https://en.wikipedia.org/wiki/Spectrogram&quot;>;é¢‘è°±å›¾&lt;/a>;è¡¨ç¤ºï¼Œä¸¤è€…å‡ç”±&lt;aå¤„ç†href=&quot;https://arxiv.org/abs/2010.11929&quot;>;è§†è§‰è½¬æ¢å™¨ï¼‰&lt;/a>;ã€‚æˆ‘ä»¬å°†è¿™äº›ç‰¹å¾è¿žæŽ¥å¹¶è¾“å…¥åˆ°ç»„åˆå™¨ä¸­ï¼Œç»„åˆå™¨æ—¨åœ¨å­¦ä¹ æ•èŽ·è¿™ä¸¤ä¸ªè¾“å…¥çš„æ–°ç‰¹å¾è¡¨ç¤ºã€‚ä¸ºäº†è§£å†³è§†é¢‘å’ŒéŸ³é¢‘ä¿¡å·ä¸­å¤§é‡æ•°æ®çš„æŒ‘æˆ˜ï¼Œç»„åˆå™¨çš„å¦ä¸€ä¸ªç›®æ ‡æ˜¯é™ä½Žè”åˆè§†é¢‘/éŸ³é¢‘è¾“å…¥çš„ç»´åº¦ï¼Œè¿™æ˜¯é€šè¿‡é€‰æ‹©è¾ƒå°‘æ•°é‡çš„è¦ç”Ÿæˆçš„è¾“å‡ºç‰¹å¾æ¥å®Œæˆçš„ã€‚ç»„åˆå™¨å¯ä»¥ç®€å•åœ°å®žçŽ°ä¸ºå› æžœå˜åŽ‹å™¨ï¼Œå®ƒåœ¨æ—¶é—´æ–¹å‘ä¸Šå¤„ç†è¾“å…¥ï¼Œå³ä»…ä½¿ç”¨å…ˆå‰æ­¥éª¤æˆ–å½“å‰æ­¥éª¤çš„è¾“å…¥ã€‚æˆ–è€…ï¼Œç»„åˆå™¨å¯ä»¥å…·æœ‰å¯å­¦ä¹ å­˜å‚¨å™¨ï¼Œå¦‚ä¸‹æ‰€è¿°ã€‚ &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Combiner æ ·å¼&lt;/h2>; &lt;p>; Combiner çš„ç®€å•ç‰ˆæœ¬é‡‡ç”¨äº† Transformer æž¶æž„ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæ¥è‡ªå½“å‰å—ï¼ˆä»¥åŠå¯é€‰çš„å…ˆå‰å—ï¼‰çš„æ‰€æœ‰éŸ³é¢‘å’Œè§†é¢‘ç‰¹å¾è¢«è¾“å…¥åˆ°å˜æ¢å™¨å¹¶æŠ•å½±åˆ°è¾ƒä½Žç»´åº¦ï¼Œå³ï¼Œé€‰æ‹©è¾ƒå°‘æ•°é‡çš„ç‰¹å¾ä½œä¸ºè¾“å‡ºâ€œç»„åˆâ€ç‰¹å¾ã€‚è™½ç„¶ Transformer é€šå¸¸ä¸ä¼šåœ¨è¿™ç§æƒ…å†µä¸‹ä½¿ç”¨ï¼Œä½†æˆ‘ä»¬å‘çŽ°é€šè¿‡é€‰æ‹© Transformer çš„æœ€åŽ &lt;em>;m&lt;/em>; ä¸ªè¾“å‡ºï¼ˆå¦‚æžœ &lt;em>;m&lt;/em>; æ˜¯ï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆåœ°é™ä½Žè¾“å…¥ç‰¹å¾çš„ç»´åº¦ã€‚æ‰€éœ€çš„è¾“å‡ºå°ºå¯¸ï¼ˆå¦‚ä¸‹æ‰€ç¤ºï¼‰ã€‚æˆ–è€…ï¼Œç»„åˆå™¨å¯ä»¥å…·æœ‰å­˜å‚¨å™¨ç»„ä»¶ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨&lt;a href=&quot;https://arxiv.org/abs/2211.09119&quot;>;ä»¤ç‰Œå›¾çµæœº&lt;/a>;ï¼ˆTTMï¼‰ï¼Œå®ƒæ”¯æŒå¯å¾®åˆ†çš„å†…å­˜å•å…ƒï¼Œç´¯ç§¯å’ŒåŽ‹ç¼©æ‰€æœ‰å…ˆå‰æ—¶é—´æ­¥é•¿çš„ç‰¹å¾ã€‚ä½¿ç”¨å›ºå®šå†…å­˜å…è®¸æ¨¡åž‹åœ¨æ¯ä¸€æ­¥å¤„ç†æ›´ç´§å‡‘çš„ç‰¹å¾é›†ï¼Œè€Œä¸æ˜¯å¤„ç†å…ˆå‰æ­¥éª¤çš„æ‰€æœ‰ç‰¹å¾ï¼Œä»Žè€Œå‡å°‘è®¡ç®—é‡ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0C7t17njiE70O5UrLHjfEHAw5dbAlNvYj7bMxQt_GkxNUdGtnqKyAwpWi7uvE_IGiS-50Q2Qyo4CAzq8uZ bkXZ-HzNh-DCh6UNSSIwxUlWSOTihmChwFXD4F3LS73C_1fusf5fQl7TyTQv2L5ycmfSCj36GK3IrN4yaOAjODj09NBmcAMJzV0TZS_0qNI/s1798/image8.png â€œ imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;619&quot; data-original-width=&quot;1798&quot; src= â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0C7t17njiE70O5UrLHjfEHAw5dbAlNvYj7bMxQt_GkxNUdGtnqKyAwpWi7uvE_IGiS-50Q2Qyo4CAzq8uZbkXZ-HzNh-DCh6UNSSIwxU lWSOtihmChwFXD4F3LS73C_1fusf5fQl7TyTQv2L5ycmfSCj36GK3IrN4yaOAjODj09NBmcAMJzV0TZS_0qNI/s16000/image8.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„åŸºäºŽ Transformer çš„ç»„åˆå™¨ï¼ˆ&lt;b>;å·¦&lt;/b>;ï¼‰å’Œä¸€ä¸ªå†…å­˜ç»„åˆå™¨ï¼ˆ&lt;b>;å³&lt;/b>;ï¼‰ ï¼ŒåŸºäºŽä»¤ç‰Œå›¾çµæœºï¼ˆTTMï¼‰ï¼Œå®ƒä½¿ç”¨å†…å­˜æ¥åŽ‹ç¼©ä»¥å‰çš„ç‰¹å¾åŽ†å²è®°å½•ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height:40%;&quot; >; &lt;br>; &lt;/div>; &lt;h2>;ç»“æžœ&lt;/h2>; &lt;p>; æˆ‘ä»¬æ ¹æ®å¤šä¸ªåŸºå‡†è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œ&lt;a href=&quot;https://www.microsoft.com/en-us/research/wp- content/uploads/2016/06/cvpr16.msr-vtt.tmei_-1.pdf&quot;>;MSRVTT-QA&lt;/a>;ï¼Œ&lt;a href=&quot;https://arxiv.org/abs/1906.02467&quot;>;ActivityNet-QA &lt;/a>; å’Œ &lt;a href=&quot;https://arxiv.org/abs/2105.08276&quot;>;NeXT-QA&lt;/a>;ï¼Œç”¨äºŽè§†é¢‘ QA ä»»åŠ¡ï¼Œå…¶ä¸­å‘å‡ºæœ‰å…³è§†é¢‘çš„åŸºäºŽæ–‡æœ¬çš„é—®é¢˜ï¼Œå¹¶ä¸”æ¨¡åž‹éœ€è¦å›žç­”ã€‚è¿™è¯„ä¼°äº†æ¨¡åž‹ç†è§£åŸºäºŽæ–‡æœ¬çš„é—®é¢˜å’Œè§†é¢‘å†…å®¹å¹¶å½¢æˆç­”æ¡ˆï¼ˆä»…å…³æ³¨ç›¸å…³ä¿¡æ¯ï¼‰çš„èƒ½åŠ›ã€‚åœ¨è¿™äº›åŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŽä¸¤ä¸ªé’ˆå¯¹é•¿è§†é¢‘è¾“å…¥å¹¶å…·æœ‰æ›´å¤æ‚çš„é—®é¢˜ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬è¿˜åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆè®¾ç½®ä¸­è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå…¶ä¸­æ¨¡åž‹ä»¥ä¸å—çº¦æŸçš„æ–¹å¼ç”Ÿæˆè‡ªç”±æ ¼å¼æ–‡æœ¬çš„ç­”æ¡ˆï¼Œéœ€è¦ä¸ŽçœŸå®žç­”æ¡ˆå®Œå…¨åŒ¹é…ã€‚è™½ç„¶è¿™ç§æ›´ä¸¥æ ¼çš„è¯„ä¼°å°†åŒä¹‰è¯è§†ä¸ºä¸æ­£ç¡®ï¼Œä½†å®ƒå¯èƒ½æ›´å¥½åœ°åæ˜ æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ &lt;/p>; &lt;p>; æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼Œå¯¹äºŽå¤§å¤šæ•°åŸºå‡†æµ‹è¯•ï¼ˆåŒ…æ‹¬æ‰€æœ‰å¼€æ”¾å¼ç”Ÿæˆè¯„ä¼°ï¼‰ï¼Œå…¶æ€§èƒ½å‡ä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³• - å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬çš„æ¨¡åž‹åªæœ‰ 3B å‚æ•°ï¼Œæ¯”ä»¥å‰çš„æ–¹æ³•å°å¾—å¤šï¼Œä¾‹å¦‚ï¼Œç«çƒˆé¸Ÿ80Bã€‚æˆ‘ä»¬ä»…ä½¿ç”¨è§†é¢‘å’Œæ–‡æœ¬è¾“å…¥æ¥ä¸Žå…¶ä»–å·¥ä½œè¿›è¡Œæ¯”è¾ƒã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡åž‹å¯ä»¥å¤„ç† 512 å¸§ï¼Œè€Œæ— éœ€å¢žåŠ æ¨¡åž‹å‚æ•°ï¼Œè¿™å¯¹äºŽå¤„ç†æ›´é•¿çš„è§†é¢‘è‡³å…³é‡è¦ã€‚æœ€åŽï¼Œé€šè¿‡ TTM ç»„åˆå™¨ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†æ›´å¥½æˆ–ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘äº† 18% çš„è®¡ç®—é‡ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwfCp3kk_xskD3rGbE9BU7nwO3t1JtjU55NX1gqHw0LLMII8I48WB979sAhPCefH-GmGsUUxfGseTqjmMnhyphenhy phenFRP1LHlZXuAJvsHhZGdSoEblQ4WUs6BnRqjFpy-iFyqEhW3FTKpVN-_mo8h0jDWJt0EUctIHjOWPW4iaD859TaN3N3omt5ejmydnN8C0uv/s1200/image3.png â€œ imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; src= â€œhttps://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwfCp3kk_xskD3rGbE9BU7nwO3t1JtjU55NX1gqHw0LLMII8I48WB979sAhPCefH-GmGsUUxfGseTqjmMnhyphenhyphenFRP1LHlZXuAJvsHhZG dSoEblQ4WUs6BnRqjFpy-iFyqEhW3FTKpVN-_mo8h0jDWJt0EUctIHjOWPW4iaD859TaN3N3omt5ejmydnN8C0uv/s16000/image3.png&quot;/>;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/ ä¸Šçš„ç»“æžœ06/cvpr16.msr-vtt.tmei_-1.pdf&quot;>;MSRVTT-QA&lt;/a>;ï¼ˆè§†é¢‘ QAï¼‰æ•°æ®é›†ã€‚&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;tablealign=&quot;center â€œ cellpadding =â€œ0â€cellspacing =â€œ 0â€ç±»=â€œtr-caption-containerâ€æ ·å¼=â€œmargin-leftï¼šè‡ªåŠ¨ï¼›æŠ“åœ°åŠ›ï¼šè‡ªåŠ¨; UPG7TVPXEVSU9ZSS4CUVUJGA6IKIQSYSKDDYVLBFIY3VKMCDRWJ- WROZ-C7TL-FOZWXSEKZNQSMJLAND23SFAA9JGPQDF645TVGPN3HSNV3TW9RHKPAGWHUIOIID4W1DIJ8XXFAVAVYK/S1200/s1200/Image7.pngâ€œ Image7.pngâ€ ImageAnChor =â€œ ImageAnChor =â€ ImageAnChor =â€œ 1â€ MARGA MARGA MARGA MARGAN-LARGIFï¼šè¾¹ç¼˜æƒåˆ©ï¼šè‡ªåŠ¨;â€œ>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 860â€ data-eriginal-width =â€œ 1200â€ src =â€œ https://blogger.googleusercontent.com/img/img/b/b/ R29vZ2xl/AVvXsEjFgcLlauVA3EKGZt031I4pWR3gpl4kk0jdyP_Oaia1J5pyp3t4VS8mUPG7TvPXevsu9Zs4cuVuJgA6IKiqsySkDDyvlBFiy3VkmcDRWJ-WRoZ-c7Tl-fozWXSEkznQSmJlAND23SfaA9jgPQDf645TVGpn3hsNV3tw9rHkpagwhuioiD4W1diJ8XxfavYK/s16000/image7.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center ;â€œ>;åœ¨&lt;a href=&quot;https://arxiv.org/abs/2105.08276&quot;>; next-qa &lt;/a>;åŸºå‡†ä¸­ï¼Œè¯¥åŸºå‡†ä¸ºè§†é¢‘QAä»»åŠ¡ã€‚&lt;/td>; &lt;/tr>;ï¼Œ &lt;/tbody>; &lt;/table>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br>; &lt;/div>; &lt;h2>;åœ¨Audio-VideoåŸºå‡†ä¸Šç»“æžœ&lt;/h2>; &lt;p>;åœ¨æµè¡ŒéŸ³é¢‘ä¸Šç»“æžœ-VIDEOæ•°æ®é›†&lt;a href=&quot;https://www.robots.ox.ac.ac.uk/~vgg/data/data/vggsound/&quot;>; vgg-sound &lt;/a>;å’Œ&lt;a href =â€œ httpsï¼š// kitchens.github.io/epic-sounds/&quot;>; epic-sounds &lt;/a>;å¦‚ä¸‹æ‰€ç¤ºã€‚ç”±äºŽè¿™äº›åŸºå‡†æ˜¯åˆ†ç±» - æˆ‘ä»¬å°†å®ƒä»¬è§†ä¸ºå¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆçš„çŽ¯å¢ƒï¼Œæˆ‘ä»¬çš„æ¨¡åž‹ä¼šäº§ç”Ÿæ¨¡åž‹çš„æ–‡æœ¬æ‰€éœ€çš„ç­çº§ï¼›ä¾‹å¦‚ï¼Œå¯¹äºŽä¸Žâ€œæ‰“é¼“â€æ´»åŠ¨ç›¸å¯¹åº”çš„ç±»IDï¼Œæˆ‘ä»¬å¸Œæœ›è¯¥æ¨¡åž‹èƒ½å¤Ÿç”Ÿæˆæ–‡æœ¬â€œæ‰“é¼“â€ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå³ä½¿æˆ‘ä»¬çš„æ¨¡åž‹åœ¨ç”Ÿæˆå¼å¼€æ”¾å¼è®¾ç½®ä¸­è¾“å‡ºç»“æžœï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿä¼˜äºŽå…ˆå‰çš„è‰ºæœ¯çŠ¶æ€ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEilvMcRgE6UcfYVRrHeniJ4K7wlOvHHXB76h_2pJ63eNEZ-1LASKSIPsCx_hntsQPG7k619EQTpV5mgvt2EIezwqnLAbdnYOvatfMD0zq97fnW3pDuQz1TUjUiNt-b2Ka9z5z3bwPZWhnDgQFXNbYdqTzTP50qKvg99Qb6UsUee7dNZfuxOWsq-6HJjdOs6/s1200/image6.png â€œ ImaNeanChor =â€ 1â€œæ ·å¼=â€ Margin-Leftï¼šauto; Margin-Rightï¼šauto;â€œ>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 742â€ data-Original-width =â€œ 1200â€ SRC = &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEilvMcRgE6UcfYVRrHeniJ4K7wlOvHHXB76h_2pJ63eNEZ-1LASKSIPsCx_hntsQPG7k619EQTpV5mgvt2EIezwqnLAbdnYOvatfMD0zq97fnW3pDuQz1TUjUiNt-b2Ka9z5z3bwPZWhnDgQFXNbYdqTzTP50qKvg99Qb6UsUee7dNZfuxOWsq-6HJjdOs6/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>;åœ¨&lt;a href=&quot;https://www.robots.ox.ac.ac.uk/~vgg/data/vggsound/&quot;>; vggä¸Šç»“æžœ-sound &lt;/a>;ï¼ˆAUDIO-VIDEO QAï¼‰æ•°æ®é›†ã€‚&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/tbody>; &lt;/table>; &lt;table align =â€œä¸­å¿ƒâ€ cellpadding =â€œ 0â€ cellSpacing =â€œ 0â€ class =â€œ class =â€ tr-caption-containerâ€œ style =â€è¾¹ç¼˜å·¦å·¦å³ï¼šauto;è¾¹ç¼˜å³ï¼šè‡ªåŠ¨;â€œ>; &lt;tbody>; &lt;tr>; &lt;td style =â€ text-alignï¼šcenter;â€œ>; &lt;a href =â€ https://blogger.googleusercontent.com/img/img/r29vz2xl/r29vz2xl/avvxssegmsumsue9- 4QKm4lQlvDS4BymTU47VxMvtdOIishS-QnLBV_sYWTVtp8dZATo3vyqeemFlV0uvBt7AY6yCFsd9DCMwRQO-o8HiQEPe_A4Ilb540-h5cAmymsQkgC3oW2BfPtEWi_w_N6bTGi6FFKogwe9fuJ4v2_Zid9_KcR5pnulxx7HujwkxV5cbCRdqny_/s1200/image2.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEgMsUe9-4QKm4lQlvDS4BymTU47VxMvtdOIishS-QnLBV_sYWTVtp8dZATo3vyqeemFlV0uvBt7AY6yCFsd9DCMwRQO-o8HiQEPe_A4Ilb540-h5cAmymsQkgC3oW2BfPtEWi_w_N6bTGi6FFKogwe9fuJ4v2_Zid9_KcR5pnulxx7HujwkxV5cbCRdqny_/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align ï¼šcenter;â€œ>;åœ¨&lt;a href=&quot;https://epic-kitchens.github.io/epic-sounds/&quot;>; epic-sounds &lt;/a>;ï¼ˆaudio-video QAï¼‰æ•°æ®é›†ä¸­ã€‚&lt;/td>; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br>; &lt;/div>; &lt;h2>;è‡ªåŠ¨å›žå½’å»ºæ¨¡çš„å¥½å¤„&lt;/h2>; &lt;p>;æˆ‘ä»¬è¿›è¡Œäº†ä¸€ä¸ªæ¶ˆèžç ”ç©¶å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸Žä½¿ç”¨ç›¸åŒè¾“å…¥ä¿¡æ¯ä½†æ ‡å‡†æ–¹æ³•ï¼ˆå³æ²¡æœ‰è‡ªåŠ¨åŒ–å’Œç»„åˆçš„åŸºå‡†ï¼‰è¿›è¡Œæ¯”è¾ƒçš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒäº†é¢„è®­ç»ƒçš„æ•ˆæžœã€‚å› ä¸ºæ ‡å‡†æ–¹æ³•ä¸é€‚åˆå¤„ç†æ›´é•¿çš„å¤„ç†è§†é¢‘ï¼Œè¯¥å®žéªŒä»…é’ˆå¯¹æ‰€æœ‰è®¾ç½®è¿›è¡Œäº†32å¸§å’Œ4ä¸ªå—ï¼Œä»¥è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚æˆ‘ä»¬çœ‹åˆ°Mirasol3bçš„æ”¹è¿›å¯¹äºŽç›¸å¯¹è¾ƒçŸ­çš„è§†é¢‘ä»ç„¶æœ‰æ•ˆã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style =â€œ text-alignï¼šcenter;â€>; &lt;a href =â€œ https://blogger.googleusercontent.com/img/r29vz2xl/avvz2xl/avvxsegjd4kzfugagagagluunosersnuosersnuosersnuahwmsbyxbyx6azhrgkrgkrgkrgkrgbbbbb1 qustigrkquzquzqug qustequ qustequzqug Q Q Qustig Qustig Qustig Qustig Qustig Qustig Qustig Qustiktequstigqug Qus q6rvmjqihjcy9otqizhuseonk1ciq2ale3n1zyzqevpdwur_81ueded5u9dxdabk8ozbonahkkkkkkkkkkkkkkkkk0hzfmhs0j6ioumyfmjki-mjki-mjki-mmjki-mmjhb76f2khl-6xxtppeneg/s12 g.an4.pn. =â€œ 1â€ style =â€œè¾¹è·å·¦ï¼šè‡ªåŠ¨; margin-rightï¼šauto;â€>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 742â€ data-Original-width =â€œ 1200â€ src =â€œ src =â€ https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjD4KZfUgaGluUNoSERSnuaHWMsbyx6AzHrgKrvDB1ZJxpOqNonvOzTI4hGVz4I8KZQT4aDLkQ6rvMjQIHJCY9otQIZHuSeoNK1ciQ2ALE3n1zYzQEvPdwUR_81uEDeD5U9DXDABK8ozbONAHkK0hZFMHS0j6IoumYfmjKI-M9ZHb76F2kHl-6XTPEn2eG/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr -captionâ€œ style =â€ text-alignï¼šä¸­å¿ƒ;â€œ>;æ¶ˆèžå®žéªŒæ¯”è¾ƒäº†æ¨¡åž‹çš„ä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚ä½¿ç”¨ç»„åˆä»ªï¼Œè‡ªå›žæ—‹å»ºæ¨¡å’Œé¢„å…ˆåŸ¹è®­éƒ½æé«˜äº†æ€§èƒ½ã€‚&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br>; &lt;br>; &lt; /div>; &lt;h2>;ç»“è®º&lt;/h2>; &lt;p>;æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡å¼è‡ªå›žæ—‹æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹é€šè¿‡åè°ƒæ—¶é—´å¹³è¡¡å’Œæ—¶é—´å¹³è¡¡æ–¹å¼ä¹‹é—´çš„å­¦ä¹ æ¥è§£å†³ä¸Žå¤šæ¨¡å¼æ•°æ®çš„å¼‚è´¨æ€§ç›¸å…³çš„æŒ‘æˆ˜ã€‚ä¸Žç»„åˆä»ªçš„åŠæ—¶è¿›è¡Œè‡ªåŠ¨è°ƒæŸ¥ï¼Œä»¥æŽ§åˆ¶åºåˆ—é•¿åº¦å¹¶äº§ç”Ÿå¼ºå¤§çš„è¡¨ç¤ºå½¢å¼ï¼Œè¿›ä¸€æ­¥è¿›è¡Œè‡ªåŠ¨åŠ å·¥ã€‚æˆ‘ä»¬è¯æ˜Žäº†ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„æ¨¡åž‹å¯ä»¥æˆåŠŸåœ°è¡¨ç¤ºé•¿æ—¶é—´çš„è§†é¢‘ï¼Œå¹¶æœ‰æ•ˆåœ°ä¸Žå…¶ä»–æ–¹å¼ç»“åˆåœ¨ä¸€èµ·ã€‚æˆ‘ä»¬åœ¨è§†é¢‘å’ŒéŸ³é¢‘è§†é¢‘é—®é¢˜ç­”æ¡ˆä¸Šèƒœè¿‡æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ˆåŒ…æ‹¬ä¸€äº›æ›´å¤§çš„æ¨¡åž‹ï¼‰ã€‚ &lt;/p>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br>; &lt;/div>; &lt;h2>; denkentledgments &lt;/h2>; &lt;p>; &lt;em>;è¿™é¡¹ç ”ç©¶ç”±iSAACçš„AJ Piergiovanniå…±åŒæ’°å†™Nobleï¼ŒDahun Kimï¼ŒMichael Ryooï¼ŒVictor Gomeså’ŒAnelia Angelovaã€‚æˆ‘ä»¬æ„Ÿè°¢Claire Cuiï¼ŒTania Bedrax-Weissï¼ŒAbhijit Ogaleï¼ŒYunhsuan Sungï¼ŒChing-Chung Changï¼ŒMarvin Ritterï¼ŒKristina Toutanovaï¼ŒMing-wei Changï¼ŒAshish Thapliyalï¼Œthapliyal Jialin Wu, Luke Friedman, Trevor Walker, Keerthana Gopalakrishnan, Jason Baldridge, Radu Soricut, Mojtaba Seyedhosseini, Alexander D&#39;Amour, Oliver Wang, Paul Natsev, Tom Duerig, Younghui Wu, Slav Petrov, Zoubin Ghahramani for their help and support.æˆ‘ä»¬è¿˜è¦æ„Ÿè°¢æ±¤å§†Â·æ–¯èŽ«ï¼ˆTom Smallï¼‰å‡†å¤‡åŠ¨ç”»ã€‚ &lt;/em>; &lt;/p>; &lt;/content>; &lt;link href =â€œ http://blog.research.google/feeds/1338549995537671616163/comments/comments/defaultâ€ /atom+xmlâ€œ/>; &lt;link href =â€ http://blog.research.google/2023/11/scaling-multimodal-ustanding-to.html#comment-formâ€œ â€œ type =â€ text/htmlâ€œ/>; &lt;link href =â€ http://www.blogger.com/feeds/8474926331452026626/posts/posts/default/13338549999999555555555376767161616161616161616163 >; &lt;link href =â€œ http://www.blogger.com/feeds/8474926331452026626/ /blog.research.google/2023/11/scaling-multimodal-ustanding-to.htmlâ€œ rel =â€œæ›¿ä»£â€ title =â€œç¼©æ”¾å¯¹é•¿è§†é¢‘çš„å¤šæ¨¡å¼ç†è§£â€ type type =â€œ text/htmlâ€/htmlâ€œ/htmlâ€/>; &lt;triped>; &lt; >; Google AI &lt;/name>; &lt;uri>; http://www.blogger.com/profile/1209862651477775266161 &lt;/uri>; &lt;Email>; &lt;Email>; noreply@blogger.com &lt;/email>; â€œ http://schemas.google.com/g/2005#thumbnailâ€ src =â€œ https://img1.blogbblog.com/img/img/b16-rounded.gifâ€ width =â€œ 16â€ &lt;/ä½œè€…>; &lt;åª’ä½“ï¼šç¼©ç•¥å›¾é«˜=â€œ 72â€ url =â€œ https://blogger.googleusercontent.com/img/r29vz2xl/avvxsehs9q_ipapneryyyyyyyyyext4zpst4zpst4zpst4zpst4zpst4zjjjjgcmoemvrjjjjjjjjqd9snpmcmcmcmcmcm ivrxpypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypypyf4 CTI9Y-BOPEI9XPCEV5YWIPNKPMECDXK1PRMKSF99TPHGF1UQB7EEW3ZSMNIMWIFWIFWIFWAJVM7GLDHSETW7EOGO1NXDD8XD8XD8PPHRIIII0FPHRR_IWPPHR_IWP8FP8FP8FJTDOUNQB/S72-CPN =â€ â€œ XMLNSï¼šMedia =â€ httpï¼š//search.yahoo.com/mrss/â€œ>; &lt;/åª’ä½“ï¼šthumbnail>; &lt;thrï¼šthrï¼šthr>; thr>; 0 &lt;/thrï¼šthr>; &lt;/entry>; &lt;/entry>; &lt;entry>; &lt;entry>; &lt;id>; &lt;id>; tagï¼štagï¼štagï¼štagï¼štagï¼štagï¼štagï¼š Blogger.comï¼Œ1999ï¼šBlog-8474926331452026626.POST-5546775652504697591 &lt;/id>; &lt;/id>; &lt;/id>; &lt;å‡ºç‰ˆ>; 2023-11-10T10ï¼š05ï¼š00.000-08ï¼š008ï¼š008ï¼š00 8ï¼š00 &lt;/00 08:00 &lt;/updated>; &lt;ç±»åˆ«æ–¹æ¡ˆ=â€œ http://www.blogger.com/atom/ns#â€ term =â€œ cassisibilityâ€>; &lt;/category>; &lt;ç±»åˆ«>; &lt;category>; &lt;ç±»åˆ«spece =â€œ httpï¼š//www.bloggerã€‚ com/atom/nsï¼ƒâ€œ term =â€œ dataSetsâ€>; &lt;/category>; &lt;ç±»åˆ«scheme =â€œ http://www.blogger.com/atom/ns#â€ =â€œ http://www.blogger.com/atom/ns#â€ term =â€œå¼€æºâ€>; &lt;/category>; &lt;title type =â€œ textâ€>;ä¸ºç ”ç©¶ç¤¾åŒºå¯ç”¨å¤§åž‹å¥åº·ç ”ç©¶&lt;/stitle>; &lt;content type =â€œ htmlâ€>; &lt;span class =â€œ byline-authorâ€>;ç”±è½¯ä»¶å·¥ç¨‹å¸ˆChintan Ghateå’ŒGoogle Research Google Research Engionerçš„Chintan Ghateå’ŒDiana Mincuå‘å¸ƒ&lt;/span>; &lt;img src =â€œ httpsï¼š// bloggerã€‚ googleusercontent.com/img/b/r29vz2xl/avvxsehdecrv8m_gtaixn2bwuwshshbj6g4jpo6 jb6uyqso-llcbn6wewcesr01ng1ng1ng1mfchoifnzgbbbbb_mn4ipswes87ftos y.1n4ptots8mhhhhmhhhhhhhhhhrn.hhrn.hhrn.mhhrn.mhhrn.mnhrn.hhrn.mhhrnnm1sssssssssssssssssssssssssssssssssssssssss 7KHFKZBXYYLB0C1IIZFQVCON-LAEBHJD96WTYLIBS03EJRTEOVNAYRWPBHB-A7RYTALFCFCFJ9SKX/S1100/MSSIGNALS-HERO.JPGâ€œ />; &lt;p>;ä½œä¸ºæ¶ˆè´¹æŠ€æœ¯ï¼Œä¾‹å¦‚&lt;a href =â€œ https://cloud.google.com/blog/topics/healthcare-care-life-sciences/google-cloud-cloud-fitbit-fitbit-fitbit-haga-collaborate-collaborate-in-pilot-on-pilot-on-pilot-on-pilot-on-pilot-hent-pileot-hend-hernt-hearp-hernt--ç ”ç©¶â€œ>;å¥èº«è¿½è¸ªå™¨&lt;/a>;å’Œ&lt;a href=&quot;https://blog.google/products/pixel/pixel/health-ealth-ai-better-sleep/&quot;>;æ‰‹æœº&lt;/a>;ç›¸å…³æ•°æ®æ”¶é›†ï¼Œåˆ©ç”¨è¿™äº›æ•°æ®é€”å¾„æ¥ç ”ç©¶å’Œæé«˜æˆ‘ä»¬å¯¹åŒ»ç–—çŠ¶å†µçš„ç†è§£çš„æœºä¼šä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬æœ‰&lt;a href=&quot;https://blog.research.google/2023/11/responsible-ai-at-google-research.html&quot;>;ä»¥å‰åœ¨æ…¢æ€§ç–¾ç—…çš„èƒŒæ™¯ä¸‹ï¼Œç‰¹åˆ«æ˜¯å¤šå‘æ€§ç¡¬åŒ–ç—‡ï¼ˆMSï¼‰ã€‚è¿™é¡¹åŠªåŠ›åˆ©ç”¨&lt;a href=&quot;https://github.com/googleclecloudplatform/fda-mystudies&quot;>; fda mystudieså¹³å°&lt;/a>;ï¼Œä¸€ä¸ªå¼€æ”¾å¼å¹³å°ï¼Œç”¨äºŽåˆ›å»ºä¸´åºŠç ”ç©¶åº”ç”¨ç¨‹åºï¼Œä½¿ä»»ä½•äººæ›´å®¹æ˜“ï¼Œè¿™ä½¿å¾—ä»»ä½•äººéƒ½æ›´å®¹æ˜“ä»¥å¯ä¿¡èµ–å’Œå®‰å…¨çš„æ–¹å¼è¿›è¡Œè‡ªå·±çš„å­¦ä¹ å¹¶æ”¶é›†é«˜è´¨é‡çš„åŒ»ç–—ä¿å¥æ•°æ®ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>; &lt;/a>; &lt;p>;ä»Šå¤©ï¼Œæˆ‘ä»¬æè¿°äº†æˆ‘ä»¬é€šè¿‡æ‰©å±•FDA Mydudieså¹³å°å¼€å‘çš„è®¾ç½®ï¼Œå¹¶æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å®ƒæ¥å»ºç«‹æ•°å­—å¥åº·ç ”ç©¶ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†é€šè¿‡è¯¥å¹³å°åˆ›å»ºçš„åä¸ºMS Signalsåˆ›å»ºçš„æŽ¢ç´¢æ€§ç ”ç©¶ï¼Œè¯¥ç ”ç©¶ç”±MSæ‚£è€…çš„ç—‡çŠ¶è·Ÿè¸ªåº”ç”¨ç¨‹åºç»„æˆã€‚è¯¥åº”ç”¨ç¨‹åºçš„ç›®æ ‡æ˜¯åŒé‡çš„ï¼š1ï¼‰ç¡®ä¿FDAç¥žç§˜ä¸»ä¹‰å¹³å°çš„å¢žå¼ºåŠŸèƒ½ä½¿æ›´ç®€åŒ–çš„ç ”ç©¶åˆ›ä½œä½“éªŒï¼› 2ï¼‰äº†è§£å¦‚ä½•ä½¿ç”¨æ–°çš„æ•°æ®æ”¶é›†æœºåˆ¶æ¥å½»åº•æ”¹å˜æ‚£è€…çš„æ…¢æ€§ç–¾ç—…ç®¡ç†å’Œè·Ÿè¸ªã€‚æˆ‘ä»¬æœ‰&lt;a href=&quot;https://github.com/googleclecloudplatform/fda-mystudies-flutter&quot;>;å¼€æ”¾æº&lt;/a>;æˆ‘ä»¬åœ¨&lt;a href =â€œ httpsï¼š// wwwww a href =â€ä¸‹çš„FDAç¥žç§˜å¹³å°ä¸‹çš„æ‰©å±•ã€‚ apache.org/licenses/license-2.0&quot;>; apache 2.0è®¸å¯è¯&lt;/a>;ä¸ºç¤¾åŒºæä¾›è‡ªå·±çš„å­¦ä¹ èµ„æºã€‚ &lt;/p>; &lt;br />; &lt;h2>;æ‰©å±•FDA Mydudies Platform &lt;/h2>; &lt;p>;åŽŸå§‹FDA Mystudieså¹³å°å…è®¸äººä»¬é…ç½®è‡ªå·±çš„ç ”ç©¶åº”ç”¨ç¨‹åºï¼Œç®¡ç†å‚ä¸Žè€…å¹¶åˆ›å»ºå•ç‹¬çš„iOSå’ŒAndroidåº”ç”¨ç¨‹åºã€‚ä¸ºäº†ç®€åŒ–ç ”ç©¶åˆ›å»ºè¿‡ç¨‹å¹¶ç¡®ä¿ç ”ç©¶çš„å‚ä¸Žåº¦å¢žåŠ ï¼Œæˆ‘ä»¬è¿›è¡Œäº†è®¸å¤šå¯è®¿é—®æ€§æ›´æ”¹ã€‚ä¸€äº›ä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼šé€šè¿‡ä½¿ç”¨&lt;a href=&quot;https://flutter.dev/&quot;>; Flutter &lt;/a>;ï¼ŒGoogleçš„å¼€æºæ¡†æž¶ç”¨äºŽæž„å»ºï¼Œè·¨å¹³å°ï¼ˆiOSå’ŒAndroidï¼‰åº”ç”¨ç¨‹åºç”Ÿæˆæ¥è‡ªå•ä¸ªä»£ç åº“çš„å¤šå¹³å°åº”ç”¨ç¨‹åºï¼›ç®€åŒ–çš„è®¾ç½®ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥å¿«é€ŸåŽŸåž‹ï¼ˆåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼‰è¿…é€Ÿè¿›è¡Œç ”ç©¶ï¼›è€Œä¸”ï¼Œæœ€é‡è¦çš„æ˜¯ï¼Œå¼ºè°ƒå¯è®¿é—®æ€§ï¼Œä»¥ä¾¿å¬åˆ°å„ç§æ‚£è€…çš„å£°éŸ³ã€‚å¯è®¿é—®æ€§å¢žå¼ºåŠŸèƒ½åŒ…æ‹¬å¯¹å¹³å°çš„åŸºæœ¬åŠŸèƒ½ä»¥åŠMSä¿¡å·ç ”ç©¶åº”ç”¨ç¨‹åºçš„ç‰¹å®šç ”ç©¶è®¾è®¡çš„æ›´æ”¹ã€‚ &lt;/p>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/>;å› ä¸ºè¿™å°†æ˜¯ä¸€ä¸ªç‚¹ï¼Œå®ƒå°†åŒæ—¶ç”ŸæˆiOSå’ŒAndroidåº”ç”¨ç¨‹åºï¼Œä»Žè€Œå‡å°‘æ”¯æŒå¤šä¸ªå¹³å°æ‰€éœ€çš„å·¥ä½œã€‚ Flutterè¿˜æä¾›&lt;a href=&quot;https://docs.flutter.dev/tools/hot-reload&quot;>; hot-reloading &lt;/a>;ï¼Œå®ƒå…è®¸å¼€å‘äººå‘˜æž„å»ºï¼†amp;å¿«é€Ÿé¢„è§ˆåŠŸèƒ½ã€‚è¯¥åº”ç”¨ç¨‹åºä¸­çš„è®¾è®¡ç³»ç»Ÿåˆ©ç”¨æ­¤åŠŸèƒ½æä¾›äº†ä¸€ä¸ªä¸­å¿ƒç‚¹ï¼Œå“ç‰Œï¼†amp; amp; amp; amp;è¯¥åº”ç”¨ç¨‹åºçš„ä¸»é¢˜å¯ä»¥æ›´æ”¹ä»¥ç¬¦åˆæ–°ç ”ç©¶çš„åŸºè°ƒå¹¶ç«‹å³é¢„è§ˆã€‚åº”ç”¨ç¨‹åºä¸­çš„æ¼”ç¤ºçŽ¯å¢ƒè¿˜åˆ©ç”¨æ­¤åŠŸèƒ½æ¥å…è®¸å¼€å‘äººå‘˜åœ¨å…¶æœºå™¨ä¸Šæœ¬åœ°å˜²ç¬‘å’Œé¢„è§ˆé—®å·ã€‚æ ¹æ®æˆ‘ä»¬çš„ç»éªŒï¼Œè¿™åœ¨A/Bæµ‹è¯•UXä»¥åŠé—®é¢˜çš„æ ¼å¼å’ŒæŽªè¾žä¸­ä¸Žä¸´åºŠåŒ»ç”Ÿç›¸å¤„çš„æ ¼å¼å’ŒæŽªè¾žä¸€ç›´å¾ˆèŠ‚çœã€‚ &lt;/p>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/>;æˆ‘ä»¬è¿›è¡Œäº†å‡ ç§å¯ç”¨æ€§å¢žå¼ºï¼š&lt;/p>; &lt;ol>; &lt;li>; Lightï¼†amp;é»‘æš—ä¸»é¢˜æ”¯æŒ&lt;/li>; &lt;li>;ç²—ä½“æ–‡æœ¬ï¼†amp;å¯å˜å­—ä½“å¤§å°&lt;/li>; &lt;li>;é«˜å¯¹æ¯”åº¦æ¨¡å¼&lt;/li>; &lt;li>;æé«˜ç”¨æˆ·å¯¹å¯è®¿é—®æ€§è®¾ç½®çš„è®¤è¯†å› æ­¤ï¼Œå¿…é¡»æ”¯æŒæ·±è‰²ä¸»é¢˜åŠŸèƒ½ï¼Œä»¥ä½¿ç»å¸¸ä½¿ç”¨ç ”ç©¶åº”ç”¨ç¨‹åºæ›´å®¹æ˜“ã€‚æŸäº›å°æˆ–è½»çš„æ–‡æœ¬å…ƒç´ å¯¹äºŽæœ‰è§†åŠ›éšœç¢çš„ç”¨æˆ·æ¥è¯´æ˜¯éš¾ä»¥è¾¨è®¤çš„ï¼Œå› æ­¤æˆ‘ä»¬æ·»åŠ äº†1ï¼‰å¤§èƒ†æ–‡æœ¬å’Œå¯¹è¾ƒå¤§å­—ä½“å°ºå¯¸çš„æ”¯æŒä»¥åŠ2ï¼‰é«˜å¯¹æ¯”åº¦çš„é¢œè‰²ç¤ºæ„å›¾ã€‚ä¸ºäº†ç¡®ä¿æ˜“äºŽæŸ¥æ‰¾çš„å¯è®¿é—®æ€§è®¾ç½®ï¼Œæˆ‘ä»¬æ”¾ç½®äº†ä¸€ä¸ªåœ¨åº”ç”¨ç¨‹åºç¬¬ä¸€æ¬¡å¯åŠ¨æœŸé—´ä»‹ç»çš„ä»‹ç»æ€§çš„ä¸€æ¬¡æ€§å±å¹•ï¼Œè¯¥å±å¹•å°†ç›´æŽ¥å°†ç”¨æˆ·å¸¦å…¥å…¶ç³»ç»Ÿå¯è®¿é—®æ€§è®¾ç½®ã€‚ &lt;/p>; &lt;div style =â€œçº¿è·¯é«˜ï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/div>; &lt;h3>;ç ”ç©¶å¯è®¿é—®æ€§å¢žå¼º&lt;/h3>; &lt;p>;ä½¿ç ”ç©¶æœ¬èº«æ›´å®¹æ˜“ä¸Žè®¤çŸ¥è¶…è´Ÿè·ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä»¥ä¸‹æ›´æ”¹ï¼š&lt;/p>; &lt;ol>; &lt;li>;æ¾„æ¸…äº†å…¥èŒè¿‡ç¨‹&lt;/li>; &lt;li>;æ”¹è¿›çš„é—®å·è®¾è®¡&lt;/li>; &lt;/ol>; &lt;/ol>; &lt;p>;é¦–å…ˆï¼Œæˆ‘ä»¬æ¾„æ¸…äº†åœ¨æ¿è½½è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡å‘ç”¨æˆ·ä»‹ç»é¦–æ¬¡æ‰“å¼€åº”ç”¨ç¨‹åºæ—¶çš„æ‰€éœ€æ­¥éª¤åˆ—è¡¨ï¼Œä»¥å‡å°‘æ··ä¹±å’Œå‚ä¸Žè€…çš„ä¸‹é™ã€‚ &lt;/p>; &lt;p>;åº”ç”¨ç¨‹åºä¸­çš„åŽŸå§‹é—®å·è®¾è®¡ä»¥å¡ç‰‡æ ¼å¼æå‡ºäº†æ¯ä¸ªé—®é¢˜ï¼Œè¯¥æ ¼å¼åˆ©ç”¨å±å¹•çš„ä¸€éƒ¨åˆ†æ¥èŽ·å¾—é˜´å½±å’Œå¡çš„æ·±åº¦æ•ˆæžœã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¤äººæ„‰å¿«çš„ç¾Žå­¦ï¼Œä½†æ˜¯åœ¨ä¼˜å…ˆå¯è®¿é—®æ€§çš„åº”ç”¨ä¸­ï¼Œè¿™äº›è§†è§‰å…ƒç´ é™åˆ¶äº†å±å¹•ä¸Šå¯ç”¨çš„ç©ºé—´ã€‚å› æ­¤ï¼Œå½“ä½¿ç”¨æ›´è¾ƒå¤§çš„å­—ä½“å¤§å°æ—¶ï¼Œä¼šæœ‰æ›´é¢‘ç¹çš„å•è¯æ–­è£‚ï¼Œä»Žè€Œé™ä½Žäº†å¯è¯»æ€§ã€‚æˆ‘ä»¬ä»…é€šè¿‡åˆ é™¤å¡è®¾è®¡å…ƒç´ å¹¶ä½¿ç”¨æ•´ä¸ªå±å¹•æ¥è§£å†³æ­¤é—®é¢˜ï¼Œä»Žè€Œå¯ä»¥æ›´å¥½åœ°ä½¿ç”¨æ›´å¤§çš„å­—ä½“å¤§å°è§†è§‰æ•ˆæžœã€‚ &lt;/p>; &lt;br />; &lt;h2>; MSä¿¡å·åŽŸåž‹ç ”ç©¶&lt;/h2>; &lt;p>;æµ‹è¯•è¿™äº›å˜åŒ–çš„å¯ç”¨æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é‡æ–°è®¾è®¡çš„å¹³å°åˆ›å»ºä¸€ä¸ªåä¸ºMS Signalsçš„åŽŸåž‹ç ”ç©¶åº”ç”¨ç¨‹åºï¼Œè¯¥åº”ç”¨ç¨‹åºä½¿ç”¨è°ƒæŸ¥ï¼Œè¯¥åº”ç”¨ç¨‹åºä½¿ç”¨è°ƒæŸ¥æ”¶é›†æœ‰å…³å‚ä¸Žè€…ä¸ŽMSç›¸å…³ç—‡çŠ¶çš„ä¿¡æ¯ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style =â€œ text-alignï¼šä¸­å¿ƒ;â€>; &lt;a href =â€œ https://blogger.googleusercontent.com/img/r29vz2xl/avvz2xl/avvxseikbf3gdeujdeujdeuujgdeuujhricfppppppp-sjyhfrzfyc3xyqublylj f.7a3fdyqubim lij qubim lij qubimirigirigirigirigirigirigimigim Qubj7a3fdyqubj7a3fdyeq7a3fdyequbj7a3fdyequbj7a3fdyeq 6ZJFK9ABPIFJCTOEYIOJBPHF7QDQSCOBWC7YPQ2BELNTYTKFKYYGZM-H6WPRCYLA4QQLTTVASMD_B2LXESMD_B2LXXE47OXFBZJ47RGBZJ4RGBZJ4RGBZLW7IFUQT3XLZCOKCOKHZB/SSS17660 =â€œè¾¹è· - å·¦ï¼šè‡ªåŠ¨;è¾¹ç¼˜æƒåˆ©ï¼šè‡ªåŠ¨;â€>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 1728â€ data-Original-width =â€œ 1760â€ 1760â€œé«˜åº¦=â€ 628â€œ src =â€ src =â€œ https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEikbf3GdEuJptK8hRicFp-sjYhfRZfYc3XyqEf7A3FDJZ_XTiDOBeMQXUYAtO5ZNoP7eI9GJRJS6zJfK9abPIFJCtOEYIOjBphF7qDqSCObwC7YpQ2BeLNTYtKFKyYGzM-h6wPrcyLA4QqLttVAsMd_B2lXxE47OxfBZJ4RgqLW7IfUqT3xlzcOKh2w_hzB/w640-h628/MSSignals.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>; &lt;em style =â€œ text-alignï¼šleft;â€>; msä¿¡å·åº”ç”¨ç¨‹åºå±å¹•æˆªå›¾ã€‚&lt;/em>; &lt;/em>; &lt;/td>; &lt;/tr >; &lt;/tbody>; &lt;/table>; &lt;ï¼ -  &lt;table align =â€œ centerâ€ cellpadding =â€œ 0â€ cellspacing =â€œ 0â€ class =â€œ tr-caption-containerâ€æ ·å¼=â€œ margin-Leftï¼šauto; auto; Margin-Rightï¼šauto;â€œ>; &lt;tbody>; &lt;tr>; &lt;td style =â€ text-alignï¼šcenter;â€œ>; &lt;a href =â€ httpsï¼š//blogger.googleuserercontent.com/img/img/r29vz2xl/r29vz2xl/avvz2xl/avvxsejecbggkdha7hdha7hdha7hdha7hdha7hdha7hdha7hdha7hdha7hdhdha7hdhdhdqunbbg-- dPx4AEoZfWd1SMYdzdZglFFkE_LbHA-_-rzwU1o1VbOvHE5aLMngCXs5AkCWp4jez0glZ1s7HFzK0deFGodiUWlj5xXhWQYGLEXOk94h2NlaSwjizkaY6jJgZfnDlngu69r4O01ifsiLs5KfOd48G7wSSjvL5AYWbN9oiB4d79k7/s1999/image2.png&quot; style=&quot;margin-left: auto;è¾¹ç¼˜æƒåˆ©ï¼šè‡ªåŠ¨;â€>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 1971â€ data-eriginal-width =â€œ 1999â€ height =â€œ 632â€ src =â€œ https://blogger.googleusercercontent.com /img/b/R29vZ2xl/AVvXsEjeCBgKDha7HDQNbbG-dPx4AEoZfWd1SMYdzdZglFFkE_LbHA-_-rzwU1o1VbOvHE5aLMngCXs5AkCWp4jez0glZ1s7HFzK0deFGodiUWlj5xXhWQYGLEXOk94h2NlaSwjizkaY6jJgZfnDlngu69r4O01ifsiLs5KfOd48G7wSSjvL5AYWbN9oiB4d79k7/w640-h632/image2.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot; tr-captionâ€œ style =â€ text-alignï¼šcenter;â€œ>; &lt;em style =â€ text-alignï¼šleft;â€œ>; msä¿¡å·åº”ç”¨ç¨‹åºå±å¹•æˆªå›¾ã€‚&lt;/em>; &lt;/td>; &lt;/td>; &lt;/tr>; &lt;/tr>; &lt;/tbody>; &lt;&lt; /table>;  - >; &lt;div style =â€œçº¿è·¯é«˜ï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/div>; &lt;h3>; MSç ”ç©¶åº”ç”¨ç¨‹åºè®¾è®¡&lt;/h3>; &lt;p>;ä½œä¸ºç¬¬ä¸€æ­¥ç ”ç©¶ä¿¡æ¯ï¼Œè¦æ±‚å‚ä¸Žè€…å®Œæˆèµ„æ ¼å’Œç ”ç©¶ç†è§£é—®å·ï¼Œä»¥ç¡®ä¿ä»–ä»¬å·²ç»é˜…è¯»äº†æ½œåœ¨çš„æ¼«é•¿ç ”ç©¶å‚ä¸Žæ¡æ¬¾ã€‚è¿™å¯èƒ½åŒ…æ‹¬ä¾‹å¦‚â€œåœ¨å“ªä¸ªå›½å®¶å¯ç”¨ï¼Ÿâ€æˆ–â€œâ€æˆ–â€œâ€ç­‰é—®é¢˜ã€‚ä½ èƒ½é€€å‡ºç ”ç©¶å—ï¼Ÿâ€è¿™æ ·çš„éƒ¨åˆ†åœ¨å¤§å¤šæ•°å¥åº·ç ”ç©¶ä¸­éƒ½æ˜¯å¸¸è§çš„ï¼Œå®ƒå¾€å¾€æ˜¯å‚ä¸Žè€…çš„ç¬¬ä¸€ä¸ªä¸‹é™ç‚¹ã€‚ &lt;/p>; &lt;p>;ä¸ºäº†æœ€å¤§ç¨‹åº¦åœ°å‡å°‘åœ¨æ­¤æ—©æœŸé˜¶æ®µçš„ç ”ç©¶ä¸‹é™ï¼Œæˆ‘ä»¬å°†èµ„æ ¼æµ‹è¯•ç®€è¦ä»‹ç»å¹¶åæ˜ äº†æ­£ç¡®çš„ç­”æ¡ˆï¼Œä»¥å›žé¦ˆå‚ä¸Žè€…çš„ç†è§£æµ‹è¯•ã€‚è¿™æœ‰åŠ©äºŽæœ€å¤§ç¨‹åº¦åœ°å‡å°‘ç”¨æˆ·å¯èƒ½éœ€è¦æµè§ˆåˆå§‹èµ„æ ¼é—®å·çš„æ¬¡æ•°ï¼Œå¹¶ç¡®ä¿å¯¹ç ”ç©¶åè®®çš„é‡è¦æ–¹é¢è¿›è¡Œæ¸…æ¥šçš„æ¬¡æ•°ã€‚ &lt;/p>; &lt;p>;æˆåŠŸå…¥å­¦åŽï¼Œå‚ä¸Žè€…è¢«å¸¦åˆ°ä¸»è¦çš„åº”ç”¨ç¨‹åºè§†å›¾ï¼Œå…¶ä¸­åŒ…å«ä¸‰é¡µï¼š&lt;/p>; &lt;ul>; &lt;li>; &lt;li>; &lt;strong>;æ´»åŠ¨ï¼š&lt;/strong>; &lt;br />;é¡µé¢åˆ—å‡ºäº†å‚ä¸Žè€…å¯ç”¨çš„é—®å·ï¼Œæ˜¯ä»–ä»¬å¤§éƒ¨åˆ†æ—¶é—´æ‰€èŠ±è´¹çš„åœ°æ–¹ã€‚é—®å·çš„é¢‘çŽ‡å„ä¸ç›¸åŒ - æœ‰äº›æ˜¯ä¸ºäº†æ”¶é›†ç—…å²è€Œåˆ›å»ºçš„ä¸€æ¬¡æ€§è°ƒæŸ¥ï¼Œè€Œå¦ä¸€äº›åˆ™æ˜¯æ¯å¤©ï¼Œæ¯å‘¨æˆ–æ¯æœˆé‡å¤çš„ï¼Œå…·ä½“å–å†³äºŽä»–ä»¬æ­£åœ¨æŽ¢ç´¢çš„ç—‡çŠ¶æˆ–åŒºåŸŸã€‚åœ¨ä¸€æ¬¡æ€§è°ƒæŸ¥ä¸­ï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªé—®é¢˜ä¸Šéƒ½æä¾›ä¸€ä¸ªè®¡æ•°å™¨ï¼Œå‘ç”¨æˆ·å‘å‡ºä¿¡å·ï¼Œå¹¶å‰©ä¸‹å¤šå°‘ä¸ªé—®é¢˜ï¼Œç±»ä¼¼äºŽèµ„æ ¼å’Œç†è§£æ­¥éª¤ä¸­çš„é—®å·ã€‚ &lt;/li>; &lt;li>; &lt;strong>;ä»ªè¡¨æ¿ï¼š&lt;/strong>; &lt;br />;ç¡®ä¿å‚ä¸Žè€…æ¢å¤äº†ä¸€äº›ä¸œè¥¿ï¼Œä»¥æ¢å–ä»–ä»¬åœ¨ç ”ç©¶ä¸­è¾“å…¥çš„ä¿¡æ¯ï¼Œä»ªè¡¨æ¿åŒºåŸŸä»‹ç»äº†ä»–ä»¬åœ¨å›¾ä¸­çš„å“åº”æ‘˜è¦æˆ–é¥¼å›¾å½¢å¼ã€‚å‚ä¸Žè€…å¯ä»¥å°†è¿™äº›æ•°æ®æ˜¾ç¤ºç»™ä»–ä»¬çš„æŠ¤ç†æä¾›è€…ï¼Œä»¥æ‘˜è¦åœ¨è¿‡åŽ»6ä¸ªæœˆä¸­çš„çŠ¶å†µï¼Œè¿™æ˜¯å¯¹å½“ä»Šè®¸å¤šäººé‡‡ç”¨çš„ä¼ ç»Ÿç¬”å’Œçº¸å¼ æ–¹æ³•çš„æ”¹è¿›ã€‚ &lt;/li>; &lt;li>; &lt;strong>;èµ„æºï¼š&lt;/strong>; &lt;br />;ä¸€ç»„æœ‰ç”¨çš„é“¾æŽ¥ï¼Œå¸®åŠ©æ–‡ç« å’Œä¸ŽMSç›¸å…³çš„å¸¸è§é—®é¢˜ã€‚ &lt;/li>; &lt;/ul>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/div>; &lt;h3>;é—®å·è®¾è®¡&lt;/h3>; &lt;p>;ï¼Œå› ä¸ºéœ€è¦ç»å¸¸è¾“å…¥æ•°æ®å¯ä»¥é¢†å¯¼ä¸ºäº†è®¤çŸ¥è¶…è´Ÿè·ï¼Œå‚ä¸Žè€…ä¸‹é™å’Œæ•°æ®è´¨é‡ä¸ä½³ï¼Œæˆ‘ä»¬é€šè¿‡ä¸¤ç§æ–¹å¼å‡è½»äº†è´Ÿæ‹…ï¼š&lt;/p>; &lt;ol>; &lt;li>;æˆ‘ä»¬å°†å¤§åž‹é—®å·åˆ†è§£ä¸ºè¾ƒå°çš„é—®å·ï¼Œå¯¼è‡´6æ¬¡æ¯æ—¥è°ƒæŸ¥ï¼Œå…¶ä¸­åŒ…å«3-5æ¯ä¸ªé—®é¢˜æ˜¯å¤šé¡¹é€‰æ‹©çš„é—®é¢˜ï¼Œå¹¶ä¸”ä¸Žå•ä¸ªç—‡çŠ¶æœ‰å…³ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬æ€»å…±æ¶µç›–äº†20ç§ä¸»è¦ç—‡çŠ¶ï¼Œå¹¶ä»¥ç±»ä¼¼çš„æ–¹å¼ä»‹ç»äº†ä¸´åºŠåŒ»ç”Ÿåœ¨ä¸´åºŠçŽ¯å¢ƒä¸­å¦‚ä½•æå‡ºè¿™äº›é—®é¢˜çš„æ–¹å¼ã€‚&lt;/li>; &lt;li>;æˆ‘ä»¬ç¡®ä¿åœ¨æ­¤å¤„å¯ä»¥è½»æ¾åœ°åœ¨&lt;/li>; &lt;/ol>; &lt;p>;åœ¨è®¾è®¡è°ƒæŸ¥å†…å®¹æ—¶ï¼Œæˆ‘ä»¬ä¸Žç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿå’Œç ”ç©¶äººå‘˜å¯†åˆ‡åˆä½œï¼Œä»¥æœ€ç»ˆç¡®å®šæŽªè¾žå’Œå¸ƒå±€ã€‚è™½ç„¶è¯¥é¢†åŸŸçš„ç ”ç©¶é€šå¸¸ä½¿ç”¨&lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/likert_scale&quot;>; Likert Scale &lt;/a>;æ”¶é›†ç—‡çŠ¶ä¿¡æ¯ï¼Œä½†æˆ‘ä»¬å®šä¹‰äº†æ›´ç›´è§‚çš„æ‚è¯­é‡è¡¨æ¥æä¾›æ›´å¥½çš„ä½“éªŒå¯¹äºŽè·Ÿè¸ªç–¾ç—…çš„å‚ä¸Žè€…ä»¥åŠä¸´åºŠåŒ»ç”Ÿæˆ–ç ”ç©¶äººå‘˜ï¼Œè§‚å¯Ÿç–¾ç—…å²ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†è§‰é—®é¢˜çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ²¡æœ‰è¦æ±‚å‚ä¸Žè€…ä»¥1åˆ°10çš„æ¯”ä¾‹è¯„ä¼°ä»–ä»¬çš„ç—‡çŠ¶ï¼Œè€Œæ˜¯æå‡ºäº†ä¸€ä¸ªå¤šé¡¹é€‰æ‹©é—®é¢˜ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†ä»–ä»¬å¯èƒ½é‡åˆ°çš„å¸¸è§è§†åŠ›é—®é¢˜ã€‚ &lt;/p>; &lt;p>;è¿™ç§è¯¦ç»†çš„é‡è¡¨å¯ä»¥é€šè¿‡åŒ…æ‹¬æœ‰åŠ©äºŽæ›´æ¸…æ¥šåœ°å®šä¹‰ç—‡çŠ¶çš„ä¸Šä¸‹æ–‡æ¥æ›´å‡†ç¡®åœ°è·Ÿè¸ªæ‚£è€…çš„ç—‡çŠ¶ã€‚è¿™ç§æ–¹æ³•è¿˜å…è®¸ç ”ç©¶äººå‘˜å›žç­”è¶…å‡ºç—‡çŠ¶ç›¸å…³æ€§çš„é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¯¹äºŽè§†åŠ›é—®é¢˜ï¼Œä½¿ç”¨è¯¦ç»†é‡è¡¨æ”¶é›†çš„æ•°æ®ä¼šå‘ç ”ç©¶äººå‘˜æ­ç¤º&lt;a href=&quot;https://www.webmd.com/eye-health/nystagmus&quot;>; nystagmus &lt;/a>;ä¸ŽåŒè§†åŠ›ç›¸æ¯”ï¼ŒMSã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQHtaxn1OL9zKbNnPfUkfEmXV8zb2dR7HJaTezZrNyhN8D_V35gfHaLtQNjoBLBxIE5lP9eiB-mxXQ7FqxbSB1d3tgTOB7fA7o6boudBmPzfiQ8CuKc117fBIFLuzem5Lo8938LqpQkxofoAL5bnpMD3hI4vOJNzHbbuB8b5RqoIP_zcD0dpr7IL9w3ysa/s1780/MSSignals-2.png&quot; style =â€œè¾¹è· - å·¦ï¼šè‡ªåŠ¨;è¾¹ç¼˜æƒåˆ©ï¼šè‡ªåŠ¨;â€>; &lt;img border =â€œ 0â€ data-Foriginal-height =â€œ 1754â€ data-Original-width =â€œ 1780â€ height =â€œ 630â€ src =â€œ src =â€ https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQHtaxn1OL9zKbNnPfUkfEmXV8zb2dR7HJaTezZrNyhN8D_V35gfHaLtQNjoBLBxIE5lP9eiB-mxXQ7FqxbSB1d3tgTOB7fA7o6boudBmPzfiQ8CuKc117fBIFLuzem5Lo8938LqpQkxofoAL5bnpMD3hI4vOJNzHbbuB8b5RqoIP_zcD0dpr7IL9w3ysa/w640-h630/MSSignals-2.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>; &lt;em style =â€œ text-alignï¼šleft;â€>;å¹¶æŽ’æ¯”è¾ƒä¸Žå·¦ä¾§çš„æŽå…‹ç‰¹ç§¤ï¼Œç„¶åŽå³ä¾§çš„è¯¦ç»†è§„æ¨¡ã€‚&lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;ï¼ -  &lt;table align =â€œ centerâ€ cellpadding =â€œ 0â€ cellSpacing =â€œ 0â€ class =â€œ tr-caption-containerâ€œ style =â€è¾¹ç¼˜å·¦å·¦å³ï¼šauto; Margin-Rightï¼šauto;â€œ>; &lt;tbody>; &lt;tr>; &lt;td style =â€ text-alignï¼šcenter;â€œ>; &lt;a href =â€ httpsï¼š//blogger.googleusercercentent.com/img/r29vz2xxl/r29vz2xl/avvz2xl/avvxsejei2le2le2le2le2ze_brlzom7jfhmm7jfhmm7jfhmmq6bmq6bmq6bmq6bblmqumq6bmq6bmq6bmq6B ubutbrt6ephhnnldxcra6atiDpl9pf6me4qfdfbmejtnxeohyphenephenermineiunldath5bmnboov7kotqppsnjyqpsnjyqpsnjyqesgxbxbxbxbxnfthlutthlutthlut thlut thlut S1999/image1.pngâ€œ style =â€ä¿è¯é‡‘å·¦ï¼šè‡ªåŠ¨;è¾¹ç¼˜æƒåˆ©ï¼šauto;â€œ>; &lt;img border =â€œ 0â€ data-original-height =â€œ 1901â€ data-eriginal-width =â€œ 1999â€ height =â€œ 608â€ src =â€œ https://blogger.googleusercontent.com /img/b/R29vZ2xl/AVvXsEjei2lEyI2z_brlZOM7JFHMQ6B0HniXXoIP2dMU61PBDA2f79eRYpMSPXuButbrt6epHhNNLdxcRa6AtIdPl9PF6mE4QFdFbMEJTNxEOhyphenhyphenERmIniUNLDaTH5BMNBOOv7kOTQpsNjYqEsGxbXnftHlUtbznCm377vz6nDJyC_mLSJTH_LVGU91JgDqGeCr6r/w640-h608/image1.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= â€œ text-alignï¼šcenter;â€>; &lt;em style =â€œ text-alignï¼šå·¦;â€>;å¹¶æŽ’æ¯”è¾ƒå·¦ä¾§çš„æŽå…‹ç‰¹åˆ»åº¦ï¼Œå³ä¾§æ˜¯å†—é•¿çš„æ¯”ä¾‹ã€‚&lt;/em>; &lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>;  - >; &lt;h2>;ä¸“æ³¨äºŽå¯è®¿é—®æ€§&lt;/h2>; &lt;p>;åŸºäºŽç§»åŠ¨çš„ç ”ç©¶é€šå¸¸ä¼šç»™æ‚£æœ‰æ…¢æ€§æ¡ä»¶çš„å‚ä¸Žè€…å¸¦æ¥å…¶ä»–æŒ‘æˆ˜ï¼šæ–‡æœ¬å¾ˆéš¾é˜…è¯»ï¼Œé¢œè‰²çš„å¯¹æ¯”å¯èƒ½ä½¿å¾—å¾ˆéš¾çœ‹åˆ°æŸäº›ä¿¡æ¯ï¼Œæˆ–è€…åœ¨æ»šåŠ¨é¡µé¢ä¸Šæ»šåŠ¨å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™å¯èƒ½å¯¼è‡´å‚ä¸Žè€…ä¸‹è½¦ï¼Œå¦‚æžœç»åŽ†æ›´å¤šçš„äººï¼Œè¿™å¯èƒ½ä¼šäº§ç”Ÿåè§çš„æ•°æ®é›†ç–¾ç—…çš„é«˜çº§å½¢å¼æ— æ³•æä¾›æ•°æ®ã€‚ &lt;/p>; &lt;p>;ä¸ºäº†é˜²æ­¢æ­¤ç±»é—®é¢˜ï¼Œæˆ‘ä»¬åŒ…æ‹¬ä»¥ä¸‹å¯è®¿é—®æ€§åŠŸèƒ½ï¼š&lt;/p>; &lt;ul>; &lt;li>;åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éƒ½é‡‡ç”¨äº†ç›²ç›®è®¿é—®çš„é…è‰²æ–¹æ¡ˆã€‚è¿™åŒ…æ‹¬æ”¹å–„å…³é”®æ–‡æœ¬å’Œé‡è¦çš„å…¶ä»–ä¿¡æ¯ä¹‹é—´çš„å¯¹æ¯”åº¦ï¼Œå¦åˆ™è¿™äº›ä¿¡æ¯å¯èƒ½ä¼šä»¥è¾ƒå°çš„å­—ä½“å’Œè¤ªè‰²çš„æ–‡æœ¬é¢œè‰²è¡¨ç¤ºã€‚&lt;/li>; &lt;li>;æˆ‘ä»¬é€šè¿‡æ”¾ç½®æ‰€æœ‰æŒ‰é’®å‡å°‘äº†è®¿é—®å…³é”®æŽ§åˆ¶æ‰€éœ€çš„ç§»åŠ¨é‡é è¿‘é¡µé¢åº•éƒ¨ï¼Œå¹¶ç¡®ä¿å¼¹å‡ºçª—å£å¯ä»¥ä»Žå±å¹•çš„åº•éƒ¨æŽ§åˆ¶ã€‚&lt;/li>; &lt;/ul>; &lt;p>;æµ‹è¯•MSä¿¡å·çš„å¯è®¿é—®æ€§ï¼Œæˆ‘ä»¬ä¸Ž&lt;a href =åˆä½œhttps://www.nationalmssociety.org/&quot;>; national MS Society &lt;/a>;æ‹›å‹Ÿå‚ä¸Žè€…è¿›è¡Œç”¨æˆ·ä½“éªŒç ”ç©¶ã€‚ä¸ºæ­¤ï¼Œåä¼šå‘å…¶æˆå‘˜å‘å‡ºäº†å‘¼åï¼Œè¦æ±‚9åå—è®¿è€…æµ‹è¯•å„ç§åº”ç”¨ç¨‹åºæµã€‚å¤§å¤šæ•°è¡¨æ˜Žï¼Œä»–ä»¬å¸Œæœ›ä¸€ç§æ¯”ç›®å‰çš„æ–¹æ³•æ›´å¥½çš„æ–¹æ³•æ¥è·Ÿè¸ªç—‡çŠ¶æ•°æ®ï¼Œä»–ä»¬è®¤ä¸ºMSä¿¡å·æ˜¯ä¸€ç§ç‹¬ç‰¹è€Œæœ‰ä»·å€¼çš„å·¥å…·ï¼Œå¯ä»¥æé«˜å…¶ç—‡çŠ¶è·Ÿè¸ªçš„å‡†ç¡®æ€§ï¼Œå¹¶ä¸”ä»–ä»¬å¸Œæœ›å…±äº«ä»ªè¡¨æ¿ä¸Žä»–ä»¬çš„åŒ»ç–—ä¿å¥æä¾›è€…çš„è§†å›¾ã€‚ &lt;/p>; &lt;br />; &lt;h2>;ä¸‹ä¸€æ­¥&lt;/h2>; &lt;p>;æˆ‘ä»¬æƒ³é¼“åŠ±æ‰€æœ‰äººä½¿ç”¨&lt;a href =â€œ https://github.com/googleclecleclodplatform/fda-mystudies-flutter â€œ>;å¼€æº&lt;/a>;å¹³å°å¼€å§‹å»ºç«‹å¹¶è¿è¡Œè‡ªå·±çš„ç ”ç©¶ã€‚æˆ‘ä»¬æ­£åœ¨åŠªåŠ›åˆ›å»ºä¸€ç»„æ ‡å‡†çš„ç ”ç©¶æ¨¡æ¿ï¼Œè¿™äº›æ¨¡æ¿å°†ç»“åˆæˆ‘ä»¬ä»Žä¸Šé¢å­¦åˆ°çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬å¸Œæœ›å°½å¿«é‡Šæ”¾è¿™äº›æ¨¡æ¿ã€‚æœ‰å…³ä»»ä½•é—®é¢˜ï¼Œè¯„è®ºæˆ–é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„&lt;a href=&quot;https://goo.gle/ms-signals&quot;>;èµ„æºé¡µé¢&lt;/a>;ã€‚ &lt;/p>; &lt;/content>; &lt;link href =â€œ http://blog.research.google/feeds/555467756775652504697591/comments/comments/default/default/defaultâ€ rel =â€œ reque =â€ reque =â€œ requeâ€ â€œ/>; &lt;link href =â€ http://blog.research.google/2023/11/enabling-large-scale-scale-health-scale-health-studies-for.html#comment-form-comment-formâ€œ rel =â€ rel =â€œ requies =â€ title =â€œ 0æ³¨é‡Šâ€ â€œ type =â€ text/htmlâ€œ/>; &lt;link href =â€ http://www.blogger.com/feeds/8474926331452026626/posts/posts/posts/default/555467756775652504697597597597591 >; &lt;link href =â€œ http://www.blogger.com/feeds/8474926331452026626/posts/posts/default/554677565652504697591â€ /blog.research.google/2023/11/enabling-large-scale-scale-health-nealth-studies-for.htmlâ€œ rel =â€œæ›¿ä»£â€ title =â€œå¯ç”¨ç ”ç©¶ç¤¾åŒºçš„å¤§è§„æ¨¡å¥åº·ç ”ç©¶â€ â€œ/>; &lt;ause>; &lt;name>; Google AI &lt;/name>; &lt;uri>; http://www.blogger.com/profile/12098626265147775266161 &lt;/uri>; &lt;emage>; &lt;emage>; noreply@blogger@blogger.com &lt;/email>;å›¾ç‰‡é«˜åº¦=â€œ16â€rel=â€œhttp://schemas.google.com/g/2005#thumbnailâ€src=â€œhttps://img1.blogblog.com/img/b16-rounded.gifâ€å®½åº¦=â€œ16â€ â€œ>; &lt;/gdï¼šimage>; &lt;/ä½œè€…>; &lt;åª’ä½“ï¼šthumbnail height =â€œ 72â€ url =â€œ https://blogger.googleusercontent.com/img/b/r29vz2xl/avvz2xl/avvxsehdecrv8m_gtaixn2bwuwshbbllclclclclclcte n2bwuwshblj6gpopo n. mfchoifnzgb_mn4ipoxy_5y1s8m3rup_08hodtoz87soquh2wfjh7khfkzbxyylb0c1iizfqvcvcqvcvcq vcvcq vcq vcvcq qun-laebhjd96wd96wty9wtylibs03ejrteovnayrteovnayrteovnayrteovnayrteovnayrteovnayrteovnayrwpbhb-a77rytalfcfcfcfcfcfcfcfcfcfcfcfcj7rrytalfcjy7rytalfcjjnrytalrfcjjy7rytalfjjjy7ryribs c/mssignals-hero.jpgâ€œ width =â€ 72â€œ xmlnsï¼šåª’ä½“=â€ httpï¼š//search.yahoo.com/mrss/â€œ>; &lt;/åª’ä½“ï¼šthumbnail>; &lt;thr>; &lt;thr>; &lt;thrï¼šthr>; 0 &lt;/thrï¼šthrï¼šthrï¼šthr>; &lt;/entry>; &lt;entry>; &lt;id>;æ ‡ç­¾ï¼šblogger.comï¼Œ1999ï¼šBlog-8474926331452026626.POST-7987071997777787277 &lt;/id>; &lt;/id>; &lt;/id>; &lt;å‡ºç‰ˆ>; 2023-11-09T14ï¼š23ï¼š00.000-0008ï¼š00.000-08ï¼š008ï¼š008ï¼š008ï¼š008ï¼š008ï¼š008ï¼š00 &lt;/å‡ºç‰ˆæ›´æ–°>; 2023-11-09T14ï¼š23ï¼š38.431-08ï¼š00 &lt;/updated>; &lt;ç±»åˆ«æ–¹æ¡ˆ=â€œ http://www.blogger.com/atom/atom/ns#â€ç±»åˆ«æ–¹æ¡ˆ=â€œ http://www.blogger.com/atom/ns#â€ term =â€œ healthâ€>; &lt;/category>; &lt;category>; &lt;category scheme =â€œ http://www.blogger.com/atom/ns#â€ term =â€œ rai-hctäº®ç‚¹â€>; &lt;/actory>; &lt;title type =â€œ textâ€>;åœ¨Googleç ”ç©¶ä¸­è´Ÿè´£çš„AIï¼šAI Researchï¼ˆCAIRï¼‰ä¸­çš„ä¸Šä¸‹æ–‡&lt;/stitle>; &lt;content type =â€œ htmlâ€>; &lt;span class =â€œ byline-author&quot;>;Posted by Katherine Heller, Research Scientist, Google Research, on behalf of the CAIR Team&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjN3mIK7184k0E4B4Pddafelrcf4yEqd1wTOxyK5LZlxKL8dFWwbEyATjS0Zbj8HBdAnIXQ40fVedg4O5oUi5_fVvOvKRQWhgIX05olZkb9YakVdRLXus3b9Pzze5oHu32X0VUpoykEvGwbZk9W2lEIJ8jUMlgzyML0yFFsyBbpbAUZgBk6TSli7bRaNQRs/s1100 /cair-hero.jpgâ€œ style =â€ displayï¼šnone;â€ />; &lt;p>;äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å’Œç›¸å…³çš„æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æŠ€æœ¯åœ¨æˆ‘ä»¬å‘¨å›´çš„ä¸–ç•Œä¸­è¶Šæ¥è¶Šæœ‰å½±å“åŠ›ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»è€ƒè™‘æˆ‘ä»¬åˆ›é€ æŠ€æœ¯å„ä¸ªæ–¹é¢å¯¹ç¤¾ä¼šå’Œä¸ªäººçš„æ½œåœ¨å½±å“ã€‚å¯¹äºŽè¿™äº›ç›®çš„ï¼ŒAIç ”ç©¶ï¼ˆCAIRï¼‰å›¢é˜Ÿçš„ä¸Šä¸‹æ–‡åœ¨æ•´ä¸ªAIç®¡é“çš„èƒŒæ™¯ä¸‹å¼€å‘äº†æ–°é¢–çš„AIæ–¹æ³•ï¼š&lt;strong>; &lt;/strong>;ä»Žæ•°æ®åˆ°æœ€ç»ˆç”¨æˆ·åé¦ˆã€‚ç”¨äºŽæž„å»ºAIç³»ç»Ÿçš„ç®¡é“é€šå¸¸ä»¥&lt;em>; data &lt;/em>;æ”¶é›†å¼€å§‹ï¼Œç„¶åŽè®¾è®¡A &lt;em>; model &lt;/em>;ä»¥åœ¨è¯¥æ•°æ®ä¸Šè¿è¡Œï¼Œ&lt;em>; &lt;em>; &lt;em>; &lt;em>;çŽ°å®žä¸–ç•Œï¼Œæœ€åŽæ˜¯äººç±»åé¦ˆ&lt;/em>;çš„ç¼–è¯‘å’Œç»“åˆã€‚ CAIRå›¢é˜Ÿçš„å·¥ä½œèµ·æºäºŽå¥åº·é¢†åŸŸï¼ŒçŽ°åœ¨æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå½±å“äº†è¯¥ç®¡é“çš„å„ä¸ªæ–¹é¢ã€‚åœ¨ä¸“é—¨ç ”ç©¶æ¨¡åž‹æž„å»ºçš„åŒæ—¶ï¼Œæˆ‘ä»¬ç‰¹åˆ«å…³æ³¨å…·æœ‰è´£ä»»çš„æž„å»ºç³»ç»Ÿï¼ŒåŒ…æ‹¬å…¬å¹³ï¼Œé²æ£’æ€§ï¼Œé€æ˜Žåº¦å’ŒåŒ…å®¹æ€§ã€‚ &lt;/p>; &lt;a name =&#39;more&#39;>; &lt;/a>; &lt;table align =â€œ centerâ€ cellpadding =â€œ 0â€ cellspacing =â€œ 0â€ class =â€œ tr-caption-containerâ€ style =â€œ Margin-Leftï¼šauto ; margin-rightï¼šauto;â€œ>; &lt;tbody>; &lt;tr>; &lt;td style =â€ text-alignï¼šcenter;â€œ>; &lt;a href =â€ httpsï¼š//blogger.googleusercontent.com/img/r29vz2xl/r29vz2xl/avvxseidxseidxsseidxbmc -Vmh8A8AdqFMHkEIqz5pcp85_vX6uPteEiaF00boHGuUo3M45rtunHL58dOillPI_7Vn3BwxavTGbmPpWcUQorJsjY6x5gh8agM9jbPio8c29iFvYUgVhO1BkEsU5eg133JKfLkcQHN3FteCyeorkzS79e0u7TDig_xCv_B_36UYLfK7gx2pgtQK/s1050/CAIR.png&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;383&quot; data-original-width=&quot;1050 &quot; height=&quot;234&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidxBmC-Vmh8A8AdqFMHkEIqz5pcp85_vX6uPteEiaF00boHGuUo3M45rtunHL58dOillPI_7Vn3BwxavTGbmPpWcUQorJsjY6x5gh8agM9jbPio8c29iFvYUgVhO1BkEsU5eg133JKfLkcQHN3FteCyeorkzS79e0u7TDig_xCv_B_36UYLfK7gx2pgtQK/w640-h234/CAIR.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/ TD>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;h2>;æ•°æ®&lt;/h2>; &lt;p>; CAIRå›¢é˜Ÿä¸“æ³¨äºŽäº†è§£æž„å»ºMLç³»ç»Ÿçš„æ•°æ®ã€‚æé«˜MLæ•°æ®é›†é€æ˜Žåº¦çš„æ ‡å‡†å¯¹æˆ‘ä»¬çš„å·¥ä½œæœ‰ç”¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é‡‡ç”¨æ–‡æ¡£æ¡†æž¶æ¥é˜æ˜Žæ•°æ®é›†å’Œæ¨¡åž‹ç‰¹å¾ä½œä¸ºæ•°æ®å’Œæ¨¡åž‹æ–‡æ¡£æŠ€æœ¯çš„å¼€å‘æŒ‡å¯¼ -  &lt;a href=&quot;https://arxiv.org/arxiv.org/abs/1803.09010&quot;>;æ•°æ®é›†çš„æ•°æ®é›†&lt;/a>;å’Œaft &lt;a href=&quot;https://arxiv.org/abs/1810.03993&quot;>;ç”¨äºŽåž‹å·æŠ¥å‘Šçš„åž‹å·å¡&lt;/a>;ã€‚ &lt;/p>; &lt;p>;ä¾‹å¦‚ï¼Œå¥åº·æ•°æ®é›†é«˜åº¦æ•æ„Ÿï¼Œä½†å½±å“å¾ˆå¤§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†&lt;a href=&quot;https://dl.acm.org/doi/fullhtml/10.1145/3531146.353239&quot;>; healthsheets &lt;/a>;ï¼Œä¸€ç§åŒ»ç–—æœåŠ¡çš„dataSheetçš„å¥åº·å®šä¹‰é€‚åº”ã€‚æˆ‘ä»¬å¼€å‘ç‰¹å®šå¥åº·è¡¨çš„åŠ¨æœºåœ¨äºŽçŽ°æœ‰çš„AIå’Œå¥åº·ç›‘ç®¡æ¡†æž¶çš„å±€é™æ€§ã€‚ &lt;a href=&quot;https://www.nejm.org/doi/10.1056/nejmp1816373&quot;>;æœ€è¿‘çš„ç ”ç©¶&lt;/a>;å»ºè®®æ•°æ®éšç§è°ƒèŠ‚å’Œæ ‡å‡†ï¼ˆä¾‹å¦‚ã€‚ ã€‚ Health Sheetsæ—¨åœ¨åœ¨é“å¾·æ•°æ®é›†åˆ†æžä¸­å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚å¥åº·ç½‘çš„å¼€å‘æ˜¯ä¸Žè®¸å¤šåˆ©ç›Šç›¸å…³è€…åˆä½œå®Œæˆçš„ï¼ŒåŒ…æ‹¬ä¸´åºŠï¼Œæ³•å¾‹å’Œç›‘ç®¡ï¼Œç”Ÿç‰©ä¼¦ç†å­¦ï¼Œéšç§å’Œäº§å“ã€‚ &lt;/p>; &lt;p>;æ­¤å¤–ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ•°æ®è¡¨å’Œå¥åº·è¡¨å¦‚ä½•ç”¨ä½œè¯Šæ–­å·¥å…·ï¼Œä»Žè€Œè¡¨çŽ°å‡ºæ•°æ®é›†çš„å±€é™æ€§å’Œä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯åœ¨ç¤¾åŒºä¸­å¼€å§‹å¯¹è¯ï¼Œå¹¶éšç€æ—¶é—´çš„æµé€ï¼Œä¸ºåŠ¨æ€çš„åŒ»ç–—ä¿å¥æ–¹æ¡ˆé‡èº«å®šåˆ¶å¥åº·è¡¨ã€‚ &lt;/p>; &lt;p>;ä¸ºäº†ä¿ƒè¿›è¿™é¡¹åŠªåŠ›ï¼Œæˆ‘ä»¬åŠ å…¥äº†&lt;a href=&quot;http://www.datadadativersity.org/&quot;>;åœ¨ä¸€èµ·&lt;/a>; &lt;/a>;å€¡è®®ï¼Œæ—¨åœ¨å¼€å‘&lt;a href =çš„è´¢å›¢â€ https://www.nature.com/articles/s41591-022-01987-w&quot;>; internationalï¼ŒåŸºäºŽå…±è¯†çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§æ ‡å‡†&lt;/a>;åœ¨å¥åº·æ•°æ®é›†ä¸­ï¼Œå¹¶æä¾›æœ‰å…³å¦‚ä½•å‡è½»é£Žé™©çš„æŒ‡å¯¼åè§ï¼Œè½¬åŒ–ä¸ºä¼¤å®³å’Œå¥åº·ä¸å¹³ç­‰ã€‚æˆä¸ºè¿™ç§å›½é™…ï¼Œè·¨å­¦ç§‘çš„åˆä½œä¼™ä¼´å…³ç³»çš„ä¸€éƒ¨åˆ†ï¼Œè¯¥ä¼™ä¼´å…³ç³»æ¶µç›–äº†å…¨çƒå­¦æœ¯ï¼Œä¸´åºŠï¼Œç›‘ç®¡ï¼Œæ”¿ç­–ï¼Œè¡Œä¸šï¼Œç—…äººå’Œæ…ˆå–„ç»„ç»‡ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å›½é™…ä¸Šè¿›è¡Œæœ‰å…³AIè´£ä»»çš„å¯¹è¯ã€‚æ¥è‡ª32ä¸ªå›½å®¶/åœ°åŒºçš„250å¤šä¸ªåˆ©ç›Šç›¸å…³è€…å·²ä¿ƒè¿›äº†å®Œå–„æ ‡å‡†&lt;strong>;ã€‚&lt;/strong>; &lt;/p>; &lt;table align =â€œä¸­å¿ƒâ€ cellpadding =â€œ 0â€ cellspacing =â€œ 0â€ class =â€œ tr-aptapion-coption-container â€œæ ·å¼=â€ Margin-Leftï¼šAuto; Margin-Rightï¼šauto;â€œ>; &lt;tbody>; &lt;tr>; &lt;td style =â€ text-alignï¼šcenter;â€œ>; &lt;a href =â€ httpsï¼š//blogger.googleusercontentã€‚ com/img/b/R29vZ2xl/AVvXsEjUogIg5rJu-5i259KxpG9DrCD7an9L1KTpugqjw__6LWGUIF-78hkPUpjbUWc8SAZ7BZk82RlI7ddaW3Fe9spfn-hbyNLk94LAFWb3XvynnbLJddwxv8sSd0swacF5_C6UV2NjM0FXzLWKiYDnW3F_SjyOvUVp0BO2YADXBqbabbUP5D7X1i5czhqfrOcw/s1050/Healthsheets.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original- height=&quot;731&quot; data-original-width=&quot;1050&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUogIg5rJu-5i259KxpG9DrCD7an9L1KTpugqjw__6LWGUIF-78hkPUpjbUWc8SAZ7BZk82RlI7ddaW3Fe9spfn-hbyNLk94LAFWb3XvynnbLJddwxv8sSd0swacF5_C6UV2NjM0FXzLWKiYDnW3F_SjyOvUVp0BO2YADXBqbabbUP5D7X1i5czhqfrOcw/s16000/Healthsheets.png&quot; />;&lt; /a>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>; &lt;em style =â€œ text-alignï¼šleft;â€>; healthsheets and Standä¸€èµ·ï¼šæœç€å¥åº·æ•°æ®æ–‡æ¡£å’Œæ ‡å‡†ã€‚&lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;h2>;æ¨¡åž‹&lt;/h2>; &lt;p>; &lt;/h2>; &lt;p>;çŽ°å®žä¸–ç•Œï¼Œä»–ä»¬å¯èƒ½æ— æ³•ä»¥é¢„æœŸçš„æ–¹å¼è¡Œäº‹ï¼Œä»Žè€Œåœ¨æ–°çš„æƒ…å†µä¸‹åšå‡ºä¸è‰¯çš„é¢„æµ‹ã€‚è¿™ç§å¤±è´¥å¯èƒ½æ˜¯å‡ºäºŽå¤šç§åŽŸå› è€Œå‘ç”Ÿçš„ï¼Œå¹¶ä¸”å¯èƒ½å¸¦æ¥è´Ÿé¢åŽæžœï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—ä¿å¥çš„èƒŒæ™¯ä¸‹ã€‚æˆ‘ä»¬çš„å·¥ä½œæ—¨åœ¨ç¡®å®šå¯èƒ½å‘çŽ°æ„å¤–æ¨¡åž‹è¡Œä¸ºçš„æƒ…å†µï¼Œç„¶åŽæ‰æˆä¸ºä¸€ä¸ªå®žè´¨æ€§çš„é—®é¢˜ï¼Œå¹¶å‡è½»æ„å¤–å’Œä¸å¸Œæœ›çš„åŽæžœã€‚ &lt;/p>; &lt;p>; CAIRå›¢é˜Ÿçš„å¤§éƒ¨åˆ†å»ºæ¨¡å·¥ä½œéƒ½è‡´åŠ›äºŽè¯†åˆ«å’Œç¼“è§£ä½•æ—¶&lt;a href=&quot;https://blog.research.google/2021/2021/10/how-underspecification-precification-presents.html&quot;>;æŒ‡å®š&lt;/a>;ã€‚æˆ‘ä»¬è¡¨æ˜Žï¼Œä»Žè®­ç»ƒåŸŸä¸­ç»˜åˆ¶çš„æŒæœ‰æ•°æ®ä¸Šè¡¨çŽ°è‰¯å¥½çš„æ¨¡åž‹åœ¨åˆ†é…å˜åŒ–ä¸‹å¹¶ä¸ç›¸åŒæˆ–å…¬å¹³ï¼Œå› ä¸ºæ¨¡åž‹åœ¨ä¾èµ–è™šå‡ç›¸å…³æ€§çš„ç¨‹åº¦ä¸Šæœ‰æ‰€ä¸åŒã€‚è¿™å¯¹ç”¨æˆ·å’Œä»Žä¸šäººå‘˜æž„æˆäº†é£Žé™©ï¼Œå› ä¸ºä½¿ç”¨æ ‡å‡†æ¨¡åž‹è¯„ä¼°å®žè·µå¯èƒ½å¾ˆéš¾é¢„æµ‹æ¨¡åž‹ä¸ç¨³å®šæ€§ã€‚ &lt;a href=&quot;https://www.jmlr.org/papers/v23/20-1335.html&quot;>;æˆ‘ä»¬å·²ç»è¯æ˜Žäº†è¿™ç§æ‹…å¿§&lt;/a>;æˆåƒå’Œç”µå­å¥åº·è®°å½•çš„é¢„æµ‹ã€‚ &lt;/p>; &lt;p>;æˆ‘ä»¬è¿˜å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨å› æžœæœºåˆ¶çŸ¥è¯†æ¥è¯Šæ–­å’Œå‡è½»æ–°çŽ¯å¢ƒä¸­çš„å…¬å¹³å’Œé²æ£’æ€§é—®é¢˜ã€‚ Knowledge of causal structure allows practitioners to anticipate &lt;a href=&quot;https://proceedings.neurips.cc/paper_files/paper/2022/hash/7a969c30dc7e74d4e891c8ffb217cf79-Abstract-Conference.html&quot;>;the generalizability of fairness properties under distribution shift in real - ä¸–ç•ŒåŒ»å­¦è®¾ç½®&lt;/a>;ã€‚æ­¤å¤–ï¼Œç ”ç©¶ç‰¹å®šå› æžœé€”å¾„æˆ–â€œå¿«æ·æ–¹å¼â€å¼•å…¥MLç³»ç»Ÿä¸­çš„åè§çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•è¯†åˆ«&lt;a a href =â€œ https://www.nature.com/articles/s41467-023-- 39902-7â€œ>;å¿«æ·æ–¹å¼å­¦ä¹ &lt;/a>;å¯¼è‡´MLç³»ç»Ÿçš„é¢„æµ‹æ— æ„è¯†åœ°å–å†³äºŽæ•æ„Ÿå±žæ€§ï¼ˆä¾‹å¦‚ï¼Œå¹´é¾„ï¼Œæ€§åˆ«ï¼Œç§æ—ï¼‰ã€‚æˆ‘ä»¬å·²ç»å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å› æžœ&lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/directed_acyclic_graph&quot;>;å®šå‘acycclic graphs &lt;/a>; V206/alabdulmohsin23aâ€œ>;åœ¨å¤æ‚çš„åˆ†é…å˜åŒ–å½¢å¼ä¸‹ï¼Œå°†MLç³»ç»Ÿé€‚åº”ä¸æ–­å˜åŒ–çš„çŽ¯å¢ƒã€‚æˆ‘ä»¬çš„å›¢é˜Ÿç›®å‰æ­£åœ¨ç ”ç©¶å¦‚ä½•å¯¹ä¸åŒå½¢å¼çš„åè§çš„å› æžœè§£é‡Šï¼ŒåŒ…æ‹¬&lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/selection_bias&quot;>;é€‰æ‹©åè§&lt;/a>;ï¼Œæ ‡ç­¾åè§å’Œæµ‹é‡è¯¯å·®ï¼Œå’Œæµ‹é‡é”™è¯¯ï¼Œå’Œæµ‹é‡è¯¯å·®ï¼Œå’Œæµ‹é‡è¯¯å·®ï¼Œ &lt;a href=&quot;https://nips.cc/virtual/2022/58452&quot;>;æ¿€åŠ±è®¾è®¡åœ¨æ¨¡åž‹å¼€å‘å’Œè¯„ä¼°æœŸé—´å‡è½»åè§çš„æŠ€æœ¯è®¾è®¡&lt;/a>;ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style =â€œ text-alignï¼šcenter;â€>; &lt;a href =â€œ https://blogger.googleusercontent.com/img/r29vz2xl/avvxssejq4thavzli3czxubnknk72olebnrj4dnanejnnednanejjojyjojyjojyjojyjyjyjyjojyjyjyjyjyjyjyqunejojojyquyjojyqunejojyqunejojojojjojyquyqunejojojyqyquyqunequsojojojojyqyquyqyqunejojyqyquyqyqy q3rvt7avpcpplijngteyiswneeamrv4xvibazb_fktvxjfcxubmjzknsyivbndjsqrhcm_adsgbuoropoynj_icf-cg_0aaaa16ghxc58xwem07xwem07xnwem07xnwyw/s7272727272272727272727272 =è¾¹è·å·¦ï¼š1EM;è¾¹ç¼˜æƒåˆ©ï¼š1EM;â€œ>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 442â€ data-eriginal-width =â€œ 727â€ src =â€œ httpsï¼š//blogger.googleusercontentã€‚ com/img/b/R29vZ2xl/AVvXsEjq4THavzli3C1qzxuAwBNk72Olybnrj4UdZeMNDna14jN8eiiq9vScEJ18bYFVUEjO4l70CYIVYQ3RVt7AvpCPPlIJNGteYIsWnEeamRV4XVibAzb_fktVXjfcXUBMjzkNsyivBNDJsqRhcM_AdsGbUOrOpoYnj_iCFF-CG_0aa16GHxc58XweM07XnWYW/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href =â€œ https://blogger.googleusercontent.com/img/b/r29vz2xl/avvxsei_hhxvw2hiuenxnikoratvffsgqfsgqfsgqfaqfaqbjbjbjbjbjbjbbbsqfqfqfqlwcytdddfor9rwtvâ€‹â€‹ffor9rwtvâ€‹â€‹qhtvquqqqqqqqqqqqqqqqqqqqqqud quldnheflhthp.qudhtpnjpw yhfymhtpnjjjpwik jj4whefkwymhwymhwymhwymhwymhwybwybwybwybwybwybwybwybwybwy y VXKJ1OHZJPZRZRZRZRZRZEB6WAP-WON7NIME6DRZJMISCHFM5JDYJULLZULZULSHUVEJX10-WNHOANX9BSREFZIL0V0VH4E2LU1EW2N/s1078/s1078/image 1.pngè¾¹ç¼˜æƒåˆ©ï¼šè‡ªåŠ¨;â€œ>; &lt;img border =â€œ 0â€ data-original-height =â€œ 382â€ data-eriginal-width =â€œ 1078â€ src =â€œ https://blogger.googleusercontent.com/img/img/b/b/ R29vZ2xl/AVvXsEi_HHXvW2hIuenXNIkORatVFSgqfaqBJbbsqFqlWCYTdfOR9RwTVqhTxGqqSPBwUhy24wYAlKn9j-vpDCths0heIL7WQk5xVxkj1OHzJpZrzZVebGB6wAP-WOn7NImE6drZjMiSchFM5JdYJulLZULSHuVEjX10-wnhOANX9BsRefZiL0v0vH4E2lU1eW2n/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center ;â€œ>; &lt;em style =â€ text-alignï¼šleft;â€œ>;å¿«æ·æ–¹å¼å­¦ä¹ ï¼šå¯¹äºŽæŸäº›åž‹å·ï¼Œä½¿ç”¨åŒ»å­¦å›¾åƒæ—¶ï¼Œå¹´é¾„å¯ä»¥ä½œä¸ºåˆ†ç±»çš„å¿«æ·æ–¹å¼ã€‚&lt;/em>; &lt;/em>; &lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tr>; &lt;/ tbody>; &lt;/table>; &lt;br />; &lt;p>; CAIRå›¢é˜Ÿè‡´åŠ›äºŽå¼€å‘æ–¹æ³•æ¥å¼€å‘æ›´å¹¿æ³›çš„åŒ…å®¹æ€§æ¨¡åž‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¿˜æ‹¥æœ‰&lt;a href =â€œ https://arxiv.org/abs/abs/2302.03874â€ >;åœ¨å‚ä¸Žç³»ç»Ÿçš„è®¾è®¡ä¸Šè¿›è¡Œ&lt;/a>;çš„å·¥ä½œï¼Œè¯¥&lt;/a>;å…è®¸ä¸ªäººé€‰æ‹©æ˜¯å¦æŠ«éœ²æ•æ„Ÿå±žæ€§ï¼Œä¾‹å¦‚ç§æ—ï¼Œå½“MLç³»ç»Ÿåšå‡ºé¢„æµ‹æ—¶ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ–¹æ³•è®ºç ”ç©¶å¯¹AIä¸­åŒ…å®¹æ€§çš„ç¤¾ä¼šç†è§£äº§ç”Ÿç§¯æžå½±å“æ–¹æ³•å¼€å‘ã€‚ &lt;/p>; &lt;br />; &lt;h2>;éƒ¨ç½²&lt;/h2>; &lt;p>; CAIRå›¢é˜Ÿæ—¨åœ¨å»ºç«‹é€šè¿‡ä½¿ç”¨ç§»åŠ¨è®¾å¤‡æŠ€æœ¯æ¥æ”¹å–„æ‰€æœ‰äººç”Ÿæ´»çš„æŠ€æœ¯ã€‚æˆ‘ä»¬æ—¨åœ¨å‡å°‘æ‚£æœ‰å¥åº·çŠ¶å†µçš„è‹¦éš¾ï¼Œè§£å†³ç³»ç»Ÿæ€§ä¸å¹³ç­‰ï¼Œå¹¶å®žçŽ°åŸºäºŽè®¾å¤‡çš„é€æ˜Žæ•°æ®æ”¶é›†ã€‚éšç€æ¶ˆè´¹è€…æŠ€æœ¯ï¼ˆä¾‹å¦‚å¥èº«è¿½è¸ªå™¨å’Œæ‰‹æœºï¼‰æˆä¸ºå¥åº·æ•°æ®æ”¶é›†çš„æ ¸å¿ƒï¼Œæˆ‘ä»¬æŽ¢ç´¢äº†è¿™äº›æŠ€æœ¯åœ¨æ…¢æ€§ç—…çš„èƒŒæ™¯ä¸‹çš„ä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯&lt;a href =â€œ httpsï¼š//en.wikipedia ã€‚æˆ‘ä»¬å¼€å‘äº†æ–°çš„æ•°æ®æ”¶é›†æœºåˆ¶å’Œé¢„æµ‹ï¼Œæˆ‘ä»¬å¸Œæœ›æœ€ç»ˆå°†å½»åº•æ”¹å˜æ‚£è€…çš„æ…¢æ€§ç—…ç®¡ç†ï¼Œä¸´åºŠè¯•éªŒï¼ŒåŒ»ç–—é€†è½¬å’Œè¯ç‰©å¼€å‘ã€‚ &lt;/p>; &lt;p>;é¦–å…ˆï¼Œæˆ‘ä»¬æ‰©å±•äº†å¼€æ”¾å¼&lt;a href=&quot;https://github.com/googlecleclecloudplatform/fda-mystudies&quot;>; fda mystudieså¹³å°&lt;/a>;ï¼Œç”¨äºŽåˆ›å»ºä¸´åºŠç ”ç©¶åº”ç”¨ç¨‹åºï¼Œä»¥ä½¿ä»»ä½•äººæ›´å®¹æ˜“ä»¥å¯ä¿¡èµ–å’Œå®‰å…¨çš„æ–¹å¼è¿›è¡Œè‡ªå·±çš„å­¦ä¹ å¹¶æ”¶é›†é«˜è´¨é‡çš„æ•°æ®ã€‚æˆ‘ä»¬çš„æ”¹è¿›åŒ…æ‹¬é›¶æ ¸å¿ƒè®¾ç½®ï¼Œä»¥ä¾¿ç ”ç©¶äººå‘˜å¯ä»¥é€šè¿‡ä½¿ç”¨&lt;a href=&quot;https://flutter.dev/&quot;>; flutter &lt;/a>;å’Œï¼Œï¼Œï¼Œä»¥åŠï¼Œé€šè¿‡ä½¿ç”¨&lt;a href=&quot;https://flutter.dev/ &lt;/a>;å’Œï¼Œï¼Œæœ€é‡è¦çš„æ˜¯ï¼Œå¼ºè°ƒå¯è®¿é—®æ€§ï¼Œä»¥ä¾¿å¬åˆ°æ‰€æœ‰æ‚£è€…çš„å£°éŸ³ã€‚æˆ‘ä»¬å¾ˆé«˜å…´åœ°å®£å¸ƒï¼Œè¿™é¡¹å·¥ä½œçŽ°åœ¨å·²ç»&lt;a href=&quot;https://github.com/googleclecloudplatform/fda-mystudies-flutter&quot;>;å¼€æ”¾æº&lt;/a>;æ˜¯åŽŸå§‹FDA-Mystudieså¹³å°çš„æ‰©å±•ã€‚æ‚¨å¯ä»¥ç«‹å³å¼€å§‹å»ºç«‹è‡ªå·±çš„å­¦ä¸šï¼ &lt;/p>; &lt;p>;ä¸ºäº†æµ‹è¯•æ­¤å¹³å°ï¼Œæˆ‘ä»¬æž„å»ºäº†ä¸€ä¸ªåŽŸåž‹åº”ç”¨ç¨‹åºï¼Œè¯¥åº”ç”¨ç¨‹åºç§°ä¸ºMSä¿¡å·ï¼Œè¯¥åº”ç”¨ç¨‹åºä½¿ç”¨è°ƒæŸ¥åœ¨æ–°é¢–çš„æ¶ˆè´¹è€…çŽ¯å¢ƒä¸­ä¸Žæ‚£è€…æŽ¥è§¦ã€‚æˆ‘ä»¬ä¸Ž&lt;a href=&quot;https://www.nationalmssociety.org/&quot;>;å›½å®¶MS Society &lt;/a>; &lt;/a>;æ‹›å‹Ÿå‚ä¸Žè€…è¿›è¡Œè¯¥åº”ç”¨ç¨‹åºçš„ç”¨æˆ·ä½“éªŒç ”ç©¶ï¼Œç›®çš„æ˜¯é™ä½Žè¾å­¦çŽ‡å¹¶æé«˜è¯¥åº”ç”¨ç¨‹åºçš„ç”¨æˆ·ä½“éªŒã€‚å¹³å°è¿›ä¸€æ­¥ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style =â€œ text-alignï¼šcenter;â€>; &lt;a href =â€œ https://blogger.googleusercontent.com/img/b/r29vz2xl/avvz2xl/avvxsejmhab dppbggggggggggggeplkxfyplkxfyrazblpjxwf9fkdkwhoh0yfkkquitkqutkmnsmnsmnsmn VNUM0B39XR7CVGHS_OZX9MEYAF7WLWDGHFSBVQVMV8MDW4TVLONTCM-ZT6KHUF0KHUF0KESQ3ROROWJWV0D2Z29P4_VCABY4_VCABY4_VCABY4UDXX6ENDACX9KEP7BEP73I3I3IFC/SSS9BEN.S9BC/S99 HOUFFC.å·¦é”®å·¦ï¼šè‡ªåŠ¨;è¾¹ç¼˜æƒåˆ©ï¼šè‡ªåŠ¨;â€œ>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 904â€ data-Original-width =â€œ 915â€é«˜åº¦=â€œ 632â€ src =â€œ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmHAb0ppbGGoplKXFyrazbLPjXWf9FKDKwOh0yfiuiTkq_kVQsme9ckeS6mnSXWkfitNJKmtMvnUm0b39xr7cvGHs_oZx9mEYAf7wlwdghFSbVqvmV8MDw4TVLontCm-zT6KhUf0kEsQ3RoroWJWv0D2z29P4_vcaby4Udx6ENdaCXx9kep73iQ5HoufCq/w640-h632/MSSignals.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>; &lt;em style =â€œ text-alignï¼šleft;â€>; msä¿¡å·åº”ç”¨ç¨‹åºå±å¹•æˆªå›¾ã€‚ï¼†nbsp; &lt;strong>; leftï¼š&lt;/strong>;ï¼†nbsp;å±å¹•ã€‚å¯èƒ½ä¼šä½¿ç”¨å®ƒæ¥æŽ¨åŠ¨MSä¸­MLç ”ç©¶çš„å‰æ²¿ã€‚åœ¨å¦ä¸€é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä¸Ž&lt;a href=&quot;https://neurolology.duke.edu/&quot;>;æœå…‹å¤§å­¦ç¥žç»ç—…å­¦ç³»å»ºç«‹äº†ç ”ç©¶åˆä½œï¼Œå¹¶è¯æ˜ŽMLæ¨¡åž‹å¯ä»¥&lt;a href =â€œ httpsï¼šhttpsï¼šhttpsï¼šhttpsï¼šhttpsï¼šhttpsï¼šhttpsï¼šhttpsï¼šhttpsï¼š //www.researchsquare.com/article/rs-2547289/v1&quot;>; accurccurtinalä½¿ç”¨ä»Žç§»åŠ¨åº”ç”¨ç¨‹åºä¸­è¿žç»­æ”¶é›†çš„æ•°æ®ï¼Œå¯ä»¥åœ¨ä¸‰ä¸ªæœˆå†…é¢„æµ‹é«˜åº¦ç—‡çŠ¶çš„å‘ç”ŸçŽ‡&lt;/a>;ã€‚ç»“æžœè¡¨æ˜Žï¼Œè®­ç»ƒæœ‰ç´ çš„æ¨¡åž‹å¯ä»¥ç”±ä¸´åºŠåŒ»ç”Ÿä½¿ç”¨æ¥è¯„ä¼°MSå‚ä¸Žè€…çš„ç—‡çŠ¶è½¨è¿¹ï¼Œè¿™å¯èƒ½ä¸ºç®¡ç†å¹²é¢„æŽªæ–½åšå‡ºå†³å®šã€‚ &lt;/p>; &lt;p>; CAIRå›¢é˜Ÿå‚ä¸Žäº†è®¸å¤šå…¶ä»–ç³»ç»Ÿçš„éƒ¨ç½²ï¼ŒåŒ…æ‹¬å†…éƒ¨å’Œå¤–éƒ¨ä½¿ç”¨ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¿˜ä¸Ž&lt;a href=&quot;https://learninglyally.org/&quot;>;å­¦ä¹ ally &lt;/a>; to &lt;a href =â€œ https://ai.googleblog.com/2023/08/study - ç¤¾ä¼šæ„è¯†åˆ°çš„ä¸´æ—¶causal.htmlâ€œ>;ä¸ºå­¦ä¹ éšœç¢å„¿ç«¥ï¼ˆä¾‹å¦‚é˜…è¯»éšœç¢ï¼‰å»ºç«‹ä¸€æœ¬ä¹¦æŽ¨èç³»ç»Ÿ&lt;/a>;ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„å·¥ä½œå¯¹æœªæ¥çš„äº§å“å¼€å‘äº§ç”Ÿç§¯æžå½±å“ã€‚ &lt;/p>; &lt;br />; &lt;h2>;äººç±»åé¦ˆ&lt;/h2>; &lt;p>;éšç€MLæ¨¡åž‹åœ¨æ•´ä¸ªå‘è¾¾å›½å®¶ä¸­å˜å¾—æ— å¤„ä¸åœ¨ï¼Œåœ¨è¾ƒä¸å‘è¾¾å›½å®¶çš„å£°éŸ³è½åŽå¯èƒ½å¤ªå®¹æ˜“äº†ã€‚ CAIRå›¢é˜Ÿçš„ä¼˜å…ˆäº‹é¡¹æ˜¯å¼¥åˆè¿™ä¸€å·®è·ï¼Œä¸Žç¤¾åŒºå»ºç«‹æ·±åŽšçš„å…³ç³»ï¼Œå¹¶é€šè¿‡ç¤¾åŒºé©±åŠ¨çš„æ–¹æ³•å…±åŒåŠªåŠ›è§£å†³ä¸ŽMLæœ‰å…³çš„é—®é¢˜ã€‚ &lt;/p>; &lt;p>;æˆ‘ä»¬è¿™æ ·åšçš„ä¸€ç§æ–¹æ³•ä¹‹ä¸€æ˜¯ä¸ŽMLçš„åŸºå±‚ç»„ç»‡åˆä½œï¼Œä¾‹å¦‚&lt;a href=&quot;https://www.sisonkebiotik.africa/home&quot;>; sisonkebiotik &lt;/a>;ï¼Œåœ¨MLå’ŒåŒ»ç–—ä¿å¥çš„äº¤æ±‡å¤„ï¼Œä¸€ä¸ªå¼€æ”¾ä¸”åŒ…å®¹æ€§çš„ç ”ç©¶äººå‘˜ï¼Œä»Žä¸šè€…å’Œçˆ±å¥½è€…å…±åŒåŠªåŠ›ï¼Œå…±åŒå»ºç«‹èƒ½åŠ›å¹¶æŽ¨åŠ¨éžæ´²å‰è¿›çš„ç ”ç©¶è®¡åˆ’ã€‚æˆ‘ä»¬ä¸ŽSisonKebiotikç¤¾åŒºåˆä½œï¼Œè¯¦ç»†ä»‹ç»äº†åŽ†å²è‡ªä¸Šè€Œä¸‹çš„å…¨çƒå¥åº·æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å»ºè®®é‡‡ç”¨åŸºäºŽäº’è¡¥çš„å¥åº·æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºå±‚å‚ä¸Žå¼ç¤¾åŒºï¼ˆGPCï¼‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬å…±åŒåˆ›å»ºäº†ä¸€ä¸ª&lt;a href=&quot;https://openreview.net/forum?id=jhy_g91r880&quot;>;ç”¨äºŽMLå’Œå…¨çƒå¥åº·çš„æ¡†æž¶å…³äºŽ&lt;a href=&quot;https://www.masakhane.io/&quot;>; masakhane &lt;/a>;ï¼ŒSisonkebiotikå’Œ&lt;a href =â€œ https://ro-ya-cv4africa.githubã€‚ io/homepage/â€œ>; ro&#39;ya &lt;/a>;ã€‚ &lt;/p>; &lt;p>;æˆ‘ä»¬æ­£åœ¨é‡‡å–å…¬å¼€å€¡è®®ï¼Œä»¥æ›´å¥½åœ°äº†è§£éžè¥¿æ–¹å›½å®¶/åœ°åŒºçš„äººå·¥æ™ºèƒ½å¯¹å¥åº·çš„ä½œç”¨ï¼Œçœ‹æ³•å’Œç”¨ä¾‹ï¼Œå¹¶åœ¨éžæ´²æœ€åˆé‡ç‚¹å…³æ³¨ã€‚ä¸Ž&lt;a href=&quot;https://ghananlp.org/&quot;>;åŠ çº³NLP &lt;/a>;ä¸€èµ·ï¼Œæˆ‘ä»¬åŠªåŠ›è¯¦ç»†ä»‹ç»&lt;a href=&quot;https://arxiv.org/abs/2304.02190&quot;>;åœ¨éžè¥¿æ–¹çŽ¯å¢ƒä¸­ï¼Œæ›´å¥½åœ°äº†è§£ç®—æ³•å…¬å¹³å’Œå¥åº·çš„åè§&lt;/a>;ã€‚æˆ‘ä»¬æœ€è¿‘å¯åŠ¨äº†ä¸€é¡¹ç ”ç©¶ï¼Œä»¥ä½¿ç”¨äººç±»åé¦ˆæ¥æ‰©å±•è¿™é¡¹å·¥ä½œã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style =â€œ text-alignï¼šcenter;â€>; &lt;a href =â€œ https://blogger.googleusercontent.com/img/r29vz2xl/avvxseiuolebmzarwmci10ro3vlhuvp5xs3ddxs3dmnkgcwlhuvp5 quccwlhuvp5 quccwmnkgcdm Q.GCDMKGCDMENWM 53cbiurqpfteanjpje7tlyehfa_lawxlsqzdaokh213r1u4zjr3m4u-yp-Dx0ndt_lcmjul6qmjul6qpabomifflkgl-7Z995 /s927/mlpipelinebiases.pngâ€œ style =â€ Margin-Leftï¼šauto; Margin-Rightï¼šauto;â€œ>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 386â€ data-Original-witth =â€œ 927â€ SRC =â€ AWXLSQZDAOKH213R1U4ZJR3M4U-DX0NDT_LCMJUL6QPABOMIFFLKGL-7Z95ULWKTZEBMU-VFFF-2CWV2DDDDD2DD2Q9MY/S16000/MLPIPELIPELILELESE tr>; &lt;tr>; &lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>; &lt;em style =â€œ text-alignï¼šleft;â€>;æ²¿MLç®¡é“çš„åè§åŠå…¶ä¸Žéžæ´²æ–‡åŒ–çš„å…³è”å·®å¼‚è½´ã€‚&lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;br />; &lt;p>; CAIRå›¢é˜Ÿè‡´åŠ›äºŽåˆ›é€ æœºä¼šï¼Œä»¥è†å¬AIå¼€å‘ä¸­æ›´å¤šè§‚ç‚¹ã€‚æˆ‘ä»¬ä¸ŽSisonKebiotikåˆä½œï¼Œå…±åŒç»„ç»‡&lt;a href=&quot;https://www.sisonkebiotik.africa/events/workshops/workshops/dl-indaba-2023&quot;>;å¥åº·å·¥ä½œå®¤æ•°æ®ç§‘å­¦&lt;/a>; https://deeplearningindaba.com/2023/&quot;>; deep Learning Indaba 2023 &lt;/a>;åœ¨åŠ çº³ã€‚æ¯ä¸ªäººçš„å£°éŸ³å¯¹äºŽä½¿ç”¨AIæŠ€æœ¯å¼€å‘æ›´ç¾Žå¥½çš„æœªæ¥è‡³å…³é‡è¦ã€‚ &lt;/p>; &lt;br />; &lt;h2>;ç¡®è®¤&lt;/h2>; &lt;p>; &lt;em>;æˆ‘ä»¬è¦æ„Ÿè°¢Negar Rostamzadehï¼ŒStephen Pfohlï¼ŒSubhrajit Royï¼ŒDiana Mincuï¼ŒChintan Ghateï¼ŒChintan Ghateï¼ŒMercy Asieduï¼ŒEmily Salkeyï¼ŒAlexander Dï¼ŒAlexander D &#39;Amour, Jessica Schrouff, Chirag Nagpal, Eltayeb Ahmed, Lev Proleev, Natalie Harris, Mohammad Havaei, Ben Hutchinson, Andrew Smart, Awa Dieng, Mahima Pushkarna, Sanmi Koyejo, Kerrie Kauer, Do Hee Park, Lee Hartsell, Jennifer Graves, Berk Ustunï¼ŒHailey Jorenï¼ŒTimnit Gebruå’ŒMargaret Mitchellçš„è´¡çŒ®å’Œå½±å“åŠ›ï¼Œä»¥åŠæˆ‘ä»¬åœ¨å­¦ä¹ Allyï¼ŒNational MS Societyï¼ŒDuke Universal Soctormï¼ŒDuke University Hospitalï¼ŒColidand Stereï¼ŒSisonkebiotikå’ŒMasakhaneçš„è®¸å¤šæœ‹å‹å’Œåˆä½œè€…ã€‚&lt;/em>; &lt;/em>; &lt;/em>; &lt;/>; &lt;/em>; &lt;/>; &lt;/em>; &lt;/ p>; &lt;/content>; &lt;link href =â€œ http://blog.research.google/feeds/79870719977777778787277/comments/comments/default/defaultâ€ rel =â€œ requiesâ€ rel =â€œ requeiesâ€ title =â€œ title =â€œ postæ³¨é‡Šâ€ >; &lt;&lt;link href =â€œ http://blog.research.google/2023/11/Responsible-ai-AT-Google-google-research.html#comment-formâ€ rel =â€œ rel =â€ re =â€œå›žå¤â€ title =â€œ 0æ³¨é‡Šâ€ text/htmlâ€œ/>; &lt;link href =â€ http://www.blogger.com/feeds/8474926331452026626/posts/posts/default/798707199997777777777777777277 =â€œ http://www.blogger.com/feeds/8474926331452026626/posts/posts/default/798707199777787787277â€ ã€‚ &lt;auter>; &lt;name>; Google AI &lt;/name>; &lt;uri>; http://www.blogger.com/profile/120986265147777775266161 &lt;/uri>; &lt;Email>; noreply@blogger.com &lt;/email>; â€œ16â€rel =â€œhttp://schemas.google.com/g/2005#thumbnailâ€src =â€œhttps://img1.blogblog.com/img/b16-rounded.gifâ€å®½åº¦=â€œ16â€>; &lt; /gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjN3mIK7184k0E4B4Pddafelrcf4yEqd1wTOxyK5LZlxKL8dFWwbEyATjS0Zbj8HBdAnIXQ40fVedg4O5oUi5_fVvOvKRQWhgIX05olZkb9YakVdRLXus3b9Pzze5oHu32X0VUpoykEvGwbZk9W2lEIJ8jUMlgzyML0yFFsyBbpbAUZgBk6TSli7bRaNQRs/s72-c/CAIR-hero.jpg&quot; width =â€œ 72â€ xmlnsï¼šåª’ä½“=â€œ http://search.yahoo.com/mrss/â€>; &lt;/åª’ä½“ï¼šthumbnail>; &lt;thrï¼šthr>; &lt;thrï¼šthr>; 0 &lt;/thrï¼šthrï¼šthr>; &lt;/entry>; &lt;/entry>; &lt;entry>; &lt;entry>; &lt;entry>; &lt;in >; tagï¼šblogger.comï¼Œ1999å¹´ï¼šBlog-8474926331452026626.POST-1303378857635363504 &lt;/id>; &lt;/id>; &lt;å‡ºç‰ˆ>; 2023-11-09T11ï¼š20ï¼š00.002-08ï¼š00.002-08ï¼š00 &lt;/00 &lt;/00 &lt;/00 ï¼š02.393-08ï¼š00 &lt;/updated>; &lt;ç±»åˆ«æ–¹æ¡ˆ=â€œ http://www.blogger.com/atom/ns#â€ term =â€œ Quantum aiâ€>; &lt;/category>; &lt;ç±»åˆ«>; www.blogger.com/atom/ns#â€œ term =â€œé‡å­è®¡ç®—â€>; &lt;/category>; &lt;title type =â€œ textâ€>;å…‹æœé”™è¯¯æ ¡æ­£çš„é‡å­å¤„ç†å™¨ä¸Šçš„æ³„æ¼&lt;span class=&quot;byline-author&quot;>;Posted by Kevin Miao and Matt McEwen, Research Scientists, Quantum AI Team&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidYny_9v0IyOBy7QbYVgwS5FAHzgHhVUt5FQvjXhi6WWJHyIIal3awBfaXNu9l3g47HElKNkFNf6XfpU7a_9ExGLlKFgOWvUOaT0PLhEoCfofJrazqT2IL1fBMtZMwfGJSnrpBrQZwQkYJOV6iMOmhWBWIH5OCPcsEPkgw -luipdbolytoggin3hjfpmwr/s320/Quantumï¼…20leakage.jpgâ€œ style =â€œ displayï¼šnone;â€ />; &lt;p>; &lt;a href=&quot;https://en.wikipedia.org/wiki/qubit&quot;>; qubits &lt;/a>; &lt;/a>; &lt;a>; Google Quantumè®¾å¤‡&lt;/a>;æ—¢ç²¾è‡´åˆå˜ˆæ‚ï¼Œå› æ­¤æœ‰å¿…è¦åˆå¹¶é”™è¯¯æ ¡æ­£ç¨‹åºï¼Œä»¥è¯†åˆ«å¹¶è¯´æ˜Žæž„å»ºæœ‰ç”¨çš„é‡å­è®¡ç®—æœºçš„é‡å­é”™è¯¯ã€‚æœ€æ™®éçš„ä¸¤ä¸ªé”™è¯¯æœºåˆ¶æ˜¯&lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/quantum_error_eror_correction#bit_flip_code&quot;>; bit-flip_code&quot;>; bit-flip errors &lt;/a>; a href =â€œ https://en.wikipedia.org/wiki/quantum_error_correction#sign_flip_codeâ€>; phode-flip errors &lt;/a>;ï¼ˆå…¶ä¸­ç¼–ç é‡å­ä¿¡æ¯çš„ç›¸ä½æ›´æ”¹çš„ç›¸ä½ï¼‰ã€‚ &lt;a href=&quot;https://blog.research.google/2021/08/demstrating-fundamentals-of-quantum.html&quot;>;é‡å­é”™è¯¯æ ¡æ­£&lt;/a>;ï¼ˆqecï¼‰æœ‰æœ›è§£å†³å¹¶å‡è½»è¿™ä¸¤ä¸ªçªå‡ºçš„é”™è¯¯ã€‚ä½†æ˜¯ï¼Œè¿˜æœ‰å„ç§å„æ ·çš„é”™è¯¯æœºåˆ¶æ¥æŒ‘æˆ˜QECçš„æœ‰æ•ˆæ€§ã€‚ &lt;/p>; &lt;a name=&#39;more&#39;>; &lt;/a>; &lt;p>; &lt;p>;å½“æˆ‘ä»¬å¸Œæœ›é‡å­é‡ä½œä¸ºç†æƒ³&lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/two-state_quantum_system&quot;>;ä¸¤ä¸ª - çº§åˆ«çš„ç³»ç»Ÿ&lt;/a>;æ²¡æœ‰æŸå¤±æœºåˆ¶ï¼Œå®žé™…ä¸Šå¹¶éžå¦‚æ­¤ã€‚æˆ‘ä»¬ä½¿ç”¨é‡å­çš„æœ€ä½Žèƒ½é‡æ°´å¹³ï¼ˆå½¢æˆ&lt;em>;è®¡ç®—åŸºç¡€&lt;/em>;ï¼‰æ¥æ‰§è¡Œè®¡ç®—ã€‚è¿™ä¸¤ä¸ªçº§åˆ«å¯¹åº”äºŽé‡å­ä¸­æ¿€å‘çš„ç¼ºå¤±ï¼ˆè®¡ç®—åŸºæ€ï¼‰æˆ–å­˜åœ¨ï¼ˆè®¡ç®—æ¿€å‘æ€ï¼‰ï¼Œå¹¶æ ‡è®°ä¸º|0âŸ©ï¼ˆâ€œ &lt;a href =â€ https://en.wikipedia.org/wiki.org/wiki /braï¼…e2ï¼…80ï¼…93Ket_notationâ€œ>; ket &lt;/a>;é›¶â€ï¼‰å’Œ|1âŸ©ï¼ˆâ€œ ket Oneâ€ï¼‰ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬çš„Qubitsè¿˜æ‹¥æœ‰è®¸å¤šç§°ä¸º&lt;em>; &lt;a href=&quot;https://arxiv.org/abs/1509.05470&quot;>;æ³„æ¼çŠ¶æ€&lt;/a>; &lt;/em>;çš„æ›´é«˜çº§åˆ«ã€‚æŒ‰ç…§æ ‡è®°çº§åˆ«æ ‡è®°çš„æƒ¯ä¾‹ï¼ŒæŒ‡ç¤ºé‡å­é‡ä¸­æœ‰å¤šå°‘æ¿€åŠ±ï¼Œæˆ‘ä»¬å°†å…¶æŒ‡å®šä¸º|2âŸ©ï¼Œ|3âŸ©ï¼Œ|4âŸ©ç­‰ç­‰ã€‚ &lt;/p>; &lt;p>;åœ¨â€œ &lt;a href=&quot;https://www.nature.com/articles/s41567-023-02226-w&quot;>;å…‹æœé‡å­é”™è¯¯æ ¡æ­£ä¸­çš„æ³„æ¼&lt;/a>;â€ em>; &lt;a href=&quot;https://www.nature.com/nphys/&quot;>;è‡ªç„¶ç‰©ç†å­¦&lt;/a>; &lt;/a>; &lt;/em>;ï¼Œæˆ‘ä»¬ç¡®å®šä½•æ—¶ä»¥åŠå¦‚ä½•å°†é‡å­æ³„æ¼åˆ°æ›´é«˜çš„çŠ¶æ€å„å·žå¯ä»¥é€šè¿‡æˆ‘ä»¬çš„ä¸¤ä¸ªQubitå¤§é—¨è…èš€é™„è¿‘çš„Qubitsã€‚ç„¶åŽï¼Œæˆ‘ä»¬è¯†åˆ«å¹¶å®žæ–½ä¸€ç§ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æ¶ˆé™¤æ³„æ¼å¹¶å°†å…¶è½¬æ¢ä¸ºQECå¯ä»¥æœ‰æ•ˆä¿®å¤çš„é”™è¯¯ã€‚æœ€åŽï¼Œæˆ‘ä»¬è¡¨æ˜Žè¿™äº›æ“ä½œæ˜¾ç€æ”¹å–„äº†QECè¿‡ç¨‹çš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚æœ€åŽçš„ç»“æžœç‰¹åˆ«å…³é”®ï¼Œå› ä¸ºå…¶ä»–æ“ä½œéœ€è¦æ—¶é—´ï¼Œé€šå¸¸ä¼šå¯¼è‡´æ›´å¤šé”™è¯¯ã€‚ &lt;/p>; &lt;div style =â€œ line-heightï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/>; &lt;/div>; &lt;h2>;ä¸Žä¸å®Œç¾Žçš„Qubitsä¸€èµ·å·¥ä½œ&lt;/h2>; &lt;p>;æˆ‘ä»¬çš„é‡å­å¤„ç†å™¨æ˜¯ç”±ç§°ä¸º&lt;çš„è¶…å¯¼é‡å­æž„å»ºçš„em>; &lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/transmon&quot;>; transmons &lt;/a>; &lt;/em>;ã€‚ä¸Žç†æƒ³çš„é‡å­é‡é‡åªæœ‰ä¸¤ä¸ªè®¡ç®—çº§åˆ«ï¼ˆè®¡ç®—åŸºç¡€çŠ¶æ€å’Œè®¡ç®—æ¿€å‘æ€ï¼‰ä¸åŒï¼ŒTransmon Qubtå…·æœ‰æ¯”è®¡ç®—æ¿€å‘æ€æ›´é«˜èƒ½é‡çš„é¢å¤–çŠ¶æ€ã€‚è¿™äº›è¾ƒé«˜çš„æ³„æ¼çŠ¶æ€å¯¹äºŽäº§ç”Ÿ&lt;a href=&quot;https://en.wikipedia.org/wiki/wiki/quantum_entanglement&quot;>;çº ç¼ &lt;/a>;çš„ç‰¹å®šæ“ä½œå¾ˆæœ‰ç”¨&lt;/a>;å¤ªéžçº¿æ€§å’Œéš¾ä»¥æ“ä½œã€‚ä½†æ˜¯ï¼Œé€šè¿‡å„ç§è¿‡ç¨‹ï¼Œä¹Ÿå¯ä»¥æ— æ„é—´å°†Transmonå‡»ä¸­è¿™äº›æ³„æ¼çŠ¶æ€ï¼ŒåŒ…æ‹¬æˆ‘ä»¬åº”ç”¨ç”¨äºŽæ“ä½œçš„å¯¹ç…§è„‰å†²ä¸­çš„ç¼ºé™·ï¼Œæˆ–è€…æ˜¯ä»Žä½Žæ¸©å†°ç®±ä¸­å‰©ä¸‹çš„å°‘é‡æµé‡å‰©ä½™çš„ã€‚è¿™äº›è¿‡ç¨‹é›†ä½“ç§°ä¸º&lt;em>;æ³„æ¼&lt;/em>;ï¼Œå®ƒæè¿°äº†é‡å­é‡ä»Žè®¡ç®—çŠ¶æ€åˆ°æ³„æ¼çŠ¶æ€çš„è¿‡æ¸¡ã€‚ &lt;/p>; &lt;p>;è€ƒè™‘åœ¨QECå®žéªŒä¸­å¹¿æ³›ä½¿ç”¨çš„ç‰¹å®šä¸¤å€æ“ä½œï¼š&lt;a href =â€œ https://en.wikipedia.org/wiki/wiki/wiki/list_of_quantum_quantum_quantum_logic_gates_gates 5B1ï¼…5D-ï¼Œå—æŽ§ï¼…2DZï¼Œ-ï¼…2Cï¼…0ACONTROLLOLLEDï¼…20SIGNâ€œ>; CZ GATE &lt;/a>;ã€‚è¯¥é—¨åœ¨ä¸¤ä¸ªé‡å­ä½ä¸Šè¿è¡Œï¼Œå½“ä¸¤ä¸ªé‡å­ä½åœ¨å…¶|1âŸ©çº§åˆ«ä¸­æ—¶ï¼Œç›¸äº’ä½œç”¨ä¼šå¯¼è‡´ä¸¤ä¸ªå•ç‹¬çš„æ¿€å‘åœ¨å…¶ä¸­ä¸€ä¸ªé‡å­ä½ä¸­ç®€çŸ­åœ°â€œæŸâ€å½¢æˆ|2âŸ©ï¼Œè€Œå¦ä¸€ä¸ªé‡å­åˆ™å˜ä¸º| 0 âŸ©ï¼Œåœ¨è¿”å›žåˆ°æ¯ä¸ªé‡å­ä½åœ¨|1âŸ©ä¸­çš„åŽŸå§‹é…ç½®ä¹‹å‰ã€‚è¿™æŸæŸç¼šäº†CZé—¨çš„çº ç¼ åŠ›é‡ã€‚ä½†æ˜¯ï¼Œåªè¦æ¦‚çŽ‡å¾ˆå°ï¼Œé—¨å°±ä¼šé‡åˆ°é”™è¯¯ï¼Œæ¿€å‘æ²¡æœ‰è¿”å›žå…¶åŽŸå§‹é…ç½®ï¼Œä»Žè€Œå¯¼è‡´æ“ä½œåœ¨|2âŸ©ï¼ˆæ³„æ¼çŠ¶æ€ï¼‰ä¸­ç•™ä¸‹é‡å­ã€‚å½“æˆ‘ä»¬æ‰§è¡Œæ•°ç™¾ä¸ªæˆ–æ›´å¤šè¿™äº›CZé—¨æ—¶ï¼Œè¿™ç§å°çš„æ³„æ¼è¯¯å·®æ¦‚çŽ‡ä¼šç´¯ç§¯ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnq7iPbsqcqffIGk3VgmUsIycfrYFQdyArF3RlBEdRKjJigk0mLym_E0OK_GZwix040pxZSPdZYr8loGNaX4An1pwtMGSiPIWruSj-S6Nleklj7YF9Y61fOtmsgl5pbeKIZCOLcWr4_4bQjZoBHz4zPNkBelyF-ZW0aUJDBpIQdamwg7VYWZxeCNk0q57L/s559/image1.png&quot; style =â€œè¾¹è· - å·¦ï¼šè‡ªåŠ¨;è¾¹ç¼˜å³ï¼šè‡ªåŠ¨;â€>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 559â€ data-Original-width =â€œ 559â€ 559â€œ height =â€ 400â€œ src =â€ src =â€œ https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnq7iPbsqcqffIGk3VgmUsIycfrYFQdyArF3RlBEdRKjJigk0mLym_E0OK_GZwix040pxZSPdZYr8loGNaX4An1pwtMGSiPIWruSj-S6Nleklj7YF9Y61fOtmsgl5pbeKIZCOLcWr4_4bQjZoBHz4zPNkBelyF-ZW0aUJDBpIQdamwg7VYWZxeCNk0q57L/w400-h400/image1.png&quot; width=&quot;400&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >; &lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>; transmon Qubitsæ”¯æŒè®¸å¤šæ³„æ¼çŠ¶æ€ï¼ˆ|2âŸ©ï¼Œ|3âŸ©ï¼Œ|4âŸ©ï¼Œâ€¦ï¼‰è¶…å‡ºè®¡ç®—åŸºç¡€ï¼ˆ|0âŸ©å’Œ|1âŸ©ï¼‰ã€‚è™½ç„¶æˆ‘ä»¬é€šå¸¸ä»…ä½¿ç”¨è®¡ç®—åŸºç¡€æ¥è¡¨ç¤ºé‡å­ä¿¡æ¯ï¼Œä½†æœ‰æ—¶é‡å­ä½è¿›å…¥è¿™äº›æ³„æ¼çŠ¶æ€ï¼Œå¹¶ç ´åæˆ‘ä»¬çš„Qubitsçš„æ­£å¸¸æ“ä½œã€‚&lt;/td>; &lt;/tr>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;br />; &lt;p>;å•ä¸ªæ³„æ¼äº‹ä»¶ç‰¹åˆ«æŸåäº†æ­£å¸¸çš„é‡å­æ“ä½œï¼Œå› ä¸ºå®ƒä¼šå¼•èµ·è®¸å¤šå•ç‹¬çš„é”™è¯¯ã€‚å½“ä¸€ä¸ªé‡å­ä½ä»¥æ³„æ¼çš„çŠ¶æ€å¯åŠ¨æ—¶ï¼ŒCZé—¨ä¸å†æ­£ç¡®çº ç¼ é‡å­ï¼Œä»Žè€Œé˜»æ­¢ç®—æ³•æ­£ç¡®æ‰§è¡Œã€‚ä¸ä»…å¦‚æ­¤ï¼Œåœ¨æ³„æ¼çŠ¶æ€ä¸‹åº”ç”¨äºŽä¸€ä¸ªQubitçš„CZé—¨ä¹Ÿä¼šå¯¼è‡´å¦ä¸€ä¸ªé‡å­æ³„æ¼ï¼Œä»Žè€Œé€šè¿‡è®¾å¤‡æ‰©æ•£æ³„æ¼ã€‚æˆ‘ä»¬çš„å·¥ä½œåŒ…æ‹¬é€ æˆæ³„æ¼çš„æ–¹å¼ä»¥åŠä¸Žæˆ‘ä»¬åœ¨é‡å­å¤„ç†å™¨ä¸­ä½¿ç”¨çš„å„ç§æ“ä½œç›¸äº’ä½œç”¨çš„å¹¿æ³›è¡¨å¾ã€‚ &lt;/p>; &lt;p>;ä¸€æ—¦Qubitè¿›å…¥æ³„æ¼çŠ¶æ€ï¼Œå®ƒå¯ä»¥ä¿ç•™åœ¨è¯¥çŠ¶æ€ä¸‹è¿›è¡Œè®¸å¤šæ“ä½œï¼Œç„¶åŽå†æ”¾æ¾å›žåˆ°è®¡ç®—çŠ¶æ€ã€‚è¿™æ„å‘³ç€ä¸€ä¸ªå•ä¸ªæ³„æ¼äº‹ä»¶ä¼šå¹²æ‰°è¯¥é‡å­çš„è®¸å¤šæ“ä½œï¼Œä»Žè€Œåˆ›å»ºäº†éšæ—¶é—´å †åœ¨ä¸€èµ·çš„æ“ä½œé”™è¯¯ï¼ˆ&lt;em>;æ—¶é—´ç›¸å…³&lt;/em>;é”™è¯¯ï¼‰ã€‚é€šè¿‡CZé—¨åœ¨è®¾å¤‡ä¸­ä¸åŒé‡å­ä½ä¹‹é—´æ³„æ¼çš„èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬åŒæ—¶çœ‹åˆ°äº†ç›¸é‚»é‡å­ä½ä¸Šçš„ä¸€å †é”™è¯¯ï¼ˆ&lt;em>; spaceä¸Žç©ºé—´ç›¸å…³çš„é”™è¯¯&lt;/em>;é”™è¯¯ï¼‰ã€‚æ³„æ¼å¼•èµ·ç©ºé—´å’Œæ—¶é—´ç›¸å…³çš„é”™è¯¯æ¨¡å¼çš„äº‹å®žä½¿å¾—ä»ŽQECç®—æ³•çš„è§’åº¦è¯Šæ–­å’Œçº æ­£å°¤å…¶éš¾ä»¥è¯Šæ–­ã€‚ &lt;/p>; &lt;div style =â€œçº¿è·¯é«˜ï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/>; &lt;/>; &lt;a href=&quot;https://blog.research.google/2023/02/suppressing-quantum-errors-erors-erors-erors-scaling.html&quot;>; Surface Code Qec Qec Qec &lt;/a>;ï¼Œä¸€å¥—åº”ç”¨äºŽä¸€å¥—ä¸å®Œç¾Žçš„æ“ä½œç‰©ç†Qubitså½¢æˆA &lt;em>;é€»è¾‘é‡å­&lt;/em>;ï¼Œå…¶å±žæ€§æ›´æŽ¥è¿‘ç†æƒ³çš„é‡å­ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„ç§°ä¸º&lt;em>; data Qubits &lt;/em>;çš„Qubitsä¿å­˜é‡å­ä¿¡æ¯ï¼Œè€Œå¦ä¸€ç»„&lt;em>; MEAKE QUBITS &lt;/em>;æ£€æŸ¥äº†æ•°æ®é‡é‡è¡¨ï¼ŒæŠ¥å‘Šå®ƒä»¬æ˜¯å¦æŠ¥å‘Šäº†é­å—äº†ä»»ä½•é”™è¯¯ï¼Œè€Œä¸ä¼šç ´åæ•°æ®é‡é‡çš„å¾®å¦™é‡å­çŠ¶æ€ã€‚ QECçš„ä¸»è¦åŸºç¡€å‡è®¾ä¹‹ä¸€æ˜¯ï¼Œæ¯ä¸ªæ“ä½œéƒ½ç‹¬ç«‹å‘ç”Ÿé”™è¯¯ï¼Œä½†æ˜¯æ³„æ¼å¯ä»¥æŒç»­åœ¨è®¸å¤šæ“ä½œä¸Šï¼Œå¹¶å¯¼è‡´å¤šä¸ªé”™è¯¯çš„ç›¸å…³æ¨¡å¼ã€‚å½“æ³„æ¼å¯¼è‡´è¿™ç§å‡è®¾è¿åæ—¶ï¼Œæˆ‘ä»¬çš„QECç­–ç•¥çš„æ€§èƒ½å—åˆ°äº†é™åˆ¶ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUgCL-XuUZldvjck8dvEO5-9ei_Oq0m4kihQ5rHgGr66ggLVjJ3XZDuNl7Tw3s6EePJ-5NTL42-0UCpNuUoC2-15jJ6uX2aPCULu-KISQJEiCYKfe3HR55vWCr3oDxmKu5g -wzbds3JM-TUGSNXOHFB8KM4SHNQKGPQGTKZS8FFRCPS-HHHH8MJSVKKLRNZA/S1588/image3.pngâ€œæ ·å¼â€ width=&quot;1588&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUgCL-XuUZldvjck8dvEO5-9ei_Oq0m4kihQ5rHgGr66ggLVjJ3XZDuNl7Tw3s6EePJ-5NTL42-0UCpNuUoC2-15jJ6uX2aPCULu-KISQJEiCYKfe3HR55vWCr3oDxmKu5g-WzBDS3jM-tuGSnxOHFb8kM4shNqKGPqGtKzs8FFRCPs-hH8mjsvkKLrNza/s16000/image3.png&quot; />; &lt;/a>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td class =â€œ tr-captionâ€ style =â€œ text-alignï¼šcenter;â€>;ä¸€æ—¦æ³„æ¼åœ¨æˆ‘ä»¬çš„è¡¨é¢ä»£ç transmonç½‘æ ¼ä¸­è¡¨çŽ°å‡ºæ¥ï¼Œå®ƒä»ç„¶å­˜åœ¨äºŽç›¸å¯¹äºŽå•ä¸ªè¡¨é¢ä»£ç QECå¾ªçŽ¯çš„é•¿æ—¶é—´ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œä¸€ä¸ªQubitä¸Šçš„æ³„æ¼ä¹Ÿå¯èƒ½å¯¼è‡´å…¶é‚»å±…æ³„æ¼ã€‚&lt;/td>; &lt;/tr>; &lt;/tbody>; &lt;/table>; &lt;/table>; &lt;br />; &lt;p>;æˆ‘ä»¬çš„&lt;a a href =â€œ httpsï¼š/ /BLOG.RESEARCH.GOOGLE/2021/08/dextrating-fundamentals-of-quantum.html#:~: text = the%20Sycamore%20Device.--Sleaky%20Qubitsï¼Œthe%20QUBITSï¼Œthe%20Goal%20Goal%20Of&quot;>; A>;è¡¨æ˜Žï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç§°ä¸º&lt;em>;å¤šçº§é‡ç½®&lt;/em>;ï¼ˆMLRï¼‰çš„æ“ä½œä»Žæµ‹é‡Qubitsä¸­åˆ é™¤æ³„æ¼ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºä¸€æ—¦æˆ‘ä»¬å¯¹é‡å­å°è¿›è¡Œæµ‹é‡ï¼Œå®ƒä»¬å°±ä¸å†æ‹¥æœ‰ä»»ä½•é‡è¦çš„é‡å­ä¿¡æ¯ã€‚åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ä¸Žéžå¸¸æœ‰æŸçš„é¢‘å¸¦ç›¸äº’ä½œç”¨ï¼Œä»Žè€Œå¯¼è‡´Qubitæ‰€å¤„çš„ä»»ä½•çŠ¶æ€ï¼ˆåŒ…æ‹¬æ³„æ¼çŠ¶æ€ï¼‰è…çƒ‚åˆ°è®¡ç®—åŸºæ€|0âŸ©ã€‚å¦‚æžœæˆ‘ä»¬æƒ³è±¡A &lt;em>; jenga &lt;/em>;å¡”ä»£è¡¨è´µæ—ä¸­çš„æ¿€å‘ï¼Œæˆ‘ä»¬å°†æ•´ä¸ªå †æ ˆç¿»å€’ã€‚ä½†æ˜¯ï¼Œä»…æ‹†å¸ä¸€å—ç –å—æ˜¯æ›´å…·æŒ‘æˆ˜æ€§çš„ã€‚åŒæ ·ï¼ŒMLRä¸é€‚ç”¨äºŽæ•°æ®é‡é‡ä½ï¼Œå› ä¸ºå®ƒä»¬å§‹ç»ˆä¿ç•™é‡è¦çš„é‡å­ä¿¡æ¯ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä¸€ç§æ–°çš„æ³„æ¼æ–¹æ³•ï¼Œä»¥æœ€å°åŒ–è®¡ç®—åŸºç¡€çŠ¶æ€ã€‚ &lt;/p>; &lt;div style =â€œçº¿è·¯é«˜ï¼š40ï¼…;â€>; &lt;br />; &lt;/>; &lt;/>; &lt;/>; Qubitæ³„æ¼åŽ»é™¤&lt;/em>;ï¼ˆDQLRï¼‰ï¼Œè¯¥ï¼ˆDQLRï¼‰é¶å‘æ•°æ®é‡ç½®ä½çš„æ³„æ¼çŠ¶æ€ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°æ®é‡é‡å’Œç›¸é‚»åº¦é‡Qubitä¸­çš„è®¡ç®—çŠ¶æ€ã€‚ dqlrç”±ä¸€ä¸ªä¸¤å€çš„é—¨ç»„æˆï¼ˆè¢«ç§°ä¸º&lt;em>; elecage iswap &lt;/em>;  -  an &lt;a a href =â€œ https://en.wikipedia.org/wiki/wiki/wiki/list_of_quantum_quantum_logic_gates_gates_gates #clifford_qubit_qubit_gates_textï¼štextï¼štextï¼štextï¼štext = 5B6ï¼…5D-ï¼Œå‡æƒ³ï¼…20swapï¼Œ-2â€œ>; iSWap &lt;/a>;å…·æœ‰æ³„æ¼çŠ¶æ€çš„æ“ä½œï¼‰å—å¯å‘æ€§å’Œç±»ä¼¼äºŽæˆ‘ä»¬çš„CZ Gateçš„å¯å‘ï¼Œç„¶åŽå¿«é€Ÿé‡ç½®åº¦é‡ç¬¦å·ï¼Œä»¥è¿›ä¸€æ­¥æ¶ˆé™¤é”™è¯¯ã€‚æ³„æ¼ISWAPé—¨éžå¸¸æœ‰æ•ˆï¼Œå¹¶ä¸”åœ¨è¡¨é¢ä»£ç å®žéªŒä¸­å¯¹CZé—¨çš„å¹¿æ³›è¡¨å¾å’Œæ ¡å‡†å¤§å¤§å—ç›Šã€‚ &lt;/p>; &lt;p>;å›žæƒ³ä¸€ä¸‹ï¼ŒCZé—¨åœ¨ä¸¤ä¸ªä¸åŒçš„Qubitä¸Šè¿›è¡Œäº†ä¸¤æ¬¡æ¿€å‘ï¼Œå¹¶å°†å®ƒä»¬ç®€è¦ä»‹ç»åˆ°ä¸€ä¸ªé‡å­ä¸Šï¼Œç„¶åŽå°†å®ƒä»¬è¿”å›žåˆ°å„è‡ªçš„é‡å­ä½ã€‚æ³„æ¼çš„ISWAPé—¨ç±»ä¼¼åœ°è¿è¡Œï¼Œä½†å‡ ä¹Žæ˜¯ç›¸åçš„ï¼Œå› æ­¤å®ƒéœ€è¦ä¸€ä¸ªå¸¦æœ‰ä¸¤ä¸ªæ¿€å‘çš„é‡å­ï¼ˆå¦åˆ™ç§°ä¸º|2âŸ©ï¼‰ï¼Œç„¶åŽå°†å®ƒä»¬åˆ†æˆä¸¤ä¸ªé‡å­ä½ã€‚æ³„æ¼çš„ISWAPé—¨ï¼ˆå°±æ­¤è€Œè¨€ï¼ŒCZé—¨ï¼‰ç‰¹åˆ«æœ‰æ•ˆï¼Œå› ä¸ºå¦‚æžœå­˜åœ¨çš„æ¿€å‘é‡å°‘äºŽä¸¤ç§æ¿€å‘ï¼Œåˆ™ä¸ä¼šåœ¨Qubitsä¸Šå·¥ä½œã€‚æˆ‘ä»¬æ­£ç²¾ç¡®åœ°åˆ é™¤äº†|2âŸ©&lt;em>; jenga &lt;/em>;ç –å—ï¼Œè€Œæ— éœ€å€’å‡ºæ•´ä¸ªå¡”ã€‚ &lt;/p>; &lt;p>;é€šè¿‡ä»”ç»†æµ‹é‡æˆ‘ä»¬çš„Transmonç½‘æ ¼ä¸Šçš„æ³„æ¼çŠ¶æ€çš„ç¾¤ä½“ï¼Œæˆ‘ä»¬å‘çŽ°DQLRå¯ä»¥å°†æ‰€æœ‰é‡å­ä½çš„å¹³å‡æ³„æ¼çŠ¶æ€äººå£é™ä½Žåˆ°çº¦0.1ï¼…ï¼Œè€Œæ²¡æœ‰å®ƒçš„è¿‘1ï¼…ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸å†è§‚å¯Ÿåˆ°æ•°æ®é‡ç½®é‡çš„æ³„æ¼é‡çš„é€æ¸å¢žåŠ ï¼Œåœ¨ä½¿ç”¨DQLRä¹‹å‰ï¼Œæ³„æ¼é‡å§‹ç»ˆåœ¨æŸç§ç¨‹åº¦ä¸Šå­˜åœ¨ã€‚ &lt;/p>; &lt;p>;ä½†æ˜¯ï¼Œè¿™ä¸ªç»“æžœåªæ˜¯éš¾é¢˜çš„ä¸€åŠã€‚å¦‚å‰æ‰€è¿°ï¼Œå¯ä»¥ä½¿ç”¨è¯¸å¦‚MLRä¹‹ç±»çš„æ“ä½œæ¥æœ‰æ•ˆåœ°æ¶ˆé™¤æ•°æ®é‡ä½ä¸Šçš„æ³„æ¼ï¼Œä½†ä¹Ÿå°†å®Œå…¨æ¶ˆé™¤å­˜å‚¨çš„é‡å­çŠ¶æ€ã€‚æˆ‘ä»¬è¿˜éœ€è¦è¯æ˜ŽDQLRä¸Žé€»è¾‘é‡å­çŠ¶æ€çš„ä¿å­˜å…¼å®¹ã€‚ &lt;/p>; &lt;p>;æ‹¼å›¾çš„åŽåŠéƒ¨åˆ†æ¥è‡ªæ‰§è¡ŒQECå®žéªŒï¼Œè¯¥æ“ä½œåœ¨æ¯ä¸ªQECå‘¨æœŸç»“æŸæ—¶äº¤ç»‡åœ¨ä¸€èµ·ï¼Œå¹¶è§‚å¯Ÿé€»è¾‘æ€§èƒ½ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ç§°ä¸º&lt;em>;æ£€æµ‹æ¦‚çŽ‡çš„åº¦é‡&lt;/em>;æ¥è¡¡é‡æˆ‘ä»¬æ‰§è¡ŒQECçš„èƒ½åŠ›ã€‚åœ¨å­˜åœ¨æ³„æ¼çš„æƒ…å†µä¸‹ï¼Œéšç€è¶Šæ¥è¶Šå¤šçš„é‡å­ä½è¿›å…¥å’Œä¿æŒæ³„æ¼çŠ¶æ€ï¼Œæ—¶é—´å’Œç©ºé—´ç›¸å…³çš„é”™è¯¯å°†å¯¼è‡´æ£€æµ‹æ¦‚çŽ‡é€æ¸å¢žåŠ ã€‚å½“æˆ‘ä»¬æ ¹æœ¬æ²¡æœ‰è¿›è¡Œé‡ç½®æ—¶ï¼Œè¿™æ˜¯æœ€æ˜Žæ˜¾çš„ï¼Œè¿™è¿…é€Ÿå¯¼è‡´æ³„æ¼å›°æ‰°çš„é€å°„ç½‘æ ¼ï¼Œå¹¶ä¸”å‡ºäºŽQECçš„ç›®çš„è€Œæ— æ³•æ“ä½œã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgC7T3bILXM6tqNCbHKb04ZwJhdanfunDEFSSbXDTa5J2MyjOWLyCGfW-dEsSrmjIZJY3e0KfvdzVYQZidJniivyaCPGJ_UouNnqxvkmWzOYUm8Zp9DY4dWS3CZmYVddS9hNVMvZgrXA1djXw9LgzvE3hZjLyzSrvzLy1qR3_d76Tp9zfdUK_pEFaWBmCYO/s1532/image2.png&quot; style=&quot;è¾¹è·å·¦ï¼šè‡ªåŠ¨;è¾¹ç¼˜å³ï¼šè‡ªåŠ¨;â€œ>; &lt;img border =â€œ 0â€ data-Original-height =â€œ 802â€ data-Original-width =â€œ 1532â€ src =â€œ httpsï¼š//blogger.googleusercorcententã€‚ com/img/b/R29vZ2xl/AVvXsEgC7T3bILXM6tqNCbHKb04ZwJhdanfunDEFSSbXDTa5J2MyjOWLyCGfW-dEsSrmjIZJY3e0KfvdzVYQZidJniivyaCPGJ_UouNnqxvkmWzOYUm8Zp9DY4dWS3CZmYVddS9hNVMvZgrXA1djXw9LgzvE3hZjLyzSrvzLy1qR3_d76Tp9zfdUK_pEFaWBmCYO/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;The prior state-of-the-art in our QEC experiments was to use MLR on the measure qubits to remove leakage. While this kept leakage population on the measure qubits (green circles) sufficiently low, data qubit leakage population (green squares) would grow and saturate to a few percent. With DQLR, leakage population on both the measure (blue circles) and data qubits (blue squares) remain acceptably low and stable.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; With MLR, the large reduction in leakage population on the measure qubits drastically decreases detection probabilities and mitigates a considerable degree of the gradual rise. This reduction in detection probability happens even though we spend more time dedicated to the MLR gate, when other errors can potentially occur. Put another way, the correlated errors that leakage causes on the grid can be much more damaging than the uncorrelated errors from the qubits waiting idle, and it is well worth it for us to trade the former for the latter. &lt;/p>; &lt;p>; When only using MLR, we observed a small but persistent residual rise in detection probabilities. We ascribed this residual increase in detection probability to leakage accumulating on the data qubits, and found that it disappeared when we implemented DQLR. And again, the observation that the detection probabilities end up lower compared to only using MLR indicates that our added operation has removed a damaging error mechanism while minimally introducing uncorrelated errors. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpZk_lDGNXr0w8H-mPyPMSGpojxd2ecI48zxj5p9ElpofUVhPX0mqkvKCPjcxMf3q5VVEhoed_PKIRHta73hwW8Jt153XGpeqasioHLlO0OapK8Amv1C3A_njsjZHuU330rOyNiL3kWqJLNA8YAAZhBha7Jn_eH8nbKd5-fbKiojSa5Yk_o0w8NQGgN_6B/s1205/image4.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;600&quot; data-original-width=&quot;1205&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpZk_lDGNXr0w8H-mPyPMSGpojxd2ecI48zxj5p9ElpofUVhPX0mqkvKCPjcxMf3q5VVEhoed_PKIRHta73hwW8Jt153XGpeqasioHLlO0OapK8Amv1C3A_njsjZHuU330rOyNiL3kWqJLNA8YAAZhBha7Jn_eH8nbKd5-fbKiojSa5Yk_o0w8NQGgN_6B/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;Leakage manifests during surface code operation as increased errors (shown as error detection probabilities) over the number of cycles. With DQLR, we no longer see a notable rise in detection probability over more surface code cycles.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Prospects for QEC scale-up&lt;/h2>; &lt;p>; Given these promising results, we are eager to implement DQLR in future QEC experiments, where we expect error mechanisms outside of leakage to be greatly improved, and sensitivity to leakage to be enhanced as we work with larger and larger transmon grids. In particular, our simulations indicate that scale-up of our surface code will almost certainly require a large reduction in leakage generation rates, or an active leakage removal technique over all qubits, such as DQLR. &lt;/p>; &lt;p>; Having laid the groundwork by understanding where leakage is generated, capturing the dynamics of leakage after it presents itself in a transmon grid, and showing that we have an effective mitigation strategy in DQLR, we believe that leakage and its associated errors no longer pose an existential threat to the prospects of executing a surface code QEC protocol on a large grid of transmon qubits. With one fewer challenge standing in the way of demonstrating working QEC, the pathway to a useful quantum computer has never been more promising. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;This work would not have been possible without the contributions of the entire Google Quantum AI Team.&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/1303378857635363504/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/overcoming-leakage-on-error-corrected.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1303378857635363504&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1303378857635363504&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/overcoming-leakage-on-error-corrected.html&quot; rel=&quot;alternate&quot; title=&quot;Overcoming leakage on error-corrected quantum processors&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidYny_9v0IyOBy7QbYVgwS5FAHzgHhVUt5FQvjXhi6WWJHyIIal3awBfaXNu9l3g47HElKNkFNf6XfpU7a_9ExGLlKFgOWvUOaT0PLhEoCfofJrazqT2IL1fBMtZMwfGJSnrpBrQZwQkYJOV6iMOmhWBWIH5OCPcsEPkgw-LuiPDBoLYToGGIN3Hjfpmwr/s72-c/Quantum%20leakage.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-4661241136828203614&lt;/id>;&lt;published>;2023-11-07T12:34:00.003-08:00&lt;/published>;&lt;updated>;2023-11-07T12:34:21.947-08:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Deep Learning&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Machine Learning&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Alternating updates for efficient transformers&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Xin Wang, Software Engineer, and Nishanth Dikkala, Research Scientist, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg68VOGvAuGk6w6db-De6SNc2OstzYrfUaCY4c03VVn_hAVb-wVsqk5zy07izav41UP3ZpurAn5kUs5QAJSzMU7Y_4en5TInN_0DA6iC8rUqAO0qmnwZXWll7yZyWvL_1HndCAtk7USVEyNxrXezwlmWDfrtQsEsQhnfjNkYvkoK5QiSIXESnXcxGvTOeKk/s1600/altup.png&quot; style=&quot;display: none;&quot; />; &lt;p>; Contemporary deep learning models have been remarkably successful in many domains, ranging from natural language to computer vision. &lt;a href=&quot;https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)&quot;>;Transformer neural networks&lt;/a>; (transformers) are a popular deep learning architecture that today comprise the foundation for most tasks in natural language processing and also are starting to extend to applications in other domains, such as &lt;a href=&quot;https://arxiv.org/abs/2010.11929&quot;>;computer vision&lt;/a>;, &lt;a href=&quot;https://blog.research.google/2023/03/palm-e-embodied-multimodal-language.html&quot;>;robotics&lt;/a>;, and &lt;a href=&quot;https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/&quot;>;autonomous driving&lt;/a>;. Moreover, they form the backbone of all the current state-of-the-art &lt;a href=&quot;https://en.wikipedia.org/wiki/Language_model&quot;>;language models&lt;/a>;. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; Increasing scale in Transformer networks has led to improved performance and the &lt;a href=&quot;https://arxiv.org/abs/2206.07682&quot;>;emergence of behavior&lt;/a>; not present in smaller networks. However, this increase in scale often comes with prohibitive increases in compute cost and inference latency. A natural question is whether we can reap the benefits of larger models without incurring the computational burden. &lt;/p>; &lt;p>; In â€œ&lt;a href=&quot;https://arxiv.org/abs/2301.13310&quot;>;Alternating Updates for Efficient Transformers&lt;/a>;â€, accepted as a Spotlight at &lt;a href=&quot;https://neurips.cc/virtual/2023/poster/72994&quot;>;NeurIPS 2023&lt;/a>;, we introduce AltUp, a method to take advantage of increased token representation without increasing the computation cost. AltUp is easy to implement, widely applicable to any transformer architecture, and requires minimal &lt;a href=&quot;https://en.wikipedia.org/wiki/Hyperparameter_optimization&quot;>;hyperparameter tuning&lt;/a>;. For instance, using a variant of AltUp on a 770M parameter T5-Large model, the addition of ~100 parameters yields a model with a significantly better quality. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Background&lt;/h2>; &lt;p>; To understand how we can achieve this, we dig into how transformerså·¥ä½œã€‚ First, they partition the input into a sequence of tokens. Each token is then mapped to an embedding vector (via the means of an embedding table) called the token embedding. We call the dimension of this vector the token representation dimension. The Transformer then operates on this sequence of token embeddings by applying a series of computation modules (called layers&lt;em>;)&lt;/em>; using its network parameters. The number of parameters in each transformer layer is a function of the layer&#39;s &lt;em>;width&lt;/em>;, which is determined by the token representation dimension. &lt;/p>; &lt;p>; To achieve benefits of scale without incurring the compute burden, prior works such as sparse mixture-of-experts (Sparse MoE) models (eg, &lt;a href=&quot;https://arxiv.org/abs/2101.03961&quot;>;Switch Transformer&lt;/a>;, &lt;a href=&quot;https://blog.research.google/2022/11/mixture-of-experts-with-expert-choice.html?m=1&quot;>;Expert Choice&lt;/a>;, &lt;a href=&quot;https://blog.research.google/2022/01/scaling-vision-with-sparse-mixture-of.html?m=1&quot;>;V-MoE&lt;/a>;) have predominantly focused on efficiently scaling up the network parameters (in the self-attention and &lt;a href=&quot;https://en.wikipedia.org/wiki/Feedforward_neural_network&quot;>;feedforward layers&lt;/a>;) by conditionally activating a subset based on the input. This allows us to scale up network size without significantly increasing compute per input. However, there is a research gap on scaling up the token representation dimension itself by conditionally activating parts of the token representation vector. &lt;/p>; &lt;p>; Recent works (for example, &lt;a href=&quot;https://arxiv.org/abs/2001.08361&quot;>;scaling laws&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/2011.14522&quot;>;infinite-width networks)&lt;/a>; have empirically and theoretically established that a wider token representation helps in learning more complicated functions. This phenomenon is also evident in modern architectures of increasing capability. For instance, the representation dimension grows from 512 (small) to 768 (base) and 1024 (corresponding to models with 770M, 3B, and 11B parameters respectively) in &lt;a href=&quot;https://arxiv.org/abs/1910.10683 &quot;>;T5 models&lt;/a>;, and from 4096 (8B) to 8192 (64B) and 18432 (540B) in &lt;a href=&quot;https://arxiv.org/abs/2204.02311&quot;>;PaLM models&lt;/a>; ã€‚ A widened representation dimension also significantly improves performance for dual encoder retrieval models. However, naÃ¯vely widening the representation vector requires one to increase the model dimension accordingly, which quadratically&lt;sup id=&quot;fnref1&quot;>;&lt;a href=&quot;#fn1&quot; rel=&quot;footnote&quot;>;1&lt;/a>;&lt;/sup>; increases the amount of computation in the feedforward computation. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Method&lt;/h2>; &lt;p>; AltUp works by partitioning a widened representation vector into equal sized blocks, processing only a single block at each layer, and using an efficient prediction-correction mechanism to infer the outputs of the other blocks (shown below on the right). This allows AltUp to simultaneously keep the model dimension, hence the computation cost, roughly constant and take advantage of using an increased token dimension. The increased token dimension allows the model to pack more information into each token&#39;s embedding. By keeping the width of each transformer layer constant, AltUp avoids incurring the quadratic increase in computation cost that would otherwise be present with a naÃ¯ve expansion of the representation. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA3Jus4rPOjc_P58AjvIw6pUlQn8O4H828q_VFXYW2-dHxVQbfrMtplwmTy-s8gPCQTg4_Cd5mOrxZHGKhFswEC3gjGs_ffzRsBLkbyzDUDiRDUe1OncBGayjX4JVpfNNTtG8RVu3r9MYaG0nx1TxzeLGvZhxKC5ySlN8GTR1LN5rSvwXIdkqGEaCvuegv/s1367/image2.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;823&quot; data-original-width=&quot;1367&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA3Jus4rPOjc_P58AjvIw6pUlQn8O4H828q_VFXYW2-dHxVQbfrMtplwmTy-s8gPCQTg4_Cd5mOrxZHGKhFswEC3gjGs_ffzRsBLkbyzDUDiRDUe1OncBGayjX4JVpfNNTtG8RVu3r9MYaG0nx1TxzeLGvZhxKC5ySlN8GTR1LN5rSvwXIdkqGEaCvuegv/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;An illustration of widening the token representation without (&lt;b>;left&lt;/b>;) and with AltUp (&lt;b>;right&lt;/b>;). This widening causes a near-quadratic increase in computation in a vanilla transformer due to the increased layer width. In contrast, Alternating Updates keeps the layer width constant and efficiently computes the output by operating on a sub-block of the representation at each layer.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; More specifically, the input to each layer is two or more blocks, one of which is passed into the 1x width transformer layer (see figure below). We refer to this block as the â€œactivatedâ€ block. This computation results in the exact output for the activated block. In parallel, we invoke a lightweight predictor that computes a weighted combination of all the input blocks. The predicted values, along with the computed value of the activated block, are passed on to a lightweight corrector that updates the predictions based on the observed values. This correction mechanism enables the inactivated blocks to be updated as a function of the activated one. Both the prediction and correction steps only involve a limited number of vector additions and multiplications and hence are much faster than a regular transformer layer. We note that this procedure can be generalized to an arbitrary number of blocks. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgGWWOVTTIeC_BqXAmfpdePJlLKoDIQdvT38SNyv6bepjrKJG8TjCqWVW1nwJMxNdE0JPaRaCvic5tE4xVYLX6Yg0wRkeucBD1u0PYKNBQ1BEmZ7YbO10IzWuOU-y8idTPYzDg69HVPqWaH3WIvMqgC4u0nucCp_0O5VsSKP1DqwzeVZAkQj3nA7wgsw4vN/s957/image3.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;504&quot; data-original-width=&quot;957&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEgGWWOVTTIeC_BqXAmfpdePJlLKoDIQdvT38SNyv6bepjrKJG8TjCqWVW1nwJMxNdE0JPaRaCvic5tE4xVYLX6Yg0wRkeucBD1u0PYKNBQ1BEmZ7YbO10IzWuOU-y8idTPYzDg69HVPqWaH3WIvMqgC4u0nucCp_0O5VsSKP1DqwzeVZAkQj3nA7wgsw4vN/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;The predictor and corrector computations: The predictor mixes sub-blocks with trainable scalar coefficients; the corrector returns a weighted average of the predictor output and the transformer output. The predictor and corrector perform scalar-vector multiplications and incur negligible computation cost compared to the transformer. The predictor outputs a linear mixing of blocks with scalar mixing coefficients p&lt;sub>;i, j&lt;/sub>; , and the corrector combines predictor output and transformer output with weights g&lt;sub>;i&lt;/sub>;.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; At a higher level, AltUp is similar to sparse MoE in that it is a method to add capacity to a model in the form of conditionally accessed (external) parameters. In sparse MoE, the additional parameters take the form of feed forward network (FFN) experts and the conditionality is with respect to the input. In AltUp, the external parameters come from the widened embedding table and the conditionality takes the form of alternating block-wise activation of the representation vector, as in the figure above. Hence, AltUp has the same underpinning as sparse MoE models. &lt;/p>; &lt;p>; An advantage of AltUp over sparse MoE is that it does not necessitate sharding since the number of additional parameters introduced is a factor&lt;sup id=&quot;fnref2&quot;>;&lt;a href=&quot;#fn2&quot; rel=&quot;footnote&quot;>;2&lt;/a>;&lt;/sup>; of the embedding table size, which typically makes up a small fraction of the overall model size. Moreover, since AltUp focuses on conditionally activating parts of a wider token representation, it can be applied synergistically with orthogonal techniques like MoE to obtain complementary performance gains. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Evaluation&lt;/h2>; &lt;p>; AltUp was evaluated on T5 models on various benchmark language tasks. Models augmented with AltUp are uniformly faster than the extrapolated dense models at the same accuracy. For example, we observe that a T5 Large model augmented with AltUp leads to a 27%, 39%, 87%, and 29% speedup on &lt;a href=&quot;https://gluebenchmark.com/&quot;>;GLUE&lt;/a>;, &lt;a href=&quot;https://super.gluebenchmark.com/&quot;>;SuperGLUE&lt;/a>;, &lt;a href=&quot;https://rajpurkar.github.io/SQuAD-explorer/&quot;>;SQuAD&lt;/a>;, and &lt;a href=&quot;https://nlp.cs.washington.edu/triviaqa/&quot;>;Trivia-QA&lt;/a>; benchmarks, respectively. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOoxdT_-82XpER17MuIVo3MNk4EcD-gFd-WDK1PVoKzfwxh8z86-b_JHf5HNvlJAmaATyIsAxJJ8Fm96KJxBXwIf290qZcTzBEEa21lObPv4tGoinpHbGCFlzoVJsZnGkb9g7sb268t3Ut6z1DhzWz790GD1wulkLB2-vs4qIvL08chhMiLj8RZhyphenhyphenwWX7b/s1386 /image5.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;982&quot; data-original-width=&quot;1386&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOoxdT_-82XpER17MuIVo3MNk4EcD-gFd-WDK1PVoKzfwxh8z86-b_JHf5HNvlJAmaATyIsAxJJ8Fm96KJxBXwIf290qZcTzBEEa21lObPv4tGoinpHbGCFlzoVJsZnGkb9g7sb268t3Ut6z1DhzWz790GD1wulkLB2-vs4qIvL08chhMiLj8RZhyphenhyphenwWX7b/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Evaluations of AltUp on T5 models of various sizes and popular benchmarks. AltUp consistently leads to sizable speedups relative to baselines at the same accuracy. Latency is measured on &lt;a href=&quot;https://cloud.google.com/tpu/docs/system-architecture-tpu-vm&quot;>;TPUv3&lt;/a>; with 8 cores. Speedup is defined as the change in latency divided by the AltUp latency (B = T5 Base, L = T5 Large, XL = T5 XL models).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; AltUp&#39;s relative performance improves as we apply it to larger models â€” compare the relative speedup of T5 Base + AltUp to that of T5 Large + AltUp. This demonstrates the scalability of AltUp and its improved performance on even larger models. Overall, AltUp consistently leads to models with better predictive performance than the corresponding baseline models with the same speed on all evaluated model sizes and benchmarks. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Extensions: Recycled AltUp&lt;/h2>; &lt;p>; The AltUp formulation adds an insignificant amount of per-layer computation, however, it does require using a wider embedding table. In certain scenarios where the vocabulary size (ie, the number of distinct tokens the tokenizer can produce) is very large, this may lead to a non-trivial amount of added computation for the initial embedding lookup and the final &lt;a href=&quot;https://www.google.com/url?q=https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax&amp;amp;sa=D&amp;amp;source=docs&amp;amp;ust=1699300629405641&amp;amp;usg=AOvVaw3tnZ18-LvY0tPP_NClQ_P-&quot;>;linear + softmax operation&lt;/a>;. A very large vocabulary may also lead to an undesirable amount of added embedding parameters. To address this, Recycled-AltUp is an extension of AltUp that avoids these computational and parameter costs by keeping the embedding table&#39;s width the same. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEha4G9LHEhhkFzDTHspvL4DKoYq3BDO7KJfkEY3oy4AAOOHJnNmM0pYp_JjmUiuVTjAAddCowxzCLlcAA7CNKIwId8pujnAXoUMH2kM7ecQLHLfRyfqSqC5RKI-7yHwo8SaXN_CCQzVSHxldF7phMVY7CiaHUYIFIpMdWxpwBAZSpQem1RmBkyvEdjUYg2K/s989/image4.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;515&quot; data-original-width=&quot;989&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEha4G9LHEhhkFzDTHspvL4DKoYq3BDO7KJfkEY3oy4AAOOHJnNmM0pYp_JjmUiuVTjAAddCowxzCLlcAA7CNKIwId8pujnAXoUMH2kM7ecQLHLfRyfqSqC5RKI-7yHwo8SaXN_CCQzVSHxldF7phMVY7CiaHUYIFIpMdWxpwBAZSpQem1RmBkyvEdjUYg2K/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;Illustration of the Architecture for Recycled-AltUp with &lt;em>;K&lt;/em>; = 2.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; In Recycled-AltUp, instead of widening the initial token embeddings, we replicate the embeddings &lt;em>;K&lt;/em>; times to form a wider token representation. Hence, Recycled-AltUp adds virtually no additional parameters relative to the baseline transformer, while benefiting from a wider token representation. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRoANGe48-HncQDuNpxAVSUGf2GPp1qp6KpnvqMbQ5Mejlq4gWpq96vu9FxkDub8aO3RqYyDmTki2Xqkj9drOprwqrHDyoQvHI4oziYFguhDnkkYZO4GXdhAKgIlfffHJ5Po7mEVGCaAkOH7oobnt-8qKjWlerZp4EeoAjZg6IG_CEVO3hhsQvlPaV2GHU/s1999/image1.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;643&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRoANGe48-HncQDuNpxAVSUGf2GPp1qp6KpnvqMbQ5Mejlq4gWpq96vu9FxkDub8aO3RqYyDmTki2Xqkj9drOprwqrHDyoQvHI4oziYFguhDnkkYZO4GXdhAKgIlfffHJ5Po7mEVGCaAkOH7oobnt-8qKjWlerZp4EeoAjZg6IG_CEVO3hhsQvlPaV2GHU/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;Recycled-AltUp on T5-B/L/XL compared to baselines. Recycled-AltUp leads to strict improvements in pre-training performance without incurring any perceptible slowdown.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We also evaluate the lightweight extension of AltUp, Recycled-AltUp, with &lt;em>;K&lt;/em>; = 2 on T5 base, large, and XL models and compare its pre-trained accuracy and speed to those of baselines. Since Recycled-AltUp does not require an expansion in the embedding table dimension, the models augmented with it have virtually the same number of trainable parameters as the baseline models. We again observe consistent improvements compared to the dense baselines. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Why does AltUp work?&lt;/h2>; &lt;p>; AltUp increases a model&#39;s capacity by adding and &lt;em>;efficiently&lt;/em>; leveraging auxiliary parameters to the embedding table, and maintaining the higher dimensional representation across the layers. We believe that a key ingredient in this computation lies in AltUp&#39;s prediction mechanism that performs an ensemble of the different blocks. This weighted combination enables continuous message passing to the entire vector despite activating only sub-blocks of it in each layer. Recycled-AltUp, on the other hand, does not add any additional parameters to the token embeddings. However, it still confers the benefit of simulating computation in a higher dimensional representation space since a higher dimensional representation vector is maintained when moving from one transformer layer to another. We conjecture that this aids the training by augmenting the flow of information through the network. An interesting research direction is to explore whether the benefits of Recycled-AltUp can be explained entirely by more favorable training dynamics. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements &lt;/h2>; &lt;p>; &lt;em>;We thank our collaborators Cenk Baykal, Dylan Cutler, and Rina Panigrahy at Google Research, and Nikhil Ghosh at University of California, Berkeley (work done during research internship at Google).&lt;/em>; &lt;/p>; &lt;!--Footnotes-->; &lt;hr width=&quot;80%&quot; />; &lt;p>; &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-size: x-small;&quot;>;&lt;sup>;&lt;a name=&quot;fn1&quot;>;&lt;b>;1&lt;/b>;&lt;/ a>;&lt;/sup>;This is because the feedforward layers of a Transformer are typically scaled quadratically with the model dimension.&amp;nbsp;&lt;a href=&quot;#fnref1&quot; rev=&quot;footnote&quot;>;&lt;sup>;â†©&lt;/sup>;&lt;/ a>;&lt;/span>; &lt;br />; &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-size: x-small;&quot;>;&lt;sup>;&lt;a name=&quot;fn2&quot;>;&lt;b>;2&lt; /b>;&lt;/a>;&lt;/sup>;This factor depends on the user-specified expansion factor, but is typically 1, ie, we double the embedding table dimension.&amp;nbsp;&lt;a href=&quot;#fnref2&quot; rev=&quot;footnote &quot;>;&lt;sup>;â†©&lt;/sup>;&lt;/a>;&lt;/span>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/4661241136828203614/comments/default&quot; rel =&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/alternating-updates-for-efficient.html# comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4661241136828203614&quot; rel =&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4661241136828203614&quot; rel=&quot;self&quot; type=&quot;application/ atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/alternating-updates-for-efficient.html&quot; rel=&quot;alternate&quot; title=&quot;Alternating updates for efficient transformers&quot; type =&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/ç”µå­é‚®ä»¶>; &lt;gdï¼šimage height =â€œ 16â€ rel =â€œ http://schemas.google.com/g/g/2005#thumbnailâ€ &quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg68VOGvAuGk6w6db-De6SNc2OstzYrfUaCY4c03VVn_hAVb-wVsqk5zy07izav41UP3ZpurAn5kUs5QAJSzMU7Y_4en5TInN_0DA6iC8rUqAO0qmnwZXWll7yZyWvL_1HndCAtk7USVEyNxrXezwlmWDfrtQsEsQhnfjNkYvkoK5QiSIXESnXcxGvTOeKk /s72-c/altup.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total >;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-8959024707515398632&lt;/id>;&lt;published>;2023-11-03T11:23:00.001-07:00&lt;/published>; &lt;updated>;2023-11-03T11:27:07.156-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Algorithms&quot;>;&lt;/category>; &lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;ICLR&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Large Language Models&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Best of both worlds: Achieving scalability and quality in text clustering&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline -author&quot;>;Posted by Sara Ahmadian and Mehran Kazemi, Research Scientists, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjR2mD5afdT_Qg9Ex4Lj94FaxB9KHiq20iLoDlOY8S8Rk5XsV6n_4dU9CFbCvSeBSONGQYqy-yMGY6-KU_y_RGICOpz76GNdzv7ecxor_rVnF31lZOd3STQF4MIE4F_EadrSI1DXY67MXnsCswY3w3X8vX8KgU_rRPs6eTZndYAbVcEezgwaUsdZEAHD59Z/s320/ hero.jpg&quot; style=&quot;display: none;&quot; />; &lt;p>; &lt;a href=&quot;https://en.wikipedia.org/wiki/Cluster_analysis&quot;>;Clustering&lt;/a>; is a fundamental, ubiquitous problem in data mining and &lt;a href=&quot;https://en.wikipedia.org/wiki/Unsupervised_learning&quot;>;unsupervised&lt;/a>; machine learning, where the goal is to group together similar items. The standard forms of clustering are metric clustering and graph clustering. In metric clustering, a given metric space defines distances between data points, which are grouped together based on their &lt;em>;separation&lt;/em>;. In graph clustering, a given graph connects similar data points through edges, and the clustering process groups data points together based on the &lt;em>;connections&lt;/em>; between them. Both clustering forms are particularly useful for large corpora where class labels can&#39;t be defined. Examples of such corpora are the ever-growing digital text collections of various internet platforms, with applications including organizing and searching documents, identifying patterns in text, and recommending relevant documents to users (see more examples in the following posts: &lt;a href=&quot;https://blog.research.google/2010/10/clustering-related-queries-based-on.html?m=1&quot;>;clustering related queries based on user intent&lt;/a>; and &lt;a href=&quot;https://blog.research.google/2021/10/practical-differentially-private.html&quot;>;practical differentially private clustering&lt;/a>;). &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; The choice of text clustering method often presents a dilemma. One approach is to use embedding models, such as &lt;a href=&quot;https://en.wikipedia.org/wiki/BERT_(language_model)&quot;>;BERT&lt;/a>; or &lt;a href=&quot;https://arxiv.org/abs/1907.11692&quot;>;RoBERTa&lt;/a>;, to define a metric clustering problem. Another is to utilize &lt;a href=&quot;https://medium.com/@geetkal67/attention-networks-a-simple-way-to-understand-cross-attention-3b396266d82e&quot;>;cross-attention&lt;/a>; (CA) models, such as &lt;a href=&quot;https://blog.research.google/2022/04/pathways-language-model-palm-scaling-to.html&quot;>;PaLM&lt;/a>; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_pre-trained_transformer&quot;>;GPT&lt;/a>;, to define a graph clustering problem. CA models can provide highly accurate similarity scores, but constructing the input graph may require a prohibitive quadratic number of inference calls to the model. On the other hand, a metric space can efficiently be defined by distances of embeddings produced by embedding models. However, these similarity distances are typically of substantial lower-quality compared to the similarity signals of CA models, and hence the produced clustering can be of much lower-quality. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRHbZ9egdnFlc6ZCmLeODTdPZoOXcjjEGCLHP8Ve3aihMExIjyLiX4n0Zy9l4nmkx-3k6rxYN5696irWyubaYAqecpxFTmP1wzjBo0MKnZMnnTjQrdSxKIWGzsySs8XB-OVHyyxKJBWI0dlrYvb_S204S6aSbkPTx8_FQTJXk8f_WDIoGgqNJTACuXNewu/s835/figure%20top.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;641&quot; data-original-width=&quot;835&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRHbZ9egdnFlc6ZCmLeODTdPZoOXcjjEGCLHP8Ve3aihMExIjyLiX4n0Zy9l4nmkx-3k6rxYN5696irWyubaYAqecpxFTmP1wzjBo0MKnZMnnTjQrdSxKIWGzsySs8XB-OVHyyxKJBWI0dlrYvb_S204S6aSbkPTx8_FQTJXk8f_WDIoGgqNJTACuXNewu/s16000/figure%20top.png&quot; />;&lt;/a>;&lt;/td>; &lt;td style=&quot;text-align: center;&quot;>;&lt; a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoY4juklU42gca4fdtnUN4t5j8Z-4rEEhyphenhyphenDi4kRfkV1wfqBs_wyldX9sU2pwtMHdVZPZf2vWnDweEPzwiLseYZenC3afIuaDRf_7arpoF-xnMAwgGXs48a_3wNG2trhN0CTkHgMVa6ZQ7ToP7IE6fpIFmbTF7YYGPFgYU3cMtyyBYIfSWVLVvRXY6Dueiy/s835/figure%20bottom.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;641&quot; data-original-width=&quot;835&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoY4juklU42gca4fdtnUN4t5j8Z-4rEEhyphenhyphenDi4kRfkV1wfqBs_wyldX9sU2pwtMHdVZPZf2vWnDweEPzwiLseYZenC3afIuaDRf_7arpoF-xnMAwgGXs48a_3wNG2trhN0CTkHgMVa6ZQ7ToP7IE6fpIFmbTF7YYGPFgYU3cMtyyBYIfSWVLVvRXY6Dueiy/s16000/figure%20bottom.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto;å³è¾¹è·ï¼šè‡ªåŠ¨ï¼› text-align: center;&quot;>;&lt;tbody>; &lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;An overview of the embedding-based and cross-attentionâ€“based similarity scoring functions and their scalability vs. quality dilemma.&lt;/td>;&lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;p>; Motivated by this, in â€œ&lt;a href=&quot;https://openreview.net/pdf?id=p0JSSa1AuV&quot;>;KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signalsâ€, presented at ICLR 2023&lt;/a>;, we describe a novel clustering algorithm that effectively combines the scalability benefits from embedding models and the quality from CA models. This graph clustering algorithm has query access to both the CA model and the embedding model, however, we apply a budget on the number of queries made to the CA model. This algorithm uses the CA model to answer edge queries, and benefits from unlimited access to similarity scores from the embedding model. We describe how this proposed setting bridges algorithm design and practical considerations, and can be applied to other clustering problems with similar available scoring functions, such as clustering problems on images and media. We demonstrate how this algorithm yields high-quality clusters with almost a linear number of query calls to the CA model. We have also &lt;a href=&quot;https://storage.googleapis.com/gresearch/kwikbucks/kwikbucks.zip&quot;>;open-sourced&lt;/a>; the data used in our experiments. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;The clustering algorithm&lt;/h2>; &lt;p>; The KwikBucks algorithm is an extension of the well-known &lt;a href=&quot;https://cesa-bianchi.di.unimi.it/Algo2/Note/kwik.pdf&quot;>;KwikCluster algorithm (Pivot algorithm)&lt;/a>;. The high-level idea is to first select a set of documents (ie, centers) with no similarity edge between them, and then form clusters around these centers. To obtain the quality from CA models and the runtime efficiency from embedding models, we introduce the novel &lt;em>;combo similarity oracle&lt;/em>; mechanism. In this approach, we utilize the embedding model to guide the selection of queries to be sent to the CA model. When given a set of center documents and a target document, the combo similarity oracle mechanism outputs a center from the set that is similar to the target document, if present. The combo similarity oracle enables us to save on budget by limiting the number of query calls to the CA model when selecting centers and forming clusters. It does this by first ranking centers based on their embedding similarity to the target document, and then querying the CA model for the pair (ie, target document and ranked center), as shown below. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjRaIWRUaPHb_4QFG2wusDoqrVUJkePKRYgLhU992eEUjnI8gpZ2JzIDBdOEb56zHEBammMVEDj_hgejIhCLcmZK5r8ADTVn54ttrOPnOnR2tuk2J8UVIRQoRc_LOHA56_WnQSWPZbB31dZMkj4VI6btb7NkdUOtM1iM1VAKP5t3F-KiBxXySFb4BrYdPmy/s1601/process.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;522&quot; data-original-width=&quot;1601&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEjRaIWRUaPHb_4QFG2wusDoqrVUJkePKRYgLhU992eEUjnI8gpZ2JzIDBdOEb56zHEBammMVEDj_hgejIhCLcmZK5r8ADTVn54ttrOPnOnR2tuk2J8UVIRQoRc_LOHA56_WnQSWPZbB31dZMkj4VI6btb7NkdUOtM1iM1VAKP5t3F-KiBxXySFb4BrYdPmy/s16000/process.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;A combo similarity oracle that for a set of documents and a target document, returns a similar document from the set, if present.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We then perform a post processing step to merge clusters if there is a strong connection between two of them, ie, when the number of connecting edges is higher than the number of missing edges between two clusters. Additionally, we apply the following steps for further computational savings on queries made to the CA model, and to improve performance at runtime: &lt;/p>; &lt;ol>; &lt;li>;We leverage &lt;a href=&quot;https://arxiv.org /pdf/2002.11557.pdf&quot;>;query-efficient correlation clustering&lt;/a>; to form a set of centers from a set of randomly selected documents instead of selecting these centers from all the documents (in the illustration below, the center nodes are red ï¼‰ã€‚ &lt;/li>;&lt;li>;We apply the combo similarity oracle mechanism to perform the cluster assignment step in parallel for all non-center documents and leave documents with no similar center as singletons. In the illustration below, the assignments are depicted by blue arrows and initially two (non-center) nodes are left as singletons due to no assignment. &lt;/li>;&lt;li>;In the post-processing step, to ensure scalability, we use the embedding similarity scores to filter down the potential mergers (in the illustration below, the green dashed boundaries show these merged clusters). &lt;/li>; &lt;/ol>;&lt;div>;&lt;br />; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1bJ65zsG-PYQwvRncviG5befEFPFhA95xoPUB_QV4hQjvz9vNEi-k4_WfZnMG9-25_t6-lpyNCE2MfD_ZSa6q30CjgBF5iRcmH3n6ThprinvD_Qx6rNCIOYuI4ml2U_rI3qI9q6E5qKW9qL1PKAzkOO6wyr8_kS2iDb_FIx2W7Hgjewh5ms2oe0QClfrj/s1322/Kwikbux%20gif.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;704&quot; data-original-width=&quot;1322&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1bJ65zsG-PYQwvRncviG5befEFPFhA95xoPUB_QV4hQjvz9vNEi-k4_WfZnMG9-25_t6-lpyNCE2MfD_ZSa6q30CjgBF5iRcmH3n6ThprinvD_Qx6rNCIOYuI4ml2U_rI3qI9q6E5qKW9qL1PKAzkOO6wyr8_kS2iDb_FIx2W7Hgjewh5ms2oe0QClfrj/s16000/Kwikbux%20gif.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Illustration of progress of the clustering algorithm on a given graph instance. &lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Results&lt;/h2>; &lt;p>; We evaluate the novel clustering algorithm on various datasets with different properties using different embedding-based and cross-attentionâ€“based models. We compare the clustering algorithm&#39;s performance with the two best performing baselines (see the &lt;a href=&quot;https://openreview.net/pdf?id=p0JSSa1AuV&quot;>;paper&lt;/a>; for more details): &lt;/p>; &lt;ul>; &lt;li>;The &lt;a href=&quot;https://arxiv.org/pdf/2002.11557.pdf&quot;>;query-efficient correlation clustering&lt;/a>; algorithm for budgeted clustering with access to CA only. &lt;/li>;&lt;li>;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spectral_clustering&quot;>;Spectral clustering&lt;/a>; on the &lt;em>;&lt;a href=&quot;https://en.wikipedia .org/wiki/Nearest_neighbor_graph&quot;>;k-nearest neighbor graph&lt;/a>;&lt;/em>; (kNN) formed by querying the CA model for the &lt;em>;k&lt;/em>;-nearest neighbors of each vertex from embedding-basedç›¸ä¼¼ã€‚ &lt;/li>; &lt;/ul>; &lt;p>; To evaluate the quality of clustering, we use &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall&quot;>;precision and recall&lt;/a>;. Precision is used to calculate the percentage of similar pairs out of all co-clustered pairs and recall is the percentage of co-clustered similar pairs out of all similar pairs. To measure the quality of the obtained solutions from our experiments, we use the &lt;a href=&quot;https://en.wikipedia.org/wiki/F-score&quot;>;F1-score&lt;/a>;, which is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Harmonic_mean&quot;>;harmonic mean&lt;/a>; of the precision and recall, where 1.0 is the highest possible value that indicates perfect precision and recall, and 0 is the lowest possible value that indicates if either precision or recall are zero. The table below reports the F1-score for Kwikbucks and various baselines in the case that we allow only a linear number of queries to the CA model. We show that Kwikbucks offers a substantial boost in performance with a 45% relative improvement compared to the best baseline when averaging across all datasets. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQbrQVGenUUG0sSZ_Ofe9xIiJ068UIBcUCEvH2dUEdji1XMElQJM13RQkuZp2XExktKlpY6VGr6QfujDWyvu9kUlYtIFSV7hKYEgz6D-CUF0Q7UPN4p58EJji5HeVgXfLoAAhatmG74b2zUnewtGKkoyPz9NQIbc43cqKZ35vcyMlJ99PaCdzk1X-WFAqr/s1574/results.jpg&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;582&quot; data-original-width=&quot;1574&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQbrQVGenUUG0sSZ_Ofe9xIiJ068UIBcUCEvH2dUEdji1XMElQJM13RQkuZp2XExktKlpY6VGr6QfujDWyvu9kUlYtIFSV7hKYEgz6D-CUF0Q7UPN4p58EJji5HeVgXfLoAAhatmG74b2zUnewtGKkoyPz9NQIbc43cqKZ35vcyMlJ99PaCdzk1X-WFAqr/s16000/results.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;Comparing the clustering algorithm to two baseline algorithms using various public datasets: (1) The &lt;a href=&quot;https://arxiv.org/pdf/2002.11557.pdf&quot;>;query-efficient correlation clustering&lt;/a>; algorithm for budgeted clustering with access to CA only, and (2) &lt;a href=&quot;https://en.wikipedia.org/wiki/Spectral_clustering&quot;>;spectral clustering&lt;/a>; on the &lt;em>; &lt;a href=&quot;https://en.wikipedia.org/wiki/Nearest_neighbor_graph&quot;>;k-nearest neighbor (kNN) graph&lt;/a>;&lt;/em>; formed by querying the CA model for the &lt;em>;k&lt;/ em>;-nearest neighbors of each vertex from embedding-based similarity. Pre-processed datasets can be downloaded &lt;a href=&quot;https://storage.googleapis.com/gresearch/kwikbucks/kwikbucks.zip&quot;>;here&lt;/a>;.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; The figure below compares the clustering algorithm&#39;s performance with baselines using different query budgets. We observe that KwikBucks consistently outperforms other baselines at various budgets. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3CboOkZ4lbp9dmH-5EkPGe1zo6JPlOQbXT1n67ke4qN0kXeZXMQKb4SUM-E6TXuyWF9UF7vvKTtl2lecg-Z5tV0mA6Hobh9NKbmy__dqGRIYcTEIzdfGjCCyih2eZW4xF33n7Y1pJGpwyDvQ75rwQsp0kZICGSPoyR8ahiBQwcZvT7ZLLeAA1BQkJtLwU/s1236/stackoverflow.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;602&quot; data-original-width=&quot;1236&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3CboOkZ4lbp9dmH-5EkPGe1zo6JPlOQbXT1n67ke4qN0kXeZXMQKb4SUM-E6TXuyWF9UF7vvKTtl2lecg-Z5tV0mA6Hobh9NKbmy__dqGRIYcTEIzdfGjCCyih2eZW4xF33n7Y1pJGpwyDvQ75rwQsp0kZICGSPoyR8ahiBQwcZvT7ZLLeAA1BQkJtLwU/s16000/stackoverflow.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;A comparison of KwikBucks with top-2 baselines when allowed different budgets for querying the cross-attention model.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; Text clustering often presents a dilemma in the choice of similarity function: embedding models are scalable but lack quality, while cross-attention models offer quality but substantially hurt scalability. We present a clustering algorithm that offers the best of both worlds: the scalability of embedding models and the quality of cross-attention models. KwikBucks can also be applied to other clustering problems with multiple similarity oracles of varying accuracy levels. This is validated with an exhaustive set of experiments on various datasets with diverse properties. See the &lt;a href=&quot;https://openreview.net/pdf?id=p0JSSa1AuV&quot;>;paper&lt;/a>; for more details. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;This project was initiated during Sandeep Silwal&#39;s summer internship at Google in 2022. We would like to express our gratitude to our co-authors, Andrew McCallum, Andrew Nystrom, Deepak Ramachandran, and Sandeep Silwal, for their valuable contributions to this work. We also thank Ravi Kumar and John Guilyard for assistance with this blog post.&lt;/em>; &lt;/p>;&lt;/div>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/8959024707515398632/ comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/best-of-both -worlds-achieving.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/ posts/default/8959024707515398632&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/8959024707515398632&quot; rel=&quot; self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/best-of-both-worlds-achieving.html&quot; rel=&quot;alternate&quot; title =&quot;Best of both worlds: Achieving scalability and quality in text clustering&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile /12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https ://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger .googleusercontent.com/img/b/R29vZ2xl/AVvXsEjR2mD5afdT_Qg9Ex4Lj94FaxB9KHiq20iLoDlOY8S8Rk5XsV6n_4dU9CFbCvSeBSONGQYqy-yMGY6-KU_y_RGICOpz76GNdzv7ecxor_rVnF31lZOd3STQF4MIE4F_EadrSI1DXY67MXnsCswY3w3X8vX8KgU_rRPs6eTZndYAbVcEezgwaUsdZEAHD59Z/s72-c/hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt; /media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-4882962745371313901&lt;/id>;&lt;published>;2023 -11-02T15:01:00.001-07:00&lt;/published>;&lt;updated>;2023-11-02T15:06:20.846-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com /atom/ns#&quot; term=&quot;Large Language Models&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Machine Learning&quot;>;&lt;/category>;&lt; category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Natural Language Understanding&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Zero-shot adaptive prompting of large language models&lt;/ stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Xingchen Wan, Student Researcher, and Ruoxi Sun, Research Scientist, Cloud AI Team&lt;/span>; &lt;img src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqTosaeIs4AMYukkmgUBEii6iQcrr9_dNKM0cHnW6m9Wi8yX0V-QCduQfkqLyQPNpVbze3OFO-nPG5Wm9DLMM8pEAfhQGq-TEJroLJGQyqNr-hlJNkToBCmgJbphrCRvlv95gkDQH0ScT7VrXu2VCTKyiWy8yYM4G8voF0kD0K2oxwg2M2xBcz1yQnU0Zb/s600/USP.gif&quot; style=&quot;display: none;&quot; />; &lt;p>; Recent advances in large language models (LLMs) are very promising as reflected in their capability for general problem-solving in &lt;em>;few-shot&lt;/em>; and &lt;em>;zero-shot&lt;/em>; setups, even without explicit training on these tasks. This is impressive because in the few-shot setup, LLMs are presented with only a few question-answer demonstrations prior to being given a test question. Even more challenging is the zero-shot setup, where the LLM is directly prompted with the &lt;em>;test question only&lt;/em>;. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; Even though the few-shot setup has dramatically reduced the amount of data required to adapt a model for a specific use-case, there are still cases where generating sample prompts can be challenging. For example, handcrafting even a small number of demos for the broad range of tasks covered by general-purpose models can be difficult or, for unseen tasks, impossible. For example, for tasks like summarization of long articles or those that require domain knowledge (eg, medical question answering), it can be challenging to generate sample answers. In such situations, models with high zero-shot performance are useful since no manual prompt generation is required. However, zero-shot performance is typically weaker as the LLM is not presented with guidance and thus is prone to spurious output. &lt;/p>; &lt;p>; In â€œ&lt;a href=&quot;https://aclanthology.org/2023.findings-acl.216/&quot;>;Better Zero-shot Reasoning with Self-Adaptive Prompting&lt;/a>;â€, published at &lt;a href=&quot;https://2023.aclweb.org/&quot;>;ACL 2023&lt;/a>;, we propose &lt;em>;Consistency-Based Self-Adaptive Prompting (COSP) &lt;/em>;to address this dilemma. COSP is a zero-shot automatic prompting method for reasoning problems that carefully selects and constructs &lt;em>;pseudo-&lt;/em>;demonstrations for LLMs using only unlabeled samples (that are typically easy to obtain) and the models&#39; own predictions. With COSP, we largely close the performance gap between zero-shot and few-shot while retaining the desirable generality of zero-shot prompting. We follow this with â€œ&lt;a href=&quot;https://arxiv.org/abs/2305.14926&quot;>;Universal Self-Adaptive Prompting&lt;/a>;â€œ (USP), accepted at &lt;a href=&quot;https://2023. emnlp.org/&quot;>;EMNLP 2023&lt;/a>;, in which we extend the idea to a wide range of &lt;em>;general &lt;/em>;natural language understanding (NLU) and natural language generation (NLG) tasks and demonstrate its effectiveness ã€‚ &lt;/p>; &lt;br />; &lt;h2>;Prompting LLMs with their own outputs&lt;/h2>; &lt;p>; Knowing that LLMs benefit from demonstrations and have at least &lt;em>;some&lt;/em>; zero-shot abilities, we wondered whether the model&#39;s zero-shot outputs could serve as demonstrations for the model to prompt itself. The challenge is that zero-shot solutions are imperfect, and we risk giving LLMs poor quality demonstrations, which could be worse than no demonstrations at all. Indeed, the figure below shows that adding a correct demonstration to a question can lead to a correct solution of the test question (Demo1 with question), whereas adding an incorrect demonstration (Demo 2 + questions, Demo 3 with questions) leads to incorrect answers ã€‚ Therefore, we need to select reliable self-generated demonstrations. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5QShw0e9OdtzA9Ob5vAtWloPZGIZgCGFSL9okO-5pxIN3M2QciE1MOT73NsdaHwOz5LiH94IZRkE0SYSJ2fiiBSNR_qHCrO-URHqZPq7Fhhpvm6wtykLsySfF9l5ERsbOqtT_J1-A8pjoOa9htdvXEnL4-WRbP-Kn85aIz7G-BvWNflcaG4lUPomVlLU8 /s1051/image6.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1051&quot; data-original-width=&quot;776&quot; height =&quot;640&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5QShw0e9OdtzA9Ob5vAtWloPZGIZgCGFSL9okO-5pxIN3M2QciE1MOT73NsdaHwOz5LiH94IZRkE0SYSJ2fiiBSNR_qHCrO-URHqZPq7Fhhpvm6wtykLsySfF9l5ERsbOqtT_J1-A8pjoOa9htdvXEnL4-WRbP-Kn85aIz7G-BvWNflcaG4lUPomVlLU8/w472-h640/image6.png&quot; width=&quot;472&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>; Example inputs &amp;amp; outputs for reasoning tasks, which illustrates the need for carefully designed selection procedure for in-context demonstrations (&lt;a href=&quot;https://arxiv.org/abs/1608.01413&quot;>;MultiArith&lt;/a>;&amp;nbsp;dataset &amp;amp;&amp;nbsp;&lt;a href=&quot;https://arxiv.org/abs/2204.02311&quot;>;PaLM-62B&lt;/a>;&amp;nbsp;model): (1) zero-shot&amp;nbsp;&lt;/em>;&lt;a href=&quot;https://blog.research.google/2022/05/language-models-perform-reasoning-via.html&quot; style=&quot;text-align: left;&quot;>;chain-of-thought&lt;/a>;&lt;em style=&quot;text-align: left;&quot;>;&amp;nbsp;with no demo: correct logic but wrong answer; (2) correct demo (Demo1) and correct answer; (3) correct but repetitive demo (Demo2) leads to repetitive outputs; (4) erroneous demo (Demo3) leads to a wrong answer; but (5) combining Demo3 and Demo1 again leads to a correct answer.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; COSP leverages a key observation of LLMs: that confident and consistent predictions are more likely correct. This observation, of course, depends on how good the uncertainty estimate of the LLM is. Luckily, in large models, &lt;a href=&quot;https://arxiv.org/abs/2207.05221&quot;>;previous&lt;/a>; &lt;a href=&quot;https://arxiv.org/abs/2210.11610&quot;>;works&lt;/a>; suggest that the uncertainty estimates are robust. Since measuring confidence requires only model predictions, not labels, we propose to use this as a zero-shot proxy of correctness. The high-confidence outputs and their inputs are then used as &lt;em>;pseudo&lt;/em>;-demonstrations. &lt;/p>; &lt;p>; With this as our starting premise, we estimate the model&#39;s confidence in its output based on its &lt;a href=&quot;https://arxiv.org/abs/2203.11171&quot;>;self-consistency&lt;/a>; and use this measure to select robust self-generated demonstrations. We ask LLMs the same question multiple times with zero-shot &lt;a href=&quot;https://blog.research.google/2022/05/language-models-perform-reasoning-via.html&quot;>;chain-of-thought&lt;/a>; (CoT) prompting. To guide the model to generate a range of possible rationales and final answers, we include randomness controlled by a â€œtemperatureâ€ hyperparameter. In an extreme case, if the model is 100% certain, it should output identical final answers each time. We then compute the entropy of the answers to gauge the uncertainty â€” the answers that have high self-consistency and for which the LLM is more certain, are likely to be correct and will be selected. &lt;/p>; &lt;p>; Assuming that w&lt;em>;e&lt;/em>; are presented with a collection of unlabeled questions, the COSP method is: &lt;/p>; &lt;ol>; &lt;li>;Input each unlabeled question into an LLM, obtaining multiple rationales and answers by sampling the model multiple times. The most frequent answers are highlighted, followed by a score that measures consistency of answers across multiple sampled outputs (higher is better). In addition to favoring more consistent answers, we also penalize repetition within a response (ie, with repeated words or phrases) and encourage diversity of selected demonstrations. We encode the preference towards consistent, un-repetitive and diverse outputs in the form of a scoring function that consists of a weighted sum of the three scores for selection of the self-generated pseudo-demonstrations.&lt;/li>; &lt;li>;We concatenate the pseudo-demonstrations into test questions, feed them to the LLM, and obtain a final predicted answer.&lt;/li>; &lt;/ol>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidn_WHASrzLG7rsqvKr5XqTi0VE0hEonQJsCRy0XHnM_DsWP4u1izMPUvfakpLd9FJvu47XXspD3vgIXrnrEhbrGR5vxSkcRRtbrU7HwHh6zLpywepMg39GUAW6uSVYxW-JzdOl5IVt9KPqLDVVCvjz86e6vQgZK79FKAF5wGdpztohbWhe7tVtVwcNBgh/s949/image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;396&quot; data-original-width=&quot;949&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidn_WHASrzLG7rsqvKr5XqTi0VE0hEonQJsCRy0XHnM_DsWP4u1izMPUvfakpLd9FJvu47XXspD3vgIXrnrEhbrGR5vxSkcRRtbrU7HwHh6zLpywepMg39GUAW6uSVYxW-JzdOl5IVt9KPqLDVVCvjz86e6vQgZK79FKAF5wGdpztohbWhe7tVtVwcNBgh/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Illustration of COSP: In Stage 1 (&lt;strong>;left&lt;/strong>;), we run zero-shot CoT multiple times to generate a pool of demonstrations (each consisting of the question, generated rationale and prediction) and assign a score. In Stage 2 (&lt;strong>;right&lt;/strong>;), we augment the current test question with pseudo-demos (blue boxes) and query the LLM again. A majority vote over outputs from both stages forms the final prediction.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; COSP focuses on question-answering tasks with CoT prompting for which it is easy to measure self-consistency since the questions have unique correct answers. But this can be difficult for other tasks, such as open-ended question-answering or generative tasks that don&#39;t have unique answers (eg, text summarization). To address this limitation, we introduce USP in which we generalize our approach to other general NLP tasks: &lt;/p>; &lt;ul>; &lt;li>;&lt;em>;Classification&lt;/em>; (CLS): Problems where we can compute the probability of each class using the neural network output logits of each class. In this way, we can measure the uncertainty without multiple sampling by computing the entropy of the logit distribution.&lt;/li>; &lt;li>;&lt;em>;Short-form generation&lt;/em>; (SFG): Problems like question answering where we can use the same procedure mentioned above for COSP, but, if necessary, without the rationale-generating step.&lt;/li>; &lt;li>;&lt;em>;Long-form generation&lt;/em>; (LFG):&lt;em>; &lt;/em>;Problems like summarization and translation, where the questions are often open-ended and the outputs are unlikely to be identical, even if the LLM is certain. In this case, we use an &lt;em>;overlap metric&lt;/em>; in which we compute the average of the &lt;em>;pairwise&lt;/em>; &lt;a href=&quot;https://en.wikipedia.org/wiki/ROUGE_(metric)&quot;>;ROUGE score&lt;/a>; between the different outputs to the same query.&lt;/li>; &lt;/ul>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjn2mgVNUmsKVPYKo3zrcQnq3nHT0xIzCk2rIOK0fSrFIOEkyCrx7MWNnTrOdwnFRlGbid1cj8OqV2xBCfOtgv5oiuUPoQjRY9CpMnjM79P0mQmoyQqluMPZsqFQUtS7AtPy5Uw-sf5UT_dV_bRbGWSRQiR5U2tDIYd2zxsk_lboJsKG4mcBZKxp5gEeT_T/s1360/image3.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;640&quot; data-original-width=&quot;1360&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjn2mgVNUmsKVPYKo3zrcQnq3nHT0xIzCk2rIOK0fSrFIOEkyCrx7MWNnTrOdwnFRlGbid1cj8OqV2xBCfOtgv5oiuUPoQjRY9CpMnjM79P0mQmoyQqluMPZsqFQUtS7AtPy5Uw-sf5UT_dV_bRbGWSRQiR5U2tDIYd2zxsk_lboJsKG4mcBZKxp5gEeT_T/s16000/image3.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Illustration of USP in exemplary tasks (classification, QA and text summarization). Similar to COSP, the LLM first generates predictions on an unlabeled dataset whose outputs are scored with logit entropy, consistency or alignment, depending on the task type, and pseudo-demonstrations are selected from these input-output pairs. In Stage 2, the test instances are augmented with pseudo-demos for prediction.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; We compute the relevant confidence scores depending on the type of task on the aforementioned set of unlabeled test samples. After scoring, similar to COSP, we pick the confident, diverse and less repetitive answers to form a model-generated pseudo-demonstration set. We finally query the LLM again in a few-shot format with these pseudo-demonstrations to obtain the final predictions on the entire test set. &lt;/p>; &lt;br />; &lt;h2>;Key Results&lt;/h2>; &lt;p>; For COSP, we focus on a set of six arithmetic and commonsense reasoning problems, and we compare against 0-shot-CoT (ie, â€œ&lt;a href=&quot;https://arxiv.org/abs/2205.11916&quot;>;Let&#39;s think step by step&lt;/a>;â€œ only). We use self-consistency in all baselines so that they use roughly the same amount of computational resources as COSP. Compared across three LLMs, we see that zero-shot COSP significantly outperforms the standard zero-shot baseline. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsRevpmsBSIsIMti071v4FFnK-khtMXTbqvf92wvdvKQhyphenhyphenTCADcsIOQhAtr1kfxkmoaQ5MNKmcJiYol1JmxCchzYl9Kn_9h9eaGZAvJBrRxsvJorbngS4fLaChBk6e9wtHgE7JvPMHN1gajpnhgZaCwuYOjo-CTUR9x8PbXEEbRG3vp8elQzMib5Kv5Qh-/s1883/image1.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1738&quot; data-original-width=&quot;1883&quot; height=&quot;369&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsRevpmsBSIsIMti071v4FFnK-khtMXTbqvf92wvdvKQhyphenhyphenTCADcsIOQhAtr1kfxkmoaQ5MNKmcJiYol1JmxCchzYl9Kn_9h9eaGZAvJBrRxsvJorbngS4fLaChBk6e9wtHgE7JvPMHN1gajpnhgZaCwuYOjo-CTUR9x8PbXEEbRG3vp8elQzMib5Kv5Qh-/w400-h369/image1.png&quot; width=&quot;400&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Key results of COSP in six arithmetic (&lt;a href=&quot;https://arxiv.org/abs/1608.01413&quot; style= &quot;text-align: left;&quot;>;MultiArith&lt;/a>;, &lt;a href=&quot;https://arxiv.org/abs/2110.14168&quot; style=&quot;text-align: left;&quot;>;GSM-8K&lt;/a>; , &lt;a href=&quot;https://aclanthology.org/D14-1058/&quot; style=&quot;text-align: left;&quot;>;AddSub&lt;/a>;, &lt;a href=&quot;https://doi.org/10.1162 /tacl_a_00160&quot; style=&quot;text-align: left;&quot;>;SingleEq&lt;/a>;) and commonsense (&lt;a href=&quot;https://doi.org/10.18653/v1/N19-1421&quot; style=&quot;text-align : left;&quot;>;CommonsenseQA&lt;/a>;, &lt;a href=&quot;https://doi.org/10.1162/tacl_a_00370&quot; style=&quot;text-align: left;&quot;>;StrategyQA&lt;/a>;) reasoning tasks using &lt;a href=&quot;https://arxiv.org/abs/2204.02311&quot;>;PaLM-62B, PaLM-540B&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/2107.03374&quot;>;GPT-3 ( code-davinci-001)&lt;/a>; models.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class =&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcbJaMBl3_Pc5S_mp9lDWz4v_SS6Mzd3QBxyn-tWdtnDNgJLX1YPRHkdPtJBanhADoEDTzJqOsk2x4uOFoV8e0h8Tml_Nt1kOd5eT7TyC-MIqWEVEiY_kZQZ0wkPU9T5HwIHXv2IHeLXdGz1MvWiQFxNNe7CaKDfUs0j9R6F8cgN4T0dgtgp86xsF9cK6l/s1999/image7.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1014&quot; data-original-width=&quot;1999&quot; height=&quot;325&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcbJaMBl3_Pc5S_mp9lDWz4v_SS6Mzd3QBxyn-tWdtnDNgJLX1YPRHkdPtJBanhADoEDTzJqOsk2x4uOFoV8e0h8Tml_Nt1kOd5eT7TyC-MIqWEVEiY_kZQZ0wkPU9T5HwIHXv2IHeLXdGz1MvWiQFxNNe7CaKDfUs0j9R6F8cgN4T0dgtgp86xsF9cK6l/w640-h325/image7.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;USP improves significantly on 0-shot performance. â€œCLSâ€ is an average of 15 classification tasks; â€œSFGâ€ is the average of five short-form generation tasks; â€œLFGâ€ is the average of two summarization tasks. â€œSFG (BBH)â€ is an average of all BIG-Bench Hard tasks, where each question is in SFG format.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; For USP, we expand our analysis to a much wider range of tasks, including more than 25 classifications, short-form generation, and long-form generation tasks. Using the state-of-the-art PaLM 2 models, we also test against the &lt;a href=&quot;https://arxiv.org/abs/2210.09261&quot;>;BIG-Bench Hard&lt;/a>; suite of tasks where LLMs have previously underperformed compared to people. We show that in all cases, USP again outperforms the baselines and is competitive to prompting with golden examples. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjsJh9EIxiF8m6jqOM7vYniG6LX8gFVa0W3V7_DEOwMCEZjbk_M4104Tg-3qMUAbYXaR3RqMTQsrZ8TN3Np5I9SXHBVJGjB6E6_1khoubPbbR-AjUnV37TYGBHu2DJpR50Ek34dwcFkjJB-OTqW4T4E-zjQhJqPX-f_PxSj7322nU2qH2VK0TBMO1QKUkfT/s901 /image5.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;901&quot; data-original-width=&quot;833&quot; height=&quot; 640&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjsJh9EIxiF8m6jqOM7vYniG6LX8gFVa0W3V7_DEOwMCEZjbk_M4104Tg-3qMUAbYXaR3RqMTQsrZ8TN3Np5I9SXHBVJGjB6E6_1khoubPbbR-AjUnV37TYGBHu2DJpR50Ek34dwcFkjJB-OTqW4T4E-zjQhJqPX-f_PxSj7322nU2qH2VK0TBMO1QKUkfT/w592-h640/image5.png&quot; width=&quot;592&quot; />;&lt;/ a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Accuracy on BIG- Bench Hard tasks with PaLM 2-M (each line represents a task of the suite). The gain/loss of USP (green stars) over standard 0-shot (green triangles) is shown in percentages. â€œHumanâ€ refers to average human performance; â€œAutoCoTâ€ and â€œRandom demoâ€ are baselines we compared against in the&amp;nbsp;&lt;a href=&quot;https://arxiv.org/abs/2305.14926&quot;>;paper&lt;/a>;; and â€œ3-shotâ€ is the few-shot performance for three handcrafted demos in CoT format.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; We also analyze the working mechanism of USP by validating the key observation above on the relation between confidence and correctness, and we found that in an overwhelming majority of the cases, USP picks confident predictions that are more likely better in all task types considered, as shown in theå¦‚ä¸‹å›¾ã€‚ &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjahSci_hJqgqxS-my79ZlINe9Dpi0yaLrMTXeTu-HXjmmAmhVXtylXK7BUdJGIPMFhFvqv31Wd6ux2ti1hJLIi9Rr8j_PIjD9ElUTWx0ViaP1fLg63Q9lqvgd7U74Uqi45IOU3CsqHaqjO94iSLyPD2dZCJf5x5hsHfU_6yukbJHpG6wDzdSVp7nwBHNFx/s1474/image2.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;507&quot; data-original-width=&quot;1474&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjahSci_hJqgqxS-my79ZlINe9Dpi0yaLrMTXeTu-HXjmmAmhVXtylXK7BUdJGIPMFhFvqv31Wd6ux2ti1hJLIi9Rr8j_PIjD9ElUTWx0ViaP1fLg63Q9lqvgd7U74Uqi45IOU3CsqHaqjO94iSLyPD2dZCJf5x5hsHfU_6yukbJHpG6wDzdSVp7nwBHNFx/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;USP picks confident predictions that are more likely better. Ground-truth performance metrics against USP confidence scores in selected tasks in various task types (blue: CLS, orange: SFG, green: LFG) with PaLM-540B.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; Zero-shot inference is a highly sought-after capability of modern LLMs, yet the success in which poses unique challenges. We propose COSP and USP, a family of versatile, zero-shot automatic prompting techniques applicable to a wide range of tasks. We show large improvement over the state-of-the-art baselines over numerous task and model combinations. &lt;/p>; &lt;br />; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;This work was conducted by Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Hanjun Dai, Julian Martin Eisenschlos, Sercan OÌˆ. ArÄ±k, and Tomas Pfister. We would like to thank Jinsung Yoon Xuezhi Wang for providing helpful reviews, and other colleagues at Google Cloud AI Research for their discussion and feedback.&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/4882962745371313901/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4882962745371313901&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4882962745371313901&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html&quot; rel=&quot;alternate&quot; title=&quot;Zero-shot adaptive prompting of large language models&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqTosaeIs4AMYukkmgUBEii6iQcrr9_dNKM0cHnW6m9Wi8yX0V-QCduQfkqLyQPNpVbze3OFO-nPG5Wm9DLMM8pEAfhQGq-TEJroLJGQyqNr-hlJNkToBCmgJbphrCRvlv95gkDQH0ScT7VrXu2VCTKyiWy8yYM4G8voF0kD0K2oxwg2M2xBcz1yQnU0Zb/s72-c/USP.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-4489259534129284932&lt;/id>;&lt;published>;2023-11-01T10:30:00.002-07:00&lt;/published>;&lt;updated>;2023-11-06T09:07:40.958-08:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Machine Learning&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;MetNet-3: A state-of-the-art neural weather model available in Google products&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Samier Merchant, Google Research, and Nal Kalchbrenner, Google DeepMind&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdgnhML03N9vxEdGH1TkBATtxGpjyO5XYgZwJY5dY0-sPIAvrmCll4J8I9owyJTNOHZdq6MMZskWsYJDZivZA_zvj2atWhUsPoxWnNyifiFAm83GC2EsZ4xgre8bCk32Yzv3vlR4pGn12H7T5Vkbz5BaErZ22JRB-OqveQ7EDHsrCYjKN65Soc1FrZNwvu/s1600/metnethero1.gif&quot; style=&quot;display: none;&quot; />; &lt;p>; Forecasting weather variables such as precipitation, temperature, and wind is key to numerous aspects of society, from daily planning and transportation to energy production. As we continue to see more extreme weather events such as floods, droughts, and heat waves, accurate forecasts can be essential to preparing for and mitigating their effects. The first 24 hours into the future are especially important as they are both highly predictable and actionable, which can help people make informed decisions in a timely manner and stay safe. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; Today we present a new weather model called &lt;a href=&quot;https://arxiv.org/abs/2306.06079&quot;>;MetNet-3&lt;/a>;, developed by Google Research and Google DeepMind. Building on the earlier &lt;a href=&quot;https://blog.research.google/2020/03/a-neural-weather-model-for-eight-hour.html?m=1&quot;>;MetNet&lt;/a>; and &lt;a href=&quot;https://blog.research.google/2021/11/metnet-2-deep-learning-for-12-hour.html&quot;>;MetNet-2&lt;/a>; models, MetNet-3 provides high resolution predictions up to 24 hours ahead for a larger set of core variables, including precipitation, surface temperature, wind speed and direction, and dew point. MetNet-3 creates a temporally smooth and highly granular forecast, with lead time intervals of 2 minutes and spatial resolutions of 1 to 4 kilometers. MetNet-3 achieves strong performance compared to traditional methods, outperforming the best single- and multi-member physics-based &lt;a href=&quot;https://en.wikipedia.org/wiki/Numerical_weather_prediction&quot;>;numerical weather prediction&lt;/a>; (NWP) models â€” such as &lt;a href=&quot;https://rapidrefresh.noaa.gov/hrrr/&quot;>;High-Resolution Rapid Refresh&lt;/a>; (HRRR) and &lt;a href=&quot;https://www.ecmwf.int/en/forecasts/documentation-and-support/medium-range-forecasts#:~:text=ENS%20is%20a%20probabilistic%20forecast,high%20winds%20or%20heavy%20rain).&quot;>;ensemble forecast suite&lt;/a>; (ENS) â€” for multiple regions up to 24 hours ahead. &lt;/p>; &lt;p>; Finally, we&#39;ve integrated MetNet-3&#39;s capabilities across various Google &lt;a href=&quot;https://support.google.com/websearch/answer/13692898&quot;>;products and technologies&lt;/a>; where weather is relevant. Currently available in the contiguous United States and parts of Europe with a focus on 12 hour precipitation forecasts, MetNet-3 is helping bring accurate and reliable weather information to people in multiple countries and languages. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>; &lt;tbody>; &lt;tr>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQcwPsDQPUe4Uon7vWWSewbqcWsAdfUIJ4yLLFiCvdQKu4ffT6E5qIMeiabtxK5wudSL-jjxa_fW5aOaBvDILq_dQzeT4RMSULORJZrjwkDscDxLnLflUybqHlPf1J8O7KB171g5I9kLVgRbGP0mr0HxbG0pY7J9ojoEZLl4JZHaMQH490XmUR_IUj_YMO/s904/image55.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;904&quot; data-original-width=&quot;476&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQcwPsDQPUe4Uon7vWWSewbqcWsAdfUIJ4yLLFiCvdQKu4ffT6E5qIMeiabtxK5wudSL-jjxa_fW5aOaBvDILq_dQzeT4RMSULORJZrjwkDscDxLnLflUybqHlPf1J8O7KB171g5I9kLVgRbGP0mr0HxbG0pY7J9ojoEZLl4JZHaMQH490XmUR_IUj_YMO/s16000/image55.gif&quot; />;&lt;/a>;&lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>; &lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixRY-kzsepNdP_arXnJbHPJFViN_N4CzjOYH_1YxfjIDI5Nben4u8BoJ-tcYrrw4a3Jp7HFBGmakeBMqKAINeVFssClJHNUjvBhYHY6vpy6nOdpEoFDhCulwIE8OM9e7fRRwXqW01AeWUJjqmnNDn32ScCeQ2S64aNvDgigDes5vWA1_RrT7oMxK8sttG7/s904/image1.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;904&quot; data-original-width=&quot;476&quot; src=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEixRY-kzsepNdP_arXnJbHPJFViN_N4CzjOYH_1YxfjIDI5Nben4u8BoJ-tcYrrw4a3Jp7HFBGmakeBMqKAINeVFssClJHNUjvBhYHY6vpy6nOdpEoFDhCulwIE8OM9e7fRRwXqW01AeWUJjqmnNDn32ScCeQ2S64aNvDgigDes5vWA1_RrT7oMxK8sttG7/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>; &lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing= â€œ0â€ç±»=â€œtr-caption-containerâ€æ ·å¼=â€œmargin-leftï¼šè‡ªåŠ¨ï¼› margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;MetNet-3 precipitation output summarized into actionable forecasts in Google Search on mobile.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Densification of sparse observations&lt;/h2>; &lt;p>; Many recent machine learning weather models use the atmospheric state generated by traditional methods (eg, data assimilation from NWPs) as the primary starting point to build forecasts. In contrast, a defining feature of the MetNet models has been to use direct observations of the atmosphere for training and evaluation. The advantage of direct observations is that they often have higher fidelity and resolution. However, direct observations come from a large variety of sensors at different altitudes, including weather stations at the surface level and satellites in orbit, and can be of varying degrees of sparsity. For example, precipitation estimates derived from radar such as &lt;a href=&quot;https://mrms.nssl.noaa.gov/&quot;>;NOAA&#39;s Multi-Radar/Multi-Sensor System&lt;/a>; (MRMS) are relatively dense images, whereas weather stations located on the ground that provide measurements for variables such as temperature and wind are mere points spread over a region. &lt;/p>; &lt;p>; In addition to the data sources used in previous MetNet models, MetNet-3 includes point measurements from weather stations as both inputs and targets with the goal of making a forecast at all locations. To this end, MetNet-3&#39;s key innovation is a technique called densification, which merges the traditional two-step process of data assimilation and simulation found in physics-based models into a single pass through the neural network. The main components of densification are illustrated below. Although the densification technique applies to a specific stream of data individually, the resulting densified forecast benefits from all the other input streams that go into MetNet-3, including topographical, satellite, radar, and NWP analysis features. No NWP forecasts are included in MetNet-3&#39;s default inputs. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEie1m1p0i-MWhS7Ih5RGzV-AQuDDPwgao4SpmnSUTdSsy7fcEwk4Soj5IJ8FqtGjhvi4ot2HKZdaQh3Hpu4CviRsx7FujT_4bbvpV8mu15Zt5bO5KbMGaaqIZoAGUp77ltVYH-zt2HTwVxbuGZHJt-0lbXZT-ukJH_KtB3pnHdRrRpZ2r5WgMSNGXnu-H8j /s1929/image22.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1929&quot; data-original-width=&quot;1600&quot; src =&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEie1m1p0i-MWhS7Ih5RGzV-AQuDDPwgao4SpmnSUTdSsy7fcEwk4Soj5IJ8FqtGjhvi4ot2HKZdaQh3Hpu4CviRsx7FujT_4bbvpV8mu15Zt5bO5KbMGaaqIZoAGUp77ltVYH-zt2HTwVxbuGZHJt-0lbXZT-ukJH_KtB3pnHdRrRpZ2r5WgMSNGXnu-H8j/s16000/image22.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;b>;A&lt;/b>;) During training, a fraction of the weather stations are masked out from the input while kept in the target. &lt;b>;B&lt;/b>;) To evaluate generalization to untrained locations, a set of weather stations represented by squares is never used for training and is only used for evaluation. &lt;b>;C&lt;/b>;) Data from these held out weather stations with sparse coverage is included during evaluation to determine prediction quality in these areas. &lt;b>;D&lt;/b>;) The final forecasts use the full set of training weather stations as input and produce fully dense forecasts aided by spatial parameter sharing.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt; div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;High resolution in space and time&lt;/h2>; &lt;p>; A central advantage of using direct observations is their high spatial and temporalè§£å†³ã€‚ For example, weather stations and ground radar stations provide measurements every few minutes at specific points and at 1 km resolutions, respectively; this is in stark contrast with the assimilation state from the state-of-the-art model &lt;a href=&quot;https://www.ecmwf.int/en/forecasts/documentation-and-support/medium-range-forecasts#:~:text=ENS%20is%20a%20probabilistic%20forecast,high%20winds%20or%20heavy%20rain).&quot;>;ENS&lt;/a>;, which is generated every 6 hours at a resolution of 9 km with hour-by-hour forecasts. To handle such a high resolution, MetNet-3 preserves another of the defining features of this series of models, &lt;em>;lead time conditioning&lt;/em>;. The lead time of the forecast in minutes is directly given as input to the neural network. This allows MetNet-3 to efficiently model the high temporal frequency of the observations for intervals as brief as 2 minutes. Densification combined with lead time conditioning and high resolution direct observations produces a fully dense 24 hour forecast with a temporal resolution of 2 minutes, while learning from just 1,000 points from the &lt;a href=&quot;https://madis.ncep.noaa.gov/madis_OMO.shtml&quot;>;One Minute Observation&lt;/a>; (OMO) network of weather stations spread across the United States. &lt;/p>; &lt;p>; MetNet-3 predicts a marginal multinomial probability distribution for each output variable and each location that provides rich information beyond just the mean. This allows us to compare the probabilistic outputs of MetNet-3 with the outputs of advanced probabilistic ensemble NWP models, including the ensemble forecast ENS from the &lt;a href=&quot;https://www.ecmwf.int/&quot;>;European Centre for Medium-Range Weather Forecasts&lt;/a>; and the &lt;a href=&quot;https://www.spc.noaa.gov/exper/href/&quot;>;High Resolution Ensemble Forecast&lt;/a>; (HREF) from the &lt;a href=&quot;https://www.noaa.gov/&quot;>;National Oceanic and Atmospheric Administration of the US&lt;/a>;. Due to the probabilistic nature of the outputs of both models, we are able to compute scores such as the &lt;a href=&quot;https://confluence.ecmwf.int/display/FUG/Section+12.B+Statistical+Concepts+-+Probabilistic+Data#:~:text=The%20Continuous%20Ranked%20Probability%20Score,the%20forecast%20is%20wholly%20inaccurate.&quot;>;Continuous Ranked Probability Score&lt;/a>; (CRPS). The following graphics highlight densification results and illustrate that MetNet&#39;s forecasts are not only of much higher resolution, but are also more accurate when evaluated at the overlapping lead times. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiJsf6Y6gV9VjK_rS_Bf_WLWdsJOq3sQbdaW26VSp2vX1Fq5j7VcWl4VDi3BeBFpEcH_YGrkU9ozJyuP5dh8tWWCU4yGzlmGBTfwM-kXGKZvdvI1DF17V4kSJSGGBIacqaCO4N1Oc8P4PymPWdglJbew_cjP9reFSJuHR3_ikZfZFuzN6aC8F17TAtiJPIg/s768/image44.gif&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;768&quot; data-original-width=&quot;600&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEiJsf6Y6gV9VjK_rS_Bf_WLWdsJOq3sQbdaW26VSp2vX1Fq5j7VcWl4VDi3BeBFpEcH_YGrkU9ozJyuP5dh8tWWCU4yGzlmGBTfwM-kXGKZvdvI1DF17V4kSJSGGBIacqaCO4N1Oc8P4PymPWdglJbew_cjP9reFSJuHR3_ikZfZFuzN6aC8F17TAtiJPIg/s16000/image44.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;&lt;b>;Top&lt;/b>;: MetNet-3&#39;s forecast of wind speed for each 2 minutes over the future 24 hours with a spatial resolution of 4km. &lt;b>;Bottom&lt;/b>;: ENS&#39;s hourly forecast with a spatial resolution of 18 km. &lt;br />;The two distinct regimes in spatial structure are primarily driven by the presence of the Colorado mountain ranges. Darker corresponds to higher wind speed. More samples available here: &lt;a href=&quot;https://youtube.com/watch?v=iB1DzHNqH_o&quot;>;1&lt;/a>;, &lt;a href=&quot;https://youtube.com/watch?v=LlWB558jKJk&quot; >;2&lt;/a>;, &lt;a href=&quot;https://youtube.com/watch?v=74bFo3nkbe4&quot;>;3&lt;/a>;, &lt;a href=&quot;https://youtube.com/watch?v= MKUzYQZn9sQ&quot;>;4&lt;/a>;.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container â€œæ ·å¼=â€ Margin-Leftï¼šAuto; Margin-Rightï¼šauto;â€œ>; &lt;tbody>; &lt;tr>; &lt;td style =â€ text-alignï¼šcenter;â€œ>; &lt;a href =â€ httpsï¼š//blogger.googleusercontentã€‚ com/img/b/R29vZ2xl/AVvXsEhBhlSum7x274E9KQGzLnjM9iXNEhifOJjKzt1Cwa5YyABCbaB68Mkr3gFvIVUhyphenhyphenaIGOqUE78MqGTK992NK8zrdKrqKxtFlYf1qeWYNkTa4PVzD3u_9lmQAjKnbLILHAkPhIOCvyAI6qBtfyf-z_xgUys3gXRJd_GSs3-qnyq0yFbjvmxdXAbVldV-xrIRJ/s1120/image11.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0 &quot; data-original-height=&quot;694&quot; data-original-width=&quot;1120&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBhlSum7x274E9KQGzLnjM9iXNEhifOJjKzt1Cwa5YyABCbaB68Mkr3gFvIVUhyphenhyphenaIGOqUE78MqGTK992NK8zrdKrqKxtFlYf1qeWYNkTa4PVzD3u_9lmQAjKnbLILHAkPhIOCvyAI6qBtfyf-z_xgUys3gXRJd_GSs3-qnyq0yFbjvmxdXAbVldV-xrIRJ/s16000/image11. png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Performance comparison between MetNet-3 and NWP baseline for wind speed based on CRPS (lower is better). In the hyperlocal setting, values of the test weather stations are given as input to the network during evaluation; the results improve further especially in the early lead times.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; In contrast to weather station variables, precipitation estimates are more dense as they come from ground radar. MetNet-3&#39;s modeling of precipitation is similar to that of MetNet-1 and 2, but extends the high resolution precipitation forecasts with a 1km spatial granularity to the same 24 hours of lead time as the other variables, as shown in the animation below. MetNet-3&#39;s performance on precipitation achieves a better CRPS value than ENS&#39;s throughout the 24 hour range. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidyInWvqdPpdIndLrxzykAODCeJ_p69uqvYOpasjFcBQU5o8Mtr-DiLfZXZrkJel9TD9SxZEmyIb58r6TZjRw57D8aSjl9P2jxCOsK7XZeXY0J3B8UMIFnl6aqXqhd0wft_NQGBi9KqpSUHAgw2c4JoYMdt27sKp6xcvOyMfjASpaZZzlI9o8lesj3GsrL/s720/image14.gif&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;683&quot; data-original-width=&quot;720&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEidyInWvqdPpdIndLrxzykAODCeJ_p69uqvYOpasjFcBQU5o8Mtr-DiLfZXZrkJel9TD9SxZEmyIb58r6TZjRw57D8aSjl9P2jxCOsK7XZeXY0J3B8UMIFnl6aqXqhd0wft_NQGBi9KqpSUHAgw2c4JoYMdt27sKp6xcvOyMfjASpaZZzlI9o8lesj3GsrL/s16000/image14.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;Case study for Thu Jan 17 2019 00:00 UTC showing the probability of instantaneous precipitation rate being above 1 mm/h on CONUS. Darker corresponds to a higher probability value. The maps also show the prediction threshold when optimized towards Critical Success Index &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall&quot;>;CSI&lt;/a>; (dark blue contours). This specific case study shows the formation of a new large precipitation pattern in the central US; it is not just forecasting of existing patterns. &lt;br />;&lt;b>;Top:&lt;/b>; ENS&#39;s hourly forecast. &lt;b>;Center:&lt;/b>; Ground truth, source NOAA&#39;s MRMS. &lt;b>;Bottom:&lt;/b>; Probability map as predicted by MetNet-3. &lt;a href=&quot;https://www.youtube.com/watch?v=TXqR9lL4368&quot;>;Native resolution available here.&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_4M2Sz50c_PDZkyHqZGfc5p5aRGpAS04ztN9N3s3VBn4_AD8GN7Vv6Vw-2phokpqtamutHT_6nGSsXb7271cfijLu3vJT1IV8Mmo1wlq1jfYcUPNs7TL6z0Cls3qGD1jA4Z0uRpj_rNXYLpFSbHEIqNOAA_V8VE_ZhsO7o-D64nDdmRei_hPEY7YT8lcg/s1102/image4.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;682&quot; data-original-width=&quot;1102&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_4M2Sz50c_PDZkyHqZGfc5p5aRGpAS04ztN9N3s3VBn4_AD8GN7Vv6Vw-2phokpqtamutHT_6nGSsXb7271cfijLu3vJT1IV8Mmo1wlq1jfYcUPNs7TL6z0Cls3qGD1jA4Z0uRpj_rNXYLpFSbHEIqNOAA_V8VE_ZhsO7o-D64nDdmRei_hPEY7YT8lcg/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Performance comparison between MetNet-3 and NWP baseline for instantaneous precipitation rate on CRPS (lower is better).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Delivering realtime ML forecasts&lt;/h2>; &lt;p>; Training and evaluating a weather forecasting model like MetNet-3 on historical data is only a part of the process of delivering ML-powered forecasts to users. There are many considerations when developing a real-time ML system for weather forecasting, such as ingesting real-time input data from multiple distinct sources, running inference, implementing real-time validation of outputs, building insights from the rich output of the model that lead to an intuitive user experience, and serving the results at Google scale â€” all on a continuous cycle, refreshed every few minutes. &lt;/p>; &lt;p>; We developed such a real-time system that is capable of producing a precipitation forecast every few minutes for the entire contiguous United States and for 27 countries in Europe for a lead time of up to 12 hours. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg88AA6lzoFtJd9ZOXt6AiiT_gTtFcJwsZNzUJ63kuYtq7XYs0LHUSp3q37zOPolA-rR_WQPciuDZsg-4Y3J0qrLUmNxMi1iBqyR4ICy4MKwRFXHtQhfkWdwPREd4qm9FVlN6rpLEebDC7MfBg7hToXhQvdsFoGObtu-Lqty3ZQSALf1yjna37tJY4fAptE/s1600/image6.gif &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;367&quot; data-original-width=&quot;1600&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg88AA6lzoFtJd9ZOXt6AiiT_gTtFcJwsZNzUJ63kuYtq7XYs0LHUSp3q37zOPolA-rR_WQPciuDZsg-4Y3J0qrLUmNxMi1iBqyR4ICy4MKwRFXHtQhfkWdwPREd4qm9FVlN6rpLEebDC7MfBg7hToXhQvdsFoGObtu-Lqty3ZQSALf1yjna37tJY4fAptE/s16000/image6.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;Illustration of the process of generating precipitation forecasts using MetNet-3.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; The system&#39;s uniqueness stems from its use of near-continuous inference, which allows the model to constantly create full forecasts based on incoming data streams. This mode of inference is different from traditional inference systems, and is necessary due to the distinct characteristics of the incoming data. The model takes in various data sources as input, such as radar, satellite, and numerical weather prediction assimilations. Each of these inputs has a different refresh frequency and spatial and temporal resolution. Some data sources, such as weather observations and radar, have characteristics similar to a continuous stream of data, while others, such as NWP assimilations, are similar to batches of data. The system is able to align all of these data sources spatially and temporally, allowing the model to create an updated understanding of the next 12 hours of precipitation at a very high cadence. &lt;/p>; &lt;p>; With the above process, the model is able to predict arbitrary discrete probability distributions. We developed novel techniques to transform this dense output space into user-friendly information that enables rich experiences throughout Google products and technologies. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Weather features in Google products&lt;/h2>; &lt;p>; People around the world rely on Google every day to provide helpful, timely, and accurate information about the weather. This information is used for a variety of purposes, such as planning outdoor activities, packing for trips, and staying safe during severe weather events. &lt;/p>; &lt;p>; The state-of-the-art accuracy, high temporal and spatial resolution, and probabilistic nature of MetNet-3 makes it possible to create unique hyperlocal weather insights. For the contiguous United States and Europe, MetNet-3 is operational and produces real-time 12 hour precipitation forecasts that are now served across Google &lt;a href=&quot;https://support.google.com/websearch/answer/13692898&quot;>;products and technologies&lt;/a>; where weather is relevant, such as Search. The rich output from the model is synthesized into actionable information and instantly served to millions of users. &lt;/p>; &lt;p>; For example, a user who searches for weather information for a precise location from their mobile device will receive highly localized precipitation forecast data, including timeline graphs with granular minute breakdowns depending on the product. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4R591KKD1ZkmhTrjo28JovCeeo2bGjb0Tn5Ohr8KEooVqZqSNlgsrJrROaPWn5XXBzEohkhZMjaX2AV3M1RikyLgO7LfIgTFt54-uumb7xxPU6blnuFC8dN8W2SjK85tBKfZQ9Kn4oR-988YKXVUTbu-N5LWWX6JurqN6RRad7Bve59oEdZC-eMsn4HH9/s600/metnet3 .gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;560&quot; data-original-width=&quot;600&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4R591KKD1ZkmhTrjo28JovCeeo2bGjb0Tn5Ohr8KEooVqZqSNlgsrJrROaPWn5XXBzEohkhZMjaX2AV3M1RikyLgO7LfIgTFt54-uumb7xxPU6blnuFC8dN8W2SjK85tBKfZQ9Kn4oR-988YKXVUTbu-N5LWWX6JurqN6RRad7Bve59oEdZC-eMsn4HH9/s16000/metnet3.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;MetNet-3 precipitation output in weather on the Google app on Android (&lt;b>;left&lt;/b>;) and mobile web Search (&lt;b>;right&lt; /b>;).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Conclusion&lt;/h2 >; &lt;p>; MetNet-3 is a new deep learning model for weather forecasting that outperforms state-of-the-art physics-based models for 24-hour forecasts of a core set of weather variables. It has the potential to create new possibilities for weather forecasting and to improve the safety and efficiency of many activities, such as transportation, agriculture, and energy production. MetNet-3 is operational and its forecasts are served across several Google products where weather is relevant. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;Many people were involved in the development of this effort ã€‚ We would like to especially thank those from Google DeepMind (Di Li, Jeremiah Harmsen, Lasse Espeholt, Marcin Andrychowicz, Zack Ontiveros), Google Research (Aaron Bell, Akib Uddin, Alex Merose, Carla Bromberg, Fred Zyda, Isalo Montacute, Jared Sisk , Jason Hickey, Luke Barrington, Mark Young, Maya Tohidi, Natalie Williams, Pramod Gupta, Shreya Agrawal, Thomas Turnbull, Tom Small, Tyler Russell), and Google Search (Agustin Pesciallo, Bill Myers, Danny Cheresnick, Jonathan Karsh, Lior Cohen , Maca Piombi, Maia Diamant, Max Kamenetsky, Maya Ekron, Mor Schlesinger, Neta Gefen-Doron, Nofar Peled Levi, Ofer Lehr, Or Hillel, Rotem Wertman, Tamar Shevach,Vinay Ruelius Shah, Yechie Labai).&lt;/em>;&lt; /p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/4489259534129284932/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot; />;&lt;link href=&quot;http://blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4489259534129284932&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot; />;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4489259534129284932&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http: //blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html&quot; rel=&quot;alternate&quot; title=&quot;MetNet-3: A state-of-the-art neural weather model available in Google products&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>; noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/ img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/ R29vZ2xl/AVvXsEhdgnhML03N9vxEdGH1TkBATtxGpjyO5XYgZwJY5dY0-sPIAvrmCll4J8I9owyJTNOHZdq6MMZskWsYJDZivZA_zvj2atWhUsPoxWnNyifiFAm83GC2EsZ4xgre8bCk32Yzv3vlR4pGn12H7T5Vkbz5BaErZ22JRB-OqveQ7EDHsrCYjKN65Soc1FrZNwvu/s72-c/metnethero1.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total >;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-4973261706617691472&lt;/id>;&lt;published>;2023-10-27T13:22:00.001- 07:00&lt;/published>;&lt;updated>;2023-10-31T14:14:34.982-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot; Android Wear&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Health&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Audioplethysmography for cardiac monitoring with hearable devices&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Xiaoran &quot;Van&quot; Fan, Experimental Scientist, and Trausti Thormundsson, Director, Google &lt;/span>; &lt;img src =&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnCItsRGs939CGCBBAi5fA-xwk9JQi7b2CQ3voKK583p4uTkQkLIXUd1lU71SLynom0Yt78bRxDflolUzzfol5UbfkPmCaNn8bIUxwAbLDatqZTPxP7SYOT45g9qJODdM1kvT6NQUsixtFTiBYr_h_Hx-pFRsmbcBKdnW3WkbcD4Bcr_cZE590VL-cSu-a/s320/hero.jpeg&quot; style=&quot;display: none;&quot; />; &lt;p>; The market for &lt;a href=&quot;https://www.telink-semi.com/introduction-true-wireless-stereo/&quot;>;true wireless stereo&lt;/a>; (TWS) &lt;a href=&quot; https://en.wikipedia.org/wiki/Active_noise_control&quot;>;active noise canceling&lt;/a>; (ANC) hearables (headphones and earbuds) has been soaring in recent years, and the global shipment volume will nearly &lt;a href=&quot; https://www.idc.com/promo/wearablevendor&quot;>;double&lt;/a>; that of smart wristbands and watches in 2023. The on-head time for hearables has extended significantly due to the recent advances in ANC, transparency mode,å’Œäººå·¥æ™ºèƒ½ã€‚ Users frequently wear hearables not just for music listening, but also for exercising, focusing, or simply mood adjustment. However, hearable health is still mostly uncharted territory for the consumer market. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; In â€œ&lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3570361.3613281&quot;>;APG: Audioplethysmography for Cardiac Monitoring in Hearables&lt;/a>;,â€ presented at &lt;a href=&quot;https://sigmobile.org/mobicom/2023/&quot;>;MobiCom 2023&lt;/a>;, we introduce a novel active in-ear health sensing modality. Audioplethysmography (APG) enables ANC hearables to monitor a user&#39;s physiological signals, such as heart rate and heart rate variability, without adding extra sensors or compromising battery life. APG exhibits high resilience to motion artifacts, adheres to &lt;a href=&quot;https://www.health.belgium.be/sites/default/files/uploads/fields/fpshealth_theme_file/19099349/Canadian%20guidelines%20for%20ultrasound.pdf&quot;>;safety regulations&lt;/a>; with an 80 dB margin below the limit, remains unaffected by seal conditions, and is inclusive of all skin tones. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3if_joqkSgp5nI0YvfWgUtgi3FoOtmeNcwcDdNNaMlPizqHpbuaeVFrp1MguLPQpT0hqrQaldH0ymqwjDzsD-u3qDR-r8Z0rnB7lsDuF9iab9CdR6GRPI7OPtqLFR29mRwfHz06kwqhppe7mvI9iVIBi8DtpIYh6E-UXs1RwUffTRxKVViTuXpSLXLAXI/s1600/image4.gif &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1600&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3if_joqkSgp5nI0YvfWgUtgi3FoOtmeNcwcDdNNaMlPizqHpbuaeVFrp1MguLPQpT0hqrQaldH0ymqwjDzsD-u3qDR-r8Z0rnB7lsDuF9iab9CdR6GRPI7OPtqLFR29mRwfHz06kwqhppe7mvI9iVIBi8DtpIYh6E-UXs1RwUffTRxKVViTuXpSLXLAXI/s16000/image4.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;APG sends a low intensity ultrasound transmitting wave (TX wave) using an ANC headphone&#39;s speakers and collects the receiving wave (RX wave) via the on-board feedback microphones. The APG signal is a pulse-like waveform that synchronizes with heartbeat and reveals rich cardiac information, such as &lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/32403992/#:~:text=The%20dicrotic%20notch%20is%20a,of%20diastole%20in%20these%20arteries.&quot;>;dicrotic notches&lt;/a>;. &lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Health sensing in the ear canal&lt;/h2>; &lt;p>; The &lt;a href=&quot;https://en.wikipedia.org/wiki/Ear_canal&quot;>;auditory canal&lt;/a>; receives its blood supply from the &lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_auricular_artery&quot;>;arteria auricularis profunda&lt;/a>;, also known as the deep ear artery. This artery forms an intricate network of smaller vessels that extensively permeate the auditory canal. Slight variations in blood vessel shape caused by the heartbeat (and &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/8834671&quot;>;blood pressure&lt;/a>;) can lead to subtle changes in the volume and pressure of the ear canals, making the ear canal an ideal location for health sensing. &lt;/p>; &lt;p>; Recent research has explored using hearables for health sensing by packaging together a plethora of sensors â€” eg, &lt;a href=&quot;https://en.wikipedia.org/wiki/Photoplethysmogram&quot;>;photoplethysmograms&lt;/a>; (PPG) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Electrocardiography&quot;>;electrocardiograms&lt;/a>; (ECG) â€” with a microcontroller to enable health applications, such as sleep monitoring, heart rate and blood pressure tracking. However, this sensor mounting paradigm inevitably adds cost, weight, power consumption, acoustic design complexity, and form factor challenges to hearables, constituting a strong barrier to its wide adoption. &lt;/p>; &lt;p>; Existing ANC hearables deploy feedback and feedforward microphones to navigate the ANC function. These microphones create &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3550314&quot;>;new opportunities&lt;/a>; for various sensing applications as they can detect or record many bio-signals inside and outside the ear canal. For example, feedback microphones can be used to listen to heartbeats and feedforward microphones can hear respirations. &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3458864.3467680&quot;>;Academic research&lt;/a>; on this passive sensing paradigm has prompted many mobile applications, including heart rate monitoring, ear disease diagnosis, respiration monitoring, and body activity recognition. However, microphones in consumer-grade ANC headphones come with &lt;a href=&quot;https://research.google/pubs/pub52579/&quot;>;built-in high-pass filters&lt;/a>; to prevent saturation from body motions or strong windå™ªéŸ³ã€‚ The signal quality of passive listening in the ear canal also heavily relies on the earbud seal conditions. As such, it is challenging to embed health features that rely on the passive listening of low frequency signals (â‰¤ 50 Hz) on commercial ANC headphones. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Measuring tiny physiological signals&lt;/h2>; &lt;p>; APG bypasses the aforementioned ANC headphone hardware constraints by sending a low intensity ultrasound probing signal through an ANC headphone&#39;s speakers. This signal triggers echoes, which are received via on-board feedback microphones. We observe that the tiny ear canal skin displacement and heartbeat vibrations modulate these ultrasound echoes. &lt;/p>; &lt;p>; We build a &lt;a href=&quot;https://en.wikipedia.org/wiki/Acoustic_resonance&quot;>;cylindrical resonance&lt;/a>; model to understand APG&#39;s underlying physics. This phenomenon happens at an extremely small scale, which makes the raw pulse signal invisible in the raw received ultrasound. We adopt &lt;a href=&quot;https://www.rp-photonics.com/optical_heterodyne_detection.html&quot;>;coherent detection&lt;/a>; to retrieve this micro physiological modulation under the noise floor (we term this retrieved signal as mixed-down signal, see the &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3570361.3613281&quot;>;paper&lt;/a>; for more details). The final APG waveform looks strikingly similar to a PPG waveform, but provides an improved view of cardiac activities with more pronounced &lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/32403992/#:~:text=The%20dicrotic%20notch%20is%20a,of%20diastole%20in%20these%20arteries.&quot;>;dicrotic notches&lt;/a>; (ie, pressure waveforms that provide rich insights about the central artery system, such as blood pressure). &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEoN64wQBOUKAhV6SHbEMqIcAuVCk01zBki8pnV1xoEseaJCT1uNRprkjKyFLYRin4a-iSrPjg3Pr-eEgc_YrOYihU61CaKl8CN5K8ET_g8vOFxHhUKQaq7Fb9xMhGVVLMS_AouTZvfDfXYRVz0ExhCIV4je2Hxqd-CVfKmmpfGjLIGeKawPEff6Ei5gfT/s1600/image5.gif &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEoN64wQBOUKAhV6SHbEMqIcAuVCk01zBki8pnV1xoEseaJCT1uNRprkjKyFLYRin4a-iSrPjg3Pr-eEgc_YrOYihU61CaKl8CN5K8ET_g8vOFxHhUKQaq7Fb9xMhGVVLMS_AouTZvfDfXYRVz0ExhCIV4je2Hxqd-CVfKmmpfGjLIGeKawPEff6Ei5gfT/s16000/image5.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;A cylindrical model with cardiac activities â„Ž(ð‘¡) that modulates both the phase and amplitude of the &lt;a href=&quot;https://www.digikey.com/en/articles /the-basics-of-mixers&quot;>;mixed-down&lt;/a>; signal. Based on the simulation from our analytical model, the amplitude ð‘…(ð‘¡) and phase Î¦(ð‘¡) of the mixed-down APG signals both reflect the cardiac activities â„Ž(ð‘¡).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;APG sensing in practice&lt;/h2>; &lt;p>; During our initial experiments, we observed that APG works robustly with bad earbuds seals and with music playing. However, we noticed the APG signal can sometimes be very noisy and could be heavily disturbed by body motion. At that point, we determined that in order to make APG useful, we had to make it more robust to compete with &lt;a href=&quot;https://curiouscyborg.com/history-of-photoplethysmography/#:~:text=The%20Photoplethysmogram%20was%20first%20observed,the%20light%20interaction%20with%20tissue.&quot;>;more than 80 years&lt;/a>; of PPG development. &lt;/p>; &lt;p>; While PPGs are widely used and highly advanced, they do have some limitations. For example, PPGs sensors typically use two to four &lt;a href=&quot;https://en.wikipedia.org/wiki/Diode&quot;>;diodes&lt;/a>; to send and receive light frequencies for sensing. However, due to the ultra high-frequency nature (hundreds of &lt;a href=&quot;https://en.wikipedia.org/wiki/Terahertz_radiation&quot;>;Terahertz&lt;/a>;) of the light, it&#39;s difficult for a single diode to send multiple colors with different frequencies. On the other hand, we can easily design a low-cost and low-power system that generates and receives more than ten audio tones (frequencies). We leverage &lt;a href=&quot;https://en.wikipedia.org/wiki/Diversity_scheme&quot;>;channel diversity&lt;/a>;, a physical phenomenon that describes how wireless signals (eg, light and audio) at different frequencies have different characters (eg, different attenuation and reflection coefficients) when the signal propagates in a medium, to enable a higher quality APG signal and motion resilience. &lt;/p>; &lt;p>; Next, we experimentally demonstrate the effectiveness of using multiple frequencies in the APG signaling. We transmit three probing signals concurrently with their frequencies spanning evenly from 30 KHz to 32 KHz. A participant was asked to shake their head four times during the experiment to introduce interference. The figure below shows that different frequencies can be transmitted simultaneously to gather various information with &lt;a href=&quot;https://www.rp-photonics.com/optical_heterodyne_detection.html&quot;>;coherent detection&lt;/a>;, a unique advantage to APG ã€‚ &lt;/p>; &lt;p>; The 30 kHz phase shows the four head movements and the magnitude (amplitude) of 31 kHz shows the pulse wave signal. This observation shows that some ultrasound frequencies might be sensitive to cardiac activities while others might be sensitive to motion. Therefore, we can use the multi-tone APG as a calibration signal to find the best frequency that measures heart rate, and use only the best frequency to get high-quality pulse waveform. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjP_DLCbWWNJRvMPnIbdAbij_YKuIuYGbTiN-drwsJnEkrybDQT_yNHIqKYrqhxfq8CrWSEVZ6kvCvZ1tIUoXtH5GBqEfyQjkjChwVqL_Cxc0dO6i3vJi_sPo7hjElUuxH9f8d3E6nkDBNGNNgCRdFhfllW8OnhGXVS120-e4Yh67vECY7_lQpDOH2I42TU/s1761/image2.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1380&quot; data-original-width=&quot;1761&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjP_DLCbWWNJRvMPnIbdAbij_YKuIuYGbTiN-drwsJnEkrybDQT_yNHIqKYrqhxfq8CrWSEVZ6kvCvZ1tIUoXtH5GBqEfyQjkjChwVqL_Cxc0dO6i3vJi_sPo7hjElUuxH9f8d3E6nkDBNGNNgCRdFhfllW8OnhGXVS120-e4Yh67vECY7_lQpDOH2I42TU/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;The mixed-down amplitude (upper row) and phase (bottom row) for a customized multi-tone APG signal that spans from 30 kHz to 32 kHz. With channel diversity, the cardiac activities are captured in some frequencies (eg, magnitude of 31 kHz) and head movements are captured in other frequencies (eg, magnitude of 30 kHz, 30 kHz, and phase of 31 kHz). &lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; After choosing the best frequency to measure heart rate, the APG pulse waveform becomes more visible with pronounced dicrotic notches , and enables accurate &lt;a href=&quot;https://en.wikipedia.org/wiki/Heart_rate_variability&quot;>;heart rate variability&lt;/a>; measurement. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0mjyX5qTrzW9rN1qexcI3Nm0hgn03m-K_kGn_A8yfqlviJ3Rc3tod-srqQ-6vuoPEo6em7z3Qx7NpgkYTMRiNVtzUidLMc1lp48n6O8hsLMqFQc8z5CKI8mqSowmEbg5ojxdG4vaYreLbv0q2YwQAk3hKwdSd1cdwQMGVtFmgwn46nvCYRuPEi6hdpcVh/s1999/image1.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;763&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0mjyX5qTrzW9rN1qexcI3Nm0hgn03m-K_kGn_A8yfqlviJ3Rc3tod-srqQ-6vuoPEo6em7z3Qx7NpgkYTMRiNVtzUidLMc1lp48n6O8hsLMqFQc8z5CKI8mqSowmEbg5ojxdG4vaYreLbv0q2YwQAk3hKwdSd1cdwQMGVtFmgwn46nvCYRuPEi6hdpcVh/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;The final APG signal used in the measurement phase (&lt;strong>;left&lt;/strong>;) and chest &lt;a href=&quot;https://en.wikipedia.org/wiki /Electrocardiography&quot;>;ECG&lt;/a>; signal (&lt;strong>;right&lt;/strong>;).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Multi-tone translates to multiple simultaneous observations, which enable the development of &lt;a href=&quot;https://en.wikipedia.org/wiki/Array_processing&quot;>;array signal processing&lt;/a>; techniques. We demonstrate the spectrogram of a running session APG experiment before and after applying &lt;a href=&quot;https://en.wikipedia.org/wiki/Signal_separation&quot;>;blind source separation&lt;/a>; (see the &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3570361.3613281&quot;>;paper&lt;/a>; for more details). We also show the ground truth heart rate measurement in the same running experiment using a &lt;a href=&quot;https://www.polar.com/us-en/sensors/h10-heart-rate-sensor&quot;>;Polar ECG chest strap &lt;/a>;ã€‚ In the raw APG, we see the running cadence (around 3.3 Hz) as well as two dim lines (around 2 Hz and 4 Hz) that indicate the user&#39;s heart rate frequency and its harmonics. The heart rate frequencies are significantly enhanced in &lt;a href=&quot;https://en.wikipedia.org/wiki/Signal-to-noise_ratio&quot;>;signal to noise ratio&lt;/a>; (SNR) after the blind source separation, which align with the ground truth heart rate frequencies. We also show the calculated heart rate and running cadence from APG and ECG. We can see that APG tracks the growth of heart rate during the running session accurately. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbwRfWHxYHVk1ARp9gzcaRTMIUO-FjAgaTqOUtfYMzJ1lpAsWSxm1MczllG4aq-3Rbi-M6u7KXqnPOdsiLJS4le05Alnf_68701LYb0DQrpbbqAYGP7jzYivDhoeniPeTmsBU7Uhg4HRyOlYdQCYWxL-xabuULYFlGdH_rIA1b1Q8ZXH8MHIYlPQcaUpYW/s1888/image3 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1423&quot; data-original-width=&quot;1888&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbwRfWHxYHVk1ARp9gzcaRTMIUO-FjAgaTqOUtfYMzJ1lpAsWSxm1MczllG4aq-3Rbi-M6u7KXqnPOdsiLJS4le05Alnf_68701LYb0DQrpbbqAYGP7jzYivDhoeniPeTmsBU7Uhg4HRyOlYdQCYWxL-xabuULYFlGdH_rIA1b1Q8ZXH8MHIYlPQcaUpYW/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;APG tracks the heart rate accurately during the running session and also measures the running cadence.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Field study and closing thoughts&lt;/h2>; &lt;p>; We conducted two rounds of user experience (UX ) studies with 153 participants. Our results demonstrate that APG achieves consistently accurate heart rate (3.21% median error across participants in all activity scenarios) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Heart_rate_variability&quot;>;heart rate variability&lt;/a>; (2.70% median error in inter-beat interval) measurements. Unlike PPG, which exhibits variable performance across skin tones, our study shows that APG is resilient to variation in: skin tone, sub-optimal seal conditions, and ear canal size. More detailed evaluations can be found in the &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3570361.3613281&quot;>;paper&lt;/a>;. &lt;/p>; &lt;p>; APG transforms any TWS ANC headphones into smart sensing headphones with a simple software upgrade, and works robustly across various user activities. The sensing carrier signal is completely inaudible and not impacted by music playing. More importantly, APG represents new knowledge in biomedical and mobile research and unlocks new possibilities for low-cost health sensing. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>;&lt;i>; APG is the result of collaboration across Google Health, product, UX and legal teams. We would like to thank David Pearl, Jesper Ramsgaard, Cody Wortham, Octavio Ponce, Patrick Amihood, Sam Sheng, Michael Pate, Leonardo Kusumo, Simon Tong, Tim Gladwin, Russ Mirov, Kason Walker, Govind Kannan, Jayvon Timmons, Dennis Rauschmayer, Chiong Lai, Shwetak Patel, Jake Garrison, Anran Wang, Shiva Rajagopal, Shelten Yuen, Seobin Jung, Yun Liu, John Hernandez, Issac Galatzer-Levy, Isaiah Fischer-Brown, Jamie Rogers, Pramod Rudrapatna, Andrew Barakat, Jason Guss, Ethan Grabau, Pol Peiffer, Bill Park, Helen O&#39;Connor, Mia Cheng, Keiichiro Yumiba, Felix Bors, Priyanka Jantre, Luzhou Xu, Jian Wang, Jaime Lien, Gerry Pallipuram, Nicholas Gillian, Michal Matuszak, Jakub Wojciechowski, Bryan Allen, Jane Hilario, and Phil Carmack for their invaluable insights and support. Thanks to external collaborators Longfei Shangguan and Rich Howard, Rutgers University and University of Pittsburgh.&lt;/i>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/4973261706617691472/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/audioplethysmography-for-cardiac.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4973261706617691472&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/4973261706617691472&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/audioplethysmography-for-cardiac.html&quot; rel=&quot;alternate&quot; title=&quot;Audioplethysmography for cardiac monitoring with hearable devices&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnCItsRGs939CGCBBAi5fA-xwk9JQi7b2CQ3voKK583p4uTkQkLIXUd1lU71SLynom0Yt78bRxDflolUzzfol5UbfkPmCaNn8bIUxwAbLDatqZTPxP7SYOT45g9qJODdM1kvT6NQUsixtFTiBYr_h_Hx-pFRsmbcBKdnW3WkbcD4Bcr_cZE590VL-cSu-a/s72-c/hero.jpeg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-6605352025607219737&lt;/id>;&lt;published>;2023-10-26T11:01:00.000-07:00&lt;/published>;&lt;updated>;2023-10-26T11:01:04.276-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;AI&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Collaboration&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Responsible AI&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Supporting benchmarks for AI safety with MLCommons&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Anoop Sinha, Technology and Society, and Marian Croak, Google Research, Responsible AI and Human Centered Technology team&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5URA9ivhxcgmfXwa0668O0HslgYQ_p_x9JJbg6nDgryyNc2QImQernPyzkLPcj1esCMOQTUnEsldIlb21E0DWPDIiE2m76qSruF0jA6jfl1sNl6mBW8JUPSWzOfE7IahHRtviFpxUTPcEZoADXHNMy3gZ2hg369y5QxhY01QRVj5kwJx4uwRKzdcBFp9v/s1600/GoogleResearch.png&quot; style=&quot;display: none;&quot; />; &lt;p>; Standard benchmarks are agreed upon ways of measuring important product qualities, and they exist in many fields. Some standard benchmarks measure safety: for example, when a car manufacturer touts a â€œfive-star overall safety rating,â€ they&#39;re citing a benchmark. Standard benchmarks already exist in machine learning (ML) and AI technologies: for instance, the &lt;a href=&quot;https://mlcommons.org/en/&quot;>;MLCommons&lt;/a>; Association operates the &lt;a href=&quot;https://mlcommons.org/en/news/mlperf-inference-storage-q323/&quot;>;MLPerf&lt;/a>; benchmarks that measure the speed of cutting edge AI hardware such as Google&#39;s TPUs. However, though there has been significant work done on &lt;a href=&quot;https://blog.google/technology/ai/our-responsible-approach-to-building-guardrails-for-generative-ai/&quot;>;AI safety&lt;/a>;, there are as yet no similar standard benchmarks for AI safety. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; We are excited to support a new effort by the non-profit MLCommons Association to develop standard AI safety benchmarks. Developing benchmarks that are effective and trusted is going to require advancing AI safety testing technology and incorporating a broad range of perspectives. The MLCommons effort aims to bring together expert researchers across academia and industry to develop standard benchmarks for measuring the safety of AI systems into scores that everyone can understand. We encourage the whole community, from AI researchers to policy experts, to &lt;a href=&quot;https://mlcommons.org/ai-safety&quot;>;join us&lt;/a>; in contributing to the effort. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Why AI safety benchmarks?&lt;/h2>; &lt;p>; Like most advanced technologies, AI has the potential for tremendous benefits but could also lead to negative outcomes without appropriate care. For example, AI technology can boost human productivity in a wide range of activities (eg, &lt;a href=&quot;https://blog.google/technology/health/how-ai-can-improve-health-for-everyone-everywhere/&quot;>;improve health diagnostics&lt;/a>; and research into diseases, analyze &lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/google-transportation-energy-emissions-reduction/&quot;>;energy usage&lt;/a>;, and more). However, without sufficient precautions, AI could also be used to support harmful or malicious activities and respond in biased or offensive ways. &lt;/p>; &lt;p>; By providing standard measures of safety across categories such as harmful use, out-of-scope responses, AI-control risks, etc., standard AI safety benchmarks could help society reap the benefits of AI while ensuring that sufficient precautions are being taken to mitigate these risks. Initially, nascent safety benchmarks could help drive AI safety research and inform responsible AI development. With time and maturity, they could help inform users and purchasers of AI systems. Eventually, they could be a valuable tool for policy makers. &lt;/p>; &lt;p>; In computer hardware, benchmarks (eg, &lt;a href=&quot;https://en.wikipedia.org/wiki/Standard_Performance_Evaluation_Corporation&quot;>;SPEC&lt;/a>;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Transaction_Processing_Performance_Council&quot;>;TPC&lt;/a>;) have shown an amazing ability to align research, engineering, and even marketing across an entire industry in pursuit of progress, and we believe standard AI safety benchmarks could help do the same in this vital area. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;What are standard AI safety benchmarks?&lt;/h2>; &lt;p>; Academic and corporate research efforts have experimented with a range of AI safety tests (eg, &lt;a href=&quot;https://arxiv.org/abs/2009.11462&quot;>;RealToxicityPrompts&lt;/a>;, &lt;a href=&quot;https://crfm.stanford.edu/2022/11/17/helm.html&quot;>;Stanford HELM&lt;/a>; fairness, bias, toxicity measurements, and &lt;a href=&quot;https://blog.google/technology/ai/our-responsible-approach-to-building-guardrails-for-generative-ai/&quot;>;Google&#39;s guardrails for generative AI&lt;/a>;). However, most of these tests focus on providing a prompt to an AI system and algorithmically scoring the output, which is a useful start but limited to the scope of the test prompts. Further, they usually use open datasets for the prompts and responses, which may already have been (often inadvertently) incorporated into training data. &lt;/p>; &lt;p>; MLCommons proposes a multi-stakeholder process for selecting tests and grouping them into subsets to measure safety for particular AI use-cases, and translating the highly technical results of those tests into scores that everyone can understand. MLCommons is proposing to create a platform that brings these existing tests together in one place and encourages the creation of more rigorous tests that move the state of the art forward. Users will be able to access these tests both through online testing where they can generate and review scores and offline testing with an engine for private testing. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;AI safety benchmarks should be a collective effort&lt;/h2>; &lt;p>; Responsible AI developers use a diverse range of safety measures, including automatic testing, manual testing, red teaming (in which human testers attempt to produce adversarial outcomes), software-imposed restrictions, data and model best-practices, and auditing. However, determining that sufficient precautions have been taken can be challenging, especially as the community of companies providing AI systems grows and diversifies. Standard AI benchmarks could provide a powerful tool for helping the community grow responsibly, both by helping vendors and users measure AI safety and by encouraging an ecosystem of resources and specialist providers focused on improving AI safety. &lt;/p>; &lt;p>; At the same time, development of mature AI safety benchmarks that are both effective and trusted is not possible without the involvement of the community. This effort will need researchers and engineers to come together and provide innovative yet practical improvements to safety testing technology that make testing both more rigorous and more efficient. Similarly, companies will need to come together and provide test data, engineering support, and financial support. Some aspects of AI safety can be subjective, and building trusted benchmarks supported by a broad consensus will require incorporating multiple perspectives, including those of public advocates, policy makers, academics, engineers, data workers, business leaders, and entrepreneurs. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Google&#39;s support for MLCommons&lt;/h2>; &lt;p>; Grounded in our &lt;a href=&quot;https://ai.google/responsibility/principles/&quot;>;AI Principles&lt;/a>; that were &lt;a href=&quot;https://blog.google/technology/ai/ai-principles/&quot;>;announced&lt;/a>; in 2018, Google is committed to specific practices for the safe, secure, and trustworthy development and use of AI (see our &lt;a href=&quot;https://ai.google/static/documents/ai-principles-2019-progress-update.pdf&quot;>;2019&lt;/a>;, &lt;a href=&quot;https://ai.google/static/documents/ai-principles-2020-progress-update.pdf&quot;>;2020&lt;/a>;, &lt;a href=&quot;https://ai.google/static/documents/ai-principles-2021-progress-update.pdf&quot;>;2021&lt;/a>;, &lt;a href=&quot;https://ai.google/static/documents/ai-principles-2022-progress-update.pdf&quot;>;2022&lt;/a>; updates). We&#39;ve also made significant &lt;a href=&quot;https://static.googleusercontent.com/media/publicpolicy.google/en//resources/whcommitments.pdf&quot;>;progress&lt;/a>; on key commitments, which will help ensure AI is developed boldly and responsibly, for the benefit of everyone. &lt;/p>; &lt;p>; Google is supporting the MLCommons Association&#39;s efforts to develop AI safety benchmarks in a number of ways. &lt;/p>; &lt;ol>; &lt;li>;&lt;em>;Testing platform&lt;/em>;: We are joining with other companies in providing funding to support the development of a testing platform. &lt;li>;&lt;em>;Technical expertise and resources&lt;/em>;: We are providing technical expertise and resources, such as the &lt;a href=&quot;https://skintone.google/mste-dataset&quot;>;Monk Skin Tone Examples Dataset&lt;/a>;, to help ensure that the benchmarks are well-designed and effective. &lt;li>;&lt;em>;Datasets&lt;/em>;: We are contributing an internal dataset for multilingual representational bias, as well as already externalized tests for stereotyping harms, such as &lt;a href=&quot;https://github.com/google-research-datasets/seegull/tree/main&quot;>;SeeGULL&lt;/a>; and &lt;a href=&quot;https://github.com/google-research-datasets/SPICE/tree/main&quot;>;SPICE&lt;/a>;. Moreover, we are sharing our datasets that focus on collecting human annotations responsibly and inclusively, like &lt;a href=&quot;https://arxiv.org/abs/2306.11247&quot;>;DICES&lt;/a>; and &lt;a href=&quot;https://www.kaggle.com/datasets/google/jigsaw-specialized-rater-pools-dataset&quot;>;SRP&lt;/a>;. &lt;/li>; &lt;/ol>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Future direction&lt;/h2>; &lt;p>; We believe that these benchmarks will be very useful for advancing research in AI safety and ensuring that AI systems are developed and deployed in a responsible manner. AI safety is &lt;a href=&quot;https://blog.google/technology/ai/a-shared-agenda-for-responsible-ai-progress/&quot;>;a collective-action problem&lt;/a>;. Groups like the &lt;a href=&quot;https://blog.google/outreach-initiatives/public-policy/google-microsoft-openai-anthropic-frontier-model-forum/&quot;>;Frontier Model Forum&lt;/a>; and &lt;a href=&quot;https://partnershiponai.org/&quot;>;Partnership on AI&lt;/a>; are also leading important standardization initiatives. We&#39;re pleased to have been part of these groups and MLCommons since their beginning. We look forward to additional collective efforts to promote the responsible development of new generative AI tools. &lt;/p>; &lt;div style=&quot;line-height:40%;&quot;>; &lt;br>; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;Many thanks to the Google team that contributed to this work: Peter Mattson, Lora Aroyo, Chris Welty, Kathy Meier-Hellstern, Parker Barnes, Tulsee Doshi, Manvinder Singh, Brian Goldman, Nitesh Goyal, Alice Friend, Nicole Delange, Kerry Barker, Madeleine Elish, Shruti Sheth, Dawn Bloxwich, William Isaac, Christina Butterfield.&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/6605352025607219737/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6605352025607219737&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/6605352025607219737&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html&quot; rel=&quot;alternate&quot; title=&quot;Supporting benchmarks for AI safety with MLCommons&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5URA9ivhxcgmfXwa0668O0HslgYQ_p_x9JJbg6nDgryyNc2QImQernPyzkLPcj1esCMOQTUnEsldIlb21E0DWPDIiE2m76qSruF0jA6jfl1sNl6mBW8JUPSWzOfE7IahHRtviFpxUTPcEZoADXHNMy3gZ2hg369y5QxhY01QRVj5kwJx4uwRKzdcBFp9v/s72-c/GoogleResearch.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-7441213378686175839&lt;/id>;&lt;published>;2023-10-26T08:57:00.003-07:00&lt;/published>;&lt;updated>;2023-11-01T17:00:03.449-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Natural Language Processing&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Speech&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Spoken question answering and speech continuation using a spectrogram-powered LLM&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Eliya Nachmani, Research Scientist, and Alon Levkovitch, Student Researcher, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQEWecXit-a9UwHz781_B9s9ZqxsJIGt7ZXx2Lk0bcSQxXBkmLfjhNQxSiq3gqVjiUZ81_178hArCQ8nNL0OaVyAi8mKixeWN2PvXTLL4I08ht-eCVqtrTRo36dxGBSDNMdlathtEd4g_qdU3T4ZmPMdGNSXHwlDP689sxzbI4Wwosyu9wp-mjadKqL3MN/s1100/Spectron-hero.jpg&quot; style=&quot;display: none;&quot; />; &lt;p>; The goal of natural language processing (NLP) is to develop computational models that can understand and generate natural language. By capturing the statistical patterns and structures of text-based natural language, language models can predict and generate coherent and meaningful sequences of words. Enabled by the increasing use of the highly successful &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;>;Transformer&lt;/a>; model architecture and with training on large amounts of text (with proportionate compute and model size), large language models (LLMs) have demonstrated remarkable success in NLP tasks. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; However, modeling spoken human language remains a challenging frontier. Spoken dialog systems have conventionally been built as a cascade of &lt;a href=&quot;https://en.wikipedia.org/wiki/Speech_recognition&quot;>;automatic speech recognition&lt;/a>; (ASR), &lt;a href=&quot;https://en.wikipedia.org/wiki/Natural-language_understanding&quot;>;natural language understanding&lt;/a>; (NLU), response generation, and &lt;a href=&quot;https://simple.wikipedia.org/wiki/Text_to_speech&quot;>;text-to-speech&lt;/a>; (TTS) systems. However, to date there have been few capable end-to-end systems for the modeling of spoken language: ie, single models that can take speech inputs and generate its continuation as speech outputs. &lt;/p>; &lt;p>;Today we present a new approach for spoken language modeling, called Spectron, published in â€œ&lt;a href=&quot;https://arxiv.org/abs/2305.15255&quot;>;Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM&lt;/a>;.â€ Spectron is the first spoken language model that is trained end-to-end to directly process spectrograms as both input and output, instead of learning discrete speech representations. Using only a pre-trained text language model, it can be fine-tuned to generate high-quality, semantically accurate spoken language. Furthermore, the proposed model improves upon direct initialization in retaining the knowledge of the original LLM as demonstrated through spoken &lt;a href=&quot;https://en.wikipedia.org/wiki/Question_answering&quot;>;question answering&lt;/a>; datasets.&lt;/p>; &lt;p>; We show that a pre-trained speech encoder and a language model decoder enable end-to-end training and state-of-the-art performance without sacrificing representational fidelity. Key to this is a novel end-to-end training objective that implicitly supervises speech recognition, text continuation, and conditional speech synthesis in a joint manner. A new spectrogram regression loss also supervises the model to match the higher-order derivatives of the spectrogram in the time and frequency domain. These derivatives express information aggregated from multiple frames at once. Thus, they express rich, longer-range information about the shape of the signal. Our overall scheme is summarized in the following figure: &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4yanW_7FsK-zlJ5XKgusakSaIGAEvDPuRZpAZ5NGJl8mW6-4hd06ZWOsk4IIf0hl5XwWFcjkdu9gH4VwqcWCqLUfZQXDM80MuDml8Tt_P0RT3fDq5cxfoPCPNagOuU0SZbSz8Vn7x_bLkxNFXKpakBPwCkgXh8T6bB4lfHQevGBjs-U4c5WA6RgC8gukW/s1815/Spectron.jpg&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1146&quot; data-original-width=&quot;1815&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4yanW_7FsK-zlJ5XKgusakSaIGAEvDPuRZpAZ5NGJl8mW6-4hd06ZWOsk4IIf0hl5XwWFcjkdu9gH4VwqcWCqLUfZQXDM80MuDml8Tt_P0RT3fDq5cxfoPCPNagOuU0SZbSz8Vn7x_bLkxNFXKpakBPwCkgXh8T6bB4lfHQevGBjs-U4c5WA6RgC8gukW/s16000/Spectron.jpg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;The Spectron model connects the encoder of a speech recognition model with a pre-trained Transformer-based decoder language model. At training, speech utterances split into a prompt and its continuation. Then the full transcript (prompt and continuation) is reconstructed along with the continuation&#39;s speech features. At inference, only a prompt is provided; the prompt&#39;s transcription, text continuation, and speech continuations are all generated by the model.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;Spectron architecture&lt;/h2>; &lt;p>; The architecture is initialized with a pre-trained speech encoder and a pre-trained decoder language model. The encoder is prompted with a speech utterance as input, which it encodes into continuous linguistic features. These features feed into the decoder as a prefix, and the whole encoder-decoder is optimized to jointly minimize a &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-entropy&quot;>;cross-entropy&lt;/a>; loss (for speech recognition and transcript continuation) and a novel reconstruction loss (for speech continuation). During inference, one provides a spoken speech prompt, which is encoded and then decoded to give both text and speech continuations. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Speech encoder&lt;/h3>; &lt;p>; The speech encoder is a 600M-parameter &lt;a href=&quot;https://arxiv.org/abs/2303.01037&quot;>;conformer&lt;/a>; encoder pre-trained on &lt;a href=&quot;https://arxiv.org/abs/2303.01037&quot;>;large-scale data&lt;/a>; (12M hours). It takes the spectrogram of the source speech as input, generating a hidden representation that incorporates both linguistic and acoustic information. The input spectrogram is first subsampled using a convolutional layer and then processed by a series of conformer blocks. Each conformer block consists of a feed-forward layer, a self-attention layer, a convolution layer, and a second feed-forward layer. The outputs are passed through a projection layer to match the hidden representations to the embedding dimension of the language model. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Language model&lt;/h3>; &lt;p>; We use a 350M or 1B parameter decoder language model (for the continuation and question-answering tasks, respectively) trained in the manner of &lt;a href=&quot;https://ai.google/static/documents/palm2techreport.pdf&quot;>;PaLM 2&lt;/a>;. The model receives the encoded features of the prompt as a prefix. Note that this is the only connection between the speech encoder and the LM decoder; ie, there is no cross-attention between the encoder and the decoder. Unlike most spoken language models, during training, the decoder is teacher-forced to predict the text transcription, text continuation, and speech embeddings. To convert the speech embeddings to and from spectrograms, we introduce lightweight modules pre- and post-network. &lt;/p>; &lt;p>; By having the same architecture decode the intermediate text and the spectrograms, we gain two benefits. First, the pre-training of the LM in the text domain allows continuation of the prompt in the text domain before synthesizing the speech. Secondly, the predicted text serves as intermediate reasoning, enhancing the quality of the synthesized speech, analogous to improvements in text-based language models when using intermediate &lt;a href=&quot;https://arxiv.org/abs/2112.00114&quot;>;scratchpads&lt;/a>; or &lt;a href=&quot;https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html&quot;>;chain-of-thought&lt;/a>; (CoT) reasoning. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Acoustic projection layers&lt;/h3>; &lt;p>; To enable the language model decoder to model spectrogram frames, we employ a multi-layer &lt;a href=&quot;https://en.wikipedia.org/wiki/Perceptron&quot;>;perceptron&lt;/a>; â€œpre-netâ€ to project the ground truth spectrogram speech continuations to the language model dimension. This pre-net compresses the spectrogram input into a lower dimension, creating a bottleneck that aids the decoding process. This bottleneck mechanism prevents the model from repetitively generating the same prediction in the decoding process. To project the LM output from the language model dimension to the spectrogram dimension, the model employs a â€œpost-netâ€, which is also a multi-layer perceptron. Both pre- and post-networks are two-layer multi-layer perceptrons. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Training objective&lt;/h3>; &lt;p>; The training methodology of Spectron uses two distinct loss functions: (i) &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-entropy&quot;>;cross-entropy loss&lt;/a>;, employed for both speech recognition and transcript continuation, and (ii) &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;>;regression loss&lt;/a>;, employed for speech continuation. During training, all parameters are updated (speech encoder, projection layer, LM, pre-net, and post-net). &lt;/p>; &lt;br />; &lt;h2>;Audio samples&lt;/h2>; &lt;p>; Following are examples of speech continuation and question answering from Spectron: &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;&lt;h3>;Speech Continuation&lt;/h3>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Prompt:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/1/src.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Continuation:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/1/pred.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Prompt:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/2/src.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Continuation:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/2/pred.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Prompt:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/3/src.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Continuation:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/3/pred.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Prompt:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/4/src.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Continuation:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/librispeech/4/pred.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td colspan=&quot;2&quot; style=&quot;text-align: left;&quot;>;&lt;h3>;Question Answering&lt;/h3>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Question:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/llama_questions/1/Q.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Answer:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/llama_questions/1/S.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;td>;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Question:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/llama_questions/2/Q.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: left;&quot;>;Answer:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td>;&lt;/tr>; &lt;tr>;&lt;td style=&quot;text-align: right;&quot;>;&lt;audio controls=&quot;controls&quot; src=&quot;https://michelleramanovich.github.io/spectron/spectron/llama_questions/2/S.wav&quot;>;&lt;/audio>;&lt;/td>;&lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;Performance&lt;/h2>; &lt;p>; To empirically evaluate the performance of the proposed approach, we conducted experiments on the&lt;a href=&quot;https://arxiv.org/abs/1912.07875&quot;>; Libri-Light dataset&lt;/a>;. Libri-Light is a 60k hour English dataset consisting of unlabelled speech readings from LibriVox audiobooks. We utilized a frozen neural vocoder called &lt;a href=&quot;https://research.google/pubs/pub51736/&quot;>;WaveFit&lt;/a>; to convert the predicted spectrograms into raw audio. We experiment with two tasks, speech continuation and spoken question answering (QA). Speech continuation quality is tested on the LibriSpeech test set. Spoken QA is tested on the Spoken WebQuestions datasets and a new test set named LLama questions, which we created. For all experiments, we use a 3 second audio prompt as input. We compare our method against existing spoken language models: &lt;a href=&quot;https://arxiv.org/abs/2209.03143&quot;>;AudioLM&lt;/a>;, &lt;a href=&quot;https://arxiv.org/abs/2102.01192&quot;>;GSLM&lt;/a>;, &lt;a href=&quot;https://arxiv.org/abs/2305.13009&quot;>;TWIST&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/2305.11000&quot;>;SpeechGPT&lt;/a>;. For the speech continuation task, we use the 350M parameter version of LM and the 1B version for the spoken QA task. &lt;/p>; &lt;p>; For the speech continuation task, we evaluate our method using three metrics. The first is &lt;a href=&quot;https://en.wikipedia.org/wiki/Perplexity&quot;>;log-perplexity&lt;/a>;, which uses an LM to evaluate the cohesion and semantic quality of the generated speech. The second is &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_opinion_score&quot;>;mean opinion score&lt;/a>; (MOS), which measures how natural the speech sounds to human evaluators. The third, speaker similarity, uses a speaker encoder to measure how similar the speaker in the output is to the speaker in the input. Performance in all 3 metrics can be seen in the following graphs. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_o_DUlZ-28VmNk20zvWBWC5FNl3GMVeigztDAtB4TR5voCdX3zzuCF-6W6DDrMVGZ2szVhyphenhyphendPz1DHvjBrALQXCMkVzuM81oBck4Wb3N1VH1ndDReAPsfbQv5x7msOD3wMiHeZM-_AcN2ekgSI_G9sF5_u0lrLKc-xxSWc2d9qi6Ubt5cutgQfpIt8uKGr/s1200/image5 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; height=&quot;396&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_o_DUlZ-28VmNk20zvWBWC5FNl3GMVeigztDAtB4TR5voCdX3zzuCF-6W6DDrMVGZ2szVhyphenhyphendPz1DHvjBrALQXCMkVzuM81oBck4Wb3N1VH1ndDReAPsfbQv5x7msOD3wMiHeZM-_AcN2ekgSI_G9sF5_u0lrLKc-xxSWc2d9qi6Ubt5cutgQfpIt8uKGr/w640-h396/image5.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/ td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Log-perplexity for completions of LibriSpeech utterances given a 3-second prompt. Lower is better.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjUncRH61ZdMzRhsx9NEXoY0P0jIMkaXhycc9AjB2I0pr8bEWxGNaY0KEF4UG0dm6ZVjRT3_aXlNKny3mmjoVgPveK4rskOgU5sApzqzIXixabv7kMeZNMxUpxs_RDqSsnij-HILgUzVZT39hoBDimw9Ecnd2lMq2ylyRCVtcU_owo8jx9ndVrLUHbGhNT/s1200/image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; height=&quot;396&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjUncRH61ZdMzRhsx9NEXoY0P0jIMkaXhycc9AjB2I0pr8bEWxGNaY0KEF4UG0dm6ZVjRT3_aXlNKny3mmjoVgPveK4rskOgU5sApzqzIXixabv7kMeZNMxUpxs_RDqSsnij-HILgUzVZT39hoBDimw9Ecnd2lMq2ylyRCVtcU_owo8jx9ndVrLUHbGhNT/w640-h396/image4.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Speaker similarity between the prompt speech and the generated speech using the speaker encoder. Higher is better.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBdPk77at7a-tSVl1cgPTlMsj4tnV391evuyYPzMXxeviG48kljCNy828jCQ5eVdOcB7ML4FHduIHCuDweZwJiv2USbNqi1EXinzyiwQYM3Sxio3g-61xTBvtb9rVt_Y4Cvns-vl3V-4Gvn1RTpBquX3a6W_NNu6u-1DrK_GT5uGXOvP0WivyO7FF2-WTf/s1200/image3.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; height=&quot;396&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBdPk77at7a-tSVl1cgPTlMsj4tnV391evuyYPzMXxeviG48kljCNy828jCQ5eVdOcB7ML4FHduIHCuDweZwJiv2USbNqi1EXinzyiwQYM3Sxio3g-61xTBvtb9rVt_Y4Cvns-vl3V-4Gvn1RTpBquX3a6W_NNu6u-1DrK_GT5uGXOvP0WivyO7FF2-WTf/w640-h396/image3.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;MOS given by human users on speech naturalness. Raters rate 5-scale subjective mean opinion score (MOS) ranging between 0 - 5 in naturalness given a speech utterance. Higher is better.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; As can be seen in the first graph, our method significantly outperforms GSLM and TWIST on the log-perplexity metric, and does slightly better than state-of-the-art methods AudioLM and SpeechGPT. In terms of MOS, Spectron exceeds the performance of all the other methods except for AudioLM. In terms of speaker similarity, our method outperforms all other methods. &lt;/p>; &lt;p>; To evaluate the ability of the models to perform question answering, we use two spoken question answering datasets. The first is the LLama Questions dataset, which uses general knowledge questions in different domains generated using the LLama2 70B LLM. The second dataset is the &lt;a href=&quot;https://huggingface.co/datasets/web_questions&quot;>;WebQuestions&lt;/a>; dataset which is a general question answering dataset. For evaluation we use only questions that fit into the 3 second prompt length. To compute accuracy, answers are transcribed and compared to the ground truth answers in text form. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi60RnurzgglmP14m9BIScZH4BmupewxydVJ5GZMKclwDgyGc3-zZdj8CK7WXmGR_-pwno1Aql0N_u0ocmftoAlTCJY0H-1cYU8YTpxZu5sdIdmG-wZAc-hIwlAbCEVDPgGz4J4a1VMcXWctbjcfCTxsDSZPD69eGfBeGyAxvyYtUX0fE2dhdT5zb71gsJ0/s1200 /image1.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;742&quot; data-original-width=&quot;1200&quot; height=&quot; 396&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi60RnurzgglmP14m9BIScZH4BmupewxydVJ5GZMKclwDgyGc3-zZdj8CK7WXmGR_-pwno1Aql0N_u0ocmftoAlTCJY0H-1cYU8YTpxZu5sdIdmG-wZAc-hIwlAbCEVDPgGz4J4a1VMcXWctbjcfCTxsDSZPD69eGfBeGyAxvyYtUX0fE2dhdT5zb71gsJ0/w640-h396/image1.png&quot; width=&quot;640&quot; />;&lt;/ a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Accuracy for Question Answering on the LLama Questions and Spoken WebQuestions datasets. Accuracy is computed using the ASR transcripts of spoken answers.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; First, we observe that all methods have more difficulty answering questions from the Spoken WebQuestions dataset than from the LLama questions dataset. Second, we observe that methods centered around spoken language modeling such as GSLM, AudioLM and TWIST have a completion-centric behavior rather than direct question answering which hindered their ability to perform QA. On the LLama questions dataset our method outperforms all other methods, while SpeechGPT is very close in performance. On the Spoken WebQuestions dataset, our method outperforms all other methods except for SpeechGPT, which does marginally better. &lt;/p>; &lt;br />; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>;&lt;i>;This project was conceived and initiated by Michelle Tadmor Ramanovich with additional significant contributions from&lt;/i>;&lt;em>;&amp;nbsp;Eliya Nachmani, Alon Levkovitch, Roy Hirsch (&lt;a href=&quot;https://verily.com/&quot;>;Verily&lt;/a>;), Julian Salazar, Chulayutsh Asawaroengchai, Soroosh Mariooryad, Ehud Rivlin (&lt;a href=&quot;https://verily.com/&quot;>;Verily&lt;/a>;) and RJ Skerry-Ryan. We also thank Heiga Zhen, Yifan Ding, Yu Zhang, Yuma Koizumi, Neil Zeghidour, Christian Frank, Marco Tagliasacchi, Nadav Bar, Benny Schlesinger and Blaise Aguera-Arcas. &lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/7441213378686175839/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application /atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/spoken-question-answering-and-speech.html#comment-form&quot; rel=&quot;replies&quot; title=&quot; 0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/7441213378686175839&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml &quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/7441213378686175839&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http ://blog.research.google/2023/10/spoken-question-answering-and-speech.html&quot; rel=&quot;alternate&quot; title=&quot;Spoken question answering and speech continuation using a spectrogram-powered LLM&quot; type=&quot;text /html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt; gdï¼šå›¾åƒé«˜åº¦=â€œ16â€rel=â€œhttp://schemas.google.com/g/2005#thumbnailâ€src=â€œhttps://img1.blogblog.com/img/b16-rounded.gifâ€å®½åº¦= &quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQEWecXit-a9UwHz781_B9s9ZqxsJIGt7ZXx2Lk0bcSQxXBkmLfjhNQxSiq3gqVjiUZ81_178hArCQ8nNL0OaVyAi8mKixeWN2PvXTLL4I08ht-eCVqtrTRo36dxGBSDNMdlathtEd4g_qdU3T4ZmPMdGNSXHwlDP689sxzbI4Wwosyu9wp-mjadKqL3MN/ s72-c/Spectron-hero.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr: total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-7317378303167958176&lt;/id>;&lt;published>;2023-10-25T15:10:00.002-07:00&lt;/published >;&lt;updated>;2023-10-26T14:03:20.633-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;AI for Social Good&quot;>; &lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Climate&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom /ns#&quot; term=&quot;Machine Learning&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Looking back at wildfire research in 2023&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author &quot;>;Posted by Yi-Fan Chen, Software Engineer, and Carla Bromberg, Program Lead, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgCepSXB1QxIgipeUbH1YGd8N3TkVoT1tAgxG0fC0PPREhbsygTQ4i58OVw6-Dt_lagwgswT0jtxUorsVmtyO9UgPEDezJHz_QiKvbJlgYF8Db8W- 68KFdyZsq_uvM7YuZo9BRo__NC4BNxD6nHZpzsimeNOaV3X8dh9aliqbAbk8ycXb25s5NfLTfNe42_/s600/WildfireModeling.gif&quot; style=&quot;display: none;&quot; />; &lt;p>;Wildfires are becoming larger and affecting more and more communities around the world, often resulting in large-scale devastation. Just this year, communities have experienced catastrophic wildfires in &lt;a href=&quot;https://en.wikipedia.org/wiki/2023_Greece_wildfires&quot;>;Greece&lt;/a>;, &lt;a href=&quot;https://en.wikipedia.org/wiki/2023_Hawaii_wildfires#Maui&quot;>;Maui&lt;/a>;, and &lt;a href=&quot;https://en.wikipedia.org/wiki/2023_Canadian_wildfires&quot;>;Canada&lt;/a>; to name a few. While the underlying causes leading to such an increase are complex â€” including changing climate patterns, forest management practices, land use development policies and many more â€” it is clear that the advancement of technologies can help to address the new challenges.&lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>;At Google Research, we&#39;ve been investing in a number of &lt;a href=&quot;https://research.google/teams/climate-and-sustainability/&quot;>;climate adaptation&lt;/a>; efforts, including the application of machine learning (ML) to aid in wildfire prevention and provide information to people during these events. For example, to help map fire boundaries, our wildfire boundary &lt;a href=&quot;https://blog.research.google/2023/02/real-time-tracking-of-wildfire.html&quot;>;tracker&lt;/a>; uses ML models and satellite imagery to map large fires in near real-time with updates every 15 minutes. To advance our various research efforts, we are partnering with wildfire experts and government agencies around the world.&lt;/p>; &lt;p>;Today we are excited to share more about our ongoing collaboration with the &lt;a href=&quot;https://www.fs.usda.gov/&quot;>;US Forest Service&lt;/a>; (USFS) to advance fire modeling tools and fire spread prediction algorithms. Starting from the newly developed USFS wildfire behavior model, we use ML to significantly reduce computation times, thus enabling the model to be employed in near real time. This new model is also capable of incorporating localized fuel characteristics, such as fuel type and distribution, in its predictions. Finally, we describe an early version of our new high-fidelity 3D fire spread model.&lt;/p>; &lt;br />; &lt;h2>;Current state of the art in wildfire modeling&lt;/h2>; &lt;p>;Today&#39;s most widely used state-of-the-art fire behavior models for fire operation and training are based on the &lt;a href=&quot;https://www.fs.usda.gov/research/treesearch/55928&quot;>;Rothermel fire model&lt;/a>; developed at the US Forest Service Fire Lab, by Rothermel et al., in the 1970s. This model considers many key factors that affect fire spread, such as the influence of wind, the slope of the terrain, the moisture level, the fuel load (eg, the density of the combustible materials in the forest), etc., and provided a good balance between computational feasibility and accuracy at the time. The Rothermel model has gained widespread use throughout the fire management community across the world.&lt;/p>; &lt;p>;Various operational tools that employ the Rothermel model, such as &lt;a href=&quot;https://www.frames.gov/behaveplus/home&quot;>;BEHAVE&lt;/a>;, &lt;a href=&quot;https://www.firelab.org/project/farsite&quot;>;FARSITE&lt;/a>;, &lt;a href=&quot;https://wfdss.usgs.gov/wfdss/pdfs/FSPro.pdf&quot;>;FSPro&lt;/a>;, and &lt;a href=&quot;https://firelab.org/project/flammap&quot;>;FlamMap&lt;/a>;, have been developed and improved over the years. These tools and the underlying model are used mainly in three important ways: (1) for training firefighters and fire managers to develop their insights and intuitions on fire behavior, (2) for fire behavior analysts to predict the development of a fire during a fire operation and to generate guidance for situation awareness and resource allocation planning, and (3) for analyzing forest management options intended to mitigate fire hazards across large landscapes.&amp;nbsp; These models are the foundation of fire operation safety and efficiency today.&lt;/p>; &lt;p>; However, there are limitations on these state-of-the art models, mostly associated with the simplification of the underlying physical processes (which was necessary when these models were created). By simplifying the physics to produce steady state predictions, the required inputs for fuel sources and weather became practical but also more abstract compared to measurable quantities.&amp;nbsp; As a result, these models are typically â€œadjustedâ€ and â€œtweakedâ€ by experienced fire behavior analysts so they work more accurately in certain situations and to compensate for uncertainties and unknowable environmental characteristics. Yet these expert adjustments mean that many of the calculations are not repeatable. &lt;/p>; &lt;p>;To overcome these limitations, USFS researchers have been working on a new model to drastically improve the physical fidelity of fire behavior prediction. This effort represents the first major shift in fire modeling in the past 50 years. While the new model &lt;a href=&quot;https://ebooks.publish.csiro.au/content/wildland-fire-behaviour&quot;>;continues to improve in capturing fire behavior&lt;/a>;, the computational cost and inference time makes it impractical to be deployed in the field or for applications with near real-time requirements. In a realistic scenario, to make this model useful and practical in training and operations, a speed up of at least 1000x would be needed.&lt;/p>; &lt;br />; &lt;h2>;Machine learning acceleration&lt;/h2>; &lt;p>;In partnership with the USFS, we have undertaken a program to apply ML to decrease computation times for complex fire models. Researchers knew that many complex inputs and features could be characterized using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot;>;deep neural network&lt;/a>;, and if successful, the trained model would lower the computational cost and latency of evaluating new scenarios. Deep learning is a branch of machine learning that uses neural networks with multiple hidden layers of nodes that do not directly correspond to actual observations. The model&#39;s hidden layers allow a rich representation of extremely complex systems â€” an ideal technique for modeling wildfire spread.&lt;/p>; &lt;p>; We used the USFS physics-based, numerical prediction models to generate many simulations of wildfire behavior and then used these simulated examples to train the deep learning model on the inputs and features to best capture the system behavior accurately. We found that the deep learning model can perform at a much lower computational cost compared to the original and is able to address behaviors resulting from fine-scale processes. In some cases, computation time for capturing the fine-scale features described above and providing a fire spread estimate was 100,000 times faster than running the physics-based numerical models. &lt;/p>; &lt;p>;This project has continued to make great progress since the first report at &lt;a href=&quot;https://www.adai.pt/newevent/event/home/index.php?target=home&amp;amp;event =4&amp;amp;defLang=2&quot;>;ICFFR&lt;/a>; in December 2022. The joint Googleâ€“USFS &lt;a href=&quot;http://books.uc.pt/chapter?chapter=978989262298921&quot;>;presentation at ICFFR 2022&lt;/ a>; and the &lt;a href=&quot;https://www.firelab.org/project/deep-learning-high-resolution-wildfire-modeling&quot;>;USFS Fire Lab&#39;s project page&lt;/a>; provides a glimpse into the ongoing workæœè¿™ä¸ªæ–¹å‘ã€‚ Our team has expanded the dataset used for training by an order of magnitude, from 40M up to 550M training examples. Additionally, we have delivered a prototype ML model that our USFS Fire Lab partner is integrating into a training app that is currently being developed for release in 2024.&lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdwdwG4NlOjrJlRs25p5yGRUdNDErx7I9aZYLVgoPhrlyiOOx6x8toan0DKoBm2-SG2JfWkZsOluT7g_BYJpDYCTqMRu3cUHqQtyeE-Hgli5j9J3ap2Sg9SrjEfOMXj_CYhbi66iIFwSJjzkii0kJv3VV5V01jbIYFQP-DWjBc9RJKKEoJZPpIZKKYO2TJ/s1999/image2.jpg&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1125&quot; data-original-width=&quot;1999&quot; height=&quot;360&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdwdwG4NlOjrJlRs25p5yGRUdNDErx7I9aZYLVgoPhrlyiOOx6x8toan0DKoBm2-SG2JfWkZsOluT7g_BYJpDYCTqMRu3cUHqQtyeE-Hgli5j9J3ap2Sg9SrjEfOMXj_CYhbi66iIFwSJjzkii0kJv3VV5V01jbIYFQP-DWjBc9RJKKEoJZPpIZKKYO2TJ/w640-h360/image2.jpg&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;span style=&quot;text-align: left;&quot;>;Google researchers visiting the USFS Fire Lab in Missoula, MT, stopping by&amp;nbsp;&lt;/span>;&lt;a href=&quot;https://inciweb.nwcg.gov/incident-information/mtfha-big-knife&quot; style=&quot;text-align: left;&quot;>;Big Knife Fire&lt;/a>;&lt;span style=&quot;text-align: left;&quot;>;&amp;nbsp;Operation Command Center.&lt;/span>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;Fine-grained fuel representation&lt;/h2>; &lt;p>;Besides training, another key use-case of the new model is for operational fire prediction. To fully leverage the advantages of the new model&#39;s capability to capture the detailed fire behavior changes from small-scale differences in fuel structures, high resolution fuel mapping and representation are needed. To this end, we are currently working on the integration of high resolution satellite imagery and geo information into ML models to allow fuel specific mapping at-scale. Some of the preliminary results will be presented at the upcoming &lt;a href=&quot;https://afefirecongress.org/schedule/&quot;>;10th International Fire Ecology and Management Congress&lt;/a>; in November 2023.&lt;/p>; &lt;br />; &lt;h2>;Future work&lt;/h2>; &lt;p>; Beyond the collaboration on the new fire spread model, there are many important and challenging problems that can help fire management and safety. Many such problems require even more accurate fire models that fully consider 3D flow interactions and fluid dynamics, thermodynamics and combustion physics. Such detailed calculations usually require high-performance computers (HPCs) or supercomputers. &lt;/p>; &lt;p>; These models can be used for research and longer-term planning purposes to develop insights on extreme fire development scenarios, build ML classification models, or establish a meaningful â€œdanger indexâ€ using the simulated results. These high-fidelity simulations can also be used to supplement physical experiments that are used in expanding the operational models mentioned above. &lt;/p>; &lt;p>;In this direction, Google research has also &lt;a href=&quot;https://www.publish.csiro.au/WF/WF22225&quot;>;developed a high-fidelity large-scale 3D fire simulator&lt;/a>; that can be run on Google TPUs. In the near future, there is a plan to further leverage this new capability to augment the experiments, and to generate data to build insights on the development of extreme fires and use the data to design a fire-danger classifier and fire-danger index protocol.&lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4SgYHTgu7Uv6WNEJsEJCuFWKolnL13g9BxK2cDuMq7-SRM4dIUK9LbNxy3v0VyY4dU87T_NnehBz4iXCfHCWwoOU6V8-15P55Oi6FvT5BvcLgR_vzYB1xMPWUtj3AiwSsoPZY-9K5i9IwIADDAIjG7hzZZZZ00n7N2jVnjlp65ePQDsJdNIuX6avw8kD_/s480/image1.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;270&quot; data-original-width=&quot;480&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4SgYHTgu7Uv6WNEJsEJCuFWKolnL13g9BxK2cDuMq7-SRM4dIUK9LbNxy3v0VyY4dU87T_NnehBz4iXCfHCWwoOU6V8-15P55Oi6FvT5BvcLgR_vzYB1xMPWUtj3AiwSsoPZY-9K5i9IwIADDAIjG7hzZZZZ00n7N2jVnjlp65ePQDsJdNIuX6avw8kD_/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;span style=&quot;text-align: left;&quot;>;An example of 3D high-fidelity simulation. This is a controlled burn field experiment (&lt;/span>;&lt;a href=&quot;https://www.fireweather.org/fireflux2&quot; style=&quot;text-align: left;&quot;>;FireFlux II&lt;/a>;&lt;span style=&quot;text-align: left;&quot;>;) simulated using&amp;nbsp;&lt;/span>;&lt;a href=&quot;https://www.publish.csiro.au/WF/WF22225&quot;>;Google&#39;s high fidelity fire simulator&lt;/a>;&lt;span style=&quot;text-align: left;&quot;>;.&lt;/span>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>;&lt;i>;We thank Mark Finney, Jason Forthofer, William Chatham and Issac Grenfell from US Forest Service Missoula Fire Science Laboratory and our colleagues John Burge, Lily Hu, Qing Wang, Cenk Gazen, Matthias Ihme,&amp;nbsp;Vivian Yang, Fei Sha and John Anderson for core contributions and useful discussions. We also thank Tyler Russell for his assistance with program management and coordination.&lt;/i>;&lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/7317378303167958176/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/7317378303167958176&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/7317378303167958176&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html&quot; rel=&quot;alternate&quot; title=&quot;Looking back at wildfire research in 2023&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgCepSXB1QxIgipeUbH1YGd8N3TkVoT1tAgxG0fC0PPREhbsygTQ4i58OVw6-Dt_lagwgswT0jtxUorsVmtyO9UgPEDezJHz_QiKvbJlgYF8Db8W-68KFdyZsq_uvM7YuZo9BRo__NC4BNxD6nHZpzsimeNOaV3X8dh9aliqbAbk8ycXb25s5NfLTfNe42_/s72-c/WildfireModeling.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-420799196308935505&lt;/id>;&lt;published>;2023-10-25T10:45:00.000-07:00&lt;/published>;&lt;updated>;2023-10-25T10:45:37.205-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Deep Learning&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;EMNLP&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;NLP&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Search&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Grammar checking at Google Search scale&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Eric Malmi, Senior Research Scientist, and Jakub Adamek, Senior Software Engineer, Google, Bard Team &lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW7pWsW1-E7U1LH1bxmjBL_2W5fS6uN2iRb2cNPBks57ubvFNJj-SjE2Zk1lFqndKWBVAeO3g3MLeJ96QUIUNJDyLTcWjeO835NT6HfJMYQBEdGqL-X_sxQ1yxMy16a0OcOLb6gSz2lqM6VofToVtN_s_F_wGB41AZwlj146y7ZXQ4PFsdywX10QO54MJ4/s320/HeroGC.jpg&quot; style=&quot;display: none;&quot; />; &lt;p>; Many people with questions about grammar turn to Google Search for guidance. While existing features, such as â€œDid you meanâ€, already handle simple typo corrections, more complex grammatical error correction (GEC) is beyond their scope. What makes the development of new Google Search features challenging is that they must have high precision and recall while outputting results &lt;a href=&quot;https://ai.googleblog.com/2009/06/speed-matters.html&quot;>;quickly&lt; /a>;. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; The conventional approach to GEC is to treat it as a &lt;a href=&quot;https://workspace.google.com/blog/ai-and-machine-learning/using-neural-machine-translation-to-correct-grammatical-in-google-docs&quot;>;translation problem&lt;/a>; and use autoregressive &lt;a href=&quot;https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html&quot;>;Transformer&lt;/a>; models to decode the response token-by-token, conditioning on the previously generated tokens. However, although Transformer models have proven to be effective at GEC, they aren&#39;t particularly efficient because the generation cannot be parallelized due to &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_model&quot;>;autoregressive&lt;/a>; decoding. Often, only a few modifications are needed to make the input text grammatically correct, so another possible solution is to treat GEC as a &lt;a href=&quot;https://arxiv.org/abs/2206.07043&quot;>;text editing&lt;/a>;é—®é¢˜ã€‚ If we could run the autoregressive decoder only to generate the modifications, that would substantially decrease the latency of the GEC model. &lt;/p>; &lt;p>; To this end, in â€œ&lt;a href=&quot;https://aclanthology.org/2022.findings-emnlp.156/&quot;>;EdiT5: Semi-Autoregressive Text-Editing with T5 Warm-Start&lt;/a>;â€, published at Findings of &lt;a href=&quot;https://2022.emnlp.org/&quot; target=&quot;_blank&quot;>;EMNLP 2022&lt;/a>;, we describe a novel text-editing model that is based on the &lt;a href=&quot;https://arxiv.org/abs/1910.10683&quot;>;T5&lt;/a>; Transformer encoder-decoder architecture. EdiT5 powers the new Google Search &lt;a href=&quot;https://support.google.com/websearch/answer/13420782&quot;>;grammar check feature&lt;/a>; that allows you to check if a phrase or sentence is grammatically correct and provides corrections when needed. Grammar check shows up when the phrase &quot;grammar check&quot; is included in a search query, and if the underlying model is confident about the correction. Additionally, it shows up for some queries that don&#39;t contain the â€œgrammar checkâ€ phrase when Search understands that is the likely intent. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-BAXZ3wH-FcJmFoKvppChwvfZay7xH5bhiYmKQocV47sCb3IMfwEec1OpBWY3b1fd2rnA4Vhy4EqOCZiAR4Xpv6xPok9yC-ZqLogbER2lcmaje1NfBCoPAtdW7rEPG22PtNn4dVuYtYH61D9fnx7kudLZilxzUbi01ePhirqtTwMu6g9trhFFuLCDUCgP/s1412/image4.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;546&quot; data-original-width=&quot;1412&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-BAXZ3wH-FcJmFoKvppChwvfZay7xH5bhiYmKQocV47sCb3IMfwEec1OpBWY3b1fd2rnA4Vhy4EqOCZiAR4Xpv6xPok9yC-ZqLogbER2lcmaje1NfBCoPAtdW7rEPG22PtNn4dVuYtYH61D9fnx7kudLZilxzUbi01ePhirqtTwMu6g9trhFFuLCDUCgP/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br / >; &lt;/div>; &lt;h2>;Model architecture&lt;/h2>; &lt;p>; For low-latency applications at Google, Transformer models are typically run on &lt;a href=&quot;https://cloud.google.com/tpu/docs/ intro-to-tpu&quot;>;TPUs&lt;/a>;. Due to their fast matrix multiplication units (MMUs), these devices are optimized for performing large matrix multiplications quickly, for example running a Transformer encoder on hundreds of tokens in only a few milliseconds. In contrast, Transformer decoding makes poor use of a TPU&#39;s capabilities, because it forces it to process only one token at a time. This makes autoregressive decoding the most time-consuming part of a translation-based GEC model. &lt;/p>; &lt;p>; In the EdiT5 approach, we reduce the number of decoding steps by treating GEC as a text editing problem. The EdiT5 text-editing model is based on the &lt;a href=&quot;https://arxiv.org/abs/1910.10683&quot;>;T5&lt;/a>; Transformer encoder-decoder architecture with a few crucial modifications. Given an input with grammatical errors, the EdiT5 model uses an encoder to determine which input tokens to keep or delete. The kept input tokens form a draft output, which is optionally reordered using a non-autoregressive &lt;a href=&quot;https://proceedings.neurips.cc/paper_files/paper/2015/file/29921001f2f04bd3baee84a12e98098f-Paper.pdf&quot;>;pointer network &lt;/a>;ã€‚ Finally, a decoder outputs the tokens that are missing from the draft, and uses a pointing mechanism to indicate where each new token should be placed to generate a grammatically correct output. The decoder is only run to produce tokens that were missing in the draft, and as a result, runs for much fewer steps than would be needed in the translation approach to GEC. &lt;/p>; &lt;p>;To further decrease the decoder latency, we reduce the decoder down to a single layer, and we compensate by increasing the size of the encoder. Overall, this decreases latency significantly because the extra work in the encoder is efficiently parallelized.&lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2_MGEcdadlbXM1zMBQzROuRbYyqmcdhcytlnwdHeIJ_M0wrtioaRixoDOxMlE3acuMZRf4KB_T5TgzUCfBBmz3eeEMnnAKHZkvFmMzFnNu_2UAI1l3jhOp2dyQyOxElXwt7iEjun_gd77uk1TMiaBLlMfxEOxcFo8W48fdD9WqbYNvUZECUEd-LHTk1-R/s1878/image2.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1332&quot; data-original-width=&quot;1878&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2_MGEcdadlbXM1zMBQzROuRbYyqmcdhcytlnwdHeIJ_M0wrtioaRixoDOxMlE3acuMZRf4KB_T5TgzUCfBBmz3eeEMnnAKHZkvFmMzFnNu_2UAI1l3jhOp2dyQyOxElXwt7iEjun_gd77uk1TMiaBLlMfxEOxcFo8W48fdD9WqbYNvUZECUEd-LHTk1-R/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Given an input with grammatical errors (â€œGuess when was I bornedâ€), the EdiT5 model uses an encoder to determine which input tokens to keep (K) or delete (D), a pointer network (pointer) to reorder kept tokens, and a decoder to insert any new tokens that are needed to generate a grammatically correct output.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We applied the EdiT5 model to the &lt;a href=&quot;https://aclanthology.org/W19-4406/&quot;>;public BEA grammatical error correction benchmark&lt;/a>;, comparing different model sizes. The experimental results show that an EdiT5 large model with 391M parameters yields a higher &lt;a href=&quot;https://en.wikipedia.org/wiki/F-score&quot;>;F0.5 score&lt;/a>;, which measures the accuracy of the corrections, while delivering a 9x speedup compared to a T5 base model with 248M parameters. The mean latency of the EdiT5 model was merely 4.1 milliseconds. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQys5EavCOAEs0dy3M8r5Ar-9v7n5qtFkek1VSfeGBXH1pQHNv6Ebem3vDedO60BlNcp3HLGqYtsT4v4Evz2u2ksTgFfQcQIqd87NPTxVzYVyzvA85Vg_jO8a18KrMT2hOQQA5hg2frOJx2L7S5SM88VBCJzd13ClrSzHnl5xg29TMMpvqA4Yl-d98vTc1/s1987/image1.jpeg&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1311&quot; data-original-width=&quot;1987&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQys5EavCOAEs0dy3M8r5Ar-9v7n5qtFkek1VSfeGBXH1pQHNv6Ebem3vDedO60BlNcp3HLGqYtsT4v4Evz2u2ksTgFfQcQIqd87NPTxVzYVyzvA85Vg_jO8a18KrMT2hOQQA5hg2frOJx2L7S5SM88VBCJzd13ClrSzHnl5xg29TMMpvqA4Yl-d98vTc1/s16000/image1.jpeg&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;Performance of the T5 and EdiT5 models of various sizes on the public BEA GEC benchmark plotted against mean latency. Compared to T5, EdiT5 offers a better latency-F0.5 trade-off. Note that the x axis is logarithmic.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Improved training data with large language models&lt;/h2>; &lt;p>; Our &lt;a href=&quot;https://arxiv.org/abs/2106.03830&quot;>;earlier research&lt;/a>;, as well as the results above, show that model size plays a crucial role in generating accurate grammatical corrections. To combine the advantages of large language models (LLMs) and the low latency of EdiT5, we leverage a technique called &lt;a href=&quot;https://arxiv.org/abs/1503.02531&quot;>;hard distillation&lt;/a>;. First, we train a teacher LLM using similar datasets used for the &lt;a href=&quot;https://ai.googleblog.com/2021/10/grammar-correction-as-you-type-on-pixel.html&quot;>;Gboard grammar model&lt;/a>;. The teacher model is then used to generate training data for the student EdiT5 model. &lt;/p>; &lt;p>; Training sets for grammar models consist of &lt;em>;ungrammatical source / grammatical target&lt;/em>; sentence pairs. Some of the training sets have noisy targets that contain grammatical errors, unnecessary paraphrasing, or unwanted artifacts. Therefore, we generate new pseudo-targets with the teacher model to get cleaner and more consistent training data. Then, we re-train the teacher model with the pseudo-targets using a technique called &lt;em>;&lt;a href=&quot;https://arxiv.org/abs/1909.13788&quot;>;self-training&lt;/a>;&lt;/em>; ã€‚ Finally, we found that when the source sentence contains many errors, the teacher sometimes corrects only part of the errors. Thus, we can further improve the quality of the pseudo-targets by feeding them to the teacher LLM for a second time, a technique called &lt;em>;&lt;a href=&quot;https://aclanthology.org/D19-1435/&quot;>;iterative refinement&lt;/a>;&lt;/em>;. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgJzgocbj86SS8moSqWrxIKz8E3CxZn712Di2CY7pwgXZ355Z4qUnDBxuEc91AU9jAdKwq4tvyaCzIqKfcJzThrjkka5q1LwXGWNa1xPi5AU7RpJDq-XmoNHs386B2bJqKDDnN8_l1mvLCSShlGjb66RWy25Z_1QXwMDpHDgsPON7r0pUqYdXZLPsx06hOC/s1089/image3.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;984&quot; data-original-width=&quot;1089&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEgJzgocbj86SS8moSqWrxIKz8E3CxZn712Di2CY7pwgXZ355Z4qUnDBxuEc91AU9jAdKwq4tvyaCzIqKfcJzThrjkka5q1LwXGWNa1xPi5AU7RpJDq-XmoNHs386B2bJqKDDnN8_l1mvLCSShlGjb66RWy25Z_1QXwMDpHDgsPON7r0pUqYdXZLPsx06hOC/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;Steps for training a large teacher model for grammatical error correction (GEC). Self-training and iterative refinement remove unnecessary paraphrasing, artifacts, and grammatical errors appearing in the original targets.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Putting it all together&lt;/h2>; &lt;p>; Using the improved GEC data, we train two EdiT5-based models: a grammatical error correction model, and a grammaticalityåˆ†ç±»å™¨ã€‚ When the grammar check feature is used, we run the query first through the correction model, and then we check if the output is indeed correct with the classifier model. Only then do we surface the correction to the user. &lt;/p>; &lt;p>; The reason to have a separate classifier model is to more easily trade off between precision and recall. Additionally, for ambiguous or nonsensical queries to the model where the best correction is unclear, the classifier reduces the risk of serving erroneous or confusing corrections. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; We have developed an efficient grammar correction model based on the state-of-the-art EdiT5 model architecture. This model allows users to check for the grammaticality of their queries in Google Search by including the â€œgrammar checkâ€ phrase in the query. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;We gratefully acknowledge the key contributions of the other team members, including Akash R, Aliaksei Severyn, Harsh Shah, Jonathan Mallinson, Mithun Kumar SR, Samer Hassan, Sebastian Krause, and Shikhar Thakur. We&#39;d also like to thank Felix Stahlberg, Shankar Kumar, and Simon Tong for helpful discussions and pointers.&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/420799196308935505/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/grammar-checking-at-google-search-scale.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/420799196308935505&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/420799196308935505&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/grammar-checking-at-google-search-scale.html&quot; rel=&quot;alternate&quot; title=&quot;Grammar checking at Google Search scale&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW7pWsW1-E7U1LH1bxmjBL_2W5fS6uN2iRb2cNPBks57ubvFNJj-SjE2Zk1lFqndKWBVAeO3g3MLeJ96QUIUNJDyLTcWjeO835NT6HfJMYQBEdGqL-X_sxQ1yxMy16a0OcOLb6gSz2lqM6VofToVtN_s_F_wGB41AZwlj146y7ZXQ4PFsdywX10QO54MJ4/s72-c/HeroGC.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-2376347423475108178&lt;/id>;&lt;published>;2023-10-20T10:07:00.000-07:00&lt;/published>;&lt;updated>;2023-11-27T16:21:27.895-08:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;distributed systems&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Publications&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Research&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Answering billions of reporting queries each day with low latency&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Jagan Sankaranarayanan, Senior Staff Software Engineer, and Indrajit Roy, Head of Napa Product, Google&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIZSvPVFwZPeTv8ivB-lHMGfoLkP-fDBuAy9GEklUVNBPPoqOXRfme5Psui7DbKssImVjFHtxoygKhFBvgpAG_C5852ocu9i7AOfWPeC1mSlaim8jfqsV55wZIULDUPk7WhxW1OISfL_CjZswN3CcZN7GJgVLBdepic8lfYAUCT0rAlXGGbnf-WuA6mRc6/s320/hero.jpg&quot; style=&quot;display: none;&quot; />; &lt;p>; &lt;a href=&quot;https://ads.google.com/home/&quot;>;Google Ads&lt;/a>; infrastructure runs on an internal data warehouse called &lt;a href=&quot;https://research.google/pubs/pub50617/&quot;>;Napa&lt;/a>;. Billions of reporting queries, which power critical dashboards used by advertising clients to measure campaign performance, run on tables stored in Napa. These tables contain records of ads performance that are keyed using particular customers and the campaign identifiers with which they are associated. Keys are tokens that are used both to associate an ads record with a particular client and campaign (eg, &lt;code>;customer_id&lt;/code>;, &lt;code>;campaign_id&lt;/code>;) and for efficient retrieval. A record contains dozens of keys, so clients use reporting queries to specify keys needed to filter the data to understand ads performance (eg, by region, device and metrics such as clicks, etc.). What makes this problem challenging is that the data is &lt;em>;skewed&lt;/em>; since queries require varying levels of effort to be answered and have stringent latency expectations. Specifically, some queries require the use of millions of records while others are answered with just a few. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; To this end, in â€œ&lt;a href=&quot;https://research.google/pubs/pub52572/&quot;>;Progressive Partitioning for Parallelized Query Execution in Napa&lt;/a>;â€, presented at &lt;a href=&quot;https://vldb.org/2023/&quot;>;VLDB 2023&lt;/a>;, we describe how the Napa data warehouse determines the amount of machine resources needed to answer reporting queries while meeting strict latency targets. We introduce a new progressive query partitioning algorithm that can &lt;a href=&quot;https://en.wikipedia.org/wiki/Parallel_computing&quot;>;parallelize&lt;/a>; query execution in the presence of complex data skews to perform consistently well in a matter of a few milliseconds. Finally, we demonstrate how Napa allows Google Ads infrastructure to serve billions of queries every day. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Query processing challenges&lt;/h2>; &lt;p>; When a client inputs a reporting query, the main challenge is to determine how to parallelize the query effectively. Napa&#39;s parallelization technique breaks up the query into even sections that are equally distributed across available machines, which then process these in parallel to significantly reduce query latency. This is done by estimating the number of records associated with a specified key, and assigning more or less equal amounts of work to machines. However, this estimation is not perfect since reviewing all records would require the same effort as answering the query. A machine that processes significantly more than others would result in run-time skews and poor performance. Each machine also needs to have sufficient work since needless parallelism leads to underutilized infrastructure. Finally, parallelization has to be a per query decision that must be executed near-perfectly billions of times, or the query may miss the stringent latency requirements. &lt;/p>; &lt;p>; The reporting query example below extracts the records denoted by keys (ie, &lt;code>;customer_id&lt;/code>; and &lt;code>;campaign_id&lt;/code>;) and then computes an aggregate (ie, &lt;code>;SUM(cost)&lt;/code>;) from an advertiser table. In this example the number of records is too large to process on a single machine, so Napa needs to use a subsequent key (eg, &lt;code>;adgroup_id&lt;/code>;) to further break up the collection of records so that equal distribution of work is achieved. It is important to note that at petabyte scale, the size of the data statistics needed for parallelization may be several terabytes. This means that the problem is not just about collecting enormous amounts of metadata, but also how it is managed. &lt;/p>; &lt;br />; &lt;span style=&quot;font-size: small;&quot;>; &lt;pre class=&quot;prettyprint&quot; style=&quot;margin-left: 40px; margin-right: 40px; white-space: pre-wrap;&quot;>; SELECT customer_id, campaign_id, SUM(cost) FROM advertiser_table WHERE customer_id in (1, 7, ..., x ) AND campaign_id in (10, 20, ..., y) GROUP BY customer_id, campaign_id; &lt;/pre>;&lt;/span>; &lt;br />; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;This reporting query example extracts records denoted by keys (ie, &lt;code>;customer_id&lt;/code>; and &lt;code>;campaign_id&lt;/code>;) and then computes an aggregate (ie, &lt;code>;SUM(cost)&lt;/code>;) from an advertiser table. The query effort is determined by the keys&#39; included in the query. Keys belonging to clients with larger campaigns may touch millions of records since the data volume directly correlates with the size of the ads campaign. This disparity of matching records based on keys reflects the &lt;em>;skewness&lt;/em>; in data, which makes query processing a challenging problem.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;p>; An effective solution minimizes the amount of metadata needed, focuses effort primarily on the skewed part of the key space to partition data efficiently, and works well within the allotted time. For example, if the query latency is a few hundred milliseconds, partitioning should take no longer than tens of milliseconds. Finally, a parallelization process should determine when it&#39;s reached the best possible partitioning that considers query latency expectations. To this end, we have developed a progressive partitioning algorithm that we describe later in this article. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Managing the data deluge&lt;/h2>; &lt;p>; Tables in Napa are constantly updated, so we use &lt;a href=&quot;https://en.wikipedia.org/wiki/Log-structured_merge-tree&quot;>;log-structured merge forests&lt;/a>; (LSM tree) to organize the deluge of table updates. LSM is a forest of sorted data that is temporally organized with a &lt;a href=&quot;https://en.wikipedia.org/wiki/B-tree&quot;>;B-tree index&lt;/a>; to support efficient key lookup queries. B-trees store summary information of the sub-trees in a hierarchical manner. Each B-tree node records the number of entries present in each subtree, which aids in the parallelization of queries. LSM allows us to &lt;a href=&quot;https://research.google/pubs/pub50617/&quot;>;decouple&lt;/a>; the process of updating the tables from the mechanics of query serving in the sense that live queries go against a different version of the data, which is atomically updated once the next batch of ingest (called delta) has been fully prepared for querying. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhrdgCgdHtjKomZM08fuF3qd6UWrgHHYvTgclc2iMV1UffAAMqVgsJVhGDSP4aPzPh4-kNb0hU7ZWkOAaf37k7PaTaH4k3m45fDzBaX9x0wxRSpvPADOXIDrtdTL62lFGJKzqEaDT6oz-fPxbkSxU3omqQAm8sWKmsA8SR4wHHKh6iAXbDGcU4a_WvEHsaL/s1999/image4.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;667&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhrdgCgdHtjKomZM08fuF3qd6UWrgHHYvTgclc2iMV1UffAAMqVgsJVhGDSP4aPzPh4-kNb0hU7ZWkOAaf37k7PaTaH4k3m45fDzBaX9x0wxRSpvPADOXIDrtdTL62lFGJKzqEaDT6oz-fPxbkSxU3omqQAm8sWKmsA8SR4wHHKh6iAXbDGcU4a_WvEHsaL/s16000/image4.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>;&lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div >; &lt;h2>;The partitioning problem&lt;/h2>; &lt;p>; The data partitioning problem in our context is that we have a massively large table that is represented as an LSM tree. In the figure below, Delta 1 and 2 each have their own B-tree, and together represent 70 records. Napa breaks the records into two pieces, and assigns each piece to a different machine. The problem becomes a partitioning problem of a forest of trees and requires a &lt;a href=&quot;https://en.wikipedia.org/wiki/Tree_traversal&quot;>;tree-traversal algorithm&lt;/a>; that can quickly split the trees into twoç­‰ä»½ã€‚ &lt;/p>; &lt;p>; To avoid visiting all the nodes of the tree, we introduce the concept of â€œgood enoughâ€ partitioning. As we begin cutting and partitioning the tree into two parts, we maintain an estimate of how bad our current answer would be if we terminated the partitioning process at that instant. This is the yardstick of how close we are to the answer and is represented below by a total error margin of 40 (at this point of execution, the two pieces are expected to be between 15 and 35 records in size, the uncertainty adds up to 40ï¼‰ã€‚ Each subsequent traversal step reduces the error estimate, and if the two pieces are approximately equal, it stops the partitioning process. This process continues until the desired error margin is reached, at which time we are guaranteed that the two pieces are more or less equal. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjP1MUE1iWt7K2hKPBmTmr4LfIgARhI3a-nKsMqrcmiOejHLJbxDyKIoV-9ZF8k9_X4w9EMLikeVOufzTTmBGMqBKdH_AyrWz_UihzrZFsaNPWFXB2dD8o2RIBbXCM0shFN8a6fUMW0g830qrJx0Q3mpOLfzyQwwuYB9nilFeKt3VfKQYde9Eq5VmN8D-2i/s473/image2.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;327&quot; data-original-width=&quot;473&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjP1MUE1iWt7K2hKPBmTmr4LfIgARhI3a-nKsMqrcmiOejHLJbxDyKIoV-9ZF8k9_X4w9EMLikeVOufzTTmBGMqBKdH_AyrWz_UihzrZFsaNPWFXB2dD8o2RIBbXCM0shFN8a6fUMW0g830qrJx0Q3mpOLfzyQwwuYB9nilFeKt3VfKQYde9Eq5VmN8D-2i/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br / >; &lt;/div>; &lt;h2>;Progressive partitioning algorithm&lt;/h2>; &lt;p>; Progressive partitioning encapsulates the notion of â€œgood enoughâ€ in that it makes a series of moves to reduce the error estimate. The input is a set of B-trees and the goal is to cut the trees into pieces of more or less equal size. The algorithm traverses one of the trees (â€œdrill down&#39;&#39; in the figure) which results in a reduction of the error estimate. The algorithm is guided by statistics that are stored with each node of the tree so that it makes an informed set of moves at each step. The challenge here is to decide how to direct effort in the best possible way so that the error bound reduces quickly in the fewest possible steps. Progressive partitioning is conducive for our use-case since the longer the algorithm runs, the more equal the pieces become. It also means that if the algorithm is stopped at any point, one still gets good partitioning, where the quality corresponds to the time spent. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsnglKJOlArk8nIcelyOi8Yej5O2OUWCwWzitU9PsT5h-0zWDyvpVhxrdMsbsB0ECvC_q6Y91peJ6Q2r5HjXJWsH47LSEDODJw1lm-aOt8lpMhcTyMU2LOf7m2KcykAnyRLFrpx_I95spiJi5qNecVwlJ7x_aRhSDTCON6G_o09WeN8x4BwQeXbJOBOzFW/s390/image1.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;281&quot; data-original-width=&quot;390&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsnglKJOlArk8nIcelyOi8Yej5O2OUWCwWzitU9PsT5h-0zWDyvpVhxrdMsbsB0ECvC_q6Y91peJ6Q2r5HjXJWsH47LSEDODJw1lm-aOt8lpMhcTyMU2LOf7m2KcykAnyRLFrpx_I95spiJi5qNecVwlJ7x_aRhSDTCON6G_o09WeN8x4BwQeXbJOBOzFW/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Prior work in this space uses a &lt;a href=&quot;https://research.google/pubs/ pub52572/&quot;>;sampled table to drive the partitioning process&lt;/a>;, while the Napa approach uses a B-tree. As mentioned earlier, even just a sample from a petabyte table can be massive. A tree-based partitioning method can achieve partitioning much more efficiently than a sample-based approach, which does not use a tree organization of the sampled records. We compare progressive partitioning with an alternative approach, where sampling of the table at various resolutions (eg, 1 record sample every 250 MB and so on) aids the partitioning of the query. Experimental results show the relative speedup from progressive partitioning for queries requiring varying numbers of machines. These results demonstrate that progressive partitioning is much faster than existing approaches and the speedup increases as the size of the query increases. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3V3INsImX_TRgcEa2VFXMK2LtVwNyCjzqYco_QMSTQWMAIfb1D5rpF7iM4xFesoltnJI9RUQNVkuuZv7nMjDIfjzhIklmdcj1xl9B8uBMfDKLIhQ9UXgH1Vrgrf2xoNvHMrv0icZDI_PKQLo9ZA6bCzrlyvX3eayjxCH_IZjFxZ1Hy9atHm6oEUqFhZz7/s1452/image3.png&quot; style=&quot;margin- left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1192&quot; data-original-width=&quot;1452&quot; height=&quot;525&quot; src=&quot;https://blogger .googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3V3INsImX_TRgcEa2VFXMK2LtVwNyCjzqYco_QMSTQWMAIfb1D5rpF7iM4xFesoltnJI9RUQNVkuuZv7nMjDIfjzhIklmdcj1xl9B8uBMfDKLIhQ9UXgH1Vrgrf2xoNvHMrv0icZDI_PKQLo9ZA6bCzrlyvX3eayjxCH_IZjFxZ1Hy9atHm6oEUqFhZz7/w640-h525/image3.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br / >; &lt;/div>; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; Napa&#39;s progressive partitioning algorithm efficiently optimizes database queries, enabling Google Ads to serve client reporting queries billions of times each day. We note that tree traversal is a common technique that students in introductory computer science courses use, yet it also serves a critical use-case at Google. We hope that this article will inspire our readers, as it demonstrates how simple techniques and carefully designed data structures can be remarkably potent if used well. Check out the &lt;a href=&quot;https://research.google/pubs/pub52572/&quot;>;paper&lt;/a>; and a &lt;a href=&quot;https://www.youtube.com/watch?v=dtWwUWB5JyQ&quot;>;recent talk&lt;/a>; describing Napa to learn more. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;This blog post describes a collaborative effort between Junichi Tatemura , Tao Zou, Jagan Sankaranarayanan, Yanlai Huang, Jim Chen, Yupu Zhang, Kevin Lai, Hao Zhang, Gokul Nath Babu Manoharan, Goetz Graefe, Divyakant Agrawal, Brad Adelberg, Shilpa Kolhar and Indrajit Roy.&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/2376347423475108178/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt; link href=&quot;http://blog.research.google/2023/10/answering-billions-of-reporting-queries.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/ html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/2376347423475108178&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot; http://www.blogger.com/feeds/8474926331452026626/posts/default/2376347423475108178&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google /2023/10/answering-billions-of-reporting-queries.html&quot; rel=&quot;alternate&quot; title=&quot;Answering billions of reporting queries each day with low latency&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name >; Google AI &lt;/name>; &lt;uri>; http://www.blogger.com/profile/1209862651477775266161 &lt;/uri>; &lt;Email>; &lt;Email>; noreply@blogger.com &lt;/email>; â€œ http://schemas.google.com/g/2005#thumbnailâ€ src =â€œ https://img1.blogbblog.com/img/img/b16-rounded.gifâ€ width =â€œ 16â€ &lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIZSvPVFwZPeTv8ivB-lHMGfoLkP-fDBuAy9GEklUVNBPPoqOXRfme5Psui7DbKssImVjFHtxoygKhFBvgpAG_C5852ocu9i7AOfWPeC1mSlaim8jfqsV55wZIULDUPk7WhxW1OISfL_CjZswN3CcZN7GJgVLBdepic8lfYAUCT0rAlXGGbnf-WuA6mRc6/s72-c/hero.jpg&quot; width= &quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>; tag:blogger.com,1999:blog-8474926331452026626.post-3886518375378801095&lt;/id>;&lt;published>;2023-10-19T09:24:00.002-07:00&lt;/published>;&lt;updated>;2023-10-19T09:43: 21.465-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Education&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www. blogger.com/atom/ns#&quot; term=&quot;Search&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Speech&quot;>;&lt;/category>;&lt; title type=&quot;text&quot;>;English learners can now practice speaking on Search&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Christian Plagemann, Director, and Katya Cox, Product Manager , Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfHhrdHOFN2-ZoUw8hxN1Gdmd5WBtL5kVUe27TeajsI3nrES8Ah13W7MIKpZ2avrsxFTdkzk-sD1noswtk20cMyPS8GjDnVMPquyxc6EhR9r53bMzncRYlj5ZBM3jMF15ndusFp2fe9ipy4bksiTLfWJ1umdcUrQUxg78SOtXfjqMbSxW_OQsSTAVZ9HV6/s600/Tivoli.gif&quot; style=&quot;display: none;&quot; />; &lt;p>; Learning a language can open up new opportunities in a person&#39;s life. It can help people connect with those from different cultures, travel the world, and advance their career. English alone is estimated to have 1.5 billion learners worldwide. Yet proficiency in a new language is difficult to achieve, and many learners cite a lack of opportunity to practice speaking actively and receiving actionable feedback as a barrier to learning. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; We are excited to announce a new feature of Google Search that helps people practice speaking and improve their language skills. Within the next few days, Android users in Argentina, Colombia, India (Hindi), Indonesia, Mexico, and Venezuela can get even more language support from Google through interactive speaking practice in English â€” expanding to more countries and languages in the future. Google Search is already a valuable tool for language learners, providing translations, definitions, and other resources to improve vocabulary. Now, learners translating &lt;em>;to&lt;/em>; or &lt;em>;from&lt;/em>; English on their Android phones will find a new English speaking practice experience with personalized feedback. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRV7Q3FKxiVB0qI6W7mk7mf_kZ_I6H_FKhzhrHcxHh5rYUNFa4E59XqRG7u0KpGX6lgvz6ihkD8fddSlHbWI18YkN9BF-KoHnyXLZdXqMdGApRNffllQR8neHSI8hFFDzeBpSkvyLjNb5_u7MJPIIIEPBpskiR_IfeN7YWXpz46seBFjEpIjghLs4-lBj2/s939/image9.gif&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;939&quot; data-original-width=&quot;428&quot; height=&quot;640&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRV7Q3FKxiVB0qI6W7mk7mf_kZ_I6H_FKhzhrHcxHh5rYUNFa4E59XqRG7u0KpGX6lgvz6ihkD8fddSlHbWI18YkN9BF-KoHnyXLZdXqMdGApRNffllQR8neHSI8hFFDzeBpSkvyLjNb5_u7MJPIIIEPBpskiR_IfeN7YWXpz46seBFjEpIjghLs4-lBj2/w292-h640/image9.gif&quot; width=&quot;292&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;A new feature of Google Search allows learners&lt;br />;to practice speaking words in context.&lt;/td>;&lt;/tr>;&lt;/ tbody>;&lt;/table>; &lt;p>; Learners are presented with real-life prompts and then form their own spoken answers using a provided vocabulary word. They engage in practice sessions of 3-5 minutes, getting personalized feedback and the option to sign up for daily reminders to keep practicing. With only a smartphone and some quality time, learners can practice at their own pace, anytime, anywhere. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Activities with personalized feedback, to supplement existing learning tools&lt;/h2>; &lt;p>; Designed to be used alongside other learning services and resources, like personal tutoring, mobile apps, and classes, the new speaking practice feature on Google Search is another tool to assist learners on their journey. &lt;/p>; &lt;p>; We have partnered with linguists, teachers, and &lt;a href=&quot;https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language&quot;>;ESL/EFL&lt;/a>; pedagogical experts to create a speaking practice experience that is effective and motivating. Learners practice vocabulary in authentic contexts, and material is repeated over dynamic intervals to increase retention â€” approaches that are known to be effective in helping learners become confident speakers. As one partner of ours shared: &lt;/p>; &lt;div style=&quot;margin-left: 40px;&quot;>; &lt;p>; &lt;em>;&quot;Speaking in a given context is a skill that language learners often lack the opportunity to practice. Therefore this tool is very useful to complement classes and other resources.&quot; - Judit Kormos, Professor, Lancaster University&lt;/em>; &lt;/p>; &lt;/div>; &lt;p>; We are also excited to be working with several language learning partners to surface content they are helping create and to connect them with learners around theä¸–ç•Œã€‚ We look forward to expanding this program further and working with any interested partner. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Personalized real-time feedback &lt;/h2>; &lt;p>; Every learner is different, so delivering personalized feedback in real time is a key part of effective practice. Responses are analyzed to provide helpful, real-time suggestions and corrections.&lt;br />; &lt;/p>; &lt;p>; The system gives &lt;em>;semantic feedback&lt;/em>;, indicating whether their response was relevant to the question and may be understood by a conversation partner. &lt;em>;Grammar feedback&lt;/em>; provides insights into possible grammatical improvements, and a set of &lt;em>;example answers&lt;/em>; at varying levels of language complexity give concrete suggestions for alternative ways to respond in this context. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjjEZsUjl4VVmcpQhX43ZJgAtH2S46YWrmpYQuoNvtTMovHKXVPCGoDqDVlyRv_XLzgDWfEWTlbGhTsQO-EvaSJC2K5rnxi5xEoM2amjSMVUKwP13r8DDurLkYyIFTcS7yzL7n11rZiCsfeRx0lLnIueV66BmAn9GSelvSCg27IOZNfqvc2JanmrGI1hKE5/s929/image8.gif&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;929&quot; data-original-width=&quot;428&quot; height=&quot;640&quot; src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjjEZsUjl4VVmcpQhX43ZJgAtH2S46YWrmpYQuoNvtTMovHKXVPCGoDqDVlyRv_XLzgDWfEWTlbGhTsQO-EvaSJC2K5rnxi5xEoM2amjSMVUKwP13r8DDurLkYyIFTcS7yzL7n11rZiCsfeRx0lLnIueV66BmAn9GSelvSCg27IOZNfqvc2JanmrGI1hKE5/w294-h640/image8.gif&quot; width=&quot;294&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;The feedback is composed of three elements: Semantic analysis, grammar correction, and example answers.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table >; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Contextual translation&lt;/h3>; &lt;p>; Among the several new technologies we developed, contextual translation provides the ability to translate individual words and phrases &lt;em>;in context&lt;/em>;. During practice sessions, learners can tap on any word they don&#39;t understand to see the translation of that word considering its context. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwfGcZuy2godKFrUvo8R6jmayMNo4pT7C3lBLuApdsJxIxqmaLfXuoQjk3E4Hs5UK5xFrb03QeABCSDgphyphenhyphencnCy8-smihT_WUZ5nPLqPjpGIM4yMhL9PnqqDG5ZsyHqLjag_uxBTIJZqw4w0lkfoF8iJAerlP2tRcE10D9f6RhSIuej6cVP9pl8xjmhiqz/s1999/image3.jpg&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;949&quot; data-original-width=&quot;1999&quot; height=&quot;190&quot; src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwfGcZuy2godKFrUvo8R6jmayMNo4pT7C3lBLuApdsJxIxqmaLfXuoQjk3E4Hs5UK5xFrb03QeABCSDgphyphenhyphencnCy8-smihT_WUZ5nPLqPjpGIM4yMhL9PnqqDG5ZsyHqLjag_uxBTIJZqw4w0lkfoF8iJAerlP2tRcE10D9f6RhSIuej6cVP9pl8xjmhiqz/w400-h190/image3.jpg&quot; width=&quot;400&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Example of contextual translation feature.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; This is a difficult technical task, since individual words in isolation often have multiple alternative meanings, and multiple words can form clusters of meaning that need to be translated in unison. Our novel approach translates the entire sentence, then estimates how the words in the original and the translated text relate to each other. This is commonly known as the &lt;a href=&quot;https://aclanthology.org/J03-1002/&quot;>;word alignment problem&lt;/a>;. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEipp97I_J7eGvrIEjtu71XmBw2GDbNTOtF4lEBnI0kP1B7fK541JKlVfle0Qv8lh3ME7rOoAwOCH26TlvsogltG_krPLLoEBRsYLKfHSFq9w28cNisWL7VVU126PxSj3r2VdGJs1Tg3SJ8aLxVFTAFzqL_KPhlVZ4baUTeex7-pUzmRyFQIMZrtfR2DJErM/s1059/image1.gif&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1059&quot; data-original-width=&quot;796&quot; height=&quot;400&quot; src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEipp97I_J7eGvrIEjtu71XmBw2GDbNTOtF4lEBnI0kP1B7fK541JKlVfle0Qv8lh3ME7rOoAwOCH26TlvsogltG_krPLLoEBRsYLKfHSFq9w28cNisWL7VVU126PxSj3r2VdGJs1Tg3SJ8aLxVFTAFzqL_KPhlVZ4baUTeex7-pUzmRyFQIMZrtfR2DJErM/w301-h400/image1.gif&quot; width=&quot;301&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Example of a translated sentence pair and its word alignment. A deep learning alignment model connects the different words that create the meaning to suggest a translation.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; The key technology piece that enables this functionality is a novel &lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot;>;deep learning&lt;/a>; model developed in collaboration with the Google Translate team, called Deep Aligner. The basic idea is to take a multilingual language model trained on hundreds of languages, then fine-tune a novel alignment model on a set of word alignment examples (see the figure above for an example) provided by human experts, for several language pairs. From this, the single model can then accurately align any language pair, reaching state-of-the-art alignment error rate (AER, a metric to measure the quality of word alignments, where lower is better). This single new model has led to dramatic improvements in alignment quality across all tested language pairs, reducing average AER from 25% to 5% compared to alignment approaches based on &lt;a href=&quot;https://aclanthology.org/C96-2141/&quot;>;Hidden Markov models&lt;/a>; (HMMs). &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjjlqhOWugi22TAIKRsT6IcyjdZaWRP17p1C80QywrJfNSRqcpwiUmOJw_Km3EEu9f-E3o8ZiH6DKlzk8Yv4xrk-CFmlsVBMoQYf3Zp5UZDF6SD_cUsY2nA9uBBFsbPBz6s5j6YOL1Q0Fx4Kt-eKpyqnP2RdGhYfKLIxjDyOPPuISBwmruGdnxUP5NdPYkF/s1084/image5.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;374&quot; data-original-width=&quot;1084&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjjlqhOWugi22TAIKRsT6IcyjdZaWRP17p1C80QywrJfNSRqcpwiUmOJw_Km3EEu9f-E3o8ZiH6DKlzk8Yv4xrk-CFmlsVBMoQYf3Zp5UZDF6SD_cUsY2nA9uBBFsbPBz6s5j6YOL1Q0Fx4Kt-eKpyqnP2RdGhYfKLIxjDyOPPuISBwmruGdnxUP5NdPYkF/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;Alignment error rates (lower is better) between English (EN) and other languages.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; This model is also incorporated into Google&#39;s translation APIs, greatly improving, for example, the formatting of translated PDFs and websites in Chrome, the translation of YouTube captions, and enhancing Google Cloud&#39;s translation API. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Grammar feedback &lt;/h3>; &lt;p>; To enable grammar feedback for accented spoken language, our research teams adapted grammar correction models for written text (see the &lt;a href=&quot;https://workspace.google.com/blog/ai-and-machine-learning/using-neural-machine-translation-to-correct-grammatical-in-google-docs&quot;>;blog&lt;/a>; and &lt;a href=&quot;https://aclanthology.org/N19-1333/&quot;>;paper&lt;/a>;) to work on automatic speech recognition (ASR) transcriptions, specifically for the case of accented speech. The key step was fine-tuning the written text model on a corpus of human and ASR transcripts of accented speech, with expert-provided grammar corrections. Furthermore, inspired by &lt;a href=&quot;https://aclanthology.org/2020.emnlp-main.418/&quot;>;previous work&lt;/a>;, the teams developed a novel edit-based output representation that leverages the high overlap between the inputs and outputs that is particularly well-suited for short input sentences common in language learning settings. &lt;/p>; &lt;p>; The edit representation can be explained using an example: &lt;/p>; &lt;ul>; &lt;li>;&lt;em>;Input&lt;/em>;: I&lt;sup>;1&lt;/sup>; am&lt;sup>;2&lt;/sup>; so&lt;sup>;3&lt;/sup>; bad&lt;sup>;4&lt;/sup>; cooking&lt;sup>;5&lt;/sup>; &lt;/li>;&lt;li>;&lt;em>;Correction&lt;/em>;: I&lt;sup>;1&lt;/sup>; am&lt;sup>;2&lt;/sup>; so&lt;sup>;3&lt;/sup>; bad&lt;sup>;4&lt;/sup>; at&lt;sup>;5&lt;/sup>; cooking&lt;sup>;6&lt;/sup>; &lt;/li>;&lt;li>;&lt;em>;Edits&lt;/em>;: (&#39;at&#39;, 4, PREPOSITION, 4) &lt;/li>; &lt;/ul>; &lt;p>; In the above, â€œatâ€ is the word that is inserted at position 4 and â€œPREPOSITIONâ€ denotes this is an error involving prepositions. We used the error tag to select tag-dependent acceptance thresholds that improved the model further. The model increased the recall of grammar problems from 4.6% to 35%. &lt;/p>; &lt;p>; Some example output from our model and a model trained on written corpora: &lt;/p>; &lt;br>; &lt;table style=&quot;text-align: center&quot;>; &lt;tbody>;&lt;tr>; &lt;td>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td>;Example 1 &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td>;Example 2 &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left&quot;>; User input (transcribed speech) &lt;/td>; &lt;td>; &lt;/td>; &lt;td>;&lt;em>;I live of my profession.&lt;/em>; &lt;/td>; &lt;td>; &lt;/td>; &lt;td>;&lt;em>;I need a efficient card and reliable.&lt;/em>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left&quot;>; Text-based grammar model &lt;/td>; &lt;td>; &lt;/td>; &lt;td>;&lt;em>;I live by my profession.&lt;/em>; &lt;/td>; &lt;td>; &lt;/td>; &lt;td>;&lt;em>;I need an efficient card and a reliable.&lt;/em>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left&quot;>; New speech-optimized model &lt;/td>; &lt;td>; &lt;/td>; &lt;td>;&lt;em>;I live off my profession.&lt;/em>; &lt;/td>; &lt;td>; &lt;/td>; &lt;td>;&lt;em>;I need an efficient and reliable card.&lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;br>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Semantic analysis&lt;/h3>; &lt;p>; A primary goal of conversation is to communicate one&#39;s intent clearly. Thus, we designed a feature that visually communicates to the learner whether their response was relevant to the context and would be understood by a partner. This is a difficult technical problem, since early language learners&#39; spoken responses can be syntactically unconventional. We had to carefully balance this technology to focus on the clarity of intent rather than correctness of syntax. &lt;/p>; &lt;p>; Our system utilizes a combination of two approaches: &lt;/p>; &lt;ol>; &lt;li>;&lt;em>;Sensibility&lt;/em>; classification: Large language models like &lt;a href=&quot;https://blog.google/technology/ai/lamda/&quot;>;LaMDA&lt;/a>; or &lt;a href=&quot;https://blog.research.google/2022/04/pathways-language-model-palm-scaling-to.html&quot;>;PaLM&lt;/a>; are designed to give natural responses in a conversation, so it&#39;s no surprise that they do well on the reverse: judging whether a given response is contextually sensible. &lt;/li>;&lt;li>;&lt;em>;Similarity&lt;/em>; to good responses: We used an &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf&quot;>;encoder architecture&lt;/a>; to compare the learner&#39;s input to a set of known good responses in a semantic embedding space. This comparison provides another useful signal on semantic relevance, further improving the quality of feedback and suggestions we provide.&lt;br />; &lt;/li>; &lt;/ol>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjnk1fQyMbEd1RoCpXD7st3-gFzcFlqF-02BbDilw5b2vG5IuZrs_IOkV0nbFCQXNVslsjxsgnKKSHLxHiDUN4riv4xuDGRnrxQe2O3CUhgcuWNzTxJhVMykcZOO0UZTCHCc0S5vG-VimzA_jZ8hrPBSN8KtUqfOpTNYyE6AXYPNOLZgq8ytF08y6X2GB7/s533/image4.gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;533&quot; data-original-width=&quot;428&quot; height=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjnk1fQyMbEd1RoCpXD7st3-gFzcFlqF-02BbDilw5b2vG5IuZrs_IOkV0nbFCQXNVslsjxsgnKKSHLxHiDUN4riv4xuDGRnrxQe2O3CUhgcuWNzTxJhVMykcZOO0UZTCHCc0S5vG-VimzA_jZ8hrPBSN8KtUqfOpTNYyE6AXYPNOLZgq8ytF08y6X2GB7/w321-h400/image4.gif&quot; width=&quot;321&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;The system provides feedback about whether the response was relevant to the prompt, and would be understood by a communication partner.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;ML-assisted content development&lt;/h2>; &lt;p>; Our available practice activities present a mix of human-expert created content, and content that was created with AI assistance and human review. This includes speaking prompts, focus words, as well as sets of example answers that showcase meaningful and contextual responses. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgacP_kIzsIz7Aqz_3hnuQsYMxeZ95DXI7ezmYnTvYOM3LXBNYR7mUJApgtw7BDLS1sSEAbjoc760T-D7gaZ8SAeo9qK40AUHkdpfiUJIItvdhagT2B-InWhoFomzhddu6ueT7gyDQcIIzrGGcZXmNjxfFo42VxQpmqkkgGS8dOh7NE3fPYZUwnGH4WhdMe/s1284/image2.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1263&quot; data-original-width=&quot;1284&quot; height=&quot;394&quot; src=&quot;https ://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgacP_kIzsIz7Aqz_3hnuQsYMxeZ95DXI7ezmYnTvYOM3LXBNYR7mUJApgtw7BDLS1sSEAbjoc760T-D7gaZ8SAeo9qK40AUHkdpfiUJIItvdhagT2B-InWhoFomzhddu6ueT7gyDQcIIzrGGcZXmNjxfFo42VxQpmqkkgGS8dOh7NE3fPYZUwnGH4WhdMe/w400-h394/image2.png&quot; width=&quot;400&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;A list of example answers is provided when the learner receives feedback and when they tap the help button.&lt;/td>;&lt;/tr>;&lt; /tbody>;&lt;/table>; &lt;p>; Since learners have different levels of ability, the language complexity of the content has to be adjusted appropriately. Prior work on language complexity estimation focuses on text of &lt;a href=&quot;https://cris.fbk.eu/handle/11582/329866&quot;>;paragraph length&lt;/a>; or &lt;a href=&quot;https://amontgomerie.github.io/2021/03/14/cefr-level-prediction.html&quot;>;longer&lt;/a>;, which differs significantly from the type of responses that our system processes. Thus, we developed novel models that can estimate the complexity of a single sentence, phrase, or even individual words. This is challenging because even a phrase composed of simple words can be hard for a language learner (eg, &quot;Let&#39;s cut to the chaseâ€). Our best model is based on &lt;a href=&quot;https://blog.research.google /2018/11/open-sourcing-bert-state-of-art-pre.html&quot;>;BERT&lt;/a>; and achieves complexity predictions closest to human expert consensus. The model was pre-trained using a large set of LLM- labeled examples, and then fine-tuned using a human expertâ€“labeled dataset. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin -å·¦ï¼šè‡ªåŠ¨ï¼› margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiW2ZhobYkx2Zfqj4BtN-5UkvVEeLlXLTkLxDAjF_fbdBNmT48F4O0MGm6u70837x4cqNlO2uNBdd4yLVFKzFgi9ox0_F27J3eHyuZUyeFKUc2mNcuiI51-iHJIKObdFGlDkZ2QnGQV4IwYIDCgvRYpXOT_4bbRaRItkFtypYSTeAv90v2R4fjUl059Bgqf/s1134/image6.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;546&quot; data-original-width=&quot;1134&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiW2ZhobYkx2Zfqj4BtN-5UkvVEeLlXLTkLxDAjF_fbdBNmT48F4O0MGm6u70837x4cqNlO2uNBdd4yLVFKzFgi9ox0_F27J3eHyuZUyeFKUc2mNcuiI51-iHJIKObdFGlDkZ2QnGQV4IwYIDCgvRYpXOT_4bbRaRItkFtypYSTeAv90v2R4fjUl059Bgqf/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;>;Mean squared error&lt;/a>; of various approaches&#39; performance estimating content difficulty on a diverse corpus of ~450 conversational passages (text / transcriptions). &lt;b>;Top row:&lt;/b>; Human raters labeled the items on a scale from 0.0 to 5.0, roughly aligned to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages&quot;>;CEFR scale&lt;/a>; (from A1 to C2). &lt;b>;Bottom four rows&lt;/b>;: Different models performed the same task, and we show the difference to the human expert consensus.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Using this model, we can evaluate the difficulty of text items, offer a diverse range of suggestions, and most importantly challenge learners appropriately for their ability levels. For example, using our model to label examples, we can fine-tune our system to generate speaking prompts at various language complexity levels. &lt;/p>; &lt;br>; &lt;table>; &lt;tbody>;&lt;tr>; &lt;td>; &lt;/td>; &lt;td style=&quot;text-align: center&quot; colspan=&quot;6&quot;>;Vocabulary focus words, to be elicited by the questions &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;guitar &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;apple &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;lion &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;Simple &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;What do you like to play?&lt;/em>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;Do you like fruit?&lt;/em>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;Do you like big cats?&lt;/em>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left ;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center ;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;Intermediate &lt;/td>; &lt;td>;&amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;Do you play any musical instruments?&lt;/em>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;What is your favorite fruit?&lt;/em>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;What is your favorite animal?&lt;/em>; &lt;/td>; &lt;/tr>; &lt;tr>; &lt;td style=&quot;text-align: left ;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center ;height:15px&quot;>;&lt;/td>; &lt;td style=&quot;text-align: center;height:15px&quot;>;&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;Complex &lt;/td>; &lt;td>;&amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;What stringed instrument do you enjoy playing?&lt;/em>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;Which type of fruit do you enjoy eating for its crunchy texture and sweet flavor?&lt;/em>; &lt;/td>; &lt;td>;&amp;nbsp;&amp;nbsp; &amp;nbsp; &lt;/td>; &lt;td style=&quot;text-align: center&quot;>;&lt;em>;Do you enjoy watching large, powerful predators?&lt;/em>; &lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;br>; &lt;p>; Furthermore, content difficulty estimation is used to gradually increase the task difficulty over time, adapting to the learner&#39;s progress. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; With these latest updates, which will roll out over the next few days, Google Search has become even more helpful. If you are an Android user in India (Hindi), Indonesia, Argentina, Colombia, Mexico, or Venezuela, give it a try by translating &lt;em>;to&lt;/em>; or &lt;em>;from&lt;/em>; English with Google. &lt;/p>; &lt;p>; We look forward to expanding to more countries and languages in the future, and to start offering partner practice content soon. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;Many people were involved in the development of this project ã€‚ Among many others, we thank our external advisers in the language learning field: Jeffrey Davitz, Judit Kormos, Deborah Healey, Anita Bowles, Susan Gaer, Andrea Revesz, Bradley Opatz, and Anne Mcquade.&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/3886518375378801095/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking-practice.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/3886518375378801095&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/3886518375378801095&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking-practice.html&quot; rel=&quot;alternate&quot; title=&quot;English learners can now practice speaking on Search&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfHhrdHOFN2-ZoUw8hxN1Gdmd5WBtL5kVUe27TeajsI3nrES8Ah13W7MIKpZ2avrsxFTdkzk-sD1noswtk20cMyPS8GjDnVMPquyxc6EhR9r53bMzncRYlj5ZBM3jMF15ndusFp2fe9ipy4bksiTLfWJ1umdcUrQUxg78SOtXfjqMbSxW_OQsSTAVZ9HV6/s72-c/Tivoli.gif&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-2371558111773883902&lt;/id>;&lt;published>;2023-10-18T14:05:00.000-07:00&lt;/published>;&lt;updated>;2023-10-18T14:05:40.676-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Quantum AI&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Quantum Computing&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Measurement-induced entanglement phase transitions in a quantum circuit&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Jesse Hoke, Student Researcher, and Pedram Roushan, Senior Research Scientist, Quantum AI Team&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjD0d2Z3JPDRdCIvFvlT3VvnLnv7sx7HndEKEnek1t_g84zs__aAh3c2TAG5hPEPYjtjJM8hikDRiSHREYGrW_TrSbHeWVC6eCq6lN2nv4ZVqmtAEg2lTyK1G26q1T-Vo9TUL9YCxVD1tG_Q8hiWBU_cbvIUo_NWrs12hPFTvbJvML4x-OU_RBzidMcwAc_/s1100/order_param_blog_1200.jpg&quot; style=&quot;display: none;&quot; />; &lt;p>; Quantum mechanics allows many phenomena that are classically impossible: a quantum particle can exist in a superposition of two states simultaneously or be entangled with another particle, such that anything you do to one seems to instantaneously also affect the other, regardless of the space between them. But perhaps no aspect of quantum theory is as striking as the act of measurement. In classical mechanics, a measurement need not affect the system being studied. But a measurement on a quantum system can profoundly influence its behavior. For example, when a quantum bit of information, called a qubit, that is in a superposition of both â€œ0â€ and â€œ1â€ is measured, its state will suddenly collapse to one of the two classically allowed states: it will be either â€œ0â€ or â€œ1,â€ but not both. This transition from the quantum to classical worlds seems to be facilitated by the act of measurement. How exactly it occurs is one of the fundamental unanswered questions in physics. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; In a large system comprising many qubits, the effect of measurements can cause new phases of quantum information to emerge. Similar to how changing parameters such as temperature and pressure can cause a phase transition in water from liquid to solid, tuning the strength of measurements can induce a phase transition in the entanglement of qubits. &lt;/p>; &lt;p>; Today in â€œ&lt;a href=&quot;https://www.nature.com/articles/s41586-023-06505-7&quot;>;Measurement-induced entanglement and teleportation on a noisy quantum processor&lt;/a>;â€, published in &lt;em>;&lt;a href=&quot;https://www.nature.com/&quot;>;Nature&lt;/a>;&lt;/em>;, we describe experimental observations of measurement-induced effects in a system of 70 qubits on our &lt;a href=&quot;https://quantumai.google/hardware&quot;>;Sycamore quantum processor&lt;/a>;. This is, by far, the largest system in which such a phase transition has been observed. Additionally, we detected &quot;quantum teleportation&quot; â€” when a quantum state is transferred from one set of qubits to another, detectable even if the details of that state are unknown â€” which emerged from measurements of a random circuit. We achieved this breakthrough by implementing a few clever â€œtricksâ€ to more readily see the signatures of measurement-induced effects in the system. &lt;/p>; &lt;br />; &lt;h2>;Background: Measurement-induced entanglement&lt;/h2>; &lt;p>; Consider a system of qubits that start out independent and unentangled with one another. If they interact with one another , they will become entangled. You can imagine this as a web, where the strands represent the entanglement between qubits. As time progresses, this web grows larger and more intricate, connecting increasingly disparate points together. &lt;/p>; &lt;p>; A full measurement of the system completely destroys this web, since every entangled superposition of qubits collapses when it&#39;s measured. But what happens when we make a measurement on only a few of the qubits? Or if we wait a long time between measurements? During the intervening time, entanglement continues to grow. The web&#39;s strands may not extend as vastly as before, but there are still patterns in the web. &lt;/p>; &lt;p>; There is a balancing point between the strength of interactions and measurements, which compete to affect the intricacy of the web. When interactions are strong and measurements are weak, entanglement remains robust and the web&#39;s strands extend farther, but when measurements begin to dominate, the entanglement web is destroyed. We call the crossover between these two extremes the &lt;em>;measurement-induced phase transition&lt;/em>;. &lt;/p>; &lt;p>; In our quantum processor, we observe this measurement-induced phase transition by varying the relative strengths between interactions and measurement. We induce interactions by performing entangling operations on pairs of qubits. But to actually see this web of entanglement in an experiment is notoriously challenging. First, we can never actually look at the strands connecting the qubits â€” we can only infer their existence by seeing statistical correlations between the measurement outcomes of the qubits. So, we need to repeat the same experiment many times to infer the pattern of the web. But there&#39;s another complication: the web pattern is different for each possible measurement outcome. Simply averaging all of the experiments together without regard for their measurement outcomes would wash out the webs&#39; patterns. To address this, some previous experiments used â€œpost-selection,â€ where only data with a particular measurement outcome is used and the rest is thrown away. This, however, causes an exponentially decaying bottleneck in the amount of â€œusableâ€ data you can acquire. In addition, there are also practical challenges related to the difficulty of mid-circuit measurements with superconducting qubits and the presence of noise in the system. &lt;/p>; &lt;br />; &lt;h2>;How we did it&lt;/h2>; &lt;p>; To address these challenges, we introduced three novel tricks to the experiment that enabled us to observe measurement-induced dynamics in a system of up to 70 qubits. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Trick 1: Space and time are interchangeable&lt;/h3>; &lt;p>; As counterintuitive as it may seem, interchanging the roles of space and time dramatically reduces the technical challenges of the experiment. Before this â€œspace-time dualityâ€ transformation, we would have had to interleave measurements with other entangling operations, frequently checking the state of selected qubits. Instead, after the transformation, we can postpone all measurements until after all other operations, which greatly simplifies the experiment. As implemented here, this transformation turns the original 1-spatial-dimensional circuit we were interested in studying into a 2-dimensional one. Additionally, since all measurements are now at the end of the circuit, the relative strength of measurements and entangling interactions is tuned by varying the number of entangling operations performed in the circuit. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjo5-hDtmBK9Odeg2d1KpiDe_fyn3e1yK0hAcYacblUt-B9-bWo9GrGUWTAdeC9jMsURYwDADlYlRm2RB9YpT6pHtaMqahpwZGMqVVuREn_J9Fi88FKFg-oiZzsW8W14HntQjXrSktkRZ3gXDyTcRUFJ_cYsk6VTrwETric5XpDK7QNhl_UGxZzc7KbmO9P/s4346/fig1_blog_1200 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;2555&quot; data-original-width=&quot;4346&quot; height=&quot;376&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjo5-hDtmBK9Odeg2d1KpiDe_fyn3e1yK0hAcYacblUt-B9-bWo9GrGUWTAdeC9jMsURYwDADlYlRm2RB9YpT6pHtaMqahpwZGMqVVuREn_J9Fi88FKFg-oiZzsW8W14HntQjXrSktkRZ3gXDyTcRUFJ_cYsk6VTrwETric5XpDK7QNhl_UGxZzc7KbmO9P/w640-h376/fig1_blog_1200.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/ td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Exchanging space and time. To avoid the complication of interleaving measurements into our experiment (shown as gauges in the&amp;nbsp;&lt;strong>;left&lt;/strong>;&amp;nbsp;panel), we utilize a space-time duality mapping to exchange the roles of space and time. This mapping transforms the 1D circuit (&lt;strong>;left&lt;/strong>;) into a 2D circuit (&lt;strong>;right&lt;/strong>;), where the circuit depth (T) now tunes the effective measurement rate.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Trick 2: Overcoming the post-selection bottleneck&lt;/h3>; &lt;p>; Since each combination of measurement outcomes on all of the qubits results in a unique web pattern of entanglement, researchers often use post-selection to examine the details of a particular web. However, because this method is very inefficient, we developed a new â€œdecodingâ€ protocol that compares each instance of the real â€œwebâ€ of entanglement to the same instance in a classical simulation. This avoids post-selection and is sensitive to features that are common to all of the webs. This common feature manifests itself into a combined classicalâ€“quantum â€œorder parameterâ€, akin to the &lt;a href=&quot;https://quantumai.google/cirq/noise/qcvv/xeb_theory#:~:text=Cross%20entropy%20benchmarking%20uses%20the,performance%20of%20a%20large%20device.&quot;>;cross-entropy benchmark&lt;/a>; used in the random circuit sampling used in our &lt;a href=&quot;https://blog.research.google/2019/10/quantum-supremacy-using-programmable.html&quot;>;beyond-classical demonstration&lt;/a>;. &lt;/p>; &lt;p>; This order parameter is calculated by selecting one of the qubits in the system as the â€œprobeâ€ qubit, measuring it, and then using the measurement record of the nearby qubits to classically â€œdecodeâ€ what the state of the probe qubit should be. By cross-correlating the measured state of the probe with this â€œdecodedâ€ prediction, we can obtain the entanglement between the probe qubit and the rest of the (unmeasured) qubits. This serves as an order parameter, which is a proxy for determining the entanglement characteristics of the entire web. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIbaxw2gTCg4rZzWx3HpDcwwVtlqe6ES7EzW5VKPhyQECZK2aVgUa0TcFI8s7Ovn41ZDobntlrRVJ3J84cAu_fQRUx4vCqZD7VDQegfA_P9LBQR6Yl64g-0Cp8pur0E4858K-Vl2UKwFZ5rar4NVHDBTL7R2Nkxy-xsAOxmI_1gBrE8FQRRvjYlkdLO9U3/s2320/order_param_blog_1200.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1760&quot; data-original-width=&quot;2320&quot; height=&quot;486&quot; src= &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIbaxw2gTCg4rZzWx3HpDcwwVtlqe6ES7EzW5VKPhyQECZK2aVgUa0TcFI8s7Ovn41ZDobntlrRVJ3J84cAu_fQRUx4vCqZD7VDQegfA_P9LBQR6Yl64g-0Cp8pur0E4858K-Vl2UKwFZ5rar4NVHDBTL7R2Nkxy-xsAOxmI_1gBrE8FQRRvjYlkdLO9U3/w640-h486/order_param_blog_1200.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;In the decoding procedure we choose a â€œprobeâ€ qubit ( pink) and classically compute its expected value, conditional on the measurement record of the surrounding qubits (yellow). The order parameter is then calculated by the cross correlation between the measured probe bit and the classically computed value.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h3>;Trick 3: Using noise to our advantage&lt;/h3>; &lt;p>; A key feature of the so-called â€œdisentangling phaseâ€ â€” where measurements dominate and entanglement is less widespread â€” is its insensitivity to noise. We can therefore look at how the probe qubit is affected by noise in the system and use that to differentiate between the two phases. In the disentangling phase, the probe will be sensitive only to local noise that occurs within a particular area near the probe. On the other hand, in the entangling phase, any noise in the system can affect the probe qubit. In this way, we are turning something that is normally seen as a nuisance in experiments into a unique probe of the system. &lt;/p>; &lt;br />; &lt;h2>;What we saw&lt;/h2>; &lt;p>; We first studied how the order parameter was affected by noise in each of the two phases. Since each of the qubits is noisy, adding more qubits to the system adds more noise. Remarkably, we indeed found that in the disentangling phase the order parameter is unaffected by adding more qubits to the system. This is because, in this phase, the strands of the web are very short, so the probe qubit is only sensitive to the noise of its nearest qubits. In contrast, we found that in the entangling phase, where the strands of the entanglement web stretch longer, the order parameter is very sensitive to the size of the system, or equivalently, the amount of noise in the system. The transition between these two sharply contrasting behaviors indicates a transition in the entanglement character of the system as the â€œstrengthâ€ of measurement is increased. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi7Z96NKSvSsw83CeFO_C3NDha5dk069lVQQIhY0w9KLzNk-uGpuy2x4B3dWTdd5WK_gu31FP4uSOPHvZT0HbKJWC3K_-YfMKUpEzFZPKdEPJLgfAkDkSgB3d5kSn5Xnevus-0lvvH6s19Zt4ix5H-qjdMixurIH7uew-9rmsXV6ke39BQS8BpgHPhp9eP-/ s2934/noise_1200.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1840&quot; data-original-width=&quot;2934&quot; height= &quot;401&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi7Z96NKSvSsw83CeFO_C3NDha5dk069lVQQIhY0w9KLzNk-uGpuy2x4B3dWTdd5WK_gu31FP4uSOPHvZT0HbKJWC3K_-YfMKUpEzFZPKdEPJLgfAkDkSgB3d5kSn5Xnevus-0lvvH6s19Zt4ix5H-qjdMixurIH7uew-9rmsXV6ke39BQS8BpgHPhp9eP-/w640-h401/noise_1200.png&quot; width=&quot;640&quot; />; &lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Order parameter vs. gate density (number of entangling operations) for different numbers of qubits. When the number of entangling operations is low, measurements play a larger role in limiting the entanglement across the system. When the number of entangling operations is high, entanglement is widespread, which results in the dependence of the order parameter on system size (inset).&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; In our experiment, we also demonstrated a novel form of quantum teleportation that arises in the entangling phase. Typically, a specific set of operations are necessary to implement quantum teleportation, but here, the teleportation emerges from the randomness of the non-unitary dynamics. When all qubits, except the probe and another system of far away qubits, are measured, the remaining two systems are strongly entangled with each other. Without measurement, these two systems of qubits would be too far away from each other to know about the existence of each other. With measurements, however, entanglement can be generated faster than the limits typically imposed by locality and causality. This â€œmeasurement-induced entanglementâ€ between the qubits (that must also be aided with a classical communications channel) is what allows for quantum teleportation to occur. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgj7SwfWiDaUv0pwEPs9frmRcXUnOVzLTQTfR4CkxZeBFCJITsGB5Bm66mF978UAa_b73UGBKFara6m_LjhVOCfOtxpG17sPBp94_nVrNT2OuNKLBLU0Ntl11WEatAI2aJ2U34gkAKoMfQwxpxPcDxGIXnF8Sy9DeX0rZ9AsikPyI7KXeBWF9515HajWJnX/s2969/teleport_1200.png&quot; style=&quot;margin- left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1754&quot; data-original-width=&quot;2969&quot; height=&quot;378&quot; src=&quot;https://blogger .googleusercontent.com/img/b/R29vZ2xl/AVvXsEgj7SwfWiDaUv0pwEPs9frmRcXUnOVzLTQTfR4CkxZeBFCJITsGB5Bm66mF978UAa_b73UGBKFara6m_LjhVOCfOtxpG17sPBp94_nVrNT2OuNKLBLU0Ntl11WEatAI2aJ2U34gkAKoMfQwxpxPcDxGIXnF8Sy9DeX0rZ9AsikPyI7KXeBWF9515HajWJnX/w640-h378/teleport_1200.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;&lt;em style=&quot;text-align: left;&quot;>;Proxy entropy vs. gate density for two far separated subsystems (pink and black qubits) when all other qubits are measured. There is a finite-size crossing at ~0.9. Above this gate density, the probe qubit is entangled with qubits on the opposite side of the system and is a signature of the teleporting phase.&lt;/em>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;br />; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; Our experiments demonstrate the effect of measurements on a quantum circuit. We show that by tuning the strength of measurements, we can induce transitions to new phases of quantum entanglement within the system and even generate an emergent form of quantum teleportation. This work could potentially have relevance to quantum computing schemes, where entanglement and measurements both play a role. &lt;/p>; &lt;br />; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;This work was done while Jesse Hoke was interning at Google from Stanford University. We would like to thank Katie McCormick, our Quantum Science Communicator, for helping to write this blog post.&lt;/em>; &lt;/p>;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/2371558111773883902/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/measurement-induced-entanglement-phase.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/2371558111773883902&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/2371558111773883902&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/measurement-induced-entanglement-phase.html&quot; rel=&quot;alternate&quot; title=&quot;Measurement-induced entanglement phase transitions in a quantum circuit&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjD0d2Z3JPDRdCIvFvlT3VvnLnv7sx7HndEKEnek1t_g84zs__aAh3c2TAG5hPEPYjtjJM8hikDRiSHREYGrW_TrSbHeWVC6eCq6lN2nv4ZVqmtAEg2lTyK1G26q1T-Vo9TUL9YCxVD1tG_Q8hiWBU_cbvIUo_NWrs12hPFTvbJvML4x-OU_RBzidMcwAc_/s72-c/order_param_blog_1200.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-524891095627230116&lt;/id>;&lt;published>;2023-10-16T10:12:00.000-07:00&lt;/published>;&lt;updated>;2023-10-16T10:12:58.579-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;AI for Social Good&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Collaboration&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Research&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Improving traffic evacuations: A case study&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Damien Pierce, Software Engineer, and John Anderson, Senior Research Director, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiq0gQYBrF4sBptEnwyqdXMyAuYpCBTZJf7JBevRgt8ZuEtflAdzaNbenGSfItI98BCpXDMpUkO3nEJyDs4XTVaCmpGrqBsLGL1E11V6-QbB629_OL_IrMhX1AfJRZIbL_O9AufL5o-kbESrDz6y_zJbP7Kj6MTn_RLQ8B7hOSlbKguvdd6jjthWNRTPZYl/s1700/trafficevac.png&quot; style=&quot;display: none;&quot; />; &lt;p>; Some cities or communities develop an evacuation plan to be used in case of an emergency. There are a number of reasons why city officials might enact their plan, a primary one being a natural disaster, such as a tornado, flood, or wildfire. An evacuation plan can help the community more effectively respond to an emergency, and so could help save lives. However, it can be difficult for a city to evaluate such a plan because it is not practical to have an entire town or city rehearse a full blown evacuation. For example, Mill Valley, a city in northern California, created a wildfire evacuation plan but lacked an estimate for how long the evacuation would take. &lt;/p>;&lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; Today we describe a case study in which we teamed up with the city of Mill Valley to test and improve their evacuation plan. We outline our approach in our paper, â€œ&lt;a href=&quot;https://arxiv.org/abs/2307.07108&quot;>;Mill Valley Evacuation Study&lt;/a>;â€. We started by using a traffic simulator to model a citywide evacuation. The research goal was to provide the city with detailed estimates for how long it would take to evacuate the city, and, by studying the egress pattern, to find modifications to make the plan more effective. While our &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S2590198220301214&quot;>;prior work&lt;/a>; on this subject provided an estimate for the evacuation time and showed how the time could be reduced if certain road changes were implemented, it turns out the recommendations in that paper â€” such as changing the number of outgoing lanes on an arterial â€” were not feasible. The current round of research improves upon the initial study by more accurately modeling the number and starting locations of vehicles, by using a more realistic map, and by working closely with city officials to ensure that recommended changes to the plan are deemed viable. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>;&lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Geography and methodology&lt;/h2>; &lt;p>; Mill Valley is in Marin County, California, north of San Francisco. Many of the residences are located on the steep hillsides of several valleys surrounded by dense redwood forests. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-rEeqPv7eEzcaCjLSS_ch9Nzuwe6cVoFjxFVDO2b-SSyRGrBZv7qybrvcSVyIsiDCTsi6ZthJRz2fESC1eHmSmrEo7aGReWESSakOtYqLfiz0usyE40XQA0Jn_RXXKHrIyWDNvIfQoBeWuT-QDacbz0kx0Wr8jKo9TryGf2drFfPdbSWW8VxRuF0eGD9h/s1999/image3.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1125&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-rEeqPv7eEzcaCjLSS_ch9Nzuwe6cVoFjxFVDO2b-SSyRGrBZv7qybrvcSVyIsiDCTsi6ZthJRz2fESC1eHmSmrEo7aGReWESSakOtYqLfiz0usyE40XQA0Jn_RXXKHrIyWDNvIfQoBeWuT-QDacbz0kx0Wr8jKo9TryGf2drFfPdbSWW8VxRuF0eGD9h/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style =&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjm-LcwnvHIYfP0WbN0YrA_LsgYRbOrXsP6_wkjU_y0b5NQROw2uPHr9VrJw3uCXzdm5DIDRgHIcdi2VjICkX3_mIYHN7WF1eyf3CjWxD1NJHh6DBaafwaYarEE-NlcqkaCemu2yghi7rUHtjWa6jrLCDKO97rWKtjsBvnVWeQENvU0sx7ne0xQI7M_el-H/s1999/image8.png&quot; style=&quot;margin-å·¦ï¼šè‡ªåŠ¨ï¼› margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1125&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjm-LcwnvHIYfP0WbN0YrA_LsgYRbOrXsP6_wkjU_y0b5NQROw2uPHr9VrJw3uCXzdm5DIDRgHIcdi2VjICkX3_mIYHN7WF1eyf3CjWxD1NJHh6DBaafwaYarEE-NlcqkaCemu2yghi7rUHtjWa6jrLCDKO97rWKtjsBvnVWeQENvU0sx7ne0xQI7M_el-H/s16000/image8.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Aerial views of Mill Valley, courtesy of the City of Mill Valley. &lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Many of those residences are in areas that have only one exit direction, toward the town center. From there the best evacuation route is toward Highway 101, which is in the flat part of the city and is the most likely area to be far from potential wildfires. Some neighborhoods have other routes that lead away from both the city and Highway 101, but those routes pass through hilly forested areas, which could be dangerous or impassable during a wildfire. So, the evacuation plan directs all vehicles west of Highway 101 to head east, to the highway (see map below). The neighborhoods east of Highway 101 are not included in the simulation because they are away from areas with a high fire hazard rating, and are close to the highway. &lt;/p>; &lt;p>; Mill Valley has about 11,400 households west of Highway 101. Most Mill Valley households have two vehicles. Evacuation times scale with the number of vehicles, so it is in the common interest to minimize the number of vehicles used during an evacuation. To that end, Mill Valley has a public awareness campaign aimed at having each household evacuate in one vehicle. While no one knows how many vehicles would be used during an evacuation, it is safe to assume it is on average between one and two per household. The basic evacuation problem, then, is how to efficiently get between 11 and 23 thousand vehicles from the various residences onto one of the three sets of Highway 101 on-ramps. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwsFEZpO2_VYt-i0FHVg3C4Jn_PMQMKMl37lNWYQTXEskYSyy4KTpVmTne00MASABWnes1eLqE0XN16dG0WN9WrvKSVL_4dbB9e5NZchWh9VOVLhzxUjfCEJ1kuAlCM5FVXLy8ydwI-SqhC40_VkOBj1rqTRBgjPdFEM6JRZqSPcwE5apKPQL-x7qdWf9u/s549/image3.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;549&quot; data-original-width=&quot;536&quot; height=&quot;640&quot; src= &quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwsFEZpO2_VYt-i0FHVg3C4Jn_PMQMKMl37lNWYQTXEskYSyy4KTpVmTne00MASABWnes1eLqE0XN16dG0WN9WrvKSVL_4dbB9e5NZchWh9VOVLhzxUjfCEJ1kuAlCM5FVXLy8ydwI-SqhC40_VkOBj1rqTRBgjPdFEM6JRZqSPcwE5apKPQL-x7qdWf9u/w624-h640/image3.png&quot; width=&quot;624&quot; />;&lt;/a>;&lt;/td>;&lt;/ tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;The simulated part of Mill Valley west of Highway 101 is inside the blue border. Highway 101 is shown in green. The red squares indicate the three sets of Highway 101 on-ramps. The pink area has the highest fire hazard rating.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; The current work uses the same general methodology as the previous research, namely, running the &lt;a href=&quot;https://en.wikipedia.org/wiki/Simulation_of_Urban_MObility&quot;>;open source SUMO agent-based traffic simulator&lt;/a>; on a map of Mill Valley. The traffic simulator models traffic by simulating each vehicle individually. The detailed behaviors of vehicles are dictated by a &lt;a href=&quot;https://sumo.dlr.de/docs/Car-Following-Models.html&quot;>;car-following model&lt;/a>;. Each vehicle is given a point and time at which to start and an initial route. The routes of most vehicles are updated throughout the simulation, depending on conditions. To consider potential changes in driver behavior under the high stress conditions of an evacuation, the effects of the â€œaggressivenessâ€ of each car is also investigated, but in our case the impacts are minimal. Some simplifying assumptions are that vehicles originate at residential addresses and the roads and highways are initially empty. These assumptions correspond approximately to conditions that could be encountered if an evacuation happens in the middle of the night. The main inputs in the simulation are the road network, the household locations, the average number of vehicles per household, and a departure temporal distribution. We have to make assumptions about the departure distribution. After discussing with the city officials, we chose a distribution such that most vehicles depart within an hour. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Four bottlenecks&lt;/h2>; &lt;p>; Mill Valley has three sets of Highway 101 on-ramps: northern, middle, and southern. All the vehicles must use one of these sets of on-ramps to reach their destination (either the northernmost or southernmost segment of Highway 101 included in our map). Given that we are only concerned with the majority of Mill Valley that lies west of the highway, there are two lanes that approach the northern on-ramps, and one lane that approaches each of the middle and southern on-ramps. Since every vehicle has to pass over one of these four lanes to reach the highway, they are the bottlenecks. Given the geography and existing infrastructure, adding more lanes is infeasible. The aim of this research, then, is to try to modify traffic patterns to maximize the rate of traffic on each of the four lanes. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Evacuation plan&lt;/h2>; &lt;p>; When we started this research, Mill Valley had a preliminary evacuationè®¡åˆ’ã€‚ It included modifying traffic patterns â€” disabling traffic lights and changing traffic rules â€” on a few road segments, as well as specifying the resources (traffic officers, signage) necessary to implement the changes. As an example, a two-way road may be changed to a one-way road to double the number of outgoing lanes. Temporarily changing the direction of traffic is called &lt;em>;contraflow&lt;/em>;. &lt;/p>; &lt;p>; The plot below shows the simulated fraction of vehicles that have departed or reached their destinations versus time, for 1, 1.5, and 2 vehicles per household (left to right). The dashed line on the far left shows the fraction that have departed. The solid black lines show the preliminary evacuation plan results and the dotted lines indicate the normal road network (baseline) results. The preliminary evacuation plan significantly speeds up the evacuation. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGFqAZbQu6Nt75U1UzXpyDmD0Hei9HCOEY-AeGExQQjIp62ubwFI0LqatEBGYtzwECiHgxtFRgZfDBeaNmFhV-WDM4vo1V0W_UJTh59oJdfjC6IusT3QZZJPcr2BAirIFp5MNe_O1_uu0EzNUFIAMJH0u_K4dmesGxEKmjejv4NMAp6DLwNlfS4mUUJ6_6/s812/image2.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;425&quot; data-original-width=&quot;812&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGFqAZbQu6Nt75U1UzXpyDmD0Hei9HCOEY-AeGExQQjIp62ubwFI0LqatEBGYtzwECiHgxtFRgZfDBeaNmFhV-WDM4vo1V0W_UJTh59oJdfjC6IusT3QZZJPcr2BAirIFp5MNe_O1_uu0EzNUFIAMJH0u_K4dmesGxEKmjejv4NMAp6DLwNlfS4mUUJ6_6/s16000/image2.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;The cumulative fraction of vehicles vs. time in hours. The demand curve is shown in the dashed line on the far left. The solid lines show the preliminary evacuation plan curves for 1, 1.5 and 2 vehicles per household (left to right). The dotted lines show the same for the baseline case.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We can understand how effective the preliminary evacuation plan is by measuring the rates at the bottlenecks. The below plots show the rate of traffic on each of the four lanes leading to the highway on-ramps for the case of 1.5 vehicles per household for both the baseline case (the normal road rules; shown shaded in gray) and the preliminary evacuation plan (shown outlined in black). The average rate per lane varies greatly in the different cases. It is clear that, while the evacuation plan leads to increased evacuation rates, there is room for improvement. In particular, the middle on-ramps are quite underutilized.&lt;/p>;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>;&lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEilGFPn9SRnlDgD_btIeFw0BM2YqNp9kSivDA0OuGqrezvaDrjyrCKalxWyzlK2HGwkzKzDEJNHKBDKp9YEpvi8AyN20raA_H88JQY2YQ96Bzx4oGEk_dXcadtyhyphenhyphenx5SVJqiLpSEwIq9Vgy9aqhKX4YiIRWwCje2LsfaiEjs1jZvahUsv-xuJV3oQyCWmFD/s1999/image1.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1500&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEilGFPn9SRnlDgD_btIeFw0BM2YqNp9kSivDA0OuGqrezvaDrjyrCKalxWyzlK2HGwkzKzDEJNHKBDKp9YEpvi8AyN20raA_H88JQY2YQ96Bzx4oGEk_dXcadtyhyphenhyphenx5SVJqiLpSEwIq9Vgy9aqhKX4YiIRWwCje2LsfaiEjs1jZvahUsv-xuJV3oQyCWmFD/s16000/image1.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;The rates of traffic on the four lanes leading to Highway 101 on-ramps for both the baseline case (normal road rules; shown shaded in gray) and the preliminary evacuation plan (shown outlined in black).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Final evacuation plan&lt;/h2>; &lt;p>; After studying the map and investigating different alternatives, we, working together with city officials, found a minimal set of new road changes that substantially lower the evacuation time compared to the preliminary evacuation plan (shown below). We call this the final evacuation plan. It extends the contraflow section of the preliminary plan 1000 feet further west, to a main intersection. Crucially, this allows for one of the (normally) two outgoing lanes to be dedicated to routing traffic to the middle on-ramps. It also creates two outgoing lanes from that main intersection clear through to the northern on-ramps, over Â¾ of a mile to the east. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVZzJcpphq9-XvpGma97D-9IPEsZ-7A_k_j9809MEEwtuI5te14hozh7VAe1i9xH8iOv8TMwErCBoK_Rxfux3GURoOqDMhNFW5VoEMl5bAII5gkoWrjFfdWlSvMhxl2hdbYb00JDAZTA-yiFsXo7Sm057QEia81G-otuKy1lZF04u_PFWY_hroXxTmtDka/s1510 /image5.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;705&quot; data-original-width=&quot;1510&quot; src=&quot; https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVZzJcpphq9-XvpGma97D-9IPEsZ-7A_k_j9809MEEwtuI5te14hozh7VAe1i9xH8iOv8TMwErCBoK_Rxfux3GURoOqDMhNFW5VoEMl5bAII5gkoWrjFfdWlSvMhxl2hdbYb00JDAZTA-yiFsXo7Sm057QEia81G-otuKy1lZF04u_PFWY_hroXxTmtDka/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr >;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;A map of the main changes in the final evacuation plan. The red line shows that traffic heading north on Camino Alto gets diverted to the middle Highway 101 on-ramps. The blue line shows traffic in the northern lane of E Blithedale Ave gets routed on the new contraflow section.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; The rate per lane plots comparing the preliminary and final evacuation plans are shown below for 1.5 vehicles per household. The simulation indicates that the final plan increases the average rate of traffic on the lane leading to the middle on-ramps from about 4 vehicles per minute to about 18. It also increases the through rate of the northern on-ramps by over 60%. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEip473wwGuslqnXu9FY1DsHgVfUbRC-9Unt1yONvUPBfQ0ekAdYVOZYFLWPjS4qtilW61kQJNBa_MKWYju4CJKabqrxu21KIQGGT0rxhOFNQrFIi46PY08lBiZNMRNnpwWozNGKbjynNdUDO5YdlxWocijTh4cvBkgh_jmsYE9PgFAWFDTbem_JLuzVrDqY/s1999/image3.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;1504&quot; data-original-width=&quot;1999&quot; src=&quot;https://blogger.googleusercontent. com/img/b/R29vZ2xl/AVvXsEip473wwGuslqnXu9FY1DsHgVfUbRC-9Unt1yONvUPBfQ0ekAdYVOZYFLWPjS4qtilW61kQJNBa_MKWYju4CJKabqrxu21KIQGGT0rxhOFNQrFIi46PY08lBiZNMRNnpwWozNGKbjynNdUDO5YdlxWocijTh4cvBkgh_jmsYE9PgFAWFDTbem_JLuzVrDqY/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align : center;&quot;>;The rates of traffic on the four lanes leading to Highway 101 on-ramps for both the preliminary case (shown shaded in gray) and the final evacuation plan (shown outlined in black).&lt;/td>;&lt;/tr >;&lt;/tbody>;&lt;/table>; &lt;p>; The below plot shows the cumulative fraction of vehicles vs. time, comparing the cases of 1, 1.5 and 2 vehicles per household for the preliminary and final evacuation plans. The speedup is quite significant, on the scale of hours. For example, with 1.5 vehicles per household, it took 5.3 hours to evacuate the city using the preliminary evacuation plan, and only 3.5 hours using the final plan. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhchH8NchEEmevzOxMoC4Rne0WOMAcijZqydDY5Qq_-5eehyphenhyphenSBp4A-GaRPVc_pQgl4etQydVCrX6gY6gNFkqt0Zk7QDkrDEMu630BoTxvppbHKvAL52aCEJ4Azzu2UlGSXhKHpzZ0-8tfa3HUpP36WYDLCRdJD4geCypjLDwatL8qB4Y6a_cYrxsJg-CnOz/s812/image6 .png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;425&quot; data-original-width=&quot;812&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhchH8NchEEmevzOxMoC4Rne0WOMAcijZqydDY5Qq_-5eehyphenhyphenSBp4A-GaRPVc_pQgl4etQydVCrX6gY6gNFkqt0Zk7QDkrDEMu630BoTxvppbHKvAL52aCEJ4Azzu2UlGSXhKHpzZ0-8tfa3HUpP36WYDLCRdJD4geCypjLDwatL8qB4Y6a_cYrxsJg-CnOz/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;The cumulative fraction of vehicles vs. time in hours. The demand curve is shown in the dashed line on the far left. The solid lines show the final evacuation plan curves for 1, 1.5 and 2 vehicles per household (left to right). The dotted lines show the same for the preliminary evacuation plan.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; Evacuation plans can be crucial in quickly getting many people to safety in emergency situations. While some cities have traffic evacuation plans in place, it can be difficult for officials to learn how well the plan works or whether it can be improved. Google Research helped Mill Valley test and evaluate their evacuation plan by running traffic simulations. We found that, while the preliminary plan did speed up the evacuation time, some minor changes to the plan significantly expedited evacuation. We worked closely with the city during this research, and Mill Valley has adopted the final plan. We were able to provide the city with more simulation details, including results for evacuating the city one area at a time. Full details can be found in &lt;a href=&quot;https://arxiv.org/abs/2307.07108&quot;>;the paper&lt;/a>;. &lt;/p>; &lt;p>; Detailed recommendations for a particular evacuation plan are necessarily specific to the area under study. So, the specific road network changes we found for Mill Valley are not directly applicable for other cities. However, we used only public data (road network from &lt;a href=&quot;http://openstreetmap.org&quot;>;OpenStreetMap&lt;/a>;; household information from census data) and an open source simulator (&lt;a href=&quot;https://sumo.dlr.de/docs/index.html&quot;>;SUMO&lt;/a>;), so any city or agency could use the methodology used in our paper to obtain results for their area. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;We thank former Mayor John McCauley and City of Mill Valley personnel Tom Welch, Lindsay Haynes, Danielle Staude, Rick Navarro and Alan Piombo for numerous discussions and feedback, and Carla Bromberg for program management.&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/524891095627230116/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text/html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/524891095627230116&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/524891095627230116&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html&quot; rel=&quot;alternate&quot; title=&quot;Improving traffic evacuations: A case study&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog.com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiq0gQYBrF4sBptEnwyqdXMyAuYpCBTZJf7JBevRgt8ZuEtflAdzaNbenGSfItI98BCpXDMpUkO3nEJyDs4XTVaCmpGrqBsLGL1E11V6-QbB629_OL_IrMhX1AfJRZIbL_O9AufL5o-kbESrDz6y_zJbP7Kj6MTn_RLQ8B7hOSlbKguvdd6jjthWNRTPZYl/s72-c/trafficevac.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post-1355231158088692780&lt;/id>;&lt;published>;2023-10-13T11:01:00.000-07:00&lt;/published>;&lt;updated>;2023-10-13T11:01:35.679-07:00&lt;/updated>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Deep Learning&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Machine Intelligence&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Machine Learning&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Natural Language Processing&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Batch calibration: Rethinking calibration for in-context learning and prompt engineering&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Han Zhou, Student Researcher, and Subhrajit Roy, Senior Research Scientist, Google Research&lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcUnpQACR3ZhIfLnnazC6jATK0TZkwm-zGcHW0iMGYkd5bOrHtp0UAzDZ51hkI-ZesK4PAW_zn29G7r9hnq6bsNrp54dCEoiinN7l2bkNkIZVOj18ym1WQBk4QZfB_LlJnImIms-LSh6E88bcDP6NZ3yDssRhyJGUFgt2IhZurObVP8jn3Bb4aiAnB_Ysg/s1550/Screenshot%202023-10-13%20at%2010.57.44%20AM.png&quot; style=&quot;display: none;&quot; />; &lt;p>; &lt;a href=&quot;https://blog.research.google/2022/05/language-models-perform-reasoning-via.html&quot;>;Prompting&lt;/a>; large language models (LLMs) has become an efficient learning paradigm for adapting LLMs to a new task by conditioning on human-designed instructions. The remarkable &lt;a href=&quot;https://en.wikipedia.org/wiki/Prompt_engineering&quot;>;in-context learning&lt;/a>; (ICL) ability of LLMs also leads to efficient few-shot learners that can generalize from few-shot input-label pairs. However, the predictions of LLMs are highly sensitive and even biased to the &lt;a href=&quot;https://aclanthology.org/2022.emnlp-main.759/&quot;>;choice of templates&lt;/a>;, &lt;a href=&quot;https://arxiv.org/abs/2104.08315&quot;>;label spaces&lt;/a>; (such as yes/no, true/false, correct/incorrect), and &lt;a href=&quot;https://aclanthology.org/2022.deelio-1.10/&quot;>;demonstration examples&lt;/a>;, resulting in unexpected performance degradation and barriers for pursuing robust LLM applications. To address this problem, &lt;a href=&quot;http://proceedings.mlr.press/v139/zhao21c.html&quot;>;calibration&lt;/a>; methods have been developed to mitigate the effects of these biases while recovering LLM performance. Though multiple calibration solutions have been provided (eg, &lt;a href=&quot;http://proceedings.mlr.press/v139/zhao21c.html&quot;>;contextual calibration&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/2305.19148&quot;>;domain-context calibration&lt;/a>;), the field currently lacks a unified analysis that systematically distinguishes and explains the unique characteristics, merits, and downsides of each approach. &lt;/p>;&lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; With this in mind, in â€œ&lt;a href=&quot;https://arxiv.org/abs/2309.17249&quot;>;Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering&lt;/a>;â€, we conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that mitigates the bias from a batch of inputs, unifies various prior approaches, and effectively addresses the limitations in previous methods. BC is zero-shot, self-adaptive (ie, inference-only), and incurs negligible additional costs. We validate the effectiveness of BC with &lt;a href=&quot;https://ai.google/discover/palm2/&quot;>;PaLM 2&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;CLIP&lt;/a>; models and demonstrate state-of-the-art performance over previous calibration baselines across more than 10 natural language understanding and image classification tasks. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Motivation&lt;/h2>; &lt;p>; In pursuit of practical guidelines for ICL calibration, we started with understanding the limitations of current methods. We find that the calibration problem can be framed as an unsupervised &lt;a href=&quot;https://en.wikipedia.org/wiki/Decision_boundary&quot;>;decision boundary&lt;/a>; learning problem. We observe that uncalibrated ICL can be biased towards predicting a class, which we explicitly refer to as &lt;em>;contextual bias&lt;/em>;, the &lt;em>;a priori&lt;/em>; propensity of LLMs to predict certain classes over others unfairly givenä¸Šä¸‹æ–‡ã€‚ For example, the prediction of LLMs can be biased towards predicting the most frequent label, or the label towards the end of the demonstration. We find that, while theoretically more flexible, non-linear boundaries (&lt;a href=&quot;https://openreview.net/forum?id=nUsP9lFADUF&quot;>;prototypical calibration&lt;/a>;) tend to be susceptible to overfitting and may suffer from instability for challenging multi-class tasks. Conversely, we find that linear decision boundaries can be more robust and generalizable across tasks. In addition, we find that relying on additional content-free inputs (eg, â€œN/Aâ€ or random in-domain tokens) as the grounds for estimating the contextual bias is &lt;em>;not&lt;/em>; always optimal and may even introduce additional bias, depending on the task type. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Batch calibration&lt;/h2>; &lt;p>; Inspired by the previous discussions, we designed BC to be a zero-shot, inference-only and generalizable calibration technique with negligible computation cost. We argue that the most critical component for calibration is to accurately estimate the contextual bias. We, therefore, opt for a linear decision boundary for its robustness, and instead of relying on content-free inputs, we propose to estimate the contextual bias for each class from a batch in a content-based manner by marginalizing the output score over all samples within the batch, which is equivalent to measuring the mean score for each class (visualized below). &lt;/p>; &lt;p>; We then obtain the calibrated probability by dividing the output probability over the contextual prior, which is equivalent to aligning the log-probability (LLM scores) distribution to the estimated mean of each class. It is noteworthy that because it requires no additional inputs to estimate the bias, this BC procedure is zero-shot, only involves unlabeled test samples, and incurs negligible computation costs. We may either compute the contextual bias once all test samples are seen, or alternatively, in an on-the-fly manner that dynamically processes the outputs. To do so, we may use a running estimate of the contextual bias for BC, thereby allowing BC&#39;s calibration term to be estimated from a small number of mini-batches that is subsequently stabilized when more mini-batches arrive. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDELq3xigMVCgnLqTDh51T8oHF0WW8FopRyRFJcv8TkN86buqLelyJ77y9kCQJd9Buae_jWy4aXpeMgWDuOZQoXjhgQz_-OYDOtmurpdD-0nuROOSbVxiQBGDTxuWxl-FTQbhiOKYO6DxtloMAQU6mG-VFYdcdlIZ3qN3ibZQ2RA321mhWlBB__vO3Jipc/s800/image1 .gif&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;450&quot; data-original-width=&quot;800&quot; src=&quot;https: //blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDELq3xigMVCgnLqTDh51T8oHF0WW8FopRyRFJcv8TkN86buqLelyJ77y9kCQJd9Buae_jWy4aXpeMgWDuOZQoXjhgQz_-OYDOtmurpdD-0nuROOSbVxiQBGDTxuWxl-FTQbhiOKYO6DxtloMAQU6mG-VFYdcdlIZ3qN3ibZQ2RA321mhWlBB__vO3Jipc/s16000/image1.gif&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Illustration of Batch Calibration (BC). Batches of demonstrations with in-context examples and test samples are passed into the LLM. Due to sources of implicit bias in the context, the score distribution from the LLM becomes biased. BC is a modular and adaptable layer option appended to the output of the LLM that generates calibrated scores (visualized for illustration only).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Experiment design&lt;/h2>; &lt;p>; For natural language tasks, we conduct experiments on 13 more diverse and challenging classification tasks, including the standard &lt;a href=&quot;https://arxiv.org/abs/1804.07461&quot;>;GLUE&lt;/a>; and &lt;a href=&quot;https://arxiv.org/abs/1905.00537&quot;>;SuperGLUE&lt;/a>; datasets. This is in contrast to previous works that only report on relatively simple single-sentence classification tasks.. For image classification tasks, we include &lt;a href=&quot;https://research.google/pubs/pub37648/&quot;>;SVHN&lt;/a>;, &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/8736785&quot;>;EuroSAT&lt;/a>;, and &lt;a href=&quot;https://openaccess.thecvf.com/content_cvpr_2017/html/Johnson_CLEVR_A_Diagnostic_CVPR_2017_paper.html&quot;>;CLEVR&lt;/a>;. We conduct experiments mainly on the state-of-the-art &lt;a href=&quot;https://ai.google/discover/palm2/&quot;>;PaLM 2&lt;/a>; with size variants PaLM 2-S, PaLM 2-M, and PaLM 2-L. For VLMs, we report the results on &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;>;CLIP ViT-B/16&lt;/a>;. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Results&lt;/h2>; &lt;p>; Notably, BC consistently outperforms ICL, yielding a significant performance enhancement of 8% and 6% on small and large variants of PaLM 2, respectively. This shows that the BC implementation successfully mitigates the contextual bias from the in-context examples and unleashes the full potential of LLM in efficient learning and quick adaptation to new tasks. In addition, BC improves over the state-of-the-art prototypical calibration (PC) baseline by 6% on PaLM 2-S, and surpasses the competitive contextual calibration (CC) baseline by another 3% on average on PaLM 2-L ã€‚ Specifically, BC is a generalizable and cheaper technique across all evaluated tasks, delivering stable performance improvement, whereas previous baselines exhibit varying degrees of performance across tasks. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkw7ccRrKee_tz5U8eECx6PaI2u8XxxZl_eeFz9XrpEFO7LUYofj3rgzfX-zpso66oSEPJ0V_1uhXtmeb8q4S-9zfIAcrzN-wWrmM6PbpuuJcOFwHpHC9tANyx1zlCFlOR7juacZ6zhkWU0gfAmG6NjGmLU5vj0u7NltSoWW0UQ0p9jejiu2asQGIh3fEZ/s1996/image5.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;752&quot; data-original-width=&quot;1996&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkw7ccRrKee_tz5U8eECx6PaI2u8XxxZl_eeFz9XrpEFO7LUYofj3rgzfX-zpso66oSEPJ0V_1uhXtmeb8q4S-9zfIAcrzN-wWrmM6PbpuuJcOFwHpHC9tANyx1zlCFlOR7juacZ6zhkWU0gfAmG6NjGmLU5vj0u7NltSoWW0UQ0p9jejiu2asQGIh3fEZ/s16000/image5.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;Batch Calibration (BC) achieves the best performance on 1-shot ICL over calibration baselines: &lt;a href=&quot;http://proceedings.mlr.press/v139/zhao21c. html&quot;>;contextual calibration&lt;/a>; (CC), &lt;a href=&quot;https://arxiv.org/abs/2305.19148&quot;>;domain-context calibration&lt;/a>; (DC), and &lt;a href=&quot;https ://openreview.net/forum?id=nUsP9lFADUF&quot;>;prototypical calibration&lt;/a>; (PC) on an average of 13 NLP tasks on PaLM 2 and outperforms the zero-shot CLIP on image tasks.&lt;/td>;&lt;/ tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We analyze the performance of BC by varying the number of ICL shots from 0 to 4, and BC again outperforms all baseline methods. We also observe an overall trend for improved performance when more shots are available, where BC demonstrates the best stability. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW3n6u0ou6R2VkY9rCWZ7uk271EVCGQPQnQriIUlFlxbwl-9YLvYBEiVl0of7uNmhAFEn4J8pHanLx0Zd1cU-XPLDRKWEBFGWeKaXbD1g6MlobIEybW0ScVo9BDYGsfdhGgVbrhRqa3aVZMcASoULP4MLscCy0Fbv6foCXAPOZossV6ZDZJBLwG74UXnj4/s1577/image3.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;488&quot; data-original-width=&quot;1577&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW3n6u0ou6R2VkY9rCWZ7uk271EVCGQPQnQriIUlFlxbwl-9YLvYBEiVl0of7uNmhAFEn4J8pHanLx0Zd1cU-XPLDRKWEBFGWeKaXbD1g6MlobIEybW0ScVo9BDYGsfdhGgVbrhRqa3aVZMcASoULP4MLscCy0Fbv6foCXAPOZossV6ZDZJBLwG74UXnj4/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;The ICL performance on various calibration techniques over the number of ICL shots on PaLM 2-S. We compare BC with the uncalibrated ICL, &lt;a href=&quot;http://proceedings.mlr.press/v139/zhao21c.html&quot;>;contextual calibration&lt;/a>; (CC), &lt;a href=&quot;https://arxiv.org/abs/2305.19148&quot;>;domain-context calibration&lt;/a>; (DC), and &lt;a href=&quot;https://openreview.net/forum?id=nUsP9lFADUF&quot;>;prototypical calibration&lt;/a>; (PC) baselines.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; We further visualize the decision boundaries of uncalibrated ICL after applying existing calibration methods and the proposed BC. We show success and failure cases for each baseline method, whereas BC is consistently effective. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwrdaLhETWK3H1Z6PE3b78M3s9mvpi0KJF55WimbcaRoBPxfCL06FKaeqv0p5zjAvwgxPHpIHOP5FlKh2nYSYNjaraaD7h6eUDD5_8iJb-LUks62D8sX6zpXg8B66QK0sHUr3owOkvqdYkyohJZDIkbmHFIbprIPksb_sR-eQaZKE2Q1nyB0ZFkkfg7rEm/s1578/image6.png&quot; style =&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;836&quot; data-original-width=&quot;1578&quot; src=&quot;https://blogger. googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwrdaLhETWK3H1Z6PE3b78M3s9mvpi0KJF55WimbcaRoBPxfCL06FKaeqv0p5zjAvwgxPHpIHOP5FlKh2nYSYNjaraaD7h6eUDD5_8iJb-LUks62D8sX6zpXg8B66QK0sHUr3owOkvqdYkyohJZDIkbmHFIbprIPksb_sR-eQaZKE2Q1nyB0ZFkkfg7rEm/s16000/image6.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style= &quot;text-align: center;&quot;>;Visualization of the decision boundaries of uncalibrated ICL, and after applying existing calibration methods and the proposed BC in representative binary classification tasks of &lt;a href=&quot;https://aclanthology.org/D13-1170 /&quot;>;SST-2&lt;/a>; (&lt;strong>;top row&lt;/strong>;) and &lt;a href=&quot;https://arxiv.org/abs/1804.07461&quot;>;QNLI&lt;/a>; (&lt;strong>;bottom row&lt;/strong>;) on 1-shot PaLM 2-S. Each axis indicates the LLM score on the defined label.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Robustness and ablation studies&lt;/h2>; &lt;p>; We analyze the robustness of BC with respect to common prompt engineering design choices that were previously shown to significantly affect LLM performance: choices and orders of in-context examples, the prompt template for ICL, and the label space. First, we find that BC is more robust to ICL choices and can mostly achieve the same performance with different ICL examples. Additionally, given a single set of ICL shots, altering the order between each ICL example has minimal impact on the BC performance. Furthermore, we analyze the robustness of BC under 10 designs of prompt templates, where BC shows consistent improvement over the ICL baseline. Therefore, though BC improves performance, a well-designed template can further enhance the performance of BC. Lastly, we examine the robustness of BC to variations in label space designs (see appendix &lt;a href=&quot;https://arxiv.org/abs/2309.17249&quot;>;in our paper&lt;/a>;). Remarkably, even when employing unconventional choices such as emoji pairs as labels, leading to dramatic oscillations of ICL performance, BC largely recovers performance. This observation demonstrates that BC increases the robustness of LLM predictions under common prompt design choices and makes prompt engineering easier. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEje_sLla9vvNG-zGdTd7j4kVQponyMZQ-_SXJVua50uisPpP6Vp0y1WMmMDUiFNufrKRCR2UdtYbdd0l5XDXyJI8kFBOx5FLuYtF8XmFpeGPsHfVVpUC-1aw0QIYs6nos8veCYdjJMQ-vX9d6a2OylTf3z8-F6FaBoNscIvC7hxf1isKO57csItgvzOTgET/s785 /image4.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;703&quot; data-original-width=&quot;785&quot; height=&quot; 358&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEje_sLla9vvNG-zGdTd7j4kVQponyMZQ-_SXJVua50uisPpP6Vp0y1WMmMDUiFNufrKRCR2UdtYbdd0l5XDXyJI8kFBOx5FLuYtF8XmFpeGPsHfVVpUC-1aw0QIYs6nos8veCYdjJMQ-vX9d6a2OylTf3z8-F6FaBoNscIvC7hxf1isKO57csItgvzOTgET/w400-h358/image4.png&quot; width=&quot;400&quot; />;&lt;/ a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Batch Calibration makes prompt engineering easier while being data-efficient. Data are visualized as a standard &lt;a href=&quot;https://en.wikipedia.org/wiki/Box_plot&quot;>;box plot&lt;/a>;, which illustrates values for the median, first and third quartiles, and minimum and maximum.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;p>; Moreover, we study the impact of batch size on the performance of BC. In contrast to PC, which also leverages an unlabeled estimate set, BC is remarkably more sample efficient, achieving a strong performance with only around 10 unlabeled samples, whereas PC requires more than 500 unlabeled samples before its performance stabilizes. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEirFWtQYRsULQPGbTFS_ACr2xvyHcv6EuSo9267r4cyX7Im7TFcFBlaDQNBXI_TBWThkqKXR4mvRncG2rEgJnvlaa6WQivBgi5TX6xQ_Xq1Y81nfhdlKGm-b8B6jBgWBB8zxhk_Vnu48TJpuv6_fc_cUfxykC9T63XlFXX0V7hE7gJ5molSshIMQLqIVnIZ/s790/image2.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;479&quot; data-original-width=&quot;790&quot; height=&quot;243&quot; src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEirFWtQYRsULQPGbTFS_ACr2xvyHcv6EuSo9267r4cyX7Im7TFcFBlaDQNBXI_TBWThkqKXR4mvRncG2rEgJnvlaa6WQivBgi5TX6xQ_Xq1Y81nfhdlKGm-b8B6jBgWBB8zxhk_Vnu48TJpuv6_fc_cUfxykC9T63XlFXX0V7hE7gJ5molSshIMQLqIVnIZ/w400-h243/image2.png&quot; width=&quot;400&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Batch Calibration makes prompt engineering easier while being insensitive to the batch size.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;div style =&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Conclusion&lt;/h2>; &lt;p>; We first revisit previous calibration methods while addressing two critical research questions from an interpretation of decision boundaries, revealing their failure cases and deficiencies. We then propose Batch Calibration, a zero-shot and inference-only calibration technique. While methodologically simple and easy to implement with negligible computation cost, we show that BC scales from a language-only setup to the vision-language context, achieving state-of-the-art performance in both modalities. BC significantly improves the robustness of LLMs with respect to prompt designs, and we expect easy prompt engineering with BC. &lt;/p>; &lt;div style=&quot;line-height: 40%;&quot;>; &lt;br />; &lt;/div>; &lt;h2>;Acknowledgements&lt;/h2>; &lt;p>; &lt;em>;This work was conducted by Han Zhou, Xingchen Wan, Lev Proleev, Diana Mincu, Jilin Chen, Katherine Heller, Subhrajit Roy. We would like to thank Mohammad Havaei and other colleagues at Google Research for their discussion and feedback.&lt;/em>; &lt;/p>; &lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/1355231158088692780/ comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/batch-calibration-rethinking ã€‚ 1355231158088692780&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/1355231158088692780&quot; rel=&quot;self&quot; type= &quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research.google/2023/10/batch-calibration-rethinking.html&quot; rel=&quot;alternate&quot; title=&quot;Batch calibration: Rethinking calibration for in-context learning and prompt engineering&quot; type=&quot;text/html&quot;/>;&lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt; email>;noreply@blogger.com&lt;/email>;&lt;gd:image height=&quot;16&quot; rel=&quot;http://schemas.google.com/g/2005#thumbnail&quot; src=&quot;https://img1.blogblog. com/img/b16-rounded.gif&quot; width=&quot;16&quot;>;&lt;/gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/ b/R29vZ2xl/AVvXsEhcUnpQACR3ZhIfLnnazC6jATK0TZkwm-zGcHW0iMGYkd5bOrHtp0UAzDZ51hkI-ZesK4PAW_zn29G7r9hnq6bsNrp54dCEoiinN7l2bkNkIZVOj18ym1WQBk4QZfB_LlJnImIms-LSh6E88bcDP6NZ3yDssRhyJGUFgt2IhZurObVP8jn3Bb4aiAnB_Ysg/s72-c/Screenshot%202023-10-13%20at%2010.57.44%20AM.png&quot; width=&quot;72&quot; xmlns:media=&quot;http://search. yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry>;&lt;entry>;&lt;id>;tag:blogger.com,1999:blog-8474926331452026626.post- 56830389427789775&lt;/id>;&lt;published>;2023-10-12T13:56:00.002-07:00&lt;/published>;&lt;updated>;2023-10-12T14:54:51.773-07:00&lt;/updated>;&lt;category scheme=&quot; http://www.blogger.com/atom/ns#&quot; term=&quot;Chemistry&quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Quantum AI &quot;>;&lt;/category>;&lt;category scheme=&quot;http://www.blogger.com/atom/ns#&quot; term=&quot;Quantum Computing&quot;>;&lt;/category>;&lt;title type=&quot;text&quot;>;Developing industrial use cases for physical simulation on future error-corrected quantum computers&lt;/stitle>;&lt;content type=&quot;html&quot;>;&lt;span class=&quot;byline-author&quot;>;Posted by Nicholas Rubin, Senior Research Scientist, and Ryan Babbush, Head of Quantum Algorithms, Quantum AI Team &lt;/span>; &lt;img src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigr1Q582VTmDaeIOT7X-hnXjEJ8QW237xvxICJqe-ZKg2zBAQn9gPfoAbLsJXmG8IFQ5B0ysoh7O60-U4mMKA4mJxB92Tm5MnY50n8B7dWpHwap3lk9_at6c4oEZ0lqjpeS-sqRZyKdyu1UjzJkbb2zRJp9nsZvkikxlK0eTZBjB5hJqvOtbaFPyWe7OfF/s1000/StoppingPower.jpg&quot; style=&quot;display: none; â€ />; &lt;p>; If you&#39;ve paid attention to the quantum computing space, you&#39;ve heard the claim that in the future, quantum computers will solve certain problems exponentially more efficiently than classical computers can. They have the potential to transform many industries, from pharmaceuticals to energy. &lt;/p>; &lt;a name=&#39;more&#39;>;&lt;/a>; &lt;p>; For the most part, these claims have rested on arguments about the asymptotic scaling of algorithms as the problem size approaches infinity, but this tells us very little about the practical performance of quantum computers for finite-sized problems. We want to be more concrete: Exactly which problems are quantum computers more suited to tackle than their classical counterparts, and exactly what quantum algorithms could we run to solve these problems? Once we&#39;ve designed an algorithm, we can go beyond analysis based on asymptotic scaling â€” we can determine the actual resources required to compile and run the algorithm on a quantum computer, and how that compares to a classical computation. &lt;/p>; &lt;p>; Over the last few years, &lt;a href=&quot;https://quantumai.google/&quot;>;Google Quantum AI&lt;/a>; has collaborated with industry and academic partners to assess the prospects for quantum simulation to revolutionize specific technologies and perform concrete analyses of the resource requirements. In 2022, we developed quantum algorithms to analyze the chemistry of an important enzyme family called &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4093435/&quot;>;cytochrome P450&lt;/a>; ã€‚ Then, in &lt;a href=&quot;https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.040303&quot;>;our paper&lt;/a>; released this fall, we demonstrated how to use a quantum computer to study sustainable alternatives to cobalt for use in lithium ion batteries. And most recently, as we report in a preprint titled â€œ&lt;a href=&quot;https://arxiv.org/abs/2308.12352v1&quot;>;Quantum computation of stopping power for inertial fusion target design&lt;/a>;,â€ we&#39;ve found a new application in modeling the properties of materials in inertial confinement fusion experiments, such as those at the &lt;a href=&quot;https://lasers.llnl.gov/&quot;>;National Ignition Facility&lt;/a>; (NIF) at&lt;a href=&quot;https://www.llnl.gov/&quot;>; Lawrence Livermore National Laboratory&lt;/a>;, which recently &lt;a href=&quot;https://www.nytimes.com/2022/12/13/science/nuclear-fusion-energy-breakthrough.html&quot;>;made headlines&lt;/a>; for a breakthrough in nuclear fusion. &lt;/p>; &lt;p>; Below, we describe these three industrially relevant applications for simulations with quantum computers. While running the algorithms will require an error-corrected quantum computer, which is &lt;a href=&quot;https://blog.research.google/2023/02/suppressing-quantum-errors-by-scaling.html?m=1&quot;>;still years away&lt;/a>;, working on this now will ensure that we are ready with efficient quantum algorithms when such a quantum computer is built. Already, our work has reduced the cost of compiling and running the algorithms significantly, as we &lt;a href=&quot;https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.030305&quot;>;have&lt;/a>; &lt;a href=&quot;https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.040332&quot;>;reported&lt;/a>; in the past. Our work is essential for demonstrating the potential of quantum computing, but it also provides our hardware team with target specifications for the number of qubits and time needed to run useful quantum algorithms in the future. &lt;/p>; &lt;br />; &lt;h2>;Application 1: The CYP450 mechanism&lt;/h2>; &lt;p>; The pharmaceutical industry is often touted as a field ripe for discovery using quantum computers. But concrete examples of such potential applications are few and far between. Working with collaborators at the pharmaceutical company &lt;a href=&quot;https://www.boehringer-ingelheim.com/&quot;>;Boehringer Ingelheim&lt;/a>;, our partners at the startup &lt;a href=&quot;https://qsimulate.com/&quot;>;QSimulate&lt;/a>;, and academic colleagues at &lt;a href=&quot;https://www.columbia.edu/&quot;>;Columbia University&lt;/a>;, we explored one example in the 2022 &lt;em>;&lt;a href=&quot;https://www.pnas.org/&quot;>;PNAS&lt;/a>;&lt;/em>; article, â€œ&lt;a href=&quot;https://www.pnas.org/doi/10.1073/pnas.2203533119&quot;>;Reliably assessing the electronic structure of cytochrome P450 on today&#39;s classical computers and tomorrow&#39;s quantum computers&lt;/a>;â€. &lt;/p>; &lt;p>; Cytochrome P450 is an enzyme family naturally found in humans that helps us metabolize drugs. It excels at its job: more than 70% of all drug metabolism is performed by enzymes of the P450 family. The enzymes work by oxidizing the drug â€” a process that depends on complex correlations between electrons. The details of the interactions are too complicated for scientists to know &lt;em>;a priori&lt;/em>; how effective the enzyme will be on a particular drug. &lt;/p>; &lt;p>; In the &lt;a href=&quot;https://www.pnas.org/doi/10.1073/pnas.2203533119&quot;>;paper&lt;/a>;, we showed how a quantum computer could approach this problem. The CYP450 metabolic process is a complex chain of reactions with many intermediate changes in the electronic structure of the enzymes throughout. We first use state-of-the-art classical methods to determine the resources required to simulate this problem on a classical computer. Then we imagine implementing a phase-estimation algorithm â€” which is needed to compute the ground-state energies of the relevant electronic configurations throughout the reaction chain â€” on a &lt;a href=&quot;https://blog.research.google/2023/02/suppressing-quantum-errors-by-scaling.html&quot;>;surface-code error-corrected quantum computer&lt;/a>;. &lt;/p>; &lt;p>; With a quantum computer, we could follow the chain of changing electronic structure with greater accuracy and fewer resources. In fact, we find that the higher accuracy offered by a quantum computer is needed to correctly resolve the chemistry in this system, so not only will a quantum computer be better, it will be necessary. And as the system size gets bigger, ie, the more quantum energy levels we include in the simulation, the more the quantum computer wins over the classical computer. Ultimately, we show that a few million physical qubits would be required to reach &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantum_supremacy&quot;>;quantum advantage&lt;/a>; for this problem. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimUWf0soJPXwDCKwwl3b46rIeysW0V9fbV_5m-oKpfZpjscw8Xo4LyI0smpSLDFQ8LOIcEFOXotDKsXvOsRkXP9BjuUhvY_ic36EG2izNuRPujdr_50wcv-GoAYR2JJh4AcmhJj6f9OfTFY_q0UyuK9hJP79QKkskP9iewyBx0FpK0-4FDjakrHLZZZZrt/s1999/image3.png &quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;869&quot; data-original-width=&quot;1999&quot; src=&quot;https:// blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimUWf0soJPXwDCKwwl3b46rIeysW0V9fbV_5m-oKpfZpjscw8Xo4LyI0smpSLDFQ8LOIcEFOXotDKsXvOsRkXP9BjuUhvY_ic36EG2izNuRPujdr_50wcv-GoAYR2JJh4AcmhJj6f9OfTFY_q0UyuK9hJP79QKkskP9iewyBx0FpK0-4FDjakrHLZZZZrt/s16000/image3.png&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class=&quot;tr- caption&quot; style=&quot;text-align: center;&quot;>;&lt;b>;Left:&lt;/b>; Example of an electron orbital (red and blue) of a CYP enzyme. More than 60 such orbitals are required to model the CYP system. &lt;b>;Right:&lt;/b>; Comparison of actual runtime (CPU) of various classical techniques (blue) to hypothetical runtime (QPU) of a quantum algorithm (green). The lower slope of the quantum algorithm demonstrates the favorable asymptotic scaling over classical methods. Already at about 20-30 orbitals, we see a crossover to the regime where a quantum algorithm would be more efficient than classical methods.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;h2>;Application 2: Lithium-ion batteries&lt;/h2>; &lt;p>; Lithium-ion batteries rely on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Electrochemical_potential&quot;>;electrochemical potential&lt;/a>; difference between two lithium containing materials. One material used today for the cathodes of Li-ion batteries is LiCoO&lt;sub>;2&lt;/sub>;. Unfortunately, it has drawbacks from a manufacturing perspective. Cobalt mining is expensive, &lt;a href=&quot;https://earth.org/cobalt-mining-in-congo&quot;>;destructive to the environment&lt;/a>;, and often utilizes &lt;a href=&quot;https://www.npr.org/sections/goatsandsoda/2023/02/01/1152893248/red-cobalt-congo-drc-mining-siddharth-kara&quot;>;unsafe or abusive labor practices&lt;/a>;. Consequently, many in the field are interested in alternatives to cobalt for lithium-ion cathodes. &lt;/p>; &lt;p>; In the 1990&#39;s, researchers discovered that nickel could replace cobalt to form LiNiO&lt;sub>;2&lt;/sub>; (called â€œlithium nickel oxideâ€ or â€œLNOâ€) for cathodes. While pure LNO was found to be unstable in production, many cathode materials used in the automotive industry today use a high fraction of nickel and hence, resemble LNO. Despite its applications to industry, however, not all of the chemical properties of LNO are understood â€” even the properties of its ground state remains a subject of debate. &lt;/p>; &lt;p>; In our recent paper, â€œ&lt;a href=&quot;https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.040303&quot;>;Fault tolerant quantum simulation of materials using Bloch orbitals&lt;/a>;,â€ we worked with the chemical company, &lt;a href=&quot;https://www.basf.com/us/en/who-we-are/change-for-climate.html&quot;>;BASF&lt;/a>;, the molecular modeling startup, QSimulate, and &lt;a href=&quot;https://researchers.mq.edu.au/en/persons/dominic-berry&quot;>;collaborators at Macquarie University&lt;/a>; in Australia to develop techniques to perform quantum simulations on systems with periodic, regularly spaced atomic structure, such as LNO. We then applied these techniques to design algorithms to study the relative energies of a few different candidate structures of LNO. With classical computers, high accuracy simulations of the quantum wavefunction are considered too expensive to perform. In our work, we found that a quantum computer would need tens of millions of physical qubits to calculate the energies of each of the four candidate ground-state LNO structures. This is out of reach of the first error-corrected quantum computers, but we expect this number to come down with future algorithmic improvements. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5aLU-bNmekPT3q2j2ePYkBdvfoZqs2bBp12TC1At6QK0YFD10laEJc2gJ7XA9HQwTKnfSP35o4zLDiSbnRAapqNWNRMOSWOAIQjoI2YVROMLM8rYpa6UGH1vNICKdvFGh6anjk5F10d1gc4_7_guWBwYbzs78hdfudj77ytUgqP_7Ep9KPzRwwRzCIGeb/s1364/image3.jpg&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;763&quot; data-original-width=&quot;1364&quot; height=&quot;358&quot; src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5aLU-bNmekPT3q2j2ePYkBdvfoZqs2bBp12TC1At6QK0YFD10laEJc2gJ7XA9HQwTKnfSP35o4zLDiSbnRAapqNWNRMOSWOAIQjoI2YVROMLM8rYpa6UGH1vNICKdvFGh6anjk5F10d1gc4_7_guWBwYbzs78hdfudj77ytUgqP_7Ep9KPzRwwRzCIGeb/w640-h358/image3.jpg&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;Four candidate structures of LNO. In the paper, we consider the resources required to compare the energies of these structures in order to find the ground state of LNO.&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;h2>;Application 3: Fusion reactor dynamics&lt;/h2>; &lt;p>; In our third and most recent example, we collaborated with theorists at &lt;a href=&quot;https://www.sandia.gov/&quot;>;Sandia National Laboratories&lt;/a>; and our Macquarie University collaborators to put our hypothetical quantum computer to the task of simulating dynamics of charged particles in the extreme conditions typical of &lt;a href=&quot;https://en.wikipedia.org/wiki/Inertial_confinement_fusion&quot;>;inertial confinement fusion&lt;/a>; (ICF) experiments, like those at the National Ignition Facility. In those experiments, high-intensity lasers are focused into a metallic cavity (&lt;a href=&quot;https://en.wikipedia.org/wiki/Hohlraum&quot;>;hohlraum&lt;/a>;) that holds a target capsule consisting of an ablator surrounding &lt;a href=&quot;https://en.wikipedia.org/wiki/Deuterium%E2%80%93tritium_fusion&quot;>;deuteriumâ€“tritium fuel&lt;/a>;. When the lasers heat the inside of the hohlraum, its walls radiate x-rays that compress the capsule, heating the deuterium and tritium inside to 10s of millions of Kelvin. This allows the nucleons in the fuel to overcome their &lt;a href=&quot;https://en.wikipedia.org/wiki/Coulomb_barrier&quot;>;mutual electrostatic repulsion&lt;/a>; and start fusing into helium nuclei, also called &lt;a href=&quot;https://en.wikipedia.org/wiki/Alpha_particle&quot;>;alpha particles&lt;/a>;. &lt;/p>; &lt;p>; Simulations of these experiments are computationally demanding and rely on models of material properties that are themselves uncertain. Even testing these models, using methods similar to those in quantum chemistry, is extremely computationally expensive. In some cases, such test calculations have consumed &amp;gt;100 million CPU hours. One of the most expensive and least accurate aspects of the simulation is the dynamics of the plasma prior to the sustained fusion stage (&amp;gt;10s of millions of Kelvin), when parts of the capsule and fuel are a more balmy 100k Kelvin. In this â€œwarm dense matterâ€ regime, quantum correlations play a larger role in the behavior of the system than in the â€œhot dense matterâ€ regime when sustained fusion takes place. &lt;/p>; &lt;p>; In our new preprint, â€œ&lt;a href=&quot;https://arxiv.org/abs/2308.12352v1&quot;>;Quantum computation of stopping power for inertial fusion target design&lt;/a>;â€, we present a quantum algorithm to compute the so-called â€œstopping powerâ€ of the warm dense matter in a nuclear fusion experiment. The stopping power is the rate at which a high energy alpha particle slows down due to &lt;a href=&quot;https://en.wikipedia.org/wiki/Coulomb%27s_law&quot;>;Coulomb interactions&lt;/a>; with the surrounding plasma. Understanding the stopping power of the system is vital for optimizing the efficiency of the reactor. As the alpha particle is slowed by the plasma around it, it transfers its energy to the plasma, heating it up. This self-heating process is the mechanism by which fusion reactions sustain the burning plasma. Detailed modeling of this process will help inform future reactor designs. &lt;/p>; &lt;p>; We estimate that the quantum algorithm needed to calculate the stopping power would require resources somewhere between the P450 application and the battery application. But since this is the first case study on first-principles dynamics (or any application at finite temperature), such estimates are just a starting point and we again expect to find algorithmic improvements to bring this cost down in the future. Despite this uncertainty, it is still certainly better than the classical alternative, for which the only tractable approaches for these simulations are &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean-field_theory&quot;>;mean-field methods &lt;/a>;ã€‚ While these methods incur unknown systematic errors when describing the physics of these systems, they are currently the only meaningful means of performing such simulations. &lt;/p>; &lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;>;&lt;tbody>; &lt;tr>;&lt;td style=&quot;text-align: center;&quot;>;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgBtVt_flUA0xvpBirTdVvlwHewAPQs6z_7fZM4dj6AwdGlrUQg0w4izYIR-vXl_qMr_EUn91KGwXFdgJgbgPT66cFU9nepPbP4SSIhHQz8RJptKV0I0r98sjCCqiKZDUPgoVyEuO3CM2cRMcnA32dX2dXbbRAsHt5FKrVOgZpWOo5sHgNmiR0YT3DOfByG/s1586/image1.png&quot; style=&quot; margin-left: auto; margin-right: auto;&quot;>;&lt;img border=&quot;0&quot; data-original-height=&quot;712&quot; data-original-width=&quot;1586&quot; height=&quot;287&quot; src=&quot;https:/ /blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgBtVt_flUA0xvpBirTdVvlwHewAPQs6z_7fZM4dj6AwdGlrUQg0w4izYIR-vXl_qMr_EUn91KGwXFdgJgbgPT66cFU9nepPbP4SSIhHQz8RJptKV0I0r98sjCCqiKZDUPgoVyEuO3CM2cRMcnA32dX2dXbbRAsHt5FKrVOgZpWOo5sHgNmiR0YT3DOfByG/w640-h287/image1.png&quot; width=&quot;640&quot; />;&lt;/a>;&lt;/td>;&lt;/tr>;&lt;tr>;&lt;td class =&quot;tr-caption&quot; style=&quot;text-align: center;&quot;>;&lt;b>;Left:&lt;/b>; A projectile (red) passing through a medium (blue) with initial velocity vproj. &lt;b>;Right:&lt;/b>; To calculate the stopping power, we monitor the energy transfer between the projectile and the medium (blue solid line) and determine its average slope (red dashed line).&lt;/td>;&lt;/tr>;&lt;/tbody>;&lt;/table>; &lt;h2>;Discussion and conclusion&lt;/h2>; &lt;p>; The examples described above are just three of a large and growing body of concrete applications for a future error-corrected quantum computer in simulating physical systems. This line of research helps us understand the classes of problems that will most benefit from the power of quantum computing. In particular, the last example is distinct from the other two in that it is simulating a dynamical system. In contrast to the other problems, which focus on finding the lowest energy, static ground state of a quantum system, quantum dynamics is concerned with how a quantum system changes over time. Since quantum computers are inherently dynamic â€” the qubit states evolve and change as each operation is performed â€” they are particularly well suited to solving these kinds of problems. Together with collaborators at Columbia, Harvard, Sandia National Laboratories and Macquarie University in Australia we recently published a paper in Nature Communications &lt;a href=&quot;https://www.nature.com/articles/s41467-023-39024-0&quot;>;demonstrating&lt;/a>; that quantum algorithms for simulating electron dynamics can be more efficient even than approximate, â€œmean-fieldâ€ classical calculations, while simultaneously offering much higher accuracy. &lt;/p>; &lt;p>; Developing and improving algorithms today prepares us to take full advantage of them when an error-corrected quantum computer is eventually realized. Just as in the classical computing case, we expect improvements at every level of the quantum computing stack to further lower the resource requirements. But this first step helps separate hyperbole from genuine applications amenable to quantum computational speedups. &lt;/p>; &lt;br />; &lt;h2>; Acknowledgements&lt;/h2>; &lt;p>;&lt;em>; We would like to thank Katie McCormick, our Quantum Science Communicator, for helping to write this blog post.&lt;/em>;&lt;/p >;&lt;/content>;&lt;link href=&quot;http://blog.research.google/feeds/56830389427789775/comments/default&quot; rel=&quot;replies&quot; title=&quot;Post Comments&quot; type=&quot;application/atom+xml&quot;/>; &lt;link href=&quot;http://blog.research.google/2023/10/developing-industrial-use-cases-for.html#comment-form&quot; rel=&quot;replies&quot; title=&quot;0 Comments&quot; type=&quot;text /html&quot;/>;&lt;link href=&quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/56830389427789775&quot; rel=&quot;edit&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href= &quot;http://www.blogger.com/feeds/8474926331452026626/posts/default/56830389427789775&quot; rel=&quot;self&quot; type=&quot;application/atom+xml&quot;/>;&lt;link href=&quot;http://blog.research. google/2023/10/developing-industrial-use-cases-for.html&quot; rel=&quot;alternate&quot; title=&quot;Developing industrial use cases for physical simulation on future error-corrected quantum computers&quot; type=&quot;text/html&quot;/>; &lt;author>;&lt;name>;Google AI&lt;/name>;&lt;uri>;http://www.blogger.com/profile/12098626514775266161&lt;/uri>;&lt;email>;noreply@blogger.com&lt;/email>;&lt;gd:image height= â€œ16â€rel =â€œhttp://schemas.google.com/g/2005#thumbnailâ€src =â€œhttps://img1.blogblog.com/img/b16-rounded.gifâ€å®½åº¦=â€œ16â€>; &lt; /gd:image>;&lt;/author>;&lt;media:thumbnail height=&quot;72&quot; url=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigr1Q582VTmDaeIOT7X-hnXjEJ8QW237xvxICJqe-ZKg2zBAQn9gPfoAbLsJXmG8IFQ5B0ysoh7O60-U4mMKA4mJxB92Tm5MnY50n8B7dWpHwap3lk9_at6c4oEZ0lqjpeS-sqRZyKdyu1UjzJkbb2zRJp9nsZvkikxlK0eTZBjB5hJqvOtbaFPyWe7OfF/s72-c /StoppingPower.jpg&quot; width=&quot;72&quot; xmlns:media=&quot;http://search.yahoo.com/mrss/&quot;>;&lt;/media:thumbnail>;&lt;thr:total>;0&lt;/thr:total>;&lt;/entry >;&lt;/feed>;